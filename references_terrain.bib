@article{AJOHNSON1972a,
  author  = {David A. Johnson},
  issue   = {October},
  journal = {Geological Society of America Bulletin},
  pages   = {3121--3144},
  title   = {Ocean-Floor Erosion in the Equatorial Pacific},
  volume  = 83,
  year    = 1972
}

@article{Abdel-malek,
  author  = {KARIM ABDEL-MALEK and JINGZHOU YANG and DENIS BLACKMORE and KEN JOY},
  doi     = {10.1142/S0218654306000858},
  issn    = {0218-6543},
  issue   = {01},
  journal = {International Journal of Shape Modeling},
  month   = 6,
  pages   = {87--127},
  title   = {SWEPT VOLUMES: FUNDATION, PERSPECTIVES, AND APPLICATIONS},
  volume  = 12,
  url     = {http://www.worldscientific.com/doi/abs/10.1142/S0218654306000858},
  year    = 2006
}

@article{Abdi2014,
  abstract  = {The effect of topographic features on wind speed and wake turbulence is evaluated by conducting Computational Fluid Dynamics (CFD) simulations using an in-house CFD program that features various turbulence models. The simulation results are assessed by computing Fractional Speed Up Ratio (FSUR) along longitudinal lines at different elevations. Such information is useful for evaluating wind loads on long span structures and micro-siting of wind turbines on complex terrain. Simulations are conducted on both idealized and real topographic features in both 2D and 3D domain. The turbulence structure behind hills is examined using several turbulence models such as the mixing-length, standard k-\ensuremath{\epsilon}, RNG k-\ensuremath{\epsilon}, realizable k-\ensuremath{\epsilon} and Smagorinsky LES models. All turbulence models predicted FSUR values on upstream side of hills adequately; however, the performance of simple turbulence models, such as mixing length, is found to be insufficient for characterizing wakes behind hills. RANS turbulence models gave results close to one another; however, those models that incorporate modifications to account for adverse pressure gradient conditions performed better at wakes behind hills. LES conducted at full scale dimensions, and using wall functions, failed to give results that are comparable to the other turbulence models. Re-conducting the simulations at model scale dimensions, hence at relatively small Reynolds number, and without using wall functions gave results that are comparable to those found in the literature. Therefore, use of wall functions can degrade quality of results in LES of high Reynolds number flows of practical interest. \textcopyright{} 2014 Published by Elsevier Ltd. All rights reserved.},
  author    = {Daniel S. Abdi and Girma T. Bitsuamlak},
  doi       = {10.1016/j.advengsoft.2014.05.002},
  issn      = 18735339,
  journal   = {Advances in Engineering Software},
  keywords  = {Complex terrain,Computational fluid dynamics,FSUR,LES,RANS,Topography,Turbulence models},
  pages     = {30--41},
  publisher = {Elsevier Ltd},
  title     = {Wind flow simulations on idealized and real complex terrain using various turbulence models},
  volume    = 75,
  year      = 2014
}

@inproceedings{Abela2015,
  abstract  = {This paper introduces Coralize, a library of generators for marine organisms such as corals and sponges. Using constructive algorithms, Coralize can generate stony corals via L-system grammars, soft corals via leaf venation algorithms and sponges via nutrient-based mesh growth. The genera-tive algorithms are parameterizable, allowing a user to adjust the parameters in order to create visually appealing 3D meshes. Such meshes can be used to automatically populate a seabed or reef, in order to create a biologically realistic and aesthetically pleasing underwater environment.},
  author    = {Ryan Abela and Antonios Liapis and Georgios N Yannakakis},
  booktitle = {Proceedings of the FDG workshop on Procedural Content Generation in Games},
  title     = {A Constructive Approach for the Generation of Underwater Environments},
  url       = {https://code.google.com/p/lsystems-csharp-lib},
  year      = 2015
}

@article{Abuzuraiq2017,
  abstract = {This paper describes an algorithm to solve the problem of partitioning a planar graph with a constraint on which partitions should be adjacent or nonadjacent. We explore the applications of the algorithm in Procedural Content Generation in games which includes: The generation of political maps, distribution of terrain and converting or linking Mission Graphs to game spaces. We solve this problem using A-Star search with a heuristic for measuring graphs similarity and we suggest techniques such as graph coarsening to limit the search space. The algorithm sensitivity to the initial state is analyzed next and a restart policy is suggested to overcome that. Additionally, we present multiple constraints that can aid in better controlling the outcomes of the algorithm and we show how these constraints can help in the implementation of the displayed applications.},
  author   = {Ahmed M. Abuzuraiq},
  doi      = {10.1145/3102071.3110575},
  isbn     = 9781450353199,
  journal  = {ACM International Conference Proceeding Series},
  keywords = {A-Star Search,Games,Graph Coarsening,Graph Isomorphism,Graph Partitioning,Isospectrality,Mission Graph,Political Maps,Procedural Content Generation,Quotient Graph,Restart Policy},
  pages    = {1--10},
  title    = {On using graph partitioning with isomorphism constraint in procedural content generation},
  volume   = {Part F1301},
  year     = 2017
}

@article{Adams2002a,
  abstract = {The genre of dungeon games, or first-person shooter games as they are more commonly known, has emerged over the last ten years to become one of the most popular types of computer game. At present, the levels in this type of game are generated manually, which is a very expensive and time-consuming process for games companies. If levels could be generated automatically then this would not only reduce development costs, but allow levels to be generated at run-time, giving game players a new playing experience each time a game was played and greatly improving the replayability of the game. In this project, a technique known as graph grammars will be used in order to allow descriptions of randomly generated game levels to be created automatically. As part of the project, algorithms to assess the size, difficulty and fun-value of a level will be developed, to allow individual levels to be tailored to particular requirements. This project is being undertaken in cooperation with Infogrames.},
  author   = {David Adams},
  pages    = 60,
  title    = {Automatic Generation of Dungeons for Computer Games},
  url      = {http://www.dcs.shef.ac.uk/intranet/teaching/public/projects/archive/ug2002/pdf/u9da.pdf},
  year     = 2002
}

@article{Ahronovitz1999,
  abstract = {The Topological Graph of Frontiers is in our opinion a good graph structure representing the topology of segmented images. In this paper we deal with topological operators which achieve directly on the graph current operations performed on segmented images. Well known graph structures such as the Region Adjacency Graph [Pav77] [Ros74] do not (and cannot) keep track of the topology and so cannot maintain it. We claim that the structures and operators described here, on the contrary, allow and do this maintenance. One of the most important informations in such images is the inclusion of nested regions and one of the most important operators is the union of regions. We deal essentially with these in this paper. They are described in detail herein and we show how the topological coherence is maintained. This is why we entitle them topological operators. Other operators that we have already developed are briefly described.},
  author   = {Ehoud Ahronovitz and Christophe Fiorio and Sylvain Glaize},
  doi      = {10.1007/3-540-49126-0\_16},
  isbn     = 3540656855,
  issn     = 16113349,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Enclosed region,Segmented image manipulation,Topological graph of frontiers,Topological operator,Topological representation},
  pages    = {207--217},
  title    = {Topological operators on the topological graph of frontiers},
  volume   = 1568,
  url      = {https://link.springer.com/content/pdf/10.1007/3-540-49126-0\_16.pdf},
  year     = 1999
}

@inproceedings{Akleman,
  author    = {E Akleman},
  booktitle = {Proc. of CSG},
  pages     = {1--15},
  title     = {Implicit painting of CSG solids},
  url       = {http://people.tamu.edu/~ergun/research/artisticdepiction/papers/csg98.pdf},
  year      = 1998
}

@article{Akleman1998,
  abstract = {Implicit painting is a non-photorealistic rendering method for painting\nimplicit surfaces. The method is based on the fact that when a difference\nequation is applied to a set of particles, these particles will move\nin 3D space. The motion of the particles is viewed as the motion\nof the hands of several painters and the trajectories of the particles\nas long unbroken brush strokes, over the implicit surfaces. These\nsurfaces are used as if they are the canvases of painters. We consider\nimplicit surface painting as a creative or `artistic' process in\nwhich the resulting artwork can be an image, a stereo image or even\nan animation that shows the painting process.},
  author   = {Ergun Akleman},
  journal  = {Proceedings of the Third International Eurographics/ACM SIGGRAPH Workshop on Implicit Surfaces 1998 (IS'98, June 15--16, 1998,Seattle, USA)},
  pages    = {63--68},
  title    = {Implicit Surface Painting},
  url      = {http://www-viz.tamu.edu/faculty/ergun/research/artisticdepiction/implicitpaint/},
  year     = 1998
}

@article{Alexa2002,
  abstract = {Meshes have become a widespread and popular representation of models in computer graphics. Morphing techniques aim at transforming a given source shape into a target shape. Morphing techniques have various applications ranging from special effects in television and movies to medical imaging and scientific visualization. Not surprisingly, morphing techniques for meshes have received a lot of interest lately. This work sums up recent developments in the area of mesh morphing. It presents a consistent framework to classify and compare various techniques approaching the same underlying problems from different angles.},
  author   = {Marc Alexa},
  doi      = {10.1111/1467-8659.00575},
  issn     = {01677055},
  issue    = 2,
  journal  = {Computer Graphics Forum},
  pages    = {173--198},
  title    = {Recent advances in mesh morphing},
  volume   = 21,
  year     = 2002
}

@article{Allegre2009,
  abstract = {This thesis deals with geometric modeling of complex 3D free-form shapes. In the context of the Art3D project (ACI Masses de Donn\'{e}es), we have investigated two research directions related to the representation of digitized objects, with a flexibility goal : dynamic surface reconstruction and multirepresentation modeling. In the first part of the thesis, we introduce a flexible combinatorial approach to surface reconstruction that makes it possible to directly generate a simplified triangulated surface from a dense input point set. The reconstructed surface can be next locally refined or coarsened in a dynamic fashion. The second part presents a hybrid modeling framework for creating complex shapes from scanned models or simple primitives. We have developed an extended CSG tree that mixes implicit surfaces, polygonal meshes, and point set models in a coherent fashion.},
  author   = {R\'{e}mi All\`{e}gre},
  journal  = {Recherche},
  pages    = {2009--2010},
  title    = {Contributions \`{a} l'introduction de flexibilit\'{e} dans la reconstruction et l'\'{e}dition de mod\`{e}les 3D},
  volume   = 1,
  url      = {https://perso.liris.cnrs.fr/raphaelle.chaine/DOCUMENTS/these\_Remi\_Allegre\_2006.pdf},
  year     = 2009
}

@article{Allemand2008,
  author  = {Denis Allemand},
  journal = {ocean-climate.org},
  pages   = {73--79},
  title   = {Coral Reefs and Climate Change},
  url     = {https://ocean-climate.org/wp-content/uploads/2017/03/coral-reefs\_07-12.pdf},
  year    = 2008
}

@article{Alonso2023,
  abstract  = {We present a novel proposal for modeling complex dynamic terrains that offers real-time rendering, dynamic updates and physical interaction of entities simultaneously. We can capture any feature from landscapes including tunnels, overhangs and caves, and we can conduct a total destruction of the terrain. Our approach is based on a Constructive Solid Geometry tree, where a set of spheres are subtracted from a base Digital Elevation Model. Erosions on terrain are easily and efficiently carried out with a spherical sculpting tool with pixel-perfect accuracy. Real-time rendering performance is achieved by applying a one-direction CPU–GPU communication strategy and using the standard depth and stencil buffer functionalities provided by any graphics processor.},
  author    = {Jes\'{u}s Alonso and Robert Joan-Arinyo and Antoni Chica},
  doi       = {10.1016/j.cag.2023.06.019},
  issn      = {00978493},
  journal   = {Computers and Graphics (Pergamon)},
  keywords  = {CSG,Terrain erosion,Terrain modeling},
  month     = 8,
  pages     = {306--315},
  publisher = {Elsevier Ltd},
  title     = {Real-time rendering and physics of complex dynamic terrains modeled as CSG trees of DEMs carved with spheres},
  volume    = 114,
  year      = 2023
}

@article{Alt1996,
  abstract = {In this chapter we survey geometric techniques which have been used to measure the sim- ilarity or distance between shapes, as well as to approximate shapes, or interpolate between shapes. Shape is a modality which plays a key role in many disciplines, ranging from com- puter vision to molecular biology. We focus on algorithmic techniques based on computational geometry that have been developed for shape matching, simplification, and morphing.},
  author   = {Helmut Alt and Leonidas J. Guibas},
  isbn     = {978-0-44-482537-7},
  issue    = {MARCH 1997},
  journal  = {Handbook of computational geometry},
  pages    = {1--34},
  title    = {Discrete Geometric Shapes: Matching, Interpolation, and Approximation},
  url      = {http://books.google.com/books?hl=en\&lr=\&id=uZdAqAWB3BcC\&oi=fnd\&pg=PA121\&dq=Discrete+Geometric+Shapes:+Matching,+Interpolation,+and+Approximation\&ots=lEx\_DDwLMF\&sig=xPC67HoYTYvLgSKz-t-E7XBJUbg},
  year     = 1996
}

@article{AmEnde2001,
  abstract = {Wakulla Springs-a group of deep, underground, water-filled caves south of Tallahassee, FL, USA-is an example where mapping has proved challenging. The Wakulla 2 expedition of the US Deep Caving Team Inc. had one primary goal-to automatically build the first fully 3D cave map. To make the map, divers had to survive the hostile environment. The divers' attention mostly focuses on staying alive, so the more automatic the surveying, the better. The critical piece of equipment for the Wakulla 2 expedition was the Digital Wall Mapper (DWM). The device was designed specifically for the project to gather survey data to make the 3D map. 32 sonar transducers were spirally arrayed around the nose of the 2-m long, 150-kg instrument. Thus, four times a second, the DWM sends and receives 32 equally spaced radial readings. The distance to the walls was important but not useful unless we knew the DWM's exact position and orientation. To record this information, we used an inertial measurement unit (IMU), which is located in the center of the DWM},
  author   = {B.A. am Ende},
  doi      = {10.1109/38.909011},
  issn     = {02721716},
  issue    = 2,
  journal  = {IEEE Computer Graphics and Applications},
  pages    = {14--20},
  title    = {3D mapping of underwater caves},
  volume   = 21,
  year     = 2001
}

@article{Anagha2019,
  abstract = {Last decade has been witnessed for the dramatic advancement in computer games. Latest studies shows that procedurally generated content makes the players remain engaged for a long time. Incorporating the user's preferences and creativity in the games is still a challenging task. In this paper, we focus on the diversity of terrain generation in terms of its components. Personalization of user experience via effective modeling, combined with real-time adjustment of the content helps for meaningful content generation. Our engine accepts input from the user in Terrain development language (TDL).The user has to specify the type and features of the terrain. The engine extracts features through Terrain Development Algorithm (TDA) and generates individual components according to the information. The end result is to provide a user skill-matched terrain, which can be rendered for various games.},
  author   = {C. Anagha Zachariah and G. Pankaj Kumar and D. R. Umesh and M. N. Arun Kumar},
  doi      = {10.35940/ijrte.C6425.098319},
  issn     = 22773878,
  issue    = 3,
  journal  = {International Journal of Recent Technology and Engineering},
  keywords = {Cellular automata,Terrain development algorithm,Terrain language},
  pages    = {8041--8045},
  title    = {Terrain generation from user text using cellular automata},
  volume   = 8,
  url      = {https://www.ijrte.org/wp-content/uploads/papers/v8i3/C6425098319.pdf},
  year     = 2019
}

@article{Andereck2014,
  abstract = {Procedural terrain generation is a highly popular topic in computer science today with applications in video games, medical rehabilitation, land planning, and even military training. Many algorithms exist to create these terrains including fractal designs, physical simulations, and applying real-world data. These systems offer various levels of interactivity and user control. We introduce a constraint-based system for procedurally generating virtual terrains. The first constraint is based on user-designed paths which can be customized for the various needs of patients experiencing medical rehabilitation. Due to the specific needs of this application, we require that our terrain shape should not manipulate the heights specified by these paths. Additional constraints may be applied from real-world data, user-painted heights, and tile borders. Given a set of constraints our generative algorithm iteratively finds the best fitting terrain shape, interpolating between and beyond the specified points. With a combination of user interaction and faithful fitting of data, our algorithm provides a more friendly system for constrained virtual terrain generation.},
  author   = {Micheal Andereck},
  title    = {Procedural Terrain Generation Based on Constraint Paths},
  url      = {https://etd.ohiolink.edu/!etd.send\_file?accession=osu1388357258\&disposition=attachment},
  year     = 2014
}

@misc{Andric2009,
  author = {Jelena Andric},
  issue  = {December},
  title  = {Lagrangian Particle Tracking},
  url    = {https://www.tfd.chalmers.se/~hani/kurser/OS\_CFD\_2009/JelenaAndric/presentationJelenaAndric.pdf},
  year   = 2009
}

@article{Angles2017,
  abstract = {<p>Implicit models can be combined by using composition operators; functions that determine the resulting shape. Recently, gradient-based composition operators have been used to express a variety of behaviours including smooth transitions, sharp edges, contact surfaces, bulging, or any combinations. The problem for designers is that building new operators is a complex task that requires specialized technical knowledge. In this work, we introduce an automatic method for deriving a gradient-based implicit operator from 2D drawings that prototype the intended visual behaviour. To solve this inverse problem, in which a shape defines a function, we introduce a general template for implicit operators. A user's sketch is interpreted as samples in the 3D operator's domain. We fit the template to the samples with a non-rigid registration approach. The process works at interactive rates and can accommodate successive refinements by the user. The final result can be applied to 3D surfaces as well as to 2D shapes. Our method is able to replicate the effect of any blending operator presented in the literature, as well as generating new ones such as non-commutative operators. We demonstrate the usability of our method with examples in font-design, collision-response modeling, implicit skinning, and complex shape design.</p>},
  author   = {Baptiste Angles and Marco Tarini and Brian Wyvill and Lo\"{\i}c Barthe and Andrea Tagliasacchi},
  doi      = {10.1145/3130800.3130825},
  issn     = {0730-0301},
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  month    = 12,
  pages    = {1--13},
  title    = {Sketch-based implicit blending},
  volume   = 36,
  url      = {https://dl.acm.org/doi/10.1145/3130800.3130825},
  year     = 2017
}

@article{Annegarn2012,
  abstract  = {Background: To date, detailed analyses of walking patterns using accelerometers during the 6-min walk test (6MWT) have not been performed in patients with chronic obstructive pulmonary disease (COPD). Therefore, it remains unclear whether and to what extent COPD patients have an altered walking pattern during the 6MWT compared to healthy elderly subjects. Methodology/Principal Findings: 79 COPD patients and 24 healthy elderly subjects performed the 6MWT wearing an accelerometer attached to the trunk. The accelerometer features (walking intensity, cadence, and walking variability) and subject characteristics were assessed and compared between groups. Moreover, associations were sought with 6-min walk distance (6MWD) using multiple ordinary least squares (OLS) regression models. COPD patients walked with a significantly lower walking intensity, lower cadence and increased walking variability compared to healthy subjects. Walking intensity and height were the only two significant determinants of 6MWD in healthy subjects, explaining 85\% of the variance in 6MWD. In COPD patients also age, cadence, walking variability measures and their interactions were included were significant determinants of 6MWD (total variance in 6MWD explained: 88\%). Conclusions/Significance: COPD patients have an altered walking pattern during 6MWT compared to healthy subjects. These differences in walking pattern partially explain the lower 6MWD in patients with COPD. \textcopyright{} 2012 Annegarn et al.},
  author    = {Janneke Annegarn and Martijn A. Spruit and Hans H.C.M. Savelberg and Paul J.B. Willems and Coby van de Bool and Annemie M.W.J. Schols and Emiel F.M. Wouters and Kenneth Meijer},
  doi       = {10.1371/journal.pone.0037329},
  issn      = 19326203,
  issue     = 5,
  journal   = {PLoS ONE},
  keywords  = {Accelerometers,Autocorrelation,Body weight,Chronic obstructive pulmonary disease,Dyspnea,Gait analysis,Geriatric care,Walking},
  month     = 5,
  pages     = {e37329},
  pmid      = 22624017,
  publisher = {Public Library of Science},
  title     = {Differences in walking pattern during 6-min walk test between patients with COPD and healthy subjects},
  volume    = 7,
  url       = {www.plosone.org},
  year      = 2012
}

@article{Arafat2017,
  abstract = {We propose a family of algorithms that transform a hypergraph drawing problem into a graph drawing problem and leverage force-directed graph drawing algorithms in order to draw hypergraphs. We propose and discuss a number of criteria to evaluate the quality of the drawings from the points of view of aesthetics and of visualization and analytics. We empirically and comparatively evaluate the quality of the drawings based on these criteria on both synthetic and real data sets. Experiments reveal that the algorithms are generally effective and the drawings generated are aesthetically pleasing.},
  author   = {Naheed Anjum Arafat and St\'{e}phane Bressan},
  doi      = {10.1007/978-3-319-64471-4\_31},
  isbn     = 9783319644707,
  issn     = 16113349,
  issue    = {March},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Force-directed graph drawing,Hypergraph,Visualization},
  pages    = {387--394},
  title    = {Hypergraph drawing by force-directed placement},
  volume   = {10439 LNCS},
  url      = {http://www.mathe2.uni-bayreuth.de/axel/papers/reingold:graph\_drawing\_by\_force\_directed\_placement.pdf},
  year     = 2017
}

@article{ArasDarganzany2011,
  author      = {Aras Darganzany},
  institution = {University of Nevada, Reno},
  title       = {Human Body Parts Tracking: Applications to Activity Recognition},
  year        = 2011
}

@article{Argudo2017a,
  abstract = {We present an efficient method for generating coherent multi-layer landscapes. We use a dictionary built from exemplars to synthesize high-resolution fully featured terrains from input low-resolution elevation data. Our example-based method consists in analyzing real-world terrain examples and learning the procedural rules directly from these inputs. We take into account not only the elevation of the terrain, but also additional layers such as the slope, orientation, drainage area, the density and distribution of vegetation, and the soil type. By increasing the variety of terrain exemplars, our method allows the user to synthesize and control different types of landscapes and biomes, such as temperate or rain forests, arid deserts and mountains.},
  author   = {Oscar Argudo and Carlos Andujar and Antonio Chica and \'{E}ric Gu\'{e}rin and Julie Digne and Adrien Peytavie and \'{E}ric Galin},
  doi      = {10.1007/s00371-017-1393-6},
  issn     = {01782789},
  issue    = {6-8},
  journal  = {Visual Computer},
  keywords = {Coherent multi-layer landscapes,Dictionary matching,Example-based modeling},
  pages    = {1005--1015},
  title    = {Coherent multi-layer landscape synthesis},
  volume   = 33,
  year     = 2017
}

@article{Argudo2018,
  abstract = {Despite recent advances in surveying techniques, publicly available Digital Elevation Models (DEMs) of terrains are lowresolution except for selected places on Earth. In this paper we present a new method to turn low-resolution DEMs into plausible and faithful high-resolution terrains. Unlike other approaches for terrain synthesis/amplification (fractal noise, hydraulic and thermal erosion, multi-resolution dictionaries), we benefit from high-resolution aerial images to produce highly-detailed DEMs mimicking the features of the real terrain. We explore different architectures for Fully Convolutional Neural Networks to learn upsampling patterns for DEMs from detailed training sets (high-resolution DEMs and orthophotos), yielding up to one order of magnitude more resolution. Our comparative results show that our method outperforms competing data amplification approaches in terms of elevation accuracy and terrain plausibility.},
  author   = {Oscar Argudo and Antonio Chica and Carlos Andujar},
  doi      = {10.1111/cgf.13345},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {Image processing,Shape modeling},
  pages    = {101--110},
  title    = {Terrain super-resolution through aerial imagery and fully convolutional networks},
  volume   = 37,
  year     = 2018
}

@article{Argudo2019,
  abstract = {<p>Mountainous digital terrains are an important element of many virtual environments and find application in games, film, simulation and training. Unfortunately, while existing synthesis methods produce locally plausible results they often fail to respect global structure. This is exacerbated by a dearth of automated metrics for assessing terrain properties at a macro level.</p>},
  author   = {Oscar Argudo and Eric Galin and Adrien Peytavie and Axel Paris and James Gain and Eric Gu\'{e}rin},
  doi      = {10.1145/3355089.3356535},
  issn     = {0730-0301},
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  month    = 12,
  pages    = {1--12},
  title    = {Orometry-based terrain analysis and synthesis},
  volume   = 38,
  url      = {https://dl.acm.org/doi/10.1145/3355089.3356535},
  year     = 2019
}

@article{Argudo2020,
  abstract = {Glaciers are some of the most visually arresting and scenic elements of cold regions and high mountain landscapes. Although snow-covered terrains have previously received attention in computer graphics, simulating the temporal evolution of glaciers as well as modeling their wide range of features has never been addressed. In this paper, we combine a Shallow Ice Approximation simulation with a procedural amplification process to author high-resolution realistic glaciers. Our multiresolution method allows the interactive simulation of the formation and the evolution of glaciers over hundreds of years. The user can easily modify the environment variables, such as the average temperature or precipitation rate, to control the glacier growth, or directly use brushes to sculpt the ice or bedrock with interactive feedback. Mesoscale and smallscale landforms that are not captured by the glacier simulation, such as crevasses, moraines, seracs, ogives, or icefalls are synthesized using procedural rules inspired by observations in glaciology and according to the physical parameters derived from the simulation. Our method lends itself to seamless integration into production pipelines to decorate reliefs with glaciers and realistic ice features.},
  author   = {Oscar Argudo and Eric Galin and Adrien Peytavie and Axel Paris and Eric Gu\'{e}rin},
  doi      = {10.1145/3414685.3417855},
  issn     = {0730-0301},
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {"Procedural terrain modeling,glacier simulation"},
  month    = 12,
  pages    = {1--14},
  title    = {Simulation, modeling and authoring of glaciers},
  volume   = 39,
  url      = {https://dl.acm.org/doi/10.1145/3414685.3417855},
  year     = 2020
}

@misc{Ash,
  author = {Peter F. Ash and Ethan D. Bolker},
  title  = {Generalized Dirichlet Tesselation},
  url    = {https://www.cs.umb.edu/~eb/dirichlet/generalizedDT.pdf}
}

@article{Ashlock2005,
  abstract = {An L-system or Lindenmayer system consists of a grammar and an interpreter. The grammar contains an axiom, usually a short string, that the grammar expands into a long, complex string. The interpreter then renders the string into an object. A midpoint L-system is a generalization of L-systems to two-dimensional arrays of characters inspired by midpoint displacement fractals. This study presents a system for simultaneously evolving the rules and and interpreter for a midpoint L-system that encodes a desired landscape. Unlike a midpoint displacement fractal a midpoint L-system is deterministic and can be evolved to yield fixed, complex shapes. The fractal character of a midpoint L-system permits the storage of a large complex virtual landscape in a small data object. The level of detail rendered by an L-system can be changed rapidly and, with a fast graphics engine, dynamically. This study introduces midpoint L-systems, gives techniques for evolving them, and demonstrates those techniques on trial landscapes that resemble hills and craters. The application of this work is for virtual reality where midpoint L-systems will allow a designer to select from many rugged versions of a landscape without requiring vast amounts of storage or machine time to render them. \textcopyright{} 2005 IEEE.},
  author   = {Daniel A. Ashlock and Stephen P. Gent and Kenneth M. Bryden},
  doi      = {10.1109/cec.2005.1555041},
  isbn     = {0780393635},
  issue    = {January},
  journal  = {2005 IEEE Congress on Evolutionary Computation, IEEE CEC 2005. Proceedings},
  pages    = {2760--2767},
  title    = {Evolution of L-systems for compact virtual landscape generation},
  volume   = 3,
  year     = 2005
}

@article{Ashual2019,
  abstract = {We introduce a method for the generation of images from an input scene graph. The method separates between a layout embedding and an appearance embedding. The dual embedding leads to generated images that better match the scene graph, have higher visual quality, and support more complex scene graphs. In addition, the embedding scheme supports multiple and diverse output images per scene graph, which can be further controlled by the user. We demonstrate two modes of per-object control: (i) importing elements from other images, and (ii) navigation in the object space by selecting an appearance archetype. Our code is publicly available at https://www.github.com/ashual/scene-generation.},
  author   = {Oron Ashual and Lior Wolf},
  doi      = {10.1109/ICCV.2019.00466},
  isbn     = 9781728148038,
  issn     = 15505499,
  journal  = {Proceedings of the IEEE International Conference on Computer Vision},
  pages    = {4560--4568},
  title    = {Specifying object attributes and relations in interactive scene generation},
  volume   = {2019-Octob},
  url      = {https://arxiv.org/pdf/1909.05379.pdf},
  year     = 2019
}

@article{Augustin2009,
  abstract  = {Wetlands protect mainland areas from erosion and damage by damping waves. Yet, this critical role of wetland is not fully understood at present, and a means for reliably determining wave damping by vegetation in engineering practice is not yet available. Laboratory experiments were conducted to measure wave attenuation resulting from synthetic emergent and nearly emergent wetland vegetation under a range of wave conditions and plant stem densities. The laboratory data were analyzed using linear wave theory to quantify bulk drag coefficients and with a nonlinear Boussinesq model to determine numerical friction factors to better represent wetland vegetation in engineering analysis. \textcopyright{} 2008 Elsevier B.V. All rights reserved.},
  author    = {Lauren N. Augustin and Jennifer L. Irish and Patrick Lynett},
  doi       = {10.1016/j.coastaleng.2008.09.004},
  issn      = {03783839},
  issue     = 3,
  journal   = {Coastal Engineering},
  keywords  = {Bottom friction,Vegetation damping,Wave attenuation,Wetlands},
  month     = 3,
  pages     = {332--340},
  publisher = {Elsevier},
  title     = {Laboratory and numerical studies of wave damping by emergent and near-emergent wetland vegetation},
  volume    = 56,
  year      = 2009
}

@misc{Ayala,
  author   = {D. Ayala and J. Rodr\'{\i}guez and A. Aguilera},
  journal  = {Faces},
  keywords = {connected component labeling,image understanding,volume visualization},
  month    = 3,
  title    = {Fast Connected Component Labeling Algorithm : A non voxel-based approach},
  url      = {https://upcommons.upc.edu/bitstream/handle/2117/97534/R02-26.pdf},
  year     = 2002
}

@article{Azman2020,
  abstract  = {Considering the significant evidential values of fingerprints in underwater criminal investigations and the need to visualise them using a user- and environmentally-friendly reagent, development of a novel, rapid and relatively greener nanobio-based reagent (NBR) is deemed beneficial. Lipase from the commercial Candida rugosa immobilised onto acid-functionalised multi-walled carbon nanotubes (NBR) was used as the safer and cheap lipid-sensing reagent to visualise groomed whole/split fingerprints on non-porous objects immersed in stagnant tap water for up to 30 days under a laboratory-controlled setting. Attenuated Total Reflectance – Fourier Transform Spectrometry, Field Emission Scanning Electron Microscopy and bioinformatics (molecular docking and molecular dynamics simulations) were employed to characterise and confirm the attachment of NBR onto the lipid constituents of wet fingerprints. Chromatographic results further confirmed the presence of n-hexadecanoic and octadecanoic acids on fingerprints up to 30 days of immersion. Thus, NBR may potentially be useful as the future state-of-the-art fingerprint visualisation technology.},
  author    = {Aida Rasyidah Azman and Naji Arafat Mahat and Roswanira Abdul Wahab and Wan Azlina Ahmad and Mohamad Afiq Mohamed Huri and Azzmer Azzar Abdul Hamid and Aliyu Adamu and Geshina Ayu Mat Saat},
  doi       = {10.1016/j.procbio.2020.05.033},
  issn      = 13595113,
  journal   = {Process Biochemistry},
  keywords  = {Bioinformatics,Candida rugosa lipase,Forensic science,Latent fingerprint,Nanobio-based reagent},
  month     = 9,
  pages     = {102--112},
  publisher = {Elsevier Ltd},
  title     = {Characterisation and computational analysis of a novel lipase nanobio-based reagent for visualising latent fingerprints on water-immersed glass slides},
  volume    = 96,
  year      = 2020
}

@article{Baboud2010,
  abstract = {We present a real-time technique to render realistic water volumes. Water volumes are represented as the space enclosed between a ground heightfield and an animable water surface heightfield. This representation allows the application of recent GPU-based heightfield rendering algorithms. Our method is a simplified raytracing approach which correctly handles reflections and refractions and allows us to render complex effects such as light absorption, refracted shadows and refracted caustics. It runs at high framerates by exploiting the power of the latest graphic cards, and could be used in real-time applications like video games, or interactive simulation.},
  author   = {Lionel Baboud and Xavier D\'{e}coret and Lionel Baboud and Xavier D\'{e}coret and Realistic Water and Real-time Eurographics Workshop and Lionel Baboud and Xavier D\'{e}coret},
  journal  = {Eurographics Workshop on Natural Phenomena},
  title    = {Realistic Water Volumes in Real-Time},
  url      = {https://hal.inria.fr/inria-00510227/document},
  year     = 2006
}

@article{Bachman2022,
  abstract = {Coral reefs are highly threatened by ocean warming and the majority are likely to be lost in less than three decades. A first step in maximizing reef conservation through this period is to identify where coral reefs are more likely to survive rising ocean temperatures, such as locations that experience lower temperatures than surrounding regions, high temperature variability, and high food supply. Such conditions are often the result of naturally occurring internal gravity waves (IGWs), oscillatory subsurface disturbances that can entrain cooler and/or nutrient-rich subsurface waters and cause high frequency temperature fluctuations. These features usually remain undetected because they occur subsurface and at spatial scales of O(1 km) and smaller. To shed light on where IGWs are likely to impact temperature conditions within coral reef regions, we present an analysis of data from the LLC4320, a massive high resolution (1/48\r{}; < 2.5~km) numerical global ocean simulation. The results highlight strong regional differences in the incidence of IGW-induced temperature variability. The analysis also reveals that thermal refugia are limited to depths where high temperature variability coincides with the actual reef depth and may not persist year-round. Assuming 10-m depth as the nominal reef depth, reef regions likely to benefit from IGW-induced cooling occur in SE Asia and the Coral Triangle, the Gal\'{a}pagos, along the Pacific shelf of Central America, and isolated locations worldwide. Such refugia are rare within the Atlantic reef sector. An interactive global atlas showing the results of this study has been made freely available online at https://ncar.github.io/coral-viz/.},
  author   = {Scott D. Bachman and Joan A. Kleypas and Mark Erdmann and Edy Setyawan},
  doi      = {10.3389/fmars.2022.921879},
  issn     = 22967745,
  issue    = {July},
  journal  = {Frontiers in Marine Science},
  keywords = {coral reefs,global atlas,internal gravity waves,temperature variability,thermal refugia},
  pages    = {1--13},
  title    = {A global atlas of potential thermal refugia for coral reefs generated by internal gravity waves},
  volume   = 9,
  year     = 2022
}

@misc{Baidoo-Williams2008,
  abstract = {Manganese, a metal with important industrial uses, is fast depleting due to various ecological constraints. There is therefore a need to find alternate mining sources. An alternative that has been constantly proffered is ocean floor mining of manganese. Ocean floor mining by human agents is not feasible. By this paper, we propose the use of swarming techniques similar to ants and termites, for the extraction of manganese nodules. Swarm applications are robust because agents in a swarm communicate locally rather than globally and failure/loss of an agent which is an inevitable occurrence in the terrain being considered will not affect the general objective of the swarm.},
  author   = {H. E. Baidoo-Williams and A. Vidyarthi and S Kapadia},
  pages    = {1--18},
  title    = {Application of Swarms for Exploration of Manganese in Deep Ocean},
  year     = 2008
}

@article{Bailly2022,
  abstract  = {This paper presents Genetic-WFC, a procedural level generation algorithm that mixes genetic optimization with Wave Function Collapse, a local adjacency constraints propagation algorithm. We use a synthetic player to evaluate the novelty, safety and complexity of the generated levels. Novelty is maximized when the synthetic player goes on tiles not visited for a long time, safety is related to how far it can see, and complexity evaluates the variability of the surrounding tiles. WFC extracts constraints from example levels, and allows us to perform the genetic search on levels with few local asset placement errors, while using as little level design rules as possible. We show that we are able to rely on WFC while optimizing the results, first by influencing WFC asset selection and then by re-encoding the chosen modules back to our genotype, in order to optimize crossover. We compare the fitness curves and best maps of our method with other approaches. We then visually explore the kind of levels we are able to generate by sampling different values of safety and complexity, giving a glimpse of the variability that our approach is able to reach.},
  author    = {Raphael Bailly and Guillaume Levieux},
  doi       = {10.1109/TG.2022.3192930},
  issn      = 24751510,
  journal   = {IEEE Transactions on Games},
  keywords  = {Complexity theory,Games,Genetic algorithm,Genetic algorithms,Maintenance engineering,Optimization,Safety,Wave functions,level design,player experience,procedural content generation,variability,video games,wave function collapse},
  pages     = {1--10},
  publisher = {IEEE},
  title     = {Genetic-WFC: Extending Wave Function Collapse With Genetic Search},
  year      = 2022
}

@article{Baker2019,
  abstract = {Through multi-agent competition, the simple objective of hide-and-seek, and standard reinforcement learning algorithms at scale, we find that agents create a self-supervised autocurriculum inducing multiple distinct rounds of emergent strategy, many of which require sophisticated tool use and coordination. We find clear evidence of six emergent phases in agent strategy in our environment, each of which creates a new pressure for the opposing team to adapt; for instance, agents learn to build multi-object shelters using moveable boxes which in turn leads to agents discovering that they can overcome obstacles using ramps. We further provide evidence that multi-agent competition may scale better with increasing environment complexity and leads to behavior that centers around far more human-relevant skills than other self-supervised reinforcement learning methods such as intrinsic motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic motivation and random initialization baselines in a suite of domain-specific intelligence tests.},
  author   = {Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
  doi      = {https://doi.org/10.48550/arXiv.1909.07528},
  month    = 9,
  title    = {Emergent Tool Use From Multi-Agent Autocurricula},
  url      = {http://arxiv.org/abs/1909.07528},
  year     = 2019
}

@inbook{Ballet2002,
  author  = {Pascal Ballet and Abdallah Zemirline and Lionel Marc\'{e} and Gilles Bernot and Franck Delaplace and Jean-Louis Giavitto and Olivier Michel and Jean-Marc Delosme and Patrick Amar and Roberto Incitti and Paul Bourgine and Christophe Godin and Fran\c{c}ois K\'{e}p\`{e}s and Philippe Tracqui and Vic Norris and Janine Guespin and Maurice Demarty and Camille Ripoll},
  journal = {Modelling and simulation of biological processes in the context of genomics},
  pages   = {257--280},
  title   = {Course on Cellular Automata, Reaction-Diffusion and Multiagents Systems for Artificial Cell Modeling},
  year    = 2002
}

@inproceedings{Balzer2009,
  author    = {Michael Balzer and Thomas Schl\"{o}mer and Oliver Deussen},
  city      = {New York, NY, USA},
  doi       = {10.1145/1576246.1531392},
  isbn      = 9781605587264,
  booktitle = {ACM SIGGRAPH 2009 papers},
  keywords  = {blue noise,ca-,density,function in the sense,importance sampling,is proportional to the,lloyd,pacity constraint,points in an area,poisson disk point sets,s method,that point distributions adapt,that the number of,to a given density,voronoi tessellations},
  month     = 7,
  pages     = {1--8},
  publisher = {ACM},
  title     = {Capacity-constrained point distributions},
  volume    = 28,
  url       = {https://dl.acm.org/doi/10.1145/1576246.1531392},
  year      = 2009
}

@article{Bansal2018,
  abstract = {Reinforcement learning algorithms can train agents that solve problems in complex, interesting environments. Normally, the complexity of the trained agent is closely related to the complexity of the environment. This suggests that a highly capable agent requires a complex environment for training. In this paper, we point out that a competitive multi-agent environment trained with self-play can produce behaviors that are far more complex than the environment itself. We also point out that such environments come with a natural curriculum, because for any skill level, an environment full of agents of this level will have the right level of difficulty. This work introduces several competitive multi-agent environments where agents compete in a 3D world with simulated physics. The trained agents learn a wide variety of complex and interesting skills, even though the environment themselves are relatively simple. The skills include behaviors such as running, blocking, ducking, tackling, fooling opponents, kicking, and defending using both arms and legs. A highlight of the learned behaviors can be found here: https://goo.gl/eR7fbX.},
  author   = {Trapit Bansal and Jakub Pachocki and Szymon Sidor and Ilya Sutskever and Igor Mordatch},
  journal  = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
  pages    = {1--12},
  title    = {Emergent complexity via multi-agent competition},
  volume   = 2,
  year     = 2018
}

@article{Baojun2009,
  abstract = {3D geological modeling has become one of the most reliable and effective means of displaying geological structures, but most commercial software products for 3D geological modeling need special techniques and much pre-processing work as well as being expensive and complicated to operate. In this paper, a simple approach to building a 3D geological model is proposed, integrating such popular software packages as 3D Studio Max (3DSMax), ArcGIS, and Virtual Reality Modeling Language (VRML). The approach can be used to build accurate 3D geological structures and to model stratigraphy at almost any level of complexity. Moreover, the resulting model can be operated interactively, including zooming in or out, rotating and moving. The paper demonstrates how this new approach can be a very effective method for 3D geological modeling. \textcopyright{} Springer-Verlag 2009.},
  author   = {Wang Baojun and Shi Bin and Song Zhen},
  doi      = {10.1007/s10064-009-0233-y},
  issn     = 14359529,
  issue    = 4,
  journal  = {Bulletin of Engineering Geology and the Environment},
  keywords = {3D geological modeling,Interactive operation,Visualization},
  pages    = {559--565},
  title    = {A simple approach to 3D geological modelling and visualization},
  volume   = 68,
  year     = 2009
}

@article{Baraff1998,
  abstract = {The bottle-neck in most cloth simulation systems is that time steps must be small to avoid numerical instability. This paper describes a cloth simulation system that can stably take large time steps. The simulation system couples a new technique for enforcing constraints on individual cloth particles with an implicit integration method. The simulator models cloth as a triangular mesh, with internal cloth forces derived using a simple continuum formulation that supports modeling operations such as local anisotropic stretch or compression; a unified treatment of damping forces is included as well. The implicit integration method generates a large, unbanded sparse linear system at each time step which is solved using a modified conjugate gradient method that simultaneously enforces particles' constraints. The constraints are always maintained exactly, independent of the number of conjugate gradient iterations, which is typically small. The resulting simulation system is significantly faster than previous accounts of cloth simulation systems in the literature.},
  author   = {David Baraff and Andrew Witkin},
  doi      = {10.1145/280814.280821},
  journal  = {Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1998},
  keywords = {Cloth,Constraints,Implicit integration,Physically-based modeling,Simulation},
  pages    = {43--54},
  title    = {Large steps in cloth simulation},
  url      = {https://www.cs.cmu.edu/~baraff/papers/sig98.pdf},
  year     = 1998
}

@article{Barthe,
  abstract = {Automatic continuous blending is a powerful and specific property of implicit surfaces. However it remains difficult to control this soft transition precisely. Indeed the shape produced at the transition level is not directly linked to geometric parameters. We introduce a new tool to manipulate implicit surfaces: implicit extrusion fields. Those fields are 2 dimensional spaces where each coordinate is a potential field of R3\textregistered{}R. Point coordinates are then iso-surfaces. Point is defined by its coordinates intersection which is a curve in 3D user space. A continuous curve (called profile) defined in this field is then represented by a surface in the user space. This surface is said to be the extrusion of profile in implicit extrusion field. 0 iso-surfaces of implicit extrusion field coordinates can be introduced in final object and profiles can be precisely defined using control points and vectors of the 3D user space. 1D cubic polynomial splines are functions of R\textregistered{}R which smoothly interpolate control points. Profiles defines by those functions allow us to propose different tools: \cdot{} Creation of 3D objects by extrusion of profile in implicit extrusion field. \cdot{} Sculpt a surface in integrating one of the 0 iso-surface of coordinates of implicit extrusion field in final object. Profile extrusion will then add or remove matter. \cdot{} Combine the two 0 iso-surfaces of the two implicit extrusion field coordinates. Profile extrusion will then precisely defined the blend. The use of polynomial splines allows us to introduce an ``almost'' free form blending. Profiles are defined by functions of R\textregistered{}R. This is why they are not free form profiles, indeed, they must be monotonous in the abscissa direction. We then propose ``almost'' free form curves. We just propose an introduction to different research ways to defined ``true'' free form profiles. More researches have now to be done in this topic to increase our model efficiency.},
  author   = {Lo\"{\i}c Barthe},
  pages    = {1--144},
  title    = {Les champs implicites d'extrusion : un outil pr\'{e}cis pour cr\'{e}er, sculpter ou combiner des formes \`{a} l'aide de surfaces implicites},
  url      = {https://www.irit.fr/~Loic.Barthe/These/These\_Loic\_27\_09\_2000.pdf}
}

@article{Barthe2001,
  abstract = {This paper presents a new interpretation of the general definition of the binary blending operator of implicit modeling. Instead of considering the operator as a composition of potential functions or as a function defined in the combined primitives metric, we propose to consider it as an implicit curve extruded in an implicit extrusion field. An implicit extrusion field is a 2D space for which each coordinate is a potential field. The study of general concepts around implicit extrusion field allows us to introduce theoretical notion of free-form blending controlled point-by-point by the user. Through the use of functional interpolation functions, we propose modeling tools to create, sculpt or combine implicit primitives by extrusion of a profile in an implicit extrusion field. \textcopyright{} World Scientific Publishing Company.},
  author   = {Lo\"{\i}c Barthe and Veronique Gaildrat and R Caubet},
  doi      = {10.1142/s0218654301000114},
  issn     = {02186543},
  issue    = 2,
  journal  = {International Journal of Shaping Modeling},
  keywords = {Boolean composition operators,Free-form transitions,Implicit curves,Implicit modeling},
  pages    = {179--198},
  title    = {Extrusion of ID implicit profiles: theory and first application},
  volume   = 7,
  url      = {https://www.irit.fr/recherches/VORTEX/publications/rendu-geometrie/IJSM2001\_Barthe\_et\_al.pdf},
  year     = 2001
}

@misc{Barthe2002,
  author      = {Lo\"{\i}c Barthe and N A Dodgson and M A Sabin and Brian Wyvill and V Gaildrat},
  doi         = {10.48456/tr-541},
  institution = {University of Cambridge, Computer Laboratory},
  title       = {Different applications of two-dimensional potential fields for volume modeling},
  url         = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-541.pdf},
  year        = 2002
}

@article{Barthe2004,
  abstract = {Potential functions allow the definition of both an implicit surface and its volume. In this representation, two categories can be distinguished: bounded and unbounded representations. Boolean composition operators are standard modelling tools allowing complex objects to be built by the combination of simple volume primitives. Though they are well defined for the second category, there is no clear definition of the properties that such operators should satisfy in order to provide bounded representation with both smooth and sharp transition. In this paper, we focus on bounded implicit representation. We first present fundamental properties to create adequate composition operators. From this theoretical framework, we derive a set of Boolean operators providing union, intersection and difference with or without smooth transition. Our new operators integrate accurate point-by-point control of smooth transitions and they generate G1 continuous potential fields even when sharp transition operators are used. \textcopyright{} World Scientific Publishing Company.},
  author   = {Lo\"{\i}c Barthe and Brian Wyvill and Erwin De Groot},
  doi      = {10.1142/S021865430400064X},
  issn     = {02186543},
  issue    = 2,
  journal  = {International Journal of Shape Modeling},
  keywords = {Blending,Bounded representation,CSG operators,Implicit modelling,Soft objects},
  pages    = {135--154},
  title    = {Controllable binary CSG operators for "soft objects"},
  volume   = 10,
  url      = {https://pages.cpsc.ucalgary.ca/~blob/pdf/barthecsg.pdf},
  year     = 2004
}

@book{Barton1995,
  abstract = {Fractals have changed the way we understand and study nature. This change has been brought about mainly by the work of B. B. Mandelbrot and his book The Fractal Geometry of Nature. Now here is a book that collects articles treating fractals in the earth sciences. The themes chosen span, as is appropriate for a discourse on fractals, many orders of magnitude; including earthquakes, ocean floor topography, fractures, faults, mineral crystallinity, gold and silver deposition. There are also chapters on dynamical processes that are fractal, such as rivers, earthquakes, and a paper on self-organized criticality. Many of the chapters discuss how to estimate fractal dimensions, Hurst exponents, and other scaling exponents. This book, in a way, represents a snapshot of a field in which fractals has brought inspiration and a fresh look at familiar subjects. New ideas and attempts to quantify the world we see around us are found throughout. Many of these ideas will grow and inspire further work, others will be superseded by new observations and insights, most probably with future contributions by the authors of these chapters. It is wonderful to witness that the idea of fractal geometry has lead to such a high rate of discovery in the earth sciences. I believe that this book will also inspire others to take part in the scientific process of revealing the unseen, clarifying what is incomplete, discarding views that turn out not to stand up to the test of experiments and observations and thereby extending our understanding of the earth.},
  author   = {Christopher C. Barton and Paul R. La Pointe},
  isbn     = 9789896540821,
  pages    = 277,
  title    = {Fractals in the Earth Sciences},
  year     = 1995
}

@misc{Bastani2018,
  abstract = {Mapping road networks is currently both expensive and labor-intensive. High-resolution aerial imagery provides a promising avenue to automatically infer a road network. Prior work uses convolutional neural networks (CNNs) to detect which pixels belong to a road (segmentation), and then uses complex post-processing heuristics to infer graph connectivity. We show that these segmentation methods have high error rates because noisy CNN outputs are difficult to correct. We propose RoadTracer, a new method to automatically construct accurate road network maps from aerial images. RoadTracer uses an iterative search process guided by a CNN-based decision function to derive the road network graph directly from the output of the CNN. We compare our approach with a segmentation method on fifteen cities, and find that at a 5\% error rate, RoadTracer correctly captures 45\% more junctions across these cities.},
  author   = {Favyen Bastani and Songtao He and Sofiane Abbar and Mohammad Alizadeh and Hari Balakrishnan and Sanjay Chawla and Sam Madden and David Dewitt},
  doi      = {10.1109/CVPR.2018.00496},
  isbn     = 9781538664209,
  issn     = 10636919,
  journal  = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  month    = 2,
  pages    = {4720--4728},
  title    = {RoadTracer: Automatic Extraction of Road Networks from Aerial Images},
  url      = {https://roadmaps.},
  year     = 2018
}

@article{Bayer2019,
  abstract    = {For the past few decades, relational databases have been the default choice for data storage, especially for enterprise applications. Currently, many other database technologies are grabbing more attention due to their high performance, scalability, and availability options, such as Not Only SQL (NoSQL) technologies. Choosing the right database technology for applications among a plethora of database options is a challenging task. This research aims to provide a systematic and experimental evaluation of four NoSQL databases across the spectrum of different NoSQL categories. The investigated databases are Redis, MongoDB, Neo4j, and Cassandra. We study multiple aspects such as the database transaction support, query options, data layout, scalability, availability, security, and durability. Besides, we analyze the data modelling of each database using a data model from the Transaction Processing Council Ad-hoc (TPCH) benchmark. Furthermore, we evaluate the query capabilities of each database using three complex queries from the same benchmark. Based on the examination, we capture the strengths and weaknesses each database has. Finally, we present a set of factors that influence the adoption of a NoSQL solution. These factors assist software architects and developers to choose the proper database technology for their specific application needs.},
  author      = {Florian Bayer},
  institution = {Technische Universitat Munchen},
  pages       = {1985--1989},
  title       = {Triplanar Displacement Mapping for Terrain Rendering},
  year        = 2019
}

@article{Bazeille2012,
  abstract = {In this article we present a new approach for object recognition in a robotic underwater context. Color is an attractive feature because of its simplicity and its robustness to scale changes, object positions and partial occlusions. Unfortunately, in the underwater medium, the colors are modified by attenuation and are not constant with the distance. To perform a color-based recognition of an object, we develop an algorithm robust with respect to the attenuation which takes into account the light modification during its path between the light source and the camera. Therefore, a given underwater object can be identified in an image by detecting all the colors compatible with its prior known color. Our method is fast, robust and needs a very few computers resources. We successfully used it when experimenting in the sea using a system we built. It is suitable for robotic applications where computers resources are limited and shared between various embedded devices. This novel concept enables the use of the color in many applications such as target interception, object tracking or obstacle detection. \textcopyright{} 2012 Springer-Verlag.},
  author   = {St\'{e}phane Bazeille and Isabelle Quidu and Luc Jaulin},
  doi      = {10.1007/s11370-012-0105-3},
  issn     = 18612776,
  issue    = 2,
  journal  = {Intelligent Service Robotics},
  keywords = {Color,Light attenuation,Underwater robot,Vision},
  pages    = {109--118},
  title    = {Color-based underwater object recognition using water light attenuation},
  volume   = 5,
  url      = {https://www.ensta-bretagne.fr/jaulin/paper\_isr\_bazeille.pdf},
  year     = 2012
}

@article{Beardall2007,
  abstract = {Height map models of terrain are computationally efficient but cannot represent terrain with concave surfaces. We present an algorithm for generating sandstone goblins using a simulation of spheroidal weathering. Sandstone goblins are a kind of hoodoo which are characterized by rounded concave shapes. The weathering simulation uses bubbles centered on axis aligned voxels to approximate geometry-dependent effects of spheroidal weathering. We demonstrate that the algorithm, together with appropriate surface textures, produces visually plausible goblins at near interactive speeds for most simulation parameters. \textcopyright{} The Eurographics Association 2007.},
  author   = {Matthew Beardall and McKay Farley and D. Ouderkirk and C. Reimschussel and J. Smith and M. Jones and P. Egbert},
  isbn     = 9783905673494,
  issn     = 18160867,
  journal  = {Natural Phenomena},
  pages    = {7--14},
  title    = {Goblins by spheroidal weathering},
  url      = {https://diglib.eg.org/bitstream/handle/10.2312/NPH.NPH07.007-014/007-014.pdf?sequence=1\&isAllowed=y\#:~:text=to additional weathering.-,weathering.,Weathering weakens the rock.},
  year     = 2007
}

@misc{Bebis_noDate,
  author = {George Bebis},
  title  = {Deformable/Active Contours (or Snakes)}
}

@article{Becher2016,
  author = {Michael Becher},
  issue  = 74,
  title  = {Feature Based Volumetric Terrain Generation},
  year   = 2016
}

@article{Becher2017,
  abstract = {Two-dimensional heightfields are the most common data structure used for storing and rendering of terrain in offline rendering and especially real-time computer graphics. By its very nature, a heightfield cannot store terrain structures with multiple vertical layers such as overhanging cliffs, caves, or arches. This restriction does not apply to volumetric data structures. However, the workflow of manual modelling and editing of volumetric terrain usually is tedious and very time-consuming. Therefore, we propose to use three-dimensional curve-based primitives to efficiently model prominent, large-scale terrain features. We present a technique for volumetric generation of a complete terrain surface from the sparse input data by means of diffusion-based algorithms. By combining an efficient, feature-based toolset with a volumetric terrain representation, the modelling workflow is accelerated and simplified while retaining the full artistic freedom of volumetric terrains. All stages of our method are GPU-accelerated using compute shaders to ensure interactive editing of terrain.},
  author   = {Michael Becher and Michael Krone and Guido Reina and Thomas Ertl},
  doi      = {10.1145/3023368.3023383},
  isbn     = 9781450348867,
  journal  = {Proceedings - I3D 2017: 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
  keywords = {Diffusion algorithms,GPU,Interactive modelling,Splinecurves,Terrain,Volumetric},
  title    = {Feature-based volumetric terrain generation},
  year     = 2017
}

@article{Beckham2017,
  abstract = {Procedural terrain generation for video games has been traditionally been done with smartly designed but handcrafted algorithms that generate heightmaps. We propose a first step toward the learning and synthesis of these using recent advances in deep generative modelling with openly available satellite imagery from NASA.},
  author   = {Christopher Beckham and Christopher Pal},
  month    = 7,
  title    = {A step towards procedural terrain generation with GANs},
  url      = {http://arxiv.org/abs/1707.03383},
  year     = 2017
}

@article{Belhadj2007,
  abstract = {We present an algorithm mainly designed to reconstruct Digital Elevation Maps (DEM). Our approach relays on a fast and highly controllable fractal-based algorithm, we are able to create DEMs according to given constraints. Thus, these constraints can be given as scattered dataset of elevations obtained by satellite, our method supersamples this data and creates the according smooth terrain surface. Moreover, as a painter can make a sketch of his model, the final user can give or edit the main characteristics, local details and morphology, of his wanted DEM instantaneously obtaining the resulting terrain surface. Note that there is no limitation on the number of local constraints (that could vary from. 0 to the number of points of the final DEM). Thus, the method we propose gives the ability to modify the global aspect (the surface behavior) as well as to constrain any local detail of the final terrain model. This paper presents the algorithm, and reconstruction examples. Using a Root Mean Square Error computation between an original model and its downsampled-then-reconstructed version, the results confirm the method good behavior and show its efficiency. Other various terrain models and alternative applications are presented. Copyright \textcopyright{} 2007 by the Association for Computing Machinery, Inc.},
  author   = {Far\`{e}s Belhadj},
  doi      = {10.1145/1294685.1294717},
  isbn     = 9781595939067,
  journal  = {ACM International Conference on Computer Graphics, Virtual Reality and Visualisation in Africa},
  keywords = {Fractals,Midpoint displacement,Surface modeling,Surface reconstruction,Terrain},
  pages    = {197--204},
  title    = {Terrain modeling: A constrained fractal model},
  year     = 2007
}

@article{Bell1975a,
  abstract = {Statistical properties of sea-floor topography are interpreted in terms of a model based on the random distribution of hills. Special emphasis is placed on estimating and interpreting the power spectrum of sea-floor elevation.},
  author   = {T. H. Bell},
  doi      = {10.1016/0011-7471(75)90090-X},
  issn     = {00117471},
  issue    = 12,
  journal  = {Deep-Sea Research and Oceanographic Abstracts},
  pages    = {883--892},
  title    = {Statistical features of sea-floor topography},
  volume   = 22,
  year     = 1975
}

@article{Belytschko2003,
  abstract = {Topology optimization is formulated in terms of the nodal variables that control an implicit function description of the shape. The implicit function is constrained by upper and lower bounds, so that only a band of nodal variables needs to be considered in each step of the optimization. The weak form of the equilibrium equation is expressed as a Heaviside function of the implicit function; the Heaviside function is regularized to permit the evaluation of sensitivities. We show that the method is a dual of the Bends\o{}e-Kikuchi method. The method is applied both to problems of optimizing single material and multi-material configurations; the latter is made possible by enrichment functions based on the extended finite element method that enable discontinuous derivatives to be accurately treated within an element. The method is remarkably robust and we found no instances of checkerboarding. The method handles topological merging and separation without any apparent difficulties. Copyright \textcopyright{} 2003 John Wiley \& Sons, Ltd.},
  author   = {T. Belytschko and S. P. Xiao and C. Parimi},
  doi      = {10.1002/nme.824},
  issn     = {00295981},
  issue    = 8,
  journal  = {International Journal for Numerical Methods in Engineering},
  keywords = {Implicit function,Topology optimization},
  pages    = {1177--1196},
  title    = {Topology optimization with implicit functions and regularization},
  volume   = 57,
  year     = 2003
}

@article{Belytschko2018,
  abstract = {<p>A paradigm is developed for generating structured finite element models from solid models by means of implicit surface definitions. The implicit surfaces are defined by radial basis functions. Internal features, such as material interfaces, sliding interfaces and cracks are treated by enrichment techniques developed in the extended finite element method. Methods for integrating the weak form for such models are proposed. These methods simplify the generation of finite element models. Results presented for several examples show that the accuracy of this method is comparable to standard unstructured finite element methods. Copyright \textcopyright{} 2002 John Wiley \&amp; Sons, Ltd.</p>},
  author   = {Ted Belytschko and Chandu Parimi and Nicolas Mo\"{e}s and N. Sukumar and Shuji Usui},
  doi      = {10.1002/nme.686},
  issn     = {0029-5981},
  issue    = 4,
  journal  = {International Journal for Numerical Methods in Engineering},
  month    = 1,
  pages    = {609--635},
  title    = {Structured extended finite element methods for solids defined by implicit surfaces},
  volume   = 56,
  url      = {https://onlinelibrary.wiley.com/doi/10.1002/nme.686},
  year     = 2003
}

@article{Benes2001,
  abstract = {New data structure for visual simulation of 3D terrains is introduced. The representation is inspired by real geological measurements and presents good trade-off between commonly used inexpensive, but inaccurate, height fields and memory demanding voxel representation. The representation is based on horizontal stratified layers consisting of one material. The layers are captured in certain positions of the landscape. This representation is then discretized into a 2D array. We demonstrate that the classical algorithm simulating thermal erosion (F.K. Musgrave, 1989), can run on this representation and we can even simulate some new properties. The simulation has been done on artificial data as well as on real data from Mars.},
  author   = {Bed\v{r}ich Bene\v{s} and Rafael Forsbach},
  doi      = {10.1109/SCCG.2001.945341},
  isbn     = {0769512151},
  journal  = {Proceedings - Spring Conference on Computer Graphics, SCCG 2001},
  keywords = {Terrain erosion,height field,layers,voxels},
  pages    = {80--86},
  title    = {Layered data representation for visual simulation of terrain erosion},
  url      = {https://data.exppad.com/public/papers/Layered\_data\_representation\_for\_Visual\_Simulation\_of\_Terrain\_Erosion.pdf},
  year     = 2001
}

@inproceedings{Benes2001a,
  author    = {Bed\v{r}ich Bene\v{s} and Rafael Forsbach},
  city      = {New York, NY, USA},
  doi       = {10.1145/513867.513880},
  isbn      = 1581134460,
  booktitle = {Proceedings of the 1st international conference on Computer graphics, virtual reality and visualisation},
  month     = 11,
  pages     = {53--57},
  publisher = {ACM},
  title     = {Parallel implementation of terrain erosion applied to the surface of Mars},
  url       = {https://dl.acm.org/doi/10.1145/513867.513880},
  year      = 2001
}

@article{Benes2003,
  abstract  = {In mainstream geometric modeling, cultivating virtual plant ecosystems is a difficult task. Algorithms for realistic scene generation are rooted in procedural models with no explicit or poor external control. We propose that virtual ecosystems modeling may be boosted using software agents as behavioral tools. An ecosystem grows and is driven by its internal rules of development. If it is left to its own fate, it will reach stability on the edge of chaos. Agents interact with ecosystems by adding plants, cutting or killing them, watering, stepping-over, or favoring some plant species. An agent is a characterization artifact that shows proactive conduct and is described by its set of sensors, effectors, internal states, and habits. Habits are defined as continuous functions and allow for characterizing a wide variety of behaviors.},
  author    = {Bed\v{r}ich Bene\v{s} and Enrique David Espinosa},
  doi       = {10.1109/CASA.2003.1199313},
  isbn      = {0769519342},
  issn      = 10928138,
  journal   = {Proceedings - IEEE Workshop on Program Comprehension},
  keywords  = {Chaos,Computational modeling,Computer graphics,Ecosystems,Insects,Layout,Software agents,Solid modeling,Stability,Uncertainty},
  pages     = {126--131},
  publisher = {IEEE},
  title     = {Modeling virtual ecosystems with the proactive guidance of agents},
  volume    = {2003-Janua},
  year      = 2003
}

@article{Benes2006,
  abstract = {This paper presents a generalized solution to modelling hydraulic erosion using ideas from fluid mechanics. The model is based on the Navier-Stokes equations, which provide the dynamics of velocity and pressure. These equations form the basis for the model to balance erosion and deposition that determine changes in the layers between water and erosion material. The eroded material is captured and relocated by water according to a material transport equation. The resulting model is fully 3D and is able to simulate a variety of phenomena including river meanders, low hill sediment wash, natural water springs and receding waterfalls. The simulations show the terrain morphogenesis and can be used for animations as well as for static scene generation. Copyright \textcopyright{} 2006 John Wiley \& Sons, Ltd.},
  author   = {Bed\v{r}ich Bene\v{s} and V\'{a}clav T\v{e}\v{s}\'{\i}nsk\'{y} and Jan Horny\v{s} and Sanjiv K. Bhatia},
  doi      = {10.1002/cav.77},
  issn     = 15464261,
  issue    = 2,
  journal  = {Computer Animation and Virtual Worlds},
  keywords = {Hydraulic erosion,Terrain morphing,Virtual world,Visualization},
  pages    = {99--108},
  title    = {Hydraulic erosion},
  volume   = 17,
  year     = 2006
}

@article{Benes2009,
  abstract = {We present a novel technique for interactive, intuitive, and efficient modeling of virtual plants and plant ecosystems. Our approach is biologically-based, but shades the user from overwhelming input parameters by simplifying them to intuitive controls. Users are able to create scenes that are populated by virtual plants. Plants communicate actively with the environment and attempt to generate an optimal spatial distribution that dynamically adapts to neighboring plants, to user defined obstacles, light, and gravity. We demonstrate simulations of ecosystems composed of up to 140 trees that are computed in less than two minutes. Various phenomena previously available for non-realtime procedural approaches are created interactively, such as plants competing for space, topiary, plant lighting, virtual forests, etc. Results are aimed at architectural modeling, the entertainment industry, and everywhere that quick and fast creation of believable biological plant models is necessary.\textcopyright{} The Eurographics Association 2009.},
  author   = {Bed\v{r}ich Bene\v{s} and Nathan Andrysco and Ond\v{r}ej \v{S}t'ava},
  issn     = 18160867,
  journal  = {Natural Phenomena},
  pages    = {9--16},
  title    = {Interactive modeling of virtual ecosystems},
  url      = {https://diglib.eg.org/xmlui/bitstream/handle/10.2312/EG.DL.conf.EG2009.nph.009-016/009-016.pdf?sequence=1},
  year     = 2009
}

@article{Benes2011,
  abstract = {Procedural methods present one of the most powerful techniques for authoring a vast variety of computer graphics models. However, their massive applicability is hindered by the lack of control and a low predictability of the results. In the classical procedural modeling pipeline, the user usually defines a set of rules, executes the procedural system, and by examining the results attempts to infer what should be changed in the system definition in order to achieve the desired output. We present guided procedural modeling, a new approach that allows a high level of top-down control by breaking the system into smaller building blocks that communicate. In our work we generalize the concept of the environment. The user creates a set of guides. Each guide defines a region in which a specific procedural model operates. These guides are connected by a set of links that serve for message passing between the procedural models attached to each guide. The entire model consists of a set of guides with procedural models, a graph representing their connection, and the method in which the guides interact. The modeling process is performed by modifying each of the described elements. The user can control the high-level description by editing the guides or manipulate the low-level description by changing the procedural rules. Changing the connectivity allows the user to create new complex forms in an easy and intuitive way. We show several examples of procedural structures, including an ornamental pattern, a street layout, a bridge, and a model of trees. We also demonstrate interactive examples for quick and intuitive editing using physics-based mass-spring system. \textcopyright{} 2010 The Author(s).},
  author   = {B. Bene\v{s} and O. \v{S}t'ava and R. M\v{e}ch and G. Miller},
  doi      = {10.1111/j.1467-8659.2011.01886.x},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  pages    = {325--334},
  title    = {Guided procedural modeling},
  volume   = 30,
  year     = 2011
}

@article{Berlemont1990,
  abstract = {A Lagrangian approach is used to describe particle dispersion in turbulent flows. Fluid particle trajectories are simulated with the aid of a correlation matrix evolving along the particle trajectory. Discrete particles are tracked in a given turbulent field taking into account crossing-trajectory effects, and the influence of the particles on the flow characteristics is deduced from momentum and energy exchanges between both phases. Comparisons of the simulations are given for both experimental and theoretical results for fluid particle diffusion problems. Particle dispersion predictions are presented for grid turbulence experiments, and for three two-phase turbulent round jets, from different authors. Predictions compared favourably with experimental results. \textcopyright{} 1990.},
  author   = {A. Berlemont and P. Desjonqueres and G. Gouesbet},
  doi      = {10.1016/0301-9322(90)90034-G},
  issn     = {03019322},
  issue    = 1,
  journal  = {International Journal of Multiphase Flow},
  keywords = {Lagrangian simulation,dispersed flows,turbulence,turbulent diffusion,two-phase flows},
  pages    = {19--34},
  title    = {Particle lagrangian simulation in turbulent flows},
  volume   = 16,
  year     = 1990
}

@article{Berlemont1996,
  author  = {Alain Berlemont and Zhezou Chang and G\'{e}rard Gouesbet},
  doi     = {10.1051/lhb/1996007},
  issn    = {0018-6368},
  issue   = {1-2},
  journal = {La Houille Blanche},
  pages   = {57--63},
  title   = {Une approche lagrangienne pour la simulation d'interactions particule/particule en \'{e}coulement},
  volume  = 82,
  url     = {https://www.shf-lhb.org/articles/lhb/pdf/1996/01/lhb1996007.pdf},
  year    = 1996
}

@article{Bernhardt2010,
  abstract = {Blending is both the strength and the weakness of functionally based implicit surfaces (such as F-reps or soft-objects). While it gives them the unique ability to smoothly merge into a single, arbitrary shape, it makes implicit modelling hard to control since implicit surfaces blend at a distance, in a way that heavily depends on the slope of the field functions that define them. This paper presents a novel, generic solution to blending of functionally-based implicit surfaces: the insight is that to be intuitive and easy to control, blends should be located where two objects overlap, while enabling other parts of the objects to come as close to each other as desired without being deformed. Our solution relies on automatically defined blending regions around the intersection curves between two objects. Outside of these volumes, a clean union of the objects is computed thanks to a new operator that guarantees the smoothness of the resulting field function; meanwhile, a smooth blend is generated inside the blending regions. Parameters can automatically be tuned in order to prevent small objects from blurring out when blended into larger ones, and to generate a progressive blend when two animated objects come in contact.},
  author   = {Adrien Bernhardt and Loic Barthe and Marie-Paule Cani and Brian Wyvill},
  doi      = {10.1111/j.1467-8659.2009.01606.x},
  issn     = {0167-7055},
  issue    = 2,
  journal  = {Computer Graphics Forum},
  month    = 5,
  pages    = {367--375},
  title    = {Implicit Blending Revisited},
  volume   = 29,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01606.x},
  year     = 2010
}

@article{Berry2011,
  abstract = {We present a simple unified algorithmic process which uses either LexBFS or MCS on a chordal graph to generate the minimal separators and the maximal cliques in linear time in a single pass. \textcopyright{} 2011 Elsevier B.V. All rights reserved.},
  author   = {Anne Berry and Romain Pogorelcnik},
  doi      = {10.1016/j.ipl.2011.02.013},
  issn     = {00200190},
  issue    = 11,
  journal  = {Information Processing Letters},
  keywords = {Graph algorithms,LexBFS,MCS,Maximal clique,Minimal separator,Moplex ordering},
  pages    = {508--511},
  title    = {A simple algorithm to generate the minimal separators and the maximal cliques of a chordal graph},
  volume   = 111,
  year     = 2011
}

@article{Bertasius,
  abstract = {We present a convolution-free approach to video classification built exclusively on self-attention over space and time. Our method, named "TimeSformer," adapts the standard Transformer architecture to video by enabling spatiotemporal feature learning directly from a sequence of frame-level patches. Our experimental study compares different self-attention schemes and suggests that "divided attention," where temporal attention and spatial attention are separately applied within each block, leads to the best video classification accuracy among the design choices considered. Despite the radically new design, TimeSformer achieves state-of-the-art results on several action recognition benchmarks, including the best reported accuracy on Kinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks, our model is faster to train, it can achieve dramatically higher test efficiency (at a small drop in accuracy), and it can also be applied to much longer video clips (over one minute long). Code and models are available at: https://github.com/facebookresearch/TimeSformer.},
  author   = {Gedas Bertasius and Heng Wang and Lorenzo Torresani},
  month    = 2,
  title    = {Is Space-Time Attention All You Need for Video Understanding?},
  url      = {http://arxiv.org/abs/2102.05095},
  year     = 2021
}

@article{Bertrand1993,
  abstract = {For several years now, the Geometric Modeling Group of Strasbourg has been working on new formal concepts and tools for describing and manipulating the boundary representation of geometric objects. In a large project of an interactive modeller for volumic objects, the description of which is based on generalized maps, it attempts to cover the whole process from mathematical modeling to efficient implementation, via a complete algebraic specification. Basic concepts and results of this experiment in horizontal and vertical software specification and development are presented along with several illustrations. Advances in algebraic specification methodology are highlighted, specially hierarchical construction of ordered sorts and operations.},
  author   = {Yves Bertrand and J. F. Dufourd and Jean Fran\c{c}on and Pascal Lienhardt},
  doi      = {10.1007/3-540-56610-4\_57},
  isbn     = 9783540566106,
  issn     = 16113349,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  pages    = {75--89},
  title    = {Algebraic specification and development in geometric modeling},
  volume   = {668 LNCS},
  url      = {https://link.springer.com/content/pdf/10.1007/3-540-56610-4\_57.pdf},
  year     = 1993
}

@article{Bertrand1999,
  abstract = {This article presents an algorithm computing a border map of an image that generalizes to the n dimension graph structures used in image analysis. Such a map represents simple and multiple adjacencies, inclusion of regions, as well as the frontier type between two adjacent regions. An algorithm computing a border map, linear to the number of elements of an image, is defined in 2D, then generalized in 3D and in nD.},
  author   = {Yves Bertrand and Christophe Fiorio and Yann Pennaneach},
  doi      = {10.1007/3-540-49126-0\_19},
  isbn     = 3540656855,
  issn     = 16113349,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Adjacency graph,Combinatorial maps,Generalized maps,Image modeling,Topology},
  pages    = {242--257},
  title    = {Border map: A topological representation for nD image analysis},
  volume   = 1568,
  url      = {https://link.springer.com/content/pdf/10.1007/3-540-49126-0\_19.pdf},
  year     = 1999
}

@article{Bertrand2000,
  abstract = {In this paper we define the 3d topological map and give an optimal algorithm which computes it from a segmented image. This data structure encodes totally all the information given by the segmentation. More, it allows to continue segmentation either algorithmically or interactively. We propose an original approach which uses several levels of maps. This allows us to propose a reasonable and implementable solution where other approaches don't allow suitable solutions. Moreover our solution has been implemented and the theoretical results translate very well in practical applications. \textcopyright{} Springer-Verlag Berlin Heidelberg 2000.},
  author   = {Yves Bertrand and Guillaume Damiand and Christophe Fiorio},
  doi      = {10.1007/3-540-44438-6\_26},
  isbn     = 3540413960,
  issn     = 16113349,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  pages    = {311--324},
  title    = {Topological encoding of 3D segmented images},
  volume   = {1953 LNCS},
  url      = {https://link.springer.com/content/pdf/10.1007/3-540-44438-6\_26.pdf},
  year     = 2000
}

@article{Bertrand2017,
  author  = {Yves Bertrand and Guillaume Damiand and Christophe Fiorio},
  journal = {GBR: Graph-Based Representation in Pattern Recognition},
  pages   = {64--73},
  title   = {Topological Map : Minimal Encoding of 3d Segmented Images},
  url     = {https://hal-lirmm.ccsd.cnrs.fr/lirmm-01168509/file/gbr\_2001\_damiand.pdf},
  year    = 2001
}

@article{Betley2021,
  abstract = {<p> <list> <list-item> <p>Decades of theory and scholarship on the concept of human well-being have informed a proliferation of approaches to assess well-being and support public policy aimed at sustainability and improving quality of life.</p> </list-item> <list-item> <p>Human well-being is multidimensional, and well-being emerges when the dimensions and interrelationships interact as a system. In this paper, we illuminate two crucial components of well-being that are often excluded from policy because of their relative difficulty to measure and manage: equity and interrelationships between humans and the environment.</p> </list-item> <list-item> <p>We use a mixed-methods approach to review and summarize progress to date in developing well-being constructs (including frameworks and methods) that address these two components.</p> </list-item> <list-item> <p>Well-being frameworks that do not consider the environment, or interrelationships between people and their environment, are not truly measuring well-being in all its dimensions.</p> </list-item> <list-item> <p>Use of equity lenses to assess well-being frameworks aligns with increasing efforts to more holistically characterize well-being and to guide sustainability management in ethical and equitable ways.</p> </list-item> <list-item> <p>Based on the findings of our review, we identify several pathways forward for the development and implementation of well-being frameworks that can inform efforts to leverage well-being for public policy.</p> </list-item> </list> </p>},
  author   = {Erin C. Betley and Amanda Sigouin and Pua'ala Pascua and Samantha H. Cheng and Kenneth Iain MacDonald and Felicity Arengo and Yildiz Aumeeruddy-Thomas and Sophie Caillon and Marney E. Isaac and Stacy D. Jupiter and Alexander Mawyer and Manuel Mejia and Alexandria C. Moore and Delphine Renard and Lea S\'{e}bastien and Nadav Gazit and Eleanor J. Sterling},
  doi      = {10.1002/pan3.10293},
  issn     = {2575-8314},
  issue    = 6,
  journal  = {People and Nature},
  month    = 12,
  pages    = {1756--1773},
  title    = {Assessing human well-being constructs with environmental and equity aspects: A review of the landscape},
  volume   = 5,
  url      = {https://besjournals.onlinelibrary.wiley.com/doi/10.1002/pan3.10293},
  year     = 2023
}

@article{Bian2015,
  abstract  = {The elderly population is increasing rapidly all over the world. One major risk for elderly people is fall accidents, especially for those living alone. In this paper, we propose a robust fall detection approach by analyzing the tracked key joints of the human body using a single depth camera. Compared to the rivals that rely on the RGB inputs, the proposed scheme is independent of illumination of the lights and can work even in a dark room. In our scheme, a pose-invariant randomized decision tree algorithm is proposed for the key joint extraction, which requires low computational cost during the training and test. Then, the support vector machine classifier is employed to determine whether a fall motion occurs, whose input is the 3-D trajectory of the head joint. The experimental results demonstrate that the proposed fall detection method is more accurate and robust compared with the state-of-the-art methods.},
  author    = {Zhen Peng Bian and Junhui Hou and Lap Pui Chau and Nadia Magnenat-Thalmann},
  doi       = {10.1109/JBHI.2014.2319372},
  issn      = 21682194,
  issue     = 2,
  journal   = {IEEE Journal of Biomedical and Health Informatics},
  keywords  = {3-D,Computer vision,fall detection,head tracking,monocular,video surveillance},
  month     = 3,
  pages     = {430--439},
  pmid      = 24771601,
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Fall detection based on body part tracking using a depth camera},
  volume    = 19,
  year      = 2015
}

@article{Bilasco2008,
  abstract = {Cet article pr\'{e}sente les contributions apport\'{e}es par la prise en compte de la s\'{e}mantique des donn\'{e}es 3D dans leur processus de gestion (Bilasco 2007c). Leur recherche et r\'{e}utilisation deviennent plus efficaces car cette s\'{e}mantique comble la distance entre l'encodage de bas niveau d'une sc\`{e}ne et ce que per\c{c}oivent les utilisateurs des objets \`{a} part enti\`{e}re (b\^{a}timents, arbres, etc.). La visualisation adapt\'{e}e des sc\`{e}nes 3D tire \'{e}galement profit de cet enrichissement s\'{e}mantique. Car les informations sur la nature des objets peuvent \^{e}tre employ\'{e}es afin de filtrer ou, au contraire, de mettre \'{e}vidence certains objets ou cat\'{e}gories d'objets en relation avec les int\'{e}r\^{e}ts des utilisateurs. Nous proposons un mod\`{e}le extensible de description autour duquel nous construisons deux plateformes de r\'{e}utilisation et d'adaptation de sc\`{e}nes 3D. Nous avons valid\'{e} les apports de ces contributions via une application de construction de sc\`{e}nes urbaines.},
  author   = {Ioan Marius Bilasco},
  journal  = {Le Monde des cartes},
  pages    = {31--34},
  title    = {LA S\'{E}MANTIQUE DE SC\`{E}NES 3D Une approche s\'{e}mantique pour l'adaptation et la r\'{e}utilisation de sc\`{e}nes 3D},
  volume   = 198,
  year     = 2008
}

@article{Bimber2008,
  abstract = {This article focuses on real-time image correction techniques that enable projector-camera systems to display images onto screens that are not optimized for projections, such as geometrically complex, colored and textured surfaces. It reviews hardware accelerated methods like pixel-precise geometric warping, radiometric compensation, multi-focal projection, and the correction of general light modulation effects. Online and offline calibration as well as invisible coding methods are explained. Novel attempts in super-resolution, high dynamic range and high-speed projection are discussed. These techniques open a variety of new applications for projection displays. Some of them will also be presented in this report. Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Picture/Image Generation I.4.8 [Image Processing and Computer Vision]: Scene Analysis I.4.9 [Image Processing and Computer Vision]: Applications \textcopyright{} The Eurographics Association 2007.},
  author   = {Oliver Bimber and Daisuke Iwai and Gordon Wetzstein and Anselm Grundhofer},
  doi      = {10.1145/1401132.1401239},
  issue    = {June 2014},
  journal  = {ACM SIGGRAPH 2008 Classes},
  keywords = {Gpu rendering,Image-correction,Projector-camera systems,Virtual and augmented reality},
  pages    = 84,
  title    = {The visual computing of projector-camera systems},
  year     = 2008
}

@article{Bishop1975,
  abstract = {The Frenet frame of a 3-timesc ontinuouslyd ifferentiab(lteh at is, C3) nondegeneratec urvei n euclideans pace has long been the standardv ehiclef ora nalysing propertieso f the curve invariantu nder euclidean motions. For arbitrarym oving framest, hati s, orthonormabl asis fields,w e can expresst he derivativeos f thef rame with respectt o the curvep arameteri n termso f the framei tself,a nd due to orthonormalityt he coefficienmt atrixi s alwayss kew-symmetrTich.u s it generallyh as three nonzeroe ntriesT. he Frenetf rameg ains part of its special significancfer omt he fact that one of the threed erivativeiss alwaysz ero.A notherf eatureo f the Frenetf rame is thati t is adapted to the curve:t he membersa re eithert angentt o or perpendicular to the curve. It is the purpose of this paper to show that there are other frames which have these same advantages and to compare them with the Frenet frame},
  author   = {Richard L. Bishop},
  doi      = {10.2307/2319846},
  issn     = {00029890},
  issue    = 3,
  journal  = {The American Mathematical Monthly},
  pages    = 246,
  title    = {There is More than One Way to Frame a Curve},
  volume   = 82,
  year     = 1975
}

@article{Bitiusca2016,
  author = {Liviu-George Bitiușc\u{a}},
  issue  = {August},
  title  = {Eulerian Fluid Simulator},
  year   = 2016
}

@article{Blomqvist2016,
  author = {Oscar Blomqvist and Pierre Kraft and Hampus Lidin and Rimmer Motzheim and Adam Tonderski and Gabriel Wagner},
  issue  = {June},
  title  = {Generating Compelling Procedural 3D Environments and Landscapes},
  year   = 2016
}

@inbook{Bloomenthal1990,
  author  = {Jules Bloomenthal},
  doi     = {10.1016/B978-0-08-050753-8.50124-8},
  isbn    = 9780080507538,
  journal = {Graphics Gems},
  pages   = {567--571},
  title   = {Calculation Of Reference Frames Along A Space Curve},
  volume  = 1,
  url     = {http://webhome.cs.uvic.ca/~blob/courses/305/notes/pdf/ref-frames.pdf},
  year    = 1990
}

@inbook{Bloomenthal1994,
  abstract = {An algorithm for the polygonization of implicit surfaces is described and an implementation in C is provided. The discussion reviews implicit surface polygonization, and compares various methods.},
  author   = {Jules Bloomenthal},
  doi      = {10.1016/b978-0-12-336156-1.50040-9},
  journal  = {Graphics Gems},
  pages    = {324--349},
  title    = {An Implicit Surface Polygonizer},
  url      = {https://people.eecs.berkeley.edu/~jrs/meshpapers/Bloomenthal.pdf},
  year     = 1994
}

@article{Bloomenthal1997,
  abstract = {Implicit surfaces are two-dimensional, geometric shapes that exist in three dimensional space. They are defined according to a particular mathematical form. This article examines their definition, representation, and geometric properties. Related fields are discussed and practical methods are reviewed.},
  author   = {Jules Bloomenthal},
  isbn     = {155860233X},
  journal  = {Introduction to implicit surfaces},
  pages    = {3--51},
  title    = {The Geometry of Implicit Surfaces},
  url      = {http://www.cs.princeton.edu/courses/archive/fall03/cs526/papers/bloomenthal02.pdf},
  year     = 1997
}

@unpublished{Blow2000,
  author = {Jonathan Blow},
  title  = {Terrain Rendering at High Levels of Detail Part I : Fast Reduction of Texture Memory Usage for Terrain Rendering},
  year   = 2000
}

@article{BMPG11,
  abstract = {We present a novel approach to fluid simulation over complex dynamic geometry designed for the specific context of virtual surgery simulation. The method combines a surface-based fluid simulation model with a multi-layer depth peeling representation to allow realistic yet efficient simulation of bleeding on complex surfaces undergoing geometry and topology modifications. Our implementation allows for fast fluid propagation and accumulation over the entire scene, and runs on the GPU at a constant low cost that is independent of the amount of blood in the scene. The proposed bleeding simulation is integrated in a complete simulator for brain tumor resection, where trainees have to manage blood aspiration and tissue/vessel cauterization while they perform virtual surgery tasks. \textcopyright{} 2011 Springer-Verlag.},
  author   = {Louis Borgeat and Philippe Massicotte and Guillaume Poirier and Guy Godin},
  doi      = {10.1007/978-3-642-23623-5\_41},
  isbn     = 9783642236228,
  issn     = {03029743},
  issue    = {PART 1},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {GPU,aspiration,bleeding,cauterization,depth peeling,fluid simulation,neurosurgery,surgery,visual simulation},
  pages    = {323--330},
  pmid     = 22003633,
  title    = {Layered surface fluid simulation for surgical training},
  volume   = {6891 LNCS},
  url      = {https://publications-cnrc.canada.ca/fra/voir/accept\'{e}/?id=ed339668-26bb-4efc-8301-69f0f5e3fc54},
  year     = 2011
}

@misc{Boers1995,
  abstract = {This paper will show how the interpretation of strings resulting from L-systems can be adapted in such a way that L-systems can be used as graph grammars. One of the advantages of this adaptation is the possibility to make use of the context dependency available in L-systems. This context is calculated by using the graph interpretation of the strings at each successive step of the rewriting mechanism. The modifications to L-systems necessary in order to use them as graph grammars will be explained. A simple proof will be given that every possible directed graph can be generated using this representation. At the end of the paper an application of this G2L-system based graph grammar will be presented. In this application a genetic algorithm optimizes the rewriting rules of an G2L-system, trying to come to a more scalable method for finding good artificial neural network architectures in comparison with methods that do not use graph grammars. The presented G2L-system was specifically designed for this application to favour modular networks, but might be useful in general as well},
  author   = {Egbert J. W. Boers},
  issue    = {October},
  keywords = {artificial neural networks,genetic algorithms,graph grammars,l-systems,modularity},
  title    = {Using L-Systems as Graph Grammar: G2L-Systems},
  url      = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.9935\&rep=rep1\&type=pdf},
  year     = 1995
}

@article{Bohannon2011,
  abstract = {Background Walking speed has implications for community functioning and is predictive of important outcomes. Determining whether an individual's walking speed is limited requires normal values for comparison. Objectives To use meta-analysis to describe normal gait speed for healthy individuals within age and gender strata. Data sources PubMed, the Cumulative Index of Nursing and Allied Health (CINAHL), Scopus, Science Citation Index and articles identified by hand searches. Study selection criteria Inclusion required that the gait speed of apparently healthy adults was documented as they walked at a normal pace over a course of 3 to 30 m. Summary data were excluded unless obtained from at least 10 participants within a gender and decade stratum. Study appraisal and synthesis methods The two authors independently reviewed articles and extracted data. Accuracy was confirmed by the other author. Data were grouped within gender and decade strata. A meta-analysis macro was used to consolidate data by strata and to determine homogeneity. Results Forty-one articles contributed data to the analysis. Combined, they provided data from 23 111 subjects. The gait speed was homogeneous within strata and ranged from a mean of 143.4 cm/second for men aged 40 to 49 years to a mean of 94.3 cm/second for women aged 80 to 99 years. Limitations The data presented herein may not be useful as a standard of normal if gait is measured over short distances from the command 'go' or if a turn is involved. Conclusions and implications The consolidation of data from multiple studies reported in this meta-analysis provides normative data that can serve as a standard against which individuals can be compared. Doing so will aid the interpretation of their performance.},
  author   = {Richard W Bohannon and A Williams Andrews},
  doi      = {10.1016/j.physio.2010.12.004},
  journal  = {Physiotherapy},
  pages    = {182--189},
  title    = {Systematic review Normal walking speed: a descriptive meta-analysis},
  volume   = 97,
  year     = 2011
}

@article{Boissonnat2002,
  abstract = {We present an algorithm to reconstruct smooth surfaces of arbitrary topology from unorganised sample points and normals. The method uses natural neighbour interpolation, works in any dimension and accommodates nonuniform samples. The reconstructed surface interpolates the data points and is implicitly represented as the zero set of some pseudo-distance function. It can be meshed so as to satisfy a user-defined error bound, which makes the method especially relevant for small point sets. Experimental results are presented for surfaces in \mathbb{R}3. \textcopyright{}2001 Elsevier Science B.V. All rights reserved.},
  author   = {Jean Daniel Boissonnat and Fr\'{e}d\'{e}ric Gazais},
  doi      = {10.1016/S0925-7721(01)00048-7},
  isbn     = 1581132247,
  issn     = {09257721},
  issue    = {1-3},
  journal  = {Computational Geometry: Theory and Applications},
  keywords = {Delaunay triangulation,Natural neighbour interpolation,Reconstruction,Smooth surface,Voronoi diagram},
  pages    = {185--203},
  title    = {Smooth surface reconstruction via natural neighbour interpolation of distance functions},
  volume   = 22,
  url      = {https://dl.acm.org/doi/pdf/10.1145/336154.336208},
  year     = 2002
}

@article{Boldea2009,
  abstract = {A new cellular-automaton model for fluid dynamics is introduced in this paper, that focus on discrete models based on point particles moving on a lattice in order to mimic a fully molecular dynamics. The CA model uses an easily implementable, deterministic pair of interaction rules. Therefore, we combine the advantage of the low computational cost of CA and its ability to mimic the realistic fluid dynamics to develop a new animating framework for computer graphics applications.},
  author   = {Costin-Radu Boldea},
  issn     = {1223-6934},
  issue    = 2,
  journal  = {Math. Comp. Sci. Ser},
  keywords = {2000 Mathematics Subject Classification Primary 68Q80; Secondary 37B15 Key words and phrases Cellular automata,Lattice gas models,Navier-Stokes equation},
  pages    = {35--41},
  title    = {A Particle Cellular Automata Model for Fluid Simulations},
  volume   = 36,
  year     = 2009
}

@article{Bonneel2015,
  author   = {Nicolas Bonneel and Julien Rabin and Gabriel Peyr\'{e} and Hanspeter Pfister},
  doi      = {10.1007/s10851-014-0506-3},
  issn     = {0924-9907},
  issue    = 1,
  journal  = {Journal of Mathematical Imaging and Vision},
  keywords = {barycenter of measures,optimal transport,radon transform,stein distance,wasser-},
  month    = 1,
  pages    = {22--45},
  title    = {Sliced and Radon Wasserstein Barycenters of Measures},
  volume   = 51,
  url      = {http://link.springer.com/10.1007/s10851-014-0506-3},
  year     = 2015
}

@inproceedings{Bossavit2011,
  abstract  = {Multitouch interaction has some unique strengths, one of them being that direct touch on 2D screens makes it fast and easy. Unfortunately, because of stereo disparity and content occlusion, direct touch interaction becomes an issue as soon as 3D stereoscopic content is visualized. We propose a new system that combines efficient direct multitouch interaction with co-located 3D stereoscopic visualization. In our approach, users benefit from well-known 2D metaphors and widgets displayed on a monoscopic touchscreen while visualizing 3D objects floating above the surface at an optically correct distance (see Figure 1(a)).},
  author    = {Benoit Bossavit and Jean-Baptiste de la Rivi\`{e}re and Toni Da Luz and Mathieu Courtois and C\'{e}dric Kervegant and Martin Hachet},
  city      = {New York, New York, USA},
  doi       = {10.1145/2048259.2048266},
  isbn      = 9781450309691,
  booktitle = {ACM SIGGRAPH 2011 Emerging Technologies on - SIGGRAPH '11},
  pages     = {1--1},
  publisher = {ACM Press},
  title     = {An immersive multitouch workspace},
  url       = {http://dl.acm.org/citation.cfm?doid=2048259.2048266},
  year      = 2011
}

@article{Bosscher1992,
  abstract = {Light is one of the major controls on reef growth and carbonate production. The growth of present reef builders depends largely upon the amount of light available for photosynthesis. As light decreases with water depth, so does reef growth. The computer model presented extends this principle by combining two functions, one for photosynthesis and the other for the extinction of light in water. The model is used to simulate the growth of Alacran Reef, Mexico, two reefs of the Great Barrier Reef and the reefs of the windward platform of St Croix, US Virgin Islands. The model also gives an accurate simulation of the growth of fore-reef walls in Belize, in agreement with the accretion hypothesis developed for this feature. Copyright \textcopyright{} 1992, Wiley Blackwell. All rights reserved},
  author   = {HEMMO BOSSCHER and WOLFGANG SCHLAGER},
  doi      = {10.1111/j.1365-3091.1992.tb02130.x},
  issn     = 13653091,
  issue    = 3,
  journal  = {Sedimentology},
  pages    = {503--512},
  title    = {Computer simulation of reef growth},
  volume   = 39,
  year     = 1992
}

@article{Botsch2004,
  abstract = {We present a freeform modeling framework for unstructured triangle meshes which is based on constraint shape optimization. The goal is to simplify the user interaction even for quite complex freeform or multiresolution modifications. The user first sets various boundary constraints to define a custom tailored (abstract) basis function which is adjusted to a given design task. The actual modi fication is then controlled by moving one single 9-dof manipulator object. The technique can handle arbitrary support regions and piecewise boundary conditions with smoothness ranging continuously from C 0 to C2. To more naturally adapt the modification to the shape of the support region, the deformed surface can be tuned to bend with anisotropic stiffness. We are able to achieve real-time response in an interactive design session even for complex meshes by precomputing a set of scalar-valued basis functions that correspond to the degrees of freedom of the manipulator by which the user controls the modification. Copyright \textcopyright{} 2004 ACM.},
  author   = {Mario Botsch and Leif Kobbelt},
  doi      = {10.1145/1186562.1015772},
  issue    = 1,
  journal  = {ACM SIGGRAPH 2004 Papers, SIGGRAPH 2004},
  keywords = {Freeform design,Surface editing,User interaction},
  pages    = {630--634},
  title    = {An intuitive framework for real-time freeform modeling},
  url      = {http://mesh.brown.edu/dgp/pdfs/Botsch-sg2004.pdf},
  year     = 2004
}

@book{Boudon,
  author = {Fred Boudon},
  title  = {Mod\'{e}lisation G\'{e}om\'{e}trique Quelques propri\'{e}t\'{e}s des maillages Repr\'{e}sentation par Cartes Combinatoires G\'{e}n\'{e}ralis\'{e}es}
}

@article{Bourret2008,
  abstract = {This study investigates the circulation on the French Guiana continental shelf under tidal influence. Indeed, hydrodynamics are characterised by a weak salinity tongue located in the middle of the shelf and induced by the Amazon River, a coastal current flowing from the southeast, and a tidal standing wave whose co-range lines are parallel to the coast. In addition to field observations, a numerical model also is used to evaluate the tidal influence on coastal circulation. The model makes use of the MOBEEHDYCS code, a three-dimensional free surface time-splitting model whose domain is bounded with a closed coastal boundary, two active boundaries (offshore and lateral) and a passive boundary. The boundary configuration and hydrodynamics require a careful choice of passive open boundary conditions. The initial and boundary conditions come from field data. The tidal currents are essentially cross-shore and do not have a great influence on the main current direction on the offshore part of the shelf. The offshore currents remain parallel to the coast. In the inner shelf, the tidal influence is found to be much more important and the tidal currents can reach 0.45 m/s. Vertically, the tidal currents are barotropic, in spite of the high stratification and they induce a horizontal cross-shore migration (about 3 km) of the weak salinity tongue and vertical oscillations of the halocline without complete mixing. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
  author   = {A. Bourret and J. L. Devenon and C. Chevalier},
  doi      = {10.1016/j.csr.2008.01.008},
  issn     = {02784343},
  issue    = 7,
  journal  = {Continental Shelf Research},
  keywords = {Coast circulation modelling,French Guiana continental shelf,Tidal influence},
  pages    = {951--961},
  title    = {Tidal influence on the hydrodynamics of the French Guiana continental shelf},
  volume   = 28,
  year     = 2008
}

@article{Bouwmeester2022,
  abstract = {The Persian Gulf is a thermally extreme environment in which reef corals have adapted to survive through temperature ranges that would be lethal to corals from other regions. Despite offering a unique opportunity to better understand how corals from other regions may adapt in the future, through a changing climate, much of the Gulf coral and fish communities remain to be described. In the southwestern Gulf nation of Qatar few reef sites have been described to date. We here characterize reef communities from 16 sites around the Qatar Peninsula, encompassing depths from 3 to 25m. We found the healthiest coral reef communities to be in deeper offshore reefs, with high coral and fish species richness and high coral abundance, likely a result of their occurrence below summer thermocline depths and distance from urban pressures. In contrast, we found shallow reefs, both nearshore and offshore, to have low species richness and abundance relative to deeper reefs, presumably due to impacts from recurrent bleaching events and development pressures over recent decades. The results of this work underscore the Qatar Peninsula as being at the biogeographic epicenter of the wider Gulf. However, further temperature increases may push both fishes and corals over their physiological limits. Management efforts at both the regional and global level are needed to reduce thermal stressors and preserve the rich reef ecosystems found in the waters surrounding Qatar.},
  author   = {Jessica Bouwmeester and Radhouane Ben-Hamadou and Pedro Range and Fahad Al Jamali and John A. Burt},
  doi      = {10.3389/fmars.2022.989841},
  issn     = 22967745,
  issue    = {September},
  journal  = {Frontiers in Marine Science},
  keywords = {Arabian Gulf,Persian Gulf,Scleractinia,climate change,coral communities,fish communities,thermal adaptation},
  pages    = {1--14},
  title    = {Spatial patterns of reef fishes and corals in the thermally extreme waters of Qatar},
  volume   = 9,
  year     = 2022
}

@article{Bowen2007,
  abstract  = {Many different methods exist for the design and implementation of software systems. These methods may be fully formal, such as the use of formal specification languages and refinement processes, or they may be totally informal, such as jotting design ideas down on paper prior to coding, or they may be somewhere in between these two extremes. Formal methods are naturally suited to underlying system behaviour while user-centred approaches to user interface design fit comfortably with more informal approaches. The challenge is to find ways of integrating user-centred design methods with formal methods so that the benefits of both are fully realised. This paper presents a way of capturing the intentions behind informal design artefacts within a formal environment and then shows several applications of this approach. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  author    = {Judy Bowen and Steve Reeves},
  doi       = {10.1016/j.entcs.2007.01.061},
  issn      = 15710661,
  issue     = {SPEC. ISS.},
  journal   = {Electronic Notes in Theoretical Computer Science},
  keywords  = {Formal methods,GUIs,informal design artefacts,refinement,user-centred design},
  month     = 7,
  pages     = {57--72},
  publisher = {Elsevier},
  title     = {Formal Models for Informal GUI Designs},
  volume    = 183,
  year      = 2007
}

@article{Brackbill1988,
  abstract = {The FLIP (Fluid-Implicit-Particle) method uses fully Lagrangian particles to eliminate convective transport, the largest source of computational diffusion in calculations of fluid flow. FLIP is an adaptation to fluids of the implicit moment method for simulating plasmas, in which particles carry everything necessary to describe the fluid. Using the particle data, Lagrangian moment equations are solved on a grid. The solutions are then used to advance the particle variables from time step to time step. An adaptive grid and implicit time differencing extend the method to multiple time and space scale flows. Aspects of FLIP's properties are illustrated by modeling of a confined eddy, a Rayleigh-Taylor, an unstable subsonic stream, and a supersonic jet. The results demonstrate FLIP's instability applicability to hydrodynamic stability problems where low dissipation is crucial to correct modeling. \textcopyright{} 1988.},
  author   = {J. U. Brackbill and D. B. Kothe and H. M. Ruppel},
  doi      = {10.1016/0010-4655(88)90020-3},
  issn     = {00104655},
  issue    = 1,
  journal  = {Computer Physics Communications},
  pages    = {25--38},
  title    = {Flip: A low-dissipation, particle-in-cell method for fluid flow},
  volume   = 48,
  year     = 1988
}

@article{Bradbury2015,
  abstract = {In this paper we present a novel approach to author vegetation cover of large natural scenes. Unlike stochastic scatter-instancing tools for plant placement (such as multi-class blue noise generators), we use a simulation based on ecological processes to produce layouts of plant distributions. In contrast to previous work on ecosystem simulation, however, we propose a framework of global and local editing operators that can be used to interact directly with the live simulation. The result facilitates an artist-directed workflow with both spatially and temporally-varying control over the simulation's output. We compare our result against random-scatter solutions, also employing such approaches as a seed to our algorithm. We demonstrate the versatility of our approach within an iterative authoring workflow, comparing it to typical artistic methods.},
  author   = {Gwyneth A Bradbury and Kartic Subr and Charalampos Koniaris and Kenny Mitchell and Tim Weyrich},
  issue    = 4,
  journal  = {The Journal of Computer Graphics Techniques},
  pages    = {28--53},
  title    = {Guided Ecological Simulation for Artistic Editing of Plant Distributions in Natural Scenes},
  volume   = 4,
  url      = {https://pure.hw.ac.uk/ws/portalfiles/portal/10342646/Bradbury2015Guided\_lowres.pdf},
  year     = 2015
}

@article{Brandel2005,
  abstract = {The present article proposes a method to significantly improve the construction and updating of 3D geological models used for oil and gas exploration. We present a prototype of a "geological pilot" which enables monitoring the automatic building of a 3D model topologically and geologically consistent, on which geological links between objects can easily be visualized. This model can automatically be revised in case of changes in the geometric data or in the interpretation. Copyright \textcopyright{} 2005 by ASME.},
  author   = {Sylvain Brandel and S\'{e}bastien Schneider and Michel Perrin and Nicolas Guiard and Jean Fran\c{c}ais Rainaud and Pascal Lienhard and Yves Bertrand},
  doi      = {10.1115/1.1884145},
  issn     = 15309827,
  issue    = 2,
  journal  = {Journal of Computing and Information Science in Engineering},
  pages    = {138--148},
  title    = {Automatic building of structured geological models},
  volume   = 5,
  url      = {https://d1wqtxts1xzle7.cloudfront.net/41885114/Automatic\_Building\_of\_Structured\_Geologi20160202-27158-1inzl1z-libre.pdf?1454417125=\&response-content-disposition=inline\%3B+filename\%3DAutomatic\_Building\_of\_Structured\_Geologi.pdf\&Expires=1666519771\&Signature},
  year     = 2005
}

@article{Brandt2019,
  abstract = {We introduce the Reduced Immersed Method (RIM) for the real-time simulation of two-way coupled incompressible fluids and elastic solids and the interaction of multiple deformables with (self-)collisions. Our framework is based on a novel discretization of the immersed boundary equations of motion, which model fluid and deformables as a single incompressible medium and their interaction as a unified system on a fixed domain combining Eulerian and Lagrangian terms. One advantage for real-time simulations resulting from this modeling is that two-way coupling phenomena can be faithfully simulated while avoiding costly calculations such as tracking the deforming fluid-solid interfaces and the associated fluid boundary conditions. Our discretization enables the combination of a PIC/FLIP fluid solver with a reduced-order Lagrangian elasticity solver. Crucial for the performance of RIM is the efficient transfer of information between the elasticity and the fluid solver and the synchronization of the Lagrangian and Eulerian settings. We introduce the concept of twin subspaces that enables an efficient reduced-order modeling of the transfer. Our experiments demonstrate that RIM handles complex meshes and highly resolved fluids for large time steps at high framerates on of-the-shelf hardware, even in the presence of high velocities and rapid user interaction. Furthermore, it extends reduced-order elasticity solvers such as Hyper-Reduced Projective Dynamics with natural collision handling.},
  author   = {Christopher Brandt and Leonardo Scandolo and Elmar Eisemann and Klaus Hildebrandt},
  doi      = {10.1145/3355089.3356496},
  issn     = 15577368,
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {Elastic solids,Fluid simulation,Immersed boundary method,Model reduction,Projective dynamics,Real-time simulation,Solid-fluid coupling,Subspace dynamics},
  title    = {The reduced immersed method for real-time fluid-elastic solid interaction and contact simulation},
  volume   = 38,
  url      = {https://graphics.tudelft.nl/Publications-new/2019/BSEH19/immersed.pdf},
  year     = 2019
}

@article{Braz2007,
  author  = {Jos\'{e} Braz and Alpesh Ranchordas and Helder Ara\'{u}jo and Joaquim Jorge},
  doi     = {10.1007/978-3-540-75274-5},
  isbn    = 9783540752721,
  issn    = 18650929,
  issue   = {January},
  journal = {Communications in Computer and Information Science},
  title   = {Terrain Synthesis by example},
  volume  = {4 CCIS},
  year    = 2007
}

@article{Bremaud2017,
  abstract = {This section features what is perhaps the earliest non-trivial result concerning the evolution of a stochastic process, namely the Galton–Watson branching process. It involves a graph, here a ``genealogical'' tree.},
  author   = {Pierre Br\'{e}maud},
  doi      = {10.1007/978-3-319-43476-6\_10},
  issn     = 21993149,
  journal  = {Probability Theory and Stochastic Modelling},
  keywords = {Bond Percolation,Extinction Probability,Giant Component,Random Graph,Subcritical Case},
  pages    = {255--286},
  title    = {Random Graphs},
  volume   = 78,
  year     = 2017
}

@book{Bressan2005,
  author  = {St\'{e}phane Bressan and Stefano Ceri and Zohra Bellahsene and Ela Hunt and Zachary Ives and Rainer Unland and Michael Rys},
  isbn    = 9783540497769,
  issn    = {03029743},
  journal = {Lecture Notes in Computer Science},
  note    = {For pages, add 21<br/><br/>Can be useful:<br/>- Evolving Creatures in Virtual Ecosystems (p 11)<br/>? Ridge-Valley Lines Smoothing and Optimizing (p. 502)<br/>? Creating Dynamic Panorama Using Particle Swarm Optimization (p. 676)<br/>- Real-Time and Realistic Simulation of Large-Scale Deep Ocean Surface (p. 686)<br/>- Exploiting Frame-to-Frame Coherence for Rendering Terrain Using Continuous LOD (p. 695)<br/>- Animating Grass in Real-Time (p. 724)<br/>- Example-Based Realistic Terrain Generation (p. 811)<br/>? A Seamless Visualizaton Model of the Global Terrain Based on the QTM (p. 1136)<br/><br/>Curiosity:<br/>- Steering Behavior Model of Visitor NPCs in Virtual Exhibition (p. 113)<br/>- Emotion Recognition Using Physiological Signals (p. 437)<br/>- Sketch Based 3D Animation Copy (p. 474)<br/>- Robust Motion Tracking in Video Sequences Using Particle Filter (p. 540)},
  title   = {Lecture Notes in Computer Science: Preface},
  volume  = 3671,
  year    = 2005
}

@article{Bridson2007,
  abstract = {In many applications in graphics, particularly rendering, generating samples from a blue noise distribution is important. However, existing efficient techniques do not easily generalize beyond two dimensions. Here I demonstrate a simple modification to dart throwing which permits generation of Poisson disk samples in O(N) time, easily implemented in arbitrary dimension.},
  author   = {Robert Bridson},
  doi      = {10.1145/1278780.1278807},
  journal  = {ACM SIGGRAPH 2007 Sketches, SIGGRAPH'07},
  keywords = {Blue noise,Poisson disk,Sampling},
  pages    = 2006,
  title    = {Fast poisson disk sampling in arbitrary dimensions},
  url      = {https://www.cs.ubc.ca/~rbridson/docs/bridson-siggraph07-poissondisk.pdf},
  year     = 2007,
  issn     = {07300301},
  issue    = 99,
  volume   = 26
}

@article{Bridson2007a,
  author  = {Robert Bridson and Matthias M\"{u}ller-Fischer},
  doi     = {10.1145/1281500.1281681},
  journal = {ACM SIGGRAPH 2007 Papers - International Conference on Computer Graphics and Interactive Techniques},
  title   = {Fluid simulation},
  year    = 2007
}

@article{Brosz2007,
  abstract = {Synthesizing terrain or adding detail to terrains manually is a long and tedious process. With procedural synthesis methods this process is faster but more difficult to control. This paper presents a new technique of terrain synthesis that uses an existing terrain to synthesize new terrain. To do this we use multi-resolution analysis to extract the high-resolution details from existing models and apply them to increase the resolution of terrain. Our synthesized terrains are more heterogeneous than procedural results, are superior to terrains created by texture transfer, and retain the large-scale characteristics of the original terrain. \textcopyright{} Springer-Verlag Berlin Heidelberg 2007.},
  author   = {John Brosz and Faramarz F. Samavati and Mario Costa Sousa},
  doi      = {10.1007/978-3-540-75274-5\_4},
  isbn     = 9783540752721,
  issn     = 18650929,
  journal  = {Communications in Computer and Information Science},
  keywords = {Terrain synthesis,modeling,multi-fractals,multi-resolution analysis},
  pages    = {58--77},
  title    = {Terrain Synthesis By-Example},
  volume   = {4 CCIS},
  url      = {https://ires.cpsc.ucalgary.ca/publ/papers/2006/refs/Brosz et al. '06.pdf},
  year     = 2007
}

@misc{Brun,
  author = {Luc Brun},
  title  = {Liste biblio cartes topologiques},
  url    = {https://brunl01.users.greyc.fr/BIBLI\_PERSO/fr/themes/theme\_hierarchical\_authordate.html}
}

@inbook{Brun2012,
  author = {Luc Brun and Walter Kropatsch},
  issue  = {June},
  title  = {Image Processing and Analysing With Graphs : Theory and Practice Chapter 1},
  year   = 2012
}

@misc{BSPanda2016,
  author = {B. S. Panda},
  title  = {Chordal Graphs : Theory and Algorithms Chordal graphs},
  url    = {https://web.iitd.ac.in/~bspanda/chordal.pdf}
}

@article{Buckee2022,
  abstract = {Sea level exerts a fundamental influence on the intertidal zone, where organisms are subject to immersion and emersion at varying timescales and frequencies. While emersed, intertidal organisms are exposed to atmospheric stressors which show marked diurnal and seasonal variability, therefore the daily and seasonal timing of low water is a key determinant of survival and growth in this zone. Using the example of shallow coral reefs, the coincidence of emersion with selected stressors was investigated for eight locations around the Australian coastline. Hourly water levels (1992 – 2016) from a high-resolution sea level hindcast (http://sealevelx.ems.uwa.edu.au), were linked to maximum surface solar radiation data from the Copernicus ERA5 atmospheric model and minimum atmospheric temperature observations from the Australian Bureau of Meteorology to identify seasonal patterns and historical occurrence of coral emersion mortality risk. Local tidal characteristics were found to dictate the time of day when low water, and therefore emersion mortality risk occurs, varying on a seasonal and regional basis. In general, risk was found to be greatest during the Austral spring when mean sea levels are lowest and a phase change in solar tidal constituents occurs. For all Great Barrier Reef sites, low tide occurs close to midday during winter and midnight in the summer, which may be fundamental factor supporting the historical bio-geographical development of the reef. Interannual variability in emersion mortality risk was mostly driven by non-tidal factors, particularly along the West Coast where El Ni\~{n}o events are associated with lower mean sea levels. This paper highlights the importance of considering emersion history when assessing intertidal environments, including shallow coral reef platform habitats, where critical low water events intrinsically influence coral health and cover. The study addresses a fundamental knowledge gap in both the field of water level science and intertidal biology in relation to the daily timing of low tide, which varies predictably on a seasonal and regional basis.},
  author   = {Joanna Buckee and Yasha Hetzel and William Edge and Jennifer Verduin and Chari Pattiaratchi},
  doi      = {10.3389/fmars.2022.904191},
  issn     = 22967745,
  issue    = {September},
  journal  = {Frontiers in Marine Science},
  keywords = {El Ni\~{n}o southern oscillation,coral reef disturbance,coral reef formation,sea level variability,sub-aerial exposure,tidal regime},
  pages    = {1--21},
  title    = {Daily timing of low tide drives seasonality in intertidal emersion mortality risk},
  volume   = 9,
  year     = 2022
}

@article{Buddemesier1976,
  abstract = {The study of coral biology in genera\l{}, and coral skeletal growth in particular has a special fascination because it reaches back even beyond the origin of classical biology to the studies and collections of the earliest naturalis ts. Y et, in spite of the antiquity and continuity of scientific attention, many of the problems considered by these investigators are stillunder active study today, together with a wide variety of more recently formulated questions. Because of i ts long past and modern diversity the subject of coral growth has a large and scattered literature and a comparably diverse foUowing. As in any broadly interdisciplinary research area, communication and assimila- tion of results and concepts in the field as a whole often lag far behind the level of sophistication of specific sub-disciplines. Our intention in this review is to assemble and compare the questions and results of various studies of coral skeletal accretion in order to disseminate as widely as possible informa- tion about mutually relevant investigations with different purposes and methodologies. It should be clearly understood that 'coral growth studies' are in reality methods or experimental approaches to larger fields of interest, each with its own literature and terminology. We will summadze briefly the different reasons for investigation of coral growth before integrating these into a review of methods and results.},
  author   = {R. W. Buddemesier and R. A. Kinzie III},
  doi      = {10.4324/9781315265353-4},
  journal  = {Oceanographic Marine Biology Annual Revue},
  pages    = {183--225},
  title    = {Coral growth},
  volume   = 14,
  year     = 1976
}

@article{Buhler2011,
  abstract = {We present a theoretical and numerical study of the decay of an internal wave caused by scattering at undulating sea-floor topography, with an eye towards building a simple model in which the decay of internal tides in the ocean can be estimated. As is well known, the interactions of internal waves with irregular boundary shapes lead to a mathematically ill-posed problem, so care needs to be taken to extract meaningful information from this problem. Here, we restrict the problem to two spatial dimensions and build a numerical tool that combines a real-space computation based on the characteristics of the underlying partial differential equation with a spectral computation that satisfies the relevant radiation conditions. Our tool works for finite-amplitude topography but is restricted to subcritical topography slopes. Detailed results are presented for the decay of the gravest vertical internal wave mode as it encounters finite stretches of either sinusoidal topography or random topography defined as a Gaussian random process with a simple power spectrum. A number of scaling laws are identified and a simple expression for the decay rate in terms of the power spectrum is given. Finally, the resulting formulae are applied to an idealized model of sea-floor topography in the ocean, which seems to indicate that this scattering process can provide a rapid decay mechanism for internal tides. However, the present results are restricted to linear fluid dynamics in two spatial dimensions and to uniform stratification, which restricts their direct application to the real ocean. \textcopyright{} 2011 Cambridge University Press.},
  author   = {Oliver B\"{u}hler and Miranda Holmes-Cerfon},
  doi      = {10.1017/jfm.2011.115},
  issn     = {00221120},
  journal  = {Journal of Fluid Mechanics},
  keywords = {Internal waves,topographic effects,wave scattering},
  pages    = {271--293},
  title    = {Decay of an internal tide due to random topography in the ocean},
  volume   = 678,
  year     = 2011
}

@article{Burt2013,
  abstract    = {Buildings with intermittent occupancy may not perform thermally the same as typical commercial and residential facilities. Thermal comfort requirements require careful envelope design coupled with the appropriate air-conditioning system operation strategies. One of the most prominent examples of such buildings is mosques. Mosques are usually occupied five intermittent times day and night all year round. Like any other building, they have to be mechanically air-conditioned to achieve the required thermal comfort for worshippers especially in harsh climatic regions. This paper describes the physical and operating characteristics typical for the intermittently occupied mosques as well as the results of the thermal optimization of a medium size mosque in the two hot-dry and hot-humid Saudi Arabian cities of Riyadh and Jeddah. The analysis utilizes a direct search optimization technique that is coupled to an hourly energy simulation program. Based on that, design guidelines are presented for the optimum thermal performance of mosques in these two cities in addition to other design and operating factors that need to be considered for mosques in general. \textcopyright{} 2009 The Author(s).},
  author      = {Thomas Burt},
  institution = {University of Calgary},
  title       = {Interactive Evolutionary Computation by Duplication and Diversification of L-Systems},
  url         = {http://algorithmicbotany.org/papers/tburt.th2013.small.pdf},
  year        = 2013
}

@article{Buys2014,
  abstract = {Human body detection and pose estimation is useful for a wide variety of applications and environments. Therefore a human body detection and pose estimation system must be adaptable and customizable. This paper presents such a system that extracts skeletons from RGB-D sensor data. The system adapts on-line to difficult unstructured scenes taken from a moving camera (since it does not require background subtraction) and benefits from using both color and depth data. It is customizable by virtue of requiring less training data, having a clearly described training method, and a customizable human kinematic model. Results show successful application to data from a moving camera in cluttered indoor environments. This system is open-source, encouraging reuse, comparison, and future research. \textcopyright{} 2013 Elsevier Inc. All rights reserved.},
  author   = {Koen Buys and Cedric Cagniart and Anatoly Baksheev and Tinne De Laet and Joris De Schutter and Caroline Pantofaru},
  doi      = {10.1016/j.jvcir.2013.03.011},
  issn     = 10473203,
  issue    = 1,
  journal  = {Journal of Visual Communication and Image Representation},
  keywords = {Body part recognition,Joint locations,Motion capture,Open source,Person detection,Pose detection,RGB-D data,Random decision forest,Real-time},
  month    = 1,
  pages    = {39--52},
  title    = {An adaptable system for RGB-D based human body detection and pose estimation},
  volume   = 25,
  year     = 2014
}

@article{Canezin2013,
  abstract = {Recent advances in implicit surface modeling now provide highly controllable blending effects. These effects rely on the field functions of R3\rightarrow{}R in which the implicit surfaces are defined. In these fields, there is an outside part in which blending is defined and an inside part. The implicit surface is the interface between these two parts. As recent operators often focus on blending, most efforts have been made on the outer part of field functions and little attention has been paid on the inner part. Yet, the inner fields are important as soon as difference and intersection operators are used. This makes its quality as crucial as the quality of the outside. In this paper, we analyze these shortcomings, and deduce new constraints on field functions such that differences and intersections can be seamlessly applied without introducing discontinuities or field distortions. In particular, we show how to adapt state of the art gradient-based union and blending operators to our new constraints. Our approach enables a precise control of the shape of both the inner or outer field boundaries. We also introduce a new set of asymmetric operators tailored for the modeling of fine details while preserving the integrity of the resulting fields. \textcopyright{} 2013 Elsevier Ltd.},
  author   = {Florian Canezin and Ga\"{e}l Guennebaud and Lo\"{\i}c Barthe},
  doi      = {10.1016/j.cag.2013.05.024},
  issn     = {00978493},
  issue    = 6,
  journal  = {Computers and Graphics (Pergamon)},
  keywords = {Blending,CSG,Composition operators,Details,Field functions,Geometric modeling,Implicit surfaces},
  pages    = {565--573},
  title    = {Adequate inner bound for geometric modeling with compact field functions},
  volume   = 37,
  url      = {https://www.irit.fr/recherches/VORTEX/publications/rendu-geometrie/SMI2013\_Canezin\_et\_al.pdf},
  year     = 2013
}

@article{Carenini2010,
  abstract = {This paper presents an interactive interface to create visually structured summaries of human conversations via ontology mapping. We have built highly accurate classifiers for mapping the sentences of a conversation in an ontology, which includes nodes for the Dialog Acts (DA) properties such as decision and subjective, along with nodes for the conversation participants. In contrast with previous work, our classifiers do not rely on features specific to any particular conversational modality. We are currently developing an interactive interface that allows the user to generate visual structured summaries by searching a conversation for sentences according to the ontology mapping. Our first prototype comprises two panels. The right panel displays the ontology, while the left panel of the our prototype displays the whole conversation, where sentences are temporally ordered. Given the information displayed in the two panels, the user can generate visual, structured summaries by selecting nodes in the ontology. As a result, the sentences that were mapped in the selected nodes will be highlighted. Our initial prototype builds on a component of the GATE system, which was originally developed as a tool for text annotation. \textcopyright{} 2010 ACM.},
  author   = {Giuseppe Carenini and Gabriel Murray},
  doi      = {10.1145/2002353.2002366},
  isbn     = 9781605589961,
  journal  = {International Conference on Intelligent User Interfaces, Proceedings IUI},
  keywords = {conversation,human,structured summaries,visual},
  pages    = {37--40},
  title    = {Visual structured summaries of human conversations},
  year     = 2010
}

@inproceedings{Caretto1973,
  abstract  = {Two procedures are described for solving the Navier-Stokes equations for steady, fully three-dimensional flows: both are extensions of earlier methods de- vised for three-dimensional boundary layers, and have the following common features: (i) the main dependent variables are the velocities and pressure; ( i i ) the latter are computed on a number of staggered, interlacing grids, each of which is associated with a particular variable; (iii) a hybrid central-upwind difference scheme is employed; and (iv) the solution algorithms are sufficiently implicit to obviate the need to approach the steady state via the time evolution of the flow, as is required by wholly explicit methods.},
  author    = {L. S. Caretto and A. D. Gosman and Suhas V. Patankar and D. B. Spalding},
  isbn      = {978-3-540-06171-7},
  booktitle = {Proceedings of the Third International Conference on Numerical Methods in Fluid Mechanics},
  pages     = {60--68},
  title     = {Two calculation procedures for steady, three-dimensional flows with recirculation},
  volume    = 19,
  url       = {http://www.springerlink.com/content/x46n27271791j492/},
  year      = 1973
}

@article{Carleton1995,
  author  = {J. H. Carleton and T. J. Done},
  doi     = {10.1007/BF00304070},
  issn    = {0722-4028},
  issue   = 1,
  journal = {Coral Reefs},
  month   = 2,
  pages   = {35--46},
  title   = {Quantitative video sampling of coral reef benthos: large-scale application},
  volume  = 14,
  url     = {http://link.springer.com/10.1007/BF00304070},
  year    = 1995
}

@article{Carr2001,
  abstract = {We use polyharmonic Radial Basis Functions (RBFs) to reconstruct smooth, manifold surfaces from point-cloud data and to repair incomplete meshes. An object's surface is defined implicitly as the zero set of an RBF fitted to the given surface data. Fast methods for fitting and evaluating RBFs allow us to model large data sets, consisting of millions of surface points, by a single RBF - previously an impossible task. A greedy algorithm in the fitting process reduces the number of RBF centers required to represent a surface and results in significant compression and further computational advantages. The energy-minimisation characterisation of polyharmonic splines result in a "smoothest" interpolant. This scale-independent characterisation is well-suited to reconstructing surfaces from non-uniformly sampled data. Holes are smoothly filled and surfaces smoothly extrapolated. We use a non-interpolating approximation when the data is noisy. The functional representation is in effect a solid model, which means that gradients and surface normals can be determined analytically. This helps generate uniform meshes and we show that the RBF representation has advantages for mesh simplification and remeshing applications. Results are presented for real-world rangefinder data. \textcopyright{} 2001 ACM.},
  author   = {J. C. Carr and R. K. Beatson and J. B. Cherrie and T. J. Mitchell and W. R. Fright and B. C. McCallum and T. R. Evans},
  doi      = {10.1145/383259.383266},
  isbn     = {158113374X},
  journal  = {Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 2001},
  keywords = {RBF,Radial Basis Function,geometry compression,mesh repair,point-cloud surfacing,solid modeling,surface reconstruction,variational implicit surfaces},
  pages    = {67--76},
  title    = {Reconstruction and representation of 3D objects with radial basis functions},
  url      = {https://www.cs.jhu.edu/~misha/Fall05/Papers/carr01.pdf},
  year     = 2001
}

@article{Carroll2013,
  abstract = {The main drawback of the Frenet frame is that it is undefined at those points where the curvature is zero. Further- more, in the case of planar curves, the Frenet frame does not agree with the standard framing of curves in the plane. The main drawback of the Bishop frame is that the principle normal vector N is not in it. Our new frame, which we call the Beta frame, combines, on a large set of curves, the best aspects of the Bishop frames and the Frenet frames. It yields a globally defined normal, a globally defined signed curvature, and a globally defined torsion. For planar curves it agrees with the standard framing of curves in the plane.},
  author   = {Daniel Carroll and Emek Kose and Ivan Sterling},
  doi      = {10.5539/jmr.v5n4p97},
  issn     = {1916-9795},
  issue    = 4,
  journal  = {Journal of Mathematics Research},
  keywords = {bishop frames,frenet frames},
  title    = {Improving Frenet's Frame Using Bishop's Frame},
  volume   = 5,
  url      = {https://www.researchgate.net/profile/Ivan-Sterling-2/publication/258840016\_Improving\_Frenet's\_Frame\_Using\_Bishop's\_Frame/links/54dcebbc0cf282895a3b3375/Improving-Frenets-Frame-Using-Bishops-Frame.pdf},
  year     = 2013
}

@article{Carter2008,
  abstract  = {Many biological machines function in discrete steps, and detection of such steps can provide insight into the machines' dynamics. It is therefore crucial to develop an automated method to detect steps, and determine how its success is impaired by the significant noise usually present. A number of step detection methods have been used in previous studies, but their robustness and relative success rate have not been evaluated. Here, we compare the performance of four step detection methods on artificial benchmark data (simulating different data acquisition and stepping rates, as well as varying amounts of Gaussian noise). For each of the methods we investigate how to optimize performance both via parameter selection and via prefiltering of the data. While our analysis reveals that many of the tested methods have similar performance when optimized, we find that the method based on a chi-squared optimization procedure is simplest to optimize, and has excellent temporal resolution. Finally, we apply these step detection methods to the question of observed step sizes for cargoes moved by multiple kinesin motors in vitro. We conclude there is strong evidence for sub-8-nm steps of the cargo's center of mass in our multiple motor records. \textcopyright{} 2008 by the Biophysical Society.},
  author    = {Brian C. Carter and Michael Vershinin and Steven P. Gross},
  doi       = {10.1529/biophysj.107.110601},
  issn      = {00063495},
  issue     = 1,
  journal   = {Biophysical Journal},
  month     = 1,
  pages     = {306--319},
  pmid      = 17827239,
  publisher = {Biophysical Society},
  title     = {A comparison of step-detection methods: How well can you do?},
  volume    = 94,
  year      = 2008
}

@article{Carvajal-rodriguez2008,
  author  = {Antonio Carvajal-rodr\'{\i}guez},
  journal = {Current Genomics},
  pages   = {155--159},
  title   = {Simulation of Genomes: A Review},
  volume  = 9,
  url     = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2679650/pdf/CG-9-155.pdf},
  year    = 2008
}

@misc{Cattaneo2005,
  abstract = {Si presentano due modelli basati sulle tecniche lattice gas per lo studio di fenomeni di fluidodinamica. Il modello FHP-N si basa su un reticolo esagonale e permette, con l'introduzione di un numero arbitrario ma finito di particelle ferme, di recuperare l'invarianza galileiana dell'equazione di Navier-Stokes. Il modello CRS \`{e} un modello in tre dimensioni che si basa sul rombododecaedro. Entrambi i modelli sono stati implementati sul Cray T3E del CINECA dove sono state ottenute ottime prestazioni e una buona scalabilit\`{a}. We introduce two lattice gas models for fluid-dynamic simulations. The FHP-N model is used for simulations in two dimensions, while the CRS model is used for the three dimensional case. Both the models have been implemented on the Cray T3E and here we present some performance and scalability data.},
  author   = {G Cattaneo and U Jocher},
  title    = {Cellular Automata for 2D and 3D fluid-dynamics simulations},
  url      = {http://www.cineca.it/editions/ssc97/html/cattaneo.htm},
  year     = 2005
}

@article{Caumon2004,
  abstract = {In Solid Modeling, a boundary representation (b-rep) defines solids by their bounding surfaces, providing an efficient volume description. Building on this representation, we present the notion of a Sealed Geological Model. In such a model, the geological surfaces define a partition ofthe domain ofinterest into regions; analytic functions can be defined in these regions to describe the spatial variations ofthe subsurface properties. Such descriptions can be used in Geophysics, 3D GIS, and for discretization purposes. In addition to the b-rep representational validity conditions, Sealed Geological Models must satisfy conditions ofgeological consistency. Bearing these conditions in mind, we describe a methodology to create and modify the shape of such sealed models interactively. We use the hierarchical relationship between geological surfaces to help reshape the contact between a fixed surface (a surface that other surfaces can slide along, such as a fault, erosion surface, or salt top) and a secondary deformable surface (e.g. horizon, older fault). Although designed to meet the demanding requirements of interactive model editing, our methodology could also make use of displacement vectors computed by an automatic process such as tomographic inversion or 3D balanced unfolding.},
  author   = {Guillaume Caumon and Fran\c{c}ois Lepage and Charles H. Swordd and Jean-Laurent Mallet},
  doi      = {10.1023/B:MATG.0000029297.18098.8a},
  issue    = {May 2004},
  journal  = {Journal of the International Association for Mathematical Geology},
  keywords = {Algorithms,Boundary Representation,Geomodeling,Solid Modeling,Validity},
  title    = {Building and Editing a Sealed Geological Model},
  year     = 2004
}

@article{Caumon2009,
  abstract = {Building a 3D geological model from field and subsurface data is a typical task in geological studies involving natural resource evaluation and hazard assessment. However, there is quite often a gap between research papers presenting case studies or specific innovations in 3D modeling and the objectives of a typical class in 3D structural modeling, as more and more is implemented at universities. In this paper, we present general procedures and guidelines to effectively build a structural model made of faults and horizons from typical sparse data. Then we describe a typical 3D structural modeling workflow based on triangulated surfaces. Our goal is not to replace software user guides, but to provide key concepts, principles, and procedures to be applied during geomodeling tasks, with a specific focus on quality control. \textcopyright{} International Association for Mathematical Geosciences 2009.},
  author   = {G. Caumon and P. Collon-Drouaillet and C. Le Carlier De Veslud and S. Viseur and J. Sausse},
  doi      = {10.1007/s11004-009-9244-2},
  issn     = 18748961,
  issue    = 8,
  journal  = {Mathematical Geosciences},
  keywords = {3D earth modeling,Geomodeling,Interpretation,Structural geology,Visualization},
  pages    = {927--945},
  title    = {Surface-based 3D modeling of geological structures},
  volume   = 41,
  year     = 2009
}

@article{Caumon2010,
  abstract = {The modeling of subsurface geometry and properties is a key element to understand Earth processes and manage natural hazards and resources. In this paper, we suggest this field should evolve beyond pure data fitting approaches by integrating geological concepts to constrain interpretations or test their consistency. This process necessarily calls for adding the time dimension to 3D modeling, both at the geological and human time scales. Also, instead of striving for one single best model, it is appropriate to generate several possible subsurface models in order to convey a quantitative sense of uncertainty. Depending on the modeling objective (e.g., quantification of natural resources, production forecast), this population of models can be ranked. Inverse theory then provides a framework to validate (or rather invalidate) models which are not compatible with certain types of observations. We review recent methods to better achieve both stochastic and time-varying geomodeling and advocate that the application of inversion should rely not only on random field models, but also on geological concepts and parameters. \textcopyright{} 2010 International Association for Mathematical Geosciences.},
  author   = {Guillaume Caumon},
  doi      = {10.1007/s11004-010-9280-y},
  issn     = 18748961,
  issue    = 5,
  journal  = {Mathematical Geosciences},
  keywords = {Geomodeling,Geostatistics,Inverse methods,Structural restoration,Uncertainty},
  pages    = {555--569},
  title    = {Towards stochastic time-varying geological modeling},
  volume   = 42,
  year     = 2010
}

@article{Cazenave1991,
  abstract = {<p>Seafloor subsidence effects due to cooling of the oceanic lithosphere have been removed from bathymetry data. The corrected ocean floor topography presents long wavelength highs, in particular over western Pacific. We show in this study that this long wavelength residual topography can be interpreted as either a term of seafloor flattening at old ages or a dynamic response to large-scale convection. Whatever its origin, this long wavelength residual topography is dominated by a degree 2 pattern highly correlated with geoid, lower mantle heterogeneities and plate age.</p>},
  author   = {Anny Cazenave and Bernard Lago},
  doi      = {10.1029/91GL01605},
  issn     = {0094-8276},
  issue    = 7,
  journal  = {Geophysical Research Letters},
  month    = 7,
  pages    = {1257--1260},
  title    = {Long wavelength topography, seafloor subsidence and flattening},
  volume   = 18,
  url      = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/91GL01605},
  year     = 1991
}

@article{Chan2019,
  abstract  = {A new system of artificial life called Lenia (from Latin lenis ``smooth''), a two-dimensional cellular automaton with continuous spacetime state and generalized local rule, is reported. Computer simulations show that Lenia supports a great diversity of complex autonomous patterns or ``life forms'' bearing resemblance to real-world microscopic organisms. More than 400 species in 18 families have been identified, many discovered via interactive evolutionary computation. They differ from other cellular automata patterns in being geometric, metameric, fuzzy, resilient, adaptive and rule generic. Basic observations of the system are presented regarding the properties of spacetime and basic settings. A broad survey of the life forms is provided and categorized into a hierarchical taxonomy, and their distribution is mapped in the parameter hyperspace. Their morphological structures and behavioral dynamics are described, and possible mechanisms of their self-organization, self-direction and plasticity are proposed. Finally, the study of Lenia and how it would be related to biology, artificial life and artificial intelligence is discussed.},
  author    = {Bert Wang Chak Chan},
  doi       = {10.25088/ComplexSystems.28.3.251},
  issn      = {08912513},
  issue     = 3,
  journal   = {Complex Systems},
  keywords  = {Artificial life,Complex system,Geometric cellular automata,Interactive evolutionary computation},
  pages     = {251--256},
  publisher = {Complex Systems Publications, Inc},
  title     = {Lenia: Biology of artificial life},
  volume    = 28,
  year      = 2019
}

@article{Chapron2020,
  abstract = {In recent years, the aging of the population has attracted considerable attention in the scientific community. An important fact is an increasing number of senior people will suffer from cognitive decline and there is almost no existing way to detect it early without the intervention of a clinician. Indeed, the sooner the cognitive decline is detected, the professional can elaborate a more adequate strategy to slow it down. In fact, Mild Cognitive Impairments (MCI) have been strongly correlated to a decreasing gait speed over the time. However, it would take a lot of human resources to carry out a standardized walking speed test every year to follow the evolution of this one. In fact, it is unthinkable in the current context of healthcare economics scarcity, thus finding a way of measuring it automatically at home could be a promising solution. This ambient sensor should be able to measure the gait speed of an inhabitant and automatically associate it to the right resident in a multi-resident context. In this paper, we present a new prototype to monitor gait speed continuously at home non intrusively. When coupled with a wristband capable of communicating through BLE, the gait speed can then be associated with the right person in a multi-resident context. The proposed prototype was tested in a realistic smart home context and results obtained are very encouraging.},
  author   = {K\'{e}vin Chapron and K\'{e}vin Bouchard and S\'{e}bastien Gaboury},
  doi      = {10.1007/s11042-020-08962-y},
  issn     = 15737721,
  journal  = {Multimedia Tools and Applications},
  keywords = {Gait speed evaluation,Multi resident identification,Smart home,Speed sensor,Wearable sensors},
  title    = {Real-time gait speed evaluation at home in a multi residents context},
  year     = 2020
}

@article{Chaudhuri2020,
  abstract = {3D models of objects and scenes are critical to many academic disciplines and industrial applications. Of particular interest is the emerging opportunity for 3D graphics to serve artificial intelligence: computer vision systems can benefit from synthetically-generated training data rendered from virtual 3D scenes, and robots can be trained to navigate in and interact with real-world environments by first acquiring skills in simulated ones. One of the most promising ways to achieve this is by learning and applying generative models of 3D content: computer programs that can synthesize new 3D shapes and scenes. To allow users to edit and manipulate the synthesized 3D content to achieve their goals, the generative model should also be structure-aware: it should express 3D shapes and scenes using abstractions that allow manipulation of their high-level structure. This state-of-the-art report surveys historical work and recent progress on learning structure-aware generative models of 3D shapes and scenes. We present fundamental representations of 3D shape and scene geometry and structures, describe prominent methodologies including probabilistic models, deep generative models, program synthesis, and neural networks for structured data, and cover many recent methods for structure-aware synthesis of 3D shapes and indoor scenes.},
  author   = {Siddhartha Chaudhuri and Daniel Ritchie and Jiajun Wu and Kai Xu and Hao Zhang},
  doi      = {10.1111/cgf.14020},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,Deep learning,Hierarchical models,Neural networks,Representation of structured data,Shape and scene synthesis,\textbullet{} Computing methodologies \rightarrow{} Structure-aware genera},
  pages    = {643--666},
  title    = {Learning Generative Models of 3D Structures},
  volume   = 39,
  year     = 2020
}

@inbook{Chellappa2003,
  abstract = {Human gait is an attractive modality for recognizing people at a distance. In this paper we adopt an appearance-based approach to the problem of gait recognition. The width of the outer contour of the binarized silhouette of a walking person is chosen as the basic image feature. Different gait features are extracted from the width vector such as the dowsampled, smoothed width vectors, the velocity profile etc. and sequences of such temporally ordered feature vectors are used for representing a person's gait. We use the dynamic time-warping (DTW) approach for matching so that non-linear time normalization may be used to deal with the naturally-occuring changes in walking speed. The performance of the proposed method is tested using different gait databases.},
  author   = {A. Kale and N. Cuntoor and B. Yegnanarayana and A.N. Rajagopalan and R. Chellappa},
  doi      = {10.1007/3-540-44887-X\_82},
  pages    = {706--714},
  title    = {Gait Analysis for Human Identification},
  url      = {http://link.springer.com/10.1007/3-540-44887-X\_82},
  year     = 2003
}

@article{Chen1993,
  author  = {Jen-Ping Chen and Dennis Lamb},
  issue   = 9,
  journal = {Journal of the Atmospheric Sciences},
  pages   = {1206--1221},
  title   = {The Theoretical Basis for the Parameterization of Ice Crystal Habits: Growth by Vapor Deposition},
  volume  = 51,
  year    = 1993
}

@inproceedings{Chen2011,
  author    = {Zhongxian Chen and Christopher S. Stuetzle and Barbara M. Cutler and Jared A. Gross and W. Randolph Franklin and Thomas F. Zimmie},
  city      = {Reston, VA},
  doi       = {10.1061/41165(397)154},
  isbn      = 9780784411650,
  booktitle = {Geo-Frontiers 2011},
  month     = 3,
  pages     = {1503--1513},
  publisher = {American Society of Civil Engineers},
  title     = {Analyses, Simulations, and Physical Modeling Validation of Levee and Embankment Erosion},
  url       = {https://ascelibrary.org/doi/10.1061/41165\%28397\%29154},
  year      = 2011
}

@article{Chen2015a,
  abstract  = {Cabled ocean observatory systems that provide abundant power and broad bandwidth communication enabling undersea science have been evolving during the last decade. To establish such permanent infrastructure in the ocean, the technology of cable network switching and fault isolation with very high reliability is essential. In this paper, we review existing switching methods as applied to a constant voltage tree topology network. We propose an actively controllable method that can configure each branch of the network only by changing the feeding current; the current level implicitly conveys the switching information. A laboratory prototype demonstrated the features of backbone switching with zero current and low voltage (less than 20 V), and active controllability of the switch.},
  author    = {Yanhu Chen and Bruce M. Howe and Canjun Yang},
  doi       = {10.1109/JOE.2014.2362830},
  issn      = {03649059},
  issue     = 4,
  journal   = {IEEE Journal of Oceanic Engineering},
  keywords  = {Cable switching,constant current,high voltage,ocean observation network},
  pages     = {993--1002},
  publisher = {IEEE},
  title     = {Actively Controllable Switching for Tree Topology Seafloor Observation Networks},
  volume    = 40,
  year      = 2015
}

@article{Chen2021,
  abstract  = {Volumetric representation is widely used in digital sculpting and terrain generation due to its highly modifiable characteristic. However, storing the entire raw voxel map requires a lot of memory, which limits its application on general machines. In this work, we propose to use a novel data structure based on the concept of layered depth-normal images to replace the commonly used scalar field for storing the volumetric information. The proposed data structure can be quickly edited, and the isosurface can be extracted by using general methods such as Marching Cubes and Dual Contouring. The proposed sculpting system can edit models with multiple resolution levels, and the surface between models of different resolutions can be connected seamlessly. Our method can achieve similar results as the existing volumetric methods while significantly reduces the memory usage and computation time. The model created by our system can be used in common game engines to make highly interactive games. Furthermore, all of our processes are parallel-friendly. We implemented a virtual reality digital content creation tool based on the proposed method to demonstrate the effectiveness and feasibility of our method.},
  author    = {Chien Wen Chen and Min Chun Hu and Wei Ta Chu and Jun Cheng Chen},
  doi       = {10.1109/ACCESS.2021.3105417},
  issn      = 21693536,
  journal   = {IEEE Access},
  keywords  = {Real-time sculpting,terrain generation,virtual reality,volumetric sculpting},
  pages     = {114914--114928},
  publisher = {IEEE},
  title     = {A Real-Time Sculpting and Terrain Generation System for Interactive Content Creation},
  volume    = 9,
  year      = 2021
}

@inproceedings{Chen2022,
  abstract  = {The fundamental solutions (Green's functions) of linear elasticity for an infinite and isotropic media are ubiquitous in interactive graphics applications that cannot afford the computational costs of volumetric meshing and finite-element simulation. For instance, the recent work of de Goes and James [2017] leveraged these Green's functions to formulate sculpting tools capturing in real-time broad and physically-plausible deformations more intuitively and realistically than traditional editing brushes. In this paper, we extend this family of Green's functions by exploiting the anisotropic behavior of general linear elastic materials, where the relationship between stress and strain in the material depends on its orientation. While this more general framework prevents the existence of analytical expressions for its fundamental solutions, we show that a finite sum of spherical harmonics can be used to decompose a Green's function, which can be further factorized into directional, radial, and material-dependent terms. From such a decou-pling, we show how to numerically derive sculpting brushes to generate anisotropic deformation and finely control their falloff profiles in real-time.},
  author    = {Jiong Chen and Mathieu Desbrun},
  city      = {New York, NY, USA},
  doi       = {10.1145/3528233.3530726},
  isbn      = 9781450393379,
  booktitle = {Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings},
  keywords  = {Green's functions,anisotropic material,elasticity,regularization,spherical harmonics.\textasteriskcentered0mm},
  month     = 8,
  pages     = {1--8},
  publisher = {ACM},
  title     = {Go Green: General Regularized Green's Functions for Elasticity},
  url       = {https://dl.acm.org/doi/10.1145/3528233.3530726},
  year      = 2022
}

@article{Cheng1997,
  abstract = {A new and simplified formula for predicting the settling velocity of natural sediment particles is developed. The formula proposes an explicit relationship between the particle Reynolds number and a dimensionless particle parameter. It is applicable to a wide range of Reynolds numbers from the Stokes flow to the turbulent regime. The proposed formula has the highest degree of prediction accuracy when compared with other published formulas. It also agrees well with the widely used diagrams and tables proposed by the U.S. Inter-Agency Committee in 1957.},
  author   = {Nian-Sheng Cheng},
  doi      = {10.1061/(asce)0733-9429(1997)123:2(149)},
  issn     = {0733-9429},
  issue    = 2,
  journal  = {Journal of Hydraulic Engineering},
  pages    = {149--152},
  title    = {Simplified Settling Velocity Formula for Sediment Particle},
  volume   = 123,
  url      = {https://dr.ntu.edu.sg/bitstream/10356/83675/2/121. Simplified settling velocity formula for sediment particle..pdf},
  year     = 1997
}

@article{Chenney2004,
  abstract = {We present flow tiles, a novel technique for representing and designing velocity fields. Unlike existing procedural flow generators, tiling offers a natural user interface for field design. Tilings can be constructed to meet a wide variety of external and internal boundary conditions, making them suitable for inclusion in larger environments. Tiles offer memory savings through the re-use of prototypical elements. Each flow tile contains a small field and many tiles can be combined to produce large flows. The corners and edges of tiles are constructed to ensure continuity across boundaries between tiles. In addition, all our tiles and the resulting tiling are divergence-free and hence suitable for representing a range of effects. We discuss issues that arise in designing flow tiles, algorithms for creating tilings, and three applications: a crowd on city streets, a river flowing between banks, and swirling fog. The first two applications use stationary fields, while the latter demonstrates a dynamic field.},
  author   = {Stephen Chenney},
  doi      = {10.1145/1028523.1028553},
  isbn     = 3905673142,
  journal  = {Computer Animation 2004 - ACM SIGGRAPH / Eurographics Symposium on Computer Animation},
  keywords = {Fluid simulation,Tiles,Tiling,Velocity field},
  pages    = {233--242},
  title    = {Flow tiles},
  year     = 2004
}

@article{Chentanez2011,
  abstract = {We present a new Eulerian fluid simulation method, which allows real-time simulations of large scale three dimensional liquids. Such scenarios have hitherto been restricted to the domain of off-line computation. To reduce computation time we use a hybrid grid representation composed of regular cubic cells on top of a layer of tall cells. With this layout water above an arbitrary terrain can be represented without consuming an excessive amount of memory and compute power, while focusing effort on the area near the surface where it most matters. Additionally, we optimized the grid representation for a GPU implementation of the fluid solver. To further accelerate the simulation, we introduce a specialized multigrid algorithm for solving the Poisson equation and propose solver modifications to keep the simulation stable for large time steps. We demonstrate the efficiency of our approach in several real-world scenarios, all running above 30 frames per second on a modern GPU. Some scenes include additional features such as two-way rigid body coupling as well as particle representations of sub-grid detail. \textcopyright{} 2011, ACM. All rights reserved.},
  author   = {Nuttapong Chentanez and Matthias M\"{u}ller},
  doi      = {10.1145/2010324.1964977},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {fluid simulation,multigrid,real time,tall cell grid},
  pages    = {1--10},
  title    = {Real-Time Eulerian Water Simulation Using a Restricted Tall Cell Grid},
  volume   = 30,
  year     = 2011
}

@article{Chevalier2004,
  abstract = {This paper deals first with the formulation of a three-dimensional numerical model intended to determine the spatial and temporal evolution of the oceanic circulation in coastal zones under the effects of various oceanic and meteorological constraints. Simulations are based on the Mobeehdycs model which was developed through collaborative work of several laboratories. Then, the paper presents the results of the application of the model to the continental shelf of French Guiana under academic but realistic climatic conditions. The application required the adaptation of the model and the use of appropriate techniques for solving the equations accounting for the peculiarities of the local constraints. The application is of importance as, because of the lack of systematic observations, the current, salinity and temperature fields at the site are poorly known. A better knowledge of these fields is recognized as of fundamental interest for a characterization of the site from the biological and the ecological viewpoints. The results clearly show the effects of the external forcing (wind and rivers) on the fields evolution, at the surface and with respect to the depth. The time scales of these evolutions as well as their mutual influence are identified. Finally, the results agree, at least qualitatively with some of the few observational results available at present.},
  author   = {Crist\`{e}le Chevalier and Melika Baklouti and Alfred Ramamonjiarisoa},
  doi      = {10.2112/03-0059r.1},
  issn     = {07490208},
  issue    = 4,
  journal  = {Journal of Coastal Research},
  keywords = {Numerical resolution of conservation equations,Oceanic circulation in coastal zones,Oceanic numerical modeling},
  pages    = {1183--1197},
  title    = {Modeling the influence of wind and rivers on current, salinity and temperature over the French Guiana continental shelf during the rainy season},
  volume   = 20,
  year     = 2004
}

@article{Chevalier2008,
  abstract = {Large mudbanks migrate westwards in the nearshore zone from the Cabo Cassipore in the Amapa state (Brazil) to the Waini River in Guiana. These mudbanks are noticeable by their size (about 4\texttimes{}109 m3 of sediment) and by the sediment dynamics they induce. Notably, visible remote sensing pictures present high turbid mud plume associated to mudbank erosion. The sediment transport is directly linked to the ambient forcing-littoral current, waves, and tide. In this paper, the turbid plume and the suspended mud transport around Guiana mudbanks are studied through a three-dimensional numerical study, under the three main different forcings. The study aims at describing the plume and the action of various physical processes in the suspended mud transport. The model results qualitatively agree with known observations issued from the literature. It is found that, the erosion-at the back of the bank-and the deposition-in front of the bank-could partly explain the migration process of these mudbanks. Waves are fundamental to create the erosion/deposition process, but littoral current and tide modulate it. Bottom flux and plume location vary with tide and these oscillations are accentuated during spring tide. In the same way, the wave incidence angle can explain the variability of erosion and deposition rate velocity along the Guiana coast. \textcopyright{} 2007 Elsevier Ltd. All rights reserved.},
  author   = {Crist\`{e}le Chevalier and Jean Marie Froidefond and Jean Luc Devenon},
  doi      = {10.1016/j.csr.2007.09.011},
  issn     = {02784343},
  issue    = {4-5},
  journal  = {Continental Shelf Research},
  keywords = {French Guiana,Modeling,Mud,Mud banks,Suspended load,Turbid plume},
  pages    = {545--560},
  title    = {Numerical analysis of the combined action of littoral current, tide and waves on the suspended mud transport and on turbid plumes around French Guiana mudbanks},
  volume   = 28,
  year     = 2008
}

@article{Chevalier2015,
  abstract = {Chevalier; C.; Devenon, J.-L.; Rougier, G., and Blanchot, J., 2015. Hydrodynamics of the Toliara reef lagoon (Madagascar): Example of a lagoon influenced by waves and tides. In meso-tidal lagoons, the coral reef barrier can be temporarily submerged at high tide and partially exposed at low tide, which causes highly specific lagoon dynamics. To understand those dynamics, three field-measurement campaigns were conducted in the Toliara Lagoon (Madagascar), where the tide and the waves increase that effect. The method combined measurements taken from fixed moorings and measurements from a small, moving, inflatable boat along the transects through the reef passages. A tidal analysis methodology adapted to this lagoon was used to reconstitute the currents through the passages and to determine the spatial and temporal current variability. Then, the lagoon water dynamics were studied. The tidal dynamics of the lagoon appear to depend significantly on flows through the passages, although they were also affected by water passing across the reef. Water entered the lagoon through the passages during the tidal flow and left it during the ebb. The tidal-prism flushing time (estimated using the tidal prism method) was 1 day during spring tide and 5 days during neap tide. At the same time, the average flow during a tidal cycle appears to be directly linked to the waves breaking over the reef. Indeed, the average cross-reef flow was inflowing and was mainly driven by the ocean swell. That inflow was balanced by an outflow through the passages. Hence, the average bulk flushing time was estimated at 13 days during the wet season and 4 days during the dry season.},
  author   = {Cristele Chevalier and Jean Luc Devenon and Gilles Rougier and Jean Blanchot},
  doi      = {10.2112/JCOASTRES-D-13-00077.1},
  issn     = 15515036,
  issue    = 6,
  journal  = {Journal of Coastal Research},
  keywords = {Meso-tidal reef lagoon,Toliara (Tulear) Lagoon.,flushing time,reef barrier overflow},
  pages    = {1403--1416},
  title    = {Hydrodynamics of the Toliara Reef Lagoon (Madagascar): Example of a Lagoon Influenced by Waves and Tides},
  volume   = 31,
  year     = 2015,
  isbn     = 1023601508
}

@article{Chevalier2017,
  abstract = {In mesotidal lagoons of the Indian Ocean, the coral reef barrier may be temporarily submerged at high tide and partially exposed at low tide, and this may cause unusual lagoon dynamics. A field measurement campaign was conducted in the north-east Mayotte Lagoon in order to understand these processes. An experimental approach was used, combining measurements taken by 1) a side-mounted Acoustic Doppler Current Profiler (ADCP) on a moving boat along transects through the reef passages (17 transects) and 2) by more conventional high-resolution moored ADCP measurements. A specific tidal analysis methodology was used to determine the spatial variability of the velocity. The tidal hydrodynamics within the lagoon were determined using a numerical model and then analyzed. The tide acted as a quasi-progressive forced wave in the lagoon: at low tide, water entered through the south passage, over the reef and left the lagoon through the north passage. This flow was reversed at high tide. The tide-driven quasi-progressive wave created a specific lagoon dynamics. Contrary to most other channel lagoons, the flow over the reef was mainly outward. This increases the inflow through the passages, which renews the water in the lagoon as shown by the indicators of age and origin of the water inside the lagoon. This study also showed the importance of these indicators for better understanding the variations and levels of plankton biomass (with chlorophyll concentration as proxy) which is quite high in this lagoon.},
  author   = {C. Chevalier and J. L. Devenon and M. Pagano and G. Rougier and J. Blanchot and R. Arfi},
  doi      = {10.1016/j.ecss.2017.06.027},
  issn     = {02727714},
  journal  = {Estuarine, Coastal and Shelf Science},
  keywords = {Barrier reef overflow,Mayotte Lagoon,Mesotidal reef lagoon,Side-mounted ADCP,Water renewal indicators},
  pages    = {182--197},
  title    = {The atypical hydrodynamics of the Mayotte Lagoon (Indian Ocean): Effects on water age and potential impact on plankton productivity},
  volume   = 196,
  year     = 2017
}

@article{Chiba1998a,
  abstract = {Visual simulation of natural scenery using computer graphics is an interesting research field with wide applications such as flight simulation and special effects in movies. There have been many studies of fractal techniques that use 1/f noise generated by FFT or the midpoint displacement method as modelling methods for imaginary mountain scenery. These methods are suitable for creating impressive mountain scenes, but they cannot create clear ridge and valley lines, which are notable features of mountains produced by erosion processes. Although a few reports have presented modelling methods that take erosion processes into account, the results have not been satisfactory. In this paper we present a simple 'quasi-physically based' method for simulating the topography of eroded mountains based on velocity fields of water flow. \textcopyright{} 1998 John Wiley \& Sons, Ltd.},
  author   = {N. Chiba and K. Muraoka and K. Fujita},
  doi      = {10.1002/(SICI)1099-1778(1998100)9:4<185::AID-VIS178>3.0.CO;2-2},
  issn     = 10498907,
  issue    = 4,
  journal  = {Journal of Visualization and Computer Animation},
  keywords = {Computer graphics,Erosion processes,Natural phenomena,Terrain,Visual simulation},
  pages    = {185--194},
  title    = {An Erosion Model Based on Velocity Fields for the Visual Simulation of Mountain Scenery},
  volume   = 9,
  year     = 1998
}

@misc{Chiu,
  abstract = {To locate the center of gravity position, previous studies photographed human body motions and then applied body segmental parameters. This study presents a novel set of algorithm to locate three-dimensional center of gravity position. The purpose of this novel system is to aid establishing the gravity plumb line for rehabilitating patients. Control variables employed in this study were angular positions of ankle joints, knee joints, hip joints, shoulder joints, elbow joints, wrist joints, waist joint, and the neck. The study was grounded in five sources: the human body model by Zatsiorsky and Seluyanov [1], three basic homogeneous rotation matrices, three basic homogeneous translation matrices, a 4\texttimes{}4 identity matrix, and seven homogeneous transformation matrices developed by Chiu [2]. The first step in adopting this novel set of algorithm was to define body joints as 38 degrees of freedom. Then an algorithm was developed to locate the center of gravity position. Three male subjects participated in this study. Two motions were simulated by a computer. The first simulated motion was a subject squatting and then rising. During this squat, both arms swing from position at the sides of the body to a position adjacent to the head. During the second simulated motion, the subject leans horizontally at the waist from left to right, with both arms swinging upward. The experimental results demonstrated that the computer program successfully simulated the angular positions of particular postures, and the algorithm effectively established the relationship between the angular positions and the plumb line of the center of gravity. This novel system can assist paralyzed patients and those with muscular dystrophy by ensuring that correct postures are employed during rehabilitation. Furthermore, this system can also locate the center of gravity position during running, jumping, and walking.},
  author   = {Ching-Hua Chiu},
  issue    = 3,
  journal  = {Journal of Medical and Biological Engineering},
  keywords = {Body segment,Center of gravity,Matrix},
  pages    = {123--128},
  title    = {Simulation of Positional Center of Gravity for Different Human Motions},
  volume   = 25,
  url      = {https://www.semanticscholar.org/paper/Simulation-of-Positional-Center-of-Gravity-for-Chiu/763372f811756405aa4dbf6ef457daf33126a7f5}
}

@article{Chng2011,
  author  = {E. Ch'ng},
  doi     = {10.1109/MCG.2010.42},
  issn    = {0272-1716},
  issue   = 4,
  journal = {IEEE Computer Graphics and Applications},
  month   = 7,
  pages   = {66--77},
  title   = {Realistic Placement of Plants for Virtual Environments},
  volume  = 31,
  url     = {http://ieeexplore.ieee.org/document/5445060/},
  year    = 2011
}

@article{Chng2013,
  abstract = {Agent-based modeling is a process of representing and simulating the intentions, behaviors and actions of complex systems with the goal of understanding specific phenomena related to the communications within complex systems that produce emergent behavior and self-organization, or for predicting spatial or behavioral patterns of individuals or groups of interacting entities. Agent-based modeling, also termed multi-agent systems, or in ecological simulation, individual-based models, spans simple to highly complex systems; their interactions can be difficult to implement and optimize programmatically, particularly when there could be hundreds of thousands of agents within a community that have multiple levels of communication. The resolution and the scale of simulation is an especially important component that could determine the accuracy of the models. This article focuses on the model resolution of complex systems, facilitated by an object-oriented communications framework, a foundation for the simulation of the fine resolution of the dynamics, behavior, preferences, interaction and n-tiered trophic networks, including the simulated environments they inhabit. It dissects individual agents with a view to modeling and simulating fine behaviors amongst a population of agent types in n-tiered networks, scalable to hundreds of thousands of species using mathematically defined behavior, efficient algorithms and adaptive data structures as support for the simulations.},
  author   = {Eugene Ch'ng},
  doi      = {10.1177/0037549712470582},
  issn     = {0037-5497},
  issue    = 5,
  journal  = {SIMULATION},
  keywords = {agent-based systems,artificial life,complexity,modeling and simulation environments,simulation system architecture},
  month    = 5,
  pages    = {635--659},
  title    = {Model resolution in complex systems simulation: Agent preferences, behavior, dynamics and n-tiered networks},
  volume   = 89,
  url      = {http://journals.sagepub.com/doi/10.1177/0037549712470582},
  year     = 2013
}

@article{Christensen-Dalsgaard2008,
  abstract = {We describe a physical simulation of natural selection in a population of legorgs, six-segment model organisms. Legorg morphology is genetically specified by five alleles on each segment. Legorgs show a simple form of motility that could evolve in originally sessile animals. This motility, the ability to move horizontally on a smooth surface, depends on the morphology and interaction of the six segments that produce different patterns of locomotion. Legorgs are selected for motility and reproduce in proportion to fitness. After just five generations, the average population motility increases 2.5 times. Additionally, we describe a slightly less time-consuming simulation of legorg evolution, where fitness is assigned by comparison with a template. The calculation of gene pools is precisely the same as in the previous simulation and produces very robust increases in fitness during five generations. The simulation is designed as a classroom experiment to explore the mechanism of natural selection. A test of its learning efficiency by evaluating the students' conception of central aspects of evolutionary theory before and after showed a significant improvement. The surprising power of natural selection in this very simple physical system may also be exploited in more advanced experiments.},
  author   = {Jakob Christensen-Dalsgaard and Morten Kanneworff},
  doi      = {10.1007/s12052-008-0099-7},
  isbn     = 1205200800,
  issn     = 19366434,
  issue    = 3,
  journal  = {Evolution: Education and Outreach},
  keywords = {Active learning,Adaptation,Evolution,Natural selection,Simulation},
  pages    = {518--526},
  title    = {Evolution in Lego \textregistered{}: A Physical Simulation of Adaptation by Natural Selection},
  volume   = 2,
  year     = 2008
}

@article{Christiansen,
  author   = {Kenneth Rohde Christiansen and Aard Keimpema},
  keywords = {computational,computer science,coral reefs,lattice-boltzmann,navier-stokes,science,simulations},
  pages    = {1--15},
  title    = {Simulation of Coral Growth},
  url      = {https://calcifer.org/kenneth-christiansen/ComputerScience/2d-coral-growth-2.pdf}
}

@article{Chrobak1995,
  abstract = {We present a linear-time algorithm that, given an n-vertex planar graph G, finds an embedding of G into a (2n - 4) \texttimes{} (n - 2) grid such that the edges of G are straight-line segments. \textcopyright{} 1995.},
  author   = {M. Chrobak and T. H. Payne},
  doi      = {10.1016/0020-0190(95)00020-D},
  issn     = {00200190},
  issue    = 4,
  journal  = {Information Processing Letters},
  keywords = {Algorithms},
  pages    = {241--246},
  title    = {A linear-time algorithm for drawing a planar graph on a grid},
  volume   = 54,
  year     = 1995
}

@article{Cippitelli2016,
  abstract  = {The aim of Active and Assisted Living is to develop tools to promote the ageing in place of elderly people, and human activity recognition algorithms can help to monitor aged people in home environments. Different types of sensors can be used to address this task and the RGBD sensors, especially the ones used for gaming, are cost-effective and provide much information about the environment. This work aims to propose an activity recognition algorithm exploiting skeleton data extracted by RGBD sensors. The system is based on the extraction of key poses to compose a feature vector, and a multiclass Support Vector Machine to perform classification. Computation and association of key poses are carried out using a clustering algorithm, without the need of a learning algorithm. The proposed approach is evaluated on five publicly available datasets for activity recognition, showing promising results especially when applied for the recognition of AAL related actions. Finally, the current applicability of this solution in AAL scenarios and the future improvements needed are discussed.},
  author    = {Enea Cippitelli and Samuele Gasparrini and Ennio Gambi and Susanna Spinsante},
  doi       = {10.1155/2016/4351435},
  issn      = 16875273,
  journal   = {Computational Intelligence and Neuroscience},
  pmid      = 27069469,
  publisher = {Hindawi Limited},
  title     = {A Human Activity Recognition System Using Skeleton Data from RGBD Sensors},
  volume    = 2016,
  year      = 2016
}

@article{Cohen-Steiner2004,
  abstract = {A method for concise, faithful approximation of complex 3D datasets is key to reducing the computational cost of graphics applications. Despite numerous applications ranging from geometry compression to reverse engineering, efficiently capturing the geometry of a surface remains a tedious task. In this paper, we present both theoretical and practical contributions that result in a novel and versatile framework for geometric approximation of surfaces. We depart from the usual strategy by casting shape approximation as a variational geometric partitioning problem. Using the concept of geometric proxies, we drive the distortion error down through repeated clustering of faces into best-fitting regions. Our approach is entirely discrete and error-driven, and does not require parameterization or local estimations of differential quantities. We also introduce a new metric based on normal deviation, and demonstrate its superior behavior at capturing anisotropy. Copyright \textcopyright{} 2004 ACM.},
  author   = {David Cohen-Steiner and Pierre Alliez and Mathieu Desbrun},
  doi      = {10.1145/1186562.1015817},
  journal  = {ACM SIGGRAPH 2004 Papers, SIGGRAPH 2004},
  keywords = {Anisotropic remeshing,Geometric approximation,Geometric error metrics,Lloyd's clustering algorithm,Surfaces},
  pages    = {905--914},
  title    = {Variational shape approximation},
  year     = 2004
}

@article{Collon2015,
  abstract = {In this paper we demonstrate how recent geomodelling techniques can be combined and used to build a 3D geological model on a real case study: the former coal mine of Merlebach (France), that is targeted to be exploited for low-temperature geothermal energy production. From geological maps, cross-sections, borehole and mine exploitation data, we build a 3D model in which are identified the rocks and infrastructures having significantly different permeabilities. First, a structural model of the main geological interfaces in our area of interest (2 horizons and 13 faults) is built with classical geomodelling techniques. Then, we propose to model by surfaces the 71 irregularly stacked, very close and very thin, sub-vertical coal beds. To ease their construction, we use an implicit method which represents 3D surfaces as isovalues of a scalar field defined in a 3D tetrahedral grid of the area. The corresponding triangulated surfaces are remeshed with a recently proposed method based on Voronoi diagrams so that the exploited parts of the coal beds, now filled by sand, can be computed. The 3D surface-based geological model, in which infrastructures can be inserted as piecewise lines, can be volumetrically meshed. It is available for download as supplemental material, as well as a volumetric grid.},
  author   = {Pauline Collon and Wendy Steckiewicz-Laurent and Jeanne Pellerin and Gautier Laurent and Guillaume Caumon and Guillaume Reichart and Laurent Vaute},
  doi      = {10.1016/j.cageo.2015.01.009},
  issn     = {00983004},
  journal  = {Computers and Geosciences},
  keywords = {3D surface-based model,Geomodelling,Geothermics,Implicit modelling,Post-mining,Surface remeshing},
  pages    = {29--43},
  title    = {3D geomodelling combining implicit surfaces and Voronoi-based remeshing: A case study in the Lorraine Coal Basin (France)},
  volume   = 77,
  url      = {https://hal.univ-lorraine.fr/hal-01276842/file/2015Pap\_Collon\_CaGeo\_PreprintV.pdf},
  year     = 2015
}

@article{Collon2017,
  abstract  = {Statistical metrics can be used to analyse the morphology of natural or simulated karst systems; they allow describing, comparing, and quantifying their geometry and topology. In this paper, we present and discuss a set of such metrics. We study their properties and their usefulness based on a set of more than 30 karstic networks mapped by speleologists. The data set includes some of the largest explored cave systems in the world and represents a broad range of geological and speleogenetic conditions allowing us to test the proposed metrics, their variability, and their usefulness for the discrimination of different morphologies. All the proposed metrics require that the topographical survey of the caves are first converted to graphs consisting of vertices and edges. This data preprocessing includes several quality check operations and some corrections to ensure that the karst is represented as accurately as possible. The statistical parameters relating to the geometry of the system are then directly computed on the graphs, while the topological parameters are computed on a reduced version of the network focusing only on its structure. Among the tested metrics, we include some that were previously proposed such as tortuosity or the Howard's coefficients. We also investigate the possibility to use new metrics derived from graph theory. In total, 21 metrics are introduced, discussed in detail, and compared on the basis of our data set. This work shows that orientation analysis and, in particular, the entropy of the orientation data can help to detect the existence of inception features. The statistics on branch length are useful to describe the extension of the conduits within the network. Rather surprisingly, the tortuosity does not vary very significantly. It could be heavily influenced by the survey methodology. The degree of interconnectivity of the network, related to the presence of maze patterns, can be measured using different metrics such as the Howard's parameters, global cyclic coefficient, or the average vertex degree. The average vertex degree of the reduced graph proved to be the most useful as it is simple to compute, it discriminates properly the interconnected systems (mazes) from the acyclic ones (tree-like structures), and it permits us to classify the acyclic systems as a function of the total number of branches. This topological information is completed by three parameters, allowing us to refine the description. The correlation of vertex degree is rather simple to obtain. It is systematically positive on all studied data sets indicating a predominance of assortative networks among karst systems. The average shortest path length is related to the transport efficiency. It is shown to be mainly correlated to the size of the network. Finally, central point dominance allows us to identify the presence of a centralized organization.},
  author    = {Pauline Collon and David Bernasconi and C\'{e}cile Vuilleumier and Philippe Renard},
  doi       = {10.1016/j.geomorph.2017.01.034},
  issn      = {0169555X},
  journal   = {Geomorphology},
  keywords  = {Database,Geometry,Graph theory,Karst characterization,Karst pattern,Topology},
  pages     = {122--142},
  publisher = {Elsevier B.V.},
  title     = {Statistical metrics for the characterization of karst network geometry and topology},
  volume    = 283,
  url       = {http://dx.doi.org/10.1016/j.geomorph.2017.01.034},
  year      = 2017
}

@article{Collon2021,
  abstract  = {The authors regret that six of the statistical metrics published in Tables 2, 5, and 6 in Collon et al. (2017) are incorrect. The errors were discovered while coding and testing the open-source python package Karstnet freely available at https://github.com/karstnet/karstnet. The errors are smaller than 2\%, except for the correlation of vertex degree, and they do not affect the general conclusions of the paper. The corrected tables are provided in this corrigendum, and we summarize below the changes. Correlation of vertex degree rk (Table 5) The corrected values of the correlation of vertex degree rk are all negative, indicating that the karstic networks in our data set are disassortative as it was reported for other natural networks by Newman (2002). This correction implies the following changes in the text: \textbullet{} In the abstract: ``The correlation of vertex degree is rather simple to obtain. It is systematically negative on all studied data sets indicating a predominance of disassortative networks among karst systems.''\textbullet{} The last paragraph of the section ``4.2.2. Correlation of vertex degrees: assortativity'' must be updated as: ``The values obtained on the 34 reduced networks are all negative, ranging from -0.56 to -0.15. The reduced representations of karstic system are thus disassortative (Table 5). Note that maximal node degrees rarely exceed 4, which limits the interpretation of this parameter, moreover as nodes of degree 2 are removed from the analysis (we work on reduced graphs).''\textbullet{} The second paragraph of the discussion (Section 5.2) must be updated as: ``The correlations of vertex degrees show that the reduced graphs of karstic systems were all slightly disassortative (-0.56 \leq{} rk \leq{} -0.15). Previously, Newman (2002) has shown that many social networks were assortative while technological and biological networks seem to be disassortative. Note that high degree vertices are quite rare in karstic networks: we did not record k values >5.''Branch lengths entropy Hlen (Table 2) In the previous Matlab code, we computed the branch length entropy on 11 bins instead of the 10 bins described in the paper. Correcting this (computing on 10 bins) slightly decreases the values, ranging now from 0.07 to 0.67 instead of 0.18 to 0.74 (page 9). Coefficient of variations of lengths CVlen (Table 2) Contrary to what was written, the coefficient of variations of the lengths was not provided in percentages but in absolute value. A CVlen = 1.09, should thus be read CVlen = 109\%. The update of Table 2 below is also the occasion to put the values in accordance with their definition. Mean length [Formula presented](Table 5) In the previous code, when computing the mean length of the branches, the looping branches (branches that close on the starting point) were ignored. If this is meaningful for tortuosity computation, these branches should not be ignored for the mean length computation. This has been corrected and explains the minor differences observable for the mean length values of Agen Allwed, Daren Cilau, Foussoubie Goule, Krubera, Lechuguilla, MammuthH\"{o}hle, Ratasse, SaintMarcel, Sakany, Shuanghe, SiebenHengsteFull and SiebenHengsteSP2. Average shortest path length [Formula presented](Table 5) In addition, the previous code also ignored independent connected components of two nodes. This is not justified. This correction slightly impacts the values of the [Formula presented]coefficient of Agen Allwed, Arphidia Robinet, Daren Cilau, Grotte du Roy, Krubera, Lechuguilla, Llangattwg, MammuthH\"{o}hle Ratasse, SaintMarcel, Sakany, SiebenHengsteUpPart. Linear correlation coefficients r (Table 6) The corrections described above impact slightly the Pearson correlation coefficient values (differences <0.01), but not the conclusions. The authors would like to apologise for any inconvenience caused.},
  author    = {Pauline Collon and David Bernasconi and C\'{e}cile Vuilleumier and Philippe Renard},
  doi       = {10.1016/j.geomorph.2021.107848},
  issn      = {0169555X},
  journal   = {Geomorphology},
  month     = 9,
  pages     = 107848,
  publisher = {Elsevier B.V.},
  title     = {Corrigendum to ``Statistical metrics for the characterization of karst network geometry and topology'' [Geomorphology (2017) 283: 122–142]},
  volume    = 389,
  url       = {https://linkinghub.elsevier.com/retrieve/pii/S0169555X21002567},
  year      = 2021
}

@article{Congote2010,
  abstract = {This work proposes an extension of the Marching Cubes algorithm, where the goal is to represent implicit functions with higher accuracy using the same grid size. The proposed algorithm displaces the vertices of the cubes iteratively until the stop condition is achieved. After each iteration, the difference between the implicit and the explicit representations is reduced, and when the algorithm finishes, the implicit surface representation using the modified cubical grid is more accurate, as the results shall confirm. The proposed algorithm corrects some topological problems that may appear in the discretization process using the original grid. \textcopyright{} 2010 Springer-Verlag Berlin Heidelberg.},
  author   = {John Congote and Aitor Moreno and I\~{n}igo Barandiaran and Javier Barandiaran and Oscar Ruiz},
  doi      = {10.1007/978-3-642-11840-1\_3},
  isbn     = 3642118399,
  issn     = 18650929,
  issue    = {January},
  journal  = {Communications in Computer and Information Science},
  pages    = {35--44},
  title    = {Extending marching cubes with adaptative methods to obtain more accurate iso-surfaces},
  volume   = {68 CCIS},
  year     = 2010
}

@article{Cordonnier2016,
  abstract = {<p>At large scale, landscapes result from the combination of two major processes: tectonics which generate the main relief through crust uplift, and weather which accounts for erosion. This paper presents the first method in computer graphics that combines uplift and hydraulic erosion to generate visually plausible terrains. Given a user-painted uplift map, we generate a stream graph over the entire domain embedding elevation information and stream flow. Our approach relies on the stream power equation introduced in geology for hydraulic erosion. By combining crust uplift and stream power erosion we generate large realistic terrains at a low computational cost. Finally, we convert this graph into a digital elevation model by blending landform feature kernels whose parameters are derived from the information in the graph. Our method gives high-level control over the large scale dendritic structures of the resulting river networks, watersheds, and mountains ridges.</p>},
  author   = {Guillaume Cordonnier and Jean Braun and Marie-Paule Cani and Bedrich Benes and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin},
  doi      = {10.1111/cgf.12820},
  issn     = {0167-7055},
  issue    = 2,
  journal  = {Computer Graphics Forum},
  month    = 5,
  pages    = {165--175},
  title    = {Large Scale Terrain Generation from Tectonic Uplift and Fluvial Erosion},
  volume   = 35,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12820},
  year     = 2016
}

@article{Cordonnier2017a,
  abstract = {Most mountain ranges are formed by the compression and folding of colliding tectonic plates. Subduction of one plate causes large-scale asymmetry while their layered composition (or stratigraphy) explains the multi-scale folded strata observed on real terrains. We introduce a novel interactive modeling technique to generate visually plausible, large scale terrains that capture these phenomena. Our method draws on both geological knowledge for consistency and on sculpting systems for user interaction. The user is provided hands-on control on the shape and motion of tectonic plates, represented using a new geologically-inspired model for the Earth crust. The model captures their volume preserving and complex folding behaviors under collision, causing mountains to grow. It generates a volumetric uplift map representing the growth rate of subsurface layers. Erosion and uplift movement are jointly simulated to generate the terrain. The stratigraphy allows us to render folded strata on eroded cliffs. We validated the usability of our sculpting interface through a user study, and compare the visual consistency of the earth crust model with geological simulation results and real terrains.},
  author   = {Guillaume Cordonnier and Marie-Paule Cani and Bed\v{r}ich Bene\v{s} and Jean Braun and \'{E}ric Galin},
  doi      = {10.1109/TVCG.2017.2689022},
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {Terrains,geology,interactive design,mountains},
  title    = {Sculpting Mountains: Interactive Terrain Modeling Based on Subsurface Geology},
  volume   = 24,
  url      = {http://www.ieee.org/publications\_standards/publications/rights/index.html},
  year     = 2017
}

@article{Cordonnier2017b,
  abstract = {We introduce a novel framework for interactive landscape authoring that supports bi-directional feedback between erosion and vegetation simulation. Vegetation and terrain erosion have strong mutual impact and their interplay influences the overall realism of virtual scenes. Despite their importance, these complex interactions have been neglected in computer graphics. Our framework overcomes this by simulating the effect of a variety of geomor-phological agents and the mutual interaction between different material and vegetation layers, including rock, sand, humus, grass, shrubs, and trees. Users are able to exploit these interactions with an authoring interface that consistently shapes the terrain and populates it with details. Our method, validated through side-by-side comparison with real terrains, can be used not only to generate realistic static landscapes, but also to follow the temporal evolution of a landscape over a few centuries.},
  author   = {Guillaume Cordonnier and \'{E}ric Galin and James Gain and Bed\v{r}ich Bene\v{s} and \'{E}ric Gu\'{e}rin and Adrien Peytavie and Marie-Paule Cani},
  doi      = {10.1145/3072959.3073667},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Erosion,Landscape,Simulation of natural phenomena,Stochastic,Terrain,Vegetation},
  title    = {Authoring landscapes by combining ecosystem and terrain erosion simulation},
  volume   = 36,
  url      = {https://hal.archives-ouvertes.fr/hal-01518967/file/authoring-landscapes-combining.pdf},
  year     = 2017
}

@article{Cordonnier2018,
  abstract = {We introduce a novel method for interactive generation of visually consistent, snow-covered landscapes and provide control of their dynamic evolution over time. Our main contribution is the real-time phenomenological simulation of avalanches and other user-guided events, such as tracks left by Nordic skiing, which can be applied to interactively sculpt the landscape. The terrain is modeled as a height field with additional layers for stable, compacted, unstable, and powdery snow, which behave in combination as a semi-viscous fluid. We incorporate the impact of several phenomena, including sunlight, temperature, prevailing wind direction, and skiing activities. The snow evolution includes snow-melt and snow-drift, which affect stability of the snow mass and the probability of avalanches. A user can shape landscapes and their evolution either with a variety of interactive brushes, or by prescribing events along a winter season time-line. Our optimized GPU-implementation allows interactive updates of snow type and depth across a large (10 \texttimes{} 10km) terrain, including real-time avalanches, making this suitable for visual assets in computer games. We evaluate our method through perceptual comparison against exiting methods and real snow-depth data.},
  author   = {Guillaume Cordonnier and Pierre Ecormier-nocca and \'{E}ric Galin and James Gain and Bed\v{r}ich Bene\v{s} and Marie-Paule Cani},
  doi      = {10.1111/cgf.13379},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {Computing methodologies \rightarrow{} Shape modeling,Human-centered computing \rightarrow{} Interaction techniques},
  pages    = {497--509},
  title    = {Interactive generation of time-evolving, snow-covered landscapes with avalanches},
  volume   = 37,
  url      = {https://hal.inria.fr/hal-01736971/file/interactive-generation-time.pdf},
  year     = 2018
}

@article{Cordonnier2023,
  abstract = {We introduce the first solution for simulating the formation and evolution of glaciers, together with their attendant erosive effects, for periods covering the combination of glacial and inter-glacial cycles. Our efficient solution includes both a fast yet accurate deep learning-based estimation of high-order ice flows and a new, multi-scale advection scheme enabling us to account for the distinct time scales at which glaciers reach equilibrium compared to eroding the terrain. We combine the resulting glacial erosion model with finer-scale erosive phenomena to account for the transport of debris flowing from cliffs. This enables us to model the formation of terrain shapes not previously adequately modeled in Computer Graphics, ranging from U-shaped and hanging valleys to fjords and glacial lakes.},
  author   = {Guillaume Cordonnier and Guillaume Jouvet and Adrien Peytavie and Jean Braun and Marie-Paule Cani and Bedrich Benes and Eric Galin and Eric Gu\'{e}rin and James Gain},
  doi      = {10.1145/3592422\"{\i}},
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Erosion,Glacial Erosion,Landscape,Simulation of Natural Phenomena,Terrain},
  pages    = 14,
  title    = {Forming Terrains by Glacial Erosion},
  volume   = 42,
  url      = {https://doi.org/10.1145/3592422.},
  year     = 2023
}

@article{Corso2022,
  abstract  = {Morphological variation in scleractinian corals has been variously ascribed to genetic differentiation and phenotypic plasticity, with a likely influence of both factors. Experimental approaches have dominated studies of phenotypic plasticity, for example with asymmetrical colony formation resulting from exposure to experimentally imposed unidirectional water flow. However, it has been difficult to disentangle the effects of competition for space between sessile organisms from the influence of physical forcing on coral morphologies in situ. To this end, we investigated morphological variation of coral colonies of the genus Pocillopora on reefs in Moorea, French Polynesia, where recovery (by 2018) after near complete loss of coral cover on the forereef in 2010 was driven predominantly by recruitment and growth of Pocillopora. We employed a large-area imaging approach at 8 study sites in the forereef of Moorea, constructing digital models of 100 m2 benthic plots to describe the orientation of ~400 individual colonies of Pocillopora. Results demonstrate that Pocillopora colonies on the forereef of Moorea exhibit non-random orientations, with a systematic orientation of the major axis that lies approximately perpendicular to the 20-30 m isobath.},
  author    = {Jack Corso and Beverly J. French and Clinton B. Edwards and Nicole E. Pedersen and Brian J. Zgliczynski and Serge Planes and Stephen Pacala and Stuart A. Sandin},
  doi       = {10.3354/meps14078},
  issn      = 16161599,
  journal   = {Marine Ecology Progress Series},
  keywords  = {Coral,Hydrodynamics,Morphology,Phenotypic plasticity,Photogrammetry},
  pages     = {177--182},
  publisher = {Inter-Research},
  title     = {Non-random orientation of Pocillopora colonies on forereefs of Moorea, French Polynesia},
  volume    = 693,
  year      = 2022
}

@article{Cortial2019,
  abstract = {We present a procedural method for authoring synthetic tectonic planets. Instead of relying on computationally demanding physically-based simulations, we capture the fundamental phenomena into a procedural method that faithfully reproduces large-scale planetary features generated by the movement and collision of the tectonic plates. We approximate complex phenomena such as plate subduction or collisions to deform the lithosphere, including the continental and oceanic crusts. The user can control the movement of the plates, which dynamically evolve and generate a variety of landforms such as continents, oceanic ridges, large scale mountain ranges or island arcs. Finally, we amplify the large-scale planet model with either procedurally-defined or real-world elevation data to synthesize coherent detailed reliefs. Our method allows the user to control the evolution of an entire planet interactively, and to trigger specific events such as catastrophic plate rifting.},
  author   = {Yann Cortial and Adrien Peytavie and \'{E}ric Galin and \'{E}ric Gu\'{e}rin},
  doi      = {10.1111/cgf.13614},
  issn     = 14678659,
  issue    = 2,
  journal  = {Eurographics Computer Graphics Forum},
  keywords = {CCS Concepts,Shape modeling,\textbullet{} Computing methodologies \rightarrow{} Computer graphics},
  pages    = {1--11},
  title    = {Procedural Tectonic Planets},
  volume   = 38,
  year     = 2019
}

@article{Cosmin2013,
  author = {Bogdan Cosmin},
  title  = {3D mesh morphing},
  year   = 2013
}

@article{Costello2017,
  abstract  = {Marine biogeographic realms have been inferred from small groups of species in particular environments (e.g., coastal, pelagic), without a global map of realms based on statistical analysis of species across all higher taxa. Here we analyze the distribution of 65,000 species of marine animals and plants, and distinguish 30 distinct marine realms, a similar proportion per area as found for land. On average, 42\% of species are unique to the realms. We reveal 18 continental-shelf and 12 offshore deep-sea realms, reflecting the wider ranges of species in the pelagic and deep-sea compared to coastal areas. The most widespread species are pelagic microscopic plankton and megafauna. Analysis of pelagic species recognizes five realms within which other realms are nested. These maps integrate the biogeography of coastal and deep-sea, pelagic and benthic environments, and show how land-barriers, salinity, depth, and environmental heterogeneity relate to the evolution of biota. The realms have applications for marine reserves, biodiversity assessments, and as an evolution relevant context for climate change studies.},
  author    = {Mark J. Costello and Peter Tsai and Pui Shan Wong and Alan Kwok Lun Cheung and Zeenatul Basher and Chhaya Chaudhary},
  doi       = {10.1038/s41467-017-01121-2},
  issn      = 20411723,
  issue     = 1,
  journal   = {Nature Communications},
  pages     = {1--9},
  pmid      = 29051522,
  publisher = {Springer US},
  title     = {Marine biogeographic realms and species endemicity},
  volume    = 8,
  url       = {http://dx.doi.org/10.1038/s41467-017-01121-2},
  year      = 2017
}

@article{Couch2021,
  abstract = {As the threats to coral reefs mount, scientists and managers are looking for innovative ways to increase the scope, scale, and efficiency of coral reef monitoring. Monitoring changes in coral communities and demographic features provides key information about ecosystem function and resilience of reefs. While most monitoring programs continue to rely on in-water visual survey methods, scientists are exploring 3D imaging technologies such as photogrammetry, also known as Structure-from-Motion (SfM), to enhance precision of monitoring, increase logistical efficiency in the field, and generate a permanent record of the reef. Here, we quantitatively compare data generated from in-water surveys to SfM-derived metrics for assessing coral demography, bleaching, and diversity in the main Hawaiian Islands as part of NOAA's National Coral Reef Monitoring Program. Our objectives were to compare between-method error to within-method error, test for bias between methods, and identify strengths and weaknesses of both methods. Colony density, average colony diameter, average partial mortality, prevalence of bleaching, species richness, and species diversity were recorded using both methods within the same survey areas. For all metrics, the magnitude of between-method error was comparable to the within-method error for the in-water method and between method error was significantly higher than within-method error for SfM for one of the seven metrics. Our results also reveal that a majority of the metrics do not vary significantly between methods, nor did we observe a significant interaction between method and habitat type or method and depth. Exceptions include estimates of partial mortality, bleaching prevalence, and Porites juvenile density–though differences between methods are generally small. Our study also highlights that SfM offers a unique opportunity to more rigorously quantify and mitigate inter-observer error by providing observers unlimited ``bottom time'' and the opportunity to work together to resolve difficult annotations. However, the necessary investment in equipment and expertise does present substantial up-front costs, and the time associated with curating imagery, photogrammetric modeling, and manual image annotation can reduce the timeliness of data reporting. SfM provides a powerful tool to reimagine how we study and manage coral reefs, and this study provides the first quantified methodological comparison to validate the transition from standard in-water methods to SfM survey methods for estimates of coral colony-level surveys.},
  author   = {Courtney S. Couch and Thomas A. Oliver and Rhonda Suka and Mia Lamirand and Mollie Asbury and Corinne Amir and Bernardo Vargas-\'{A}ngel and Morgan Winston and Brittany Huntington and Frances Lichowski and Ariel Halperin and Andrew Gray and Joao Garriques and Jennifer Samson},
  doi      = {10.3389/fmars.2021.647943},
  issn     = 22967745,
  issue    = {May},
  journal  = {Frontiers in Marine Science},
  keywords = {Hawaii,benthic monitoring,coral demography,coral diversity,coral reef,photogrammetry,structure-from-motion},
  pages    = {1--14},
  title    = {Comparing Coral Colony Surveys From In-Water Observations and Structure-From-Motion Imagery Shows Low Methodological Bias},
  volume   = 8,
  year     = 2021
}

@article{Coulais2005,
  abstract = {Water is one of the most important natural phenomena to be rendered in computer graphics. Although ocean waves animation has been well studied in Computer graphics, only few studies have been done for underwater animation. In this paper, we present a new real-time method for animation of suspended particles and seaweeds in underwater scenes. One of the main advantages of this method, compared to other approaches, is the real-time animation of submerged objects by taking into account some natural underwater forces that govern their movements, such as forces generated by water surface in deep and shallow waters as well as underwater currents. Taking into account forces generated by ocean surface is an original approach in Computer Graphics. In addition, real-time animation of complex underwater scenes composed of a great number of particles and seaweeds can be performed by the use of appropriate levels of details.},
  author   = {Y. Coulais and D. Ghazanfarpour and O. Terraz and S. Thon},
  isbn     = 3905673568,
  journal  = {EG UK Theory and Practice of Computer Graphics, TPCG 2005},
  title    = {Real-Time Animation of Particles and Seaweeds in Underwater Scenes},
  url      = {https://diglib.eg.org/bitstream/handle/10.2312/LocalChapterEvents.TPCG.TPCGUK05.019-026/019-026.pdf?sequence=1},
  year     = 2005
}

@misc{CourseBartheFonctionsImplicites,
  author = {Lo\"{\i}c Barthe},
  title  = {Fonctions, formes 3D, assemblages et animation},
  url    = {https://www.irit.fr/recherches/VORTEX/vulgarisation/Loic/2015-04\_Sofia-Kovaleskaia\_Loic-Barthe.pdf}
}

@misc{CourseImplicitSurfaces2014,
  author = {Princeton University},
  title  = {Implicit Surfaces \& Solid Representations 3D Object Representations},
  url    = {https://www.cs.princeton.edu/courses/archive/spring14/cos426/lectures/09-implicit.pdf},
  year   = 2014
}

@article{Cowart2010,
  abstract = {Continued climate change, sea-level rise, and coastal development have lead to concern about shoreline dynamics beyond oceanfront areas, encompassing more sheltered coastal water bodies such as estuaries. Because estuaries are critically important ecosystems, understanding coastline changes in these areas is necessary to evaluating resource risks. A transect-based approach is commonly used to quantify shoreline change on linear (i.e., ocean) shorelines; however, due to the complex morphology of the study area, a point-based approach was developed and applied in this study. Shoreline-change rates and additional parameters (i.e., wave energy and shoreline composition) were determined using 1958 and 1998 aerial photography and available datasets. From this data, the average shoreline change in the study area is -0.24 m yr(-1), with 88\% of the shoreline eroding. Of the parameters analyzed, shoreline composition appears to have an important control on shoreline erosion, whereas wave energy is not significantly correlated with shoreline-change rates.},
  author   = {Lisa Cowart and J. P. Walsh and D. Reide Corbett},
  doi      = {10.2112/jcoastres-d-09-00117.1},
  issn     = {0749-0208},
  issue    = {September},
  journal  = {Journal of Coastal Research},
  pages    = {817--830},
  title    = {Analyzing Estuarine Shoreline Change: A Case Study of Cedar Island, North Carolina},
  volume   = 265,
  year     = 2010
}

@inbook{Crane2007,
  abstract = {The GPU Gems series features a collection of the most essential algorithms required by Next-Generation 3D Mittring, Lead Graphics Programmer, third volume of the best-selling GPU Gems series provides a snapshot of today's latest Graphics Processing Unit (GPU) programming techniques. The programmability of modern GPUs allows developers to not only distinguish themselves from one another but also to use this awesome processing power for non-graphics applications, such as physics simulation, financial analysis, and even virus detection, particularly with the CUDA architecture. Graphics remains the leading application for GPUs, and readers will find that the latest algorithms create ultra-realistic characters, better lighting, and post-rendering compositing effects. Major topics and EffectsPhysics SimulationGPU are from the following corporations and SystemsAppleBudapest University of Technology and Chinese University of Hong KongCornell Technical University in PragueDartmouth CollegeDigital Illusions Creative EntertainmentEindhoven University of TechnologyElectronic ArtsHavokHelsinki University of TechnologyImperial College LondonInfinity WardJuniper University of Bordeauxmental imagesMicrosoft ResearchMove InteractiveNCsoft CorporationNVIDIA CorporationPerpetual EntertainmentPlaylogic Game StudiosSEGA CorporationUFRGS (Brazil)Ulm UniversityUniversity of California, DavisUniversity of Central FloridaUniversity of CopenhagenUniversity of GironaUniversity of Illinois at Urbana-ChampaignUniversity of North Carolina Chapel HillUniversity of TokyoUniversity of WaterlooSection Editors include NVIDIA engineers: Cyril Zeller, Evan Hart, Ignacio Casta o, Kevin Bjorke, Kevin Myers, and Nolan Goodnight.The accompanying DVD includes complementary examples and sample programs.},
  author   = {Keenan Crane and Ignacio Llama and Sarah Tariq},
  isbn     = {0321515269},
  issue    = {August 2007},
  journal  = {GPU Gems 3},
  pages    = 1008,
  title    = {Real-Time Simulation and Rendering of 3D Fluids},
  url      = {http://www.amazon.com/GPU-Gems-3-Hubert-Nguyen/dp/0321515269\%5Cnhttp://http.developer.nvidia.com/GPUGems3/gpugems3\_ch03.html},
  year     = 2007
}

@article{Crause2015,
  author      = {Justin Crause},
  institution = {University of Cape Town},
  title       = {Fast, Realistic Terrain Synthesis},
  url         = {http://library.wur.nl/WebQuery/wurpubs/fulltext/353506},
  year        = 2015
}

@article{Crespin1996,
  author  = {Beno\^{\i}t Crespin and Carole Blanc and Christophe Schlick},
  doi     = {10.1111/1467-8659.1530165},
  issn    = {01677055},
  issue   = 3,
  journal = {Computer Graphics Forum},
  pages   = {165--174},
  title   = {Implicit sweep objects},
  volume  = 15,
  year    = 1996
}

@article{Croissant2017,
  abstract = {Mountain ranges are frequently subjected to mass wasting events triggered by storms or earthquakes and supply large volumes of sediment into river networks. Besides altering river dynamics, large sediment deliveries to alluvial fans are known to cause hydro-sedimentary hazards such as flooding and river avulsion. Here we explore how the sediment supply history affects hydro-sedimentary river and fan hazards, and how well can it be predicted given the uncertainties on boundary conditions. We use the 2D morphodynamic model Eros with a new 2D hydrodynamic model driven by a sequence of flood, a sediment entrainment/transport/deposition model and a bank erosion law. We first evaluate the model against a natural case: the 1999 Mount Adams rock avalanche and subsequent avulsion on the Poerua river fan (West Coast, New Zealand). By adjusting for the unknown sediment supply history, Eros predicts the evolution of the alluvial riverbed during the first post-landslide stages within 30 cm. The model is subsequently used to infer how the sediment supply volume and rate control the fan aggradation patterns and associated hazards. Our results show that the total injected volume controls the overall levels of aggradation, but supply rates have a major control on the location of preferential deposition, avulsion and increased flooding risk. Fan re-incision following exhaustion of the landslide-derived sediment supply leads to sediment transfer and deposition downstream and poses similar, but delayed, hydro-sedimentary hazards. Our results demonstrate that 2D morphodynamics models are able to capture the full range of hazards occurring in alluvial fans including river avulsion aggradation and floods. However, only ensemble simulations accounting for uncertainties in boundary conditions (e.g., discharge history, initial topography, grain size) as well as model realization (e.g., non-linearities in hydro-sedimentary processes) can be used to produce probabilistic hazards maps relevant for decision making. Copyright \textcopyright{} 2017 John Wiley \& Sons, Ltd.},
  author   = {Thomas Croissant and Dimitri Lague and Philippe Davy and Tim Davies and Philippe Steer},
  doi      = {10.1002/esp.4171},
  issn     = 10969837,
  issue    = 13,
  journal  = {Earth Surface Processes and Landforms},
  keywords = {alluvial fan dynamics,hydro-sedimentary hazards,morphodynamic modeling},
  pages    = {2054--2067},
  title    = {A precipiton-based approach to model hydro-sedimentary hazards induced by large sediment supplies in alluvial fans},
  volume   = 42,
  year     = 2017
}

@article{Cruz2018,
  author = {Leandro Cruz and Luiz Velho and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin},
  doi    = {https://dx.doi.org/10.5220/0005360201890194},
  isbn   = {0005360201890},
  title  = {Patch-based Terrain Synthesis},
  year   = 2018
}

@article{Csébfalvi2023,
  abstract = {Recently, it has been shown that the quality of GPU-based trilinear volume resampling can be significantly improved if the six additional trilinear samples evaluated for the gradient estimation also contribute to the reconstruction of the underlying function [Cs\'{e}19]. Although this improvement increases the approximation order from two to three without any extra cost, the continuity order remains C0. In this paper, we go one step further showing that a C1 continuous triquadratic B-spline reconstruction and its analytic partial derivatives can be evaluated by taking only one more trilinear sample into account. Thus, our method is the first volume-resampling technique that is nearly as fast as trilinear interpolation combined with on-the-fly central differencing, but provides a higher-quality reconstruction together with a consistent analytic gradient calculation. Furthermore, we show that our fast evaluation scheme can also be adapted to the Mitchell-Netravali [MN88] notch filter, for which a fast GPU implementation has not been known so far.},
  author   = {Bal\'{a}zs Cs\'{e}bfalvi},
  doi      = {10.1111/cgf.14753},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,Image processing,Texturing,\textbullet{} Computing methodologies \rightarrow{} Volumetric models},
  pages    = {191--200},
  title    = {One Step Further Beyond Trilinear Interpolation and Central Differences: Triquadratic Reconstruction and its Analytic Derivatives at the Cost of One Additional Texture Fetch},
  volume   = 42,
  year     = 2023
}

@article{Curry1999,
  abstract = {L-systems have been shown to be a useful tool for modeling plants; however, the generation of realistic plant models requires an extensive knowledge of L-systems. People who are not L-system experts require a simpler way of creating plant models. This paper will describe my attempts at designing a user interface which allows the user to guide the evolution of plant models generated from a parametric L-system and the genetic algorithm employed to facilitate this evolution. The nal goal of this research would be a design environment in which plant models could be easily and quickly generated without explicit knowledge of L-systems. The plant models would still be L-systems but the user would not ever need to see them. By exploring the concept of evolution as a method for developing plant models we m a y also gain insight i n to the development of plants themselves.},
  author   = {Roger Curry},
  pages    = 27,
  title    = {On the Evolution of Parametric L-systems},
  url      = {http://algorithmicbotany.org/papers/on-the-evolution-of-parametric-l-systems.pdf},
  year     = 1999
}

@article{Cutler2002,
  abstract = {We present a procedural approach to authoring layered, solid models. Using a simple scripting language, we define the internal structure of a volume from one or more input meshes. Sculpting and simulation operators are applied within the context of the language to shape and modify the model. Our framework treats simulation as a modeling operator rather than simply as a tool for animation, thereby suggesting a new paradigm for modeling as well as a new level of abstraction for interacting with simulation environments. Capturing real-world effects with standard modeling techniques is extremely challenging. Our key contribution is a concise procedural approach for seamlessly building and modifying complex solid geometry. We present an implementation of our language using a flexible tetrahedral representation. We show a variety of complex objects modeled in our system using tools that interface with finite element method and particle system simulations.},
  author   = {Barbara Cutler and Julie Dorsey and Leonard McMillan and Matthias M\"{u}ller and Robert Jagnow},
  doi      = {10.1145/566654.566581},
  isbn     = 1581135211,
  issn     = {07300301},
  issue    = 3,
  journal  = {ACM Transactions on Graphics},
  keywords = {Signed-distance function,Tetrahedral representation,Volumetric modeling},
  pages    = {302--311},
  title    = {A procedural approach to authoring solid models},
  volume   = 21,
  year     = 2002
}

@article{DaCosta2015,
  abstract  = {The physical habitat simulation sub-routine of the Instream Flow Incremental Methodology (IFIM) uses hydraulic modeling and suitability indices of target fish species to predict how differences in-stream flows affect the microhabitat occupation by fish species. This habitat modelling approach was adopted to assess the ecological effects of running flows on three neotropical fish species of different orders (Bryconamericus ornaticeps, Ancistrus multispinis and Geophagus brasiliensis).The study encompassed two reaches of an Atlantic Forest stream in Southeastern Brazil where topographic and hydraulic (depth, velocity and type of substrate) characteristics were measured to implement one-dimensional hydraulic simulation. Sub aquatic observation of fish was performed to collect data on microhabitat use and these data were used to develop habitat suitability curves that were used in the habitat simulation to obtain the habitat suitability index (HSI) and weighted usable area (WUA) versus flow curves. Upon these curves minimum and optimum environmental flows for the target fish species were proposed. Bryconamericus ornaticeps and A. multispinis selected microhabitats around 0.6 m depth, whereas G. brasiliensis showed a wider suitable range (0.35-0.9 m). All the three species were mainly observed in microhabitat with low flow velocity (0.1 m/s). Bryconamericus ornaticeps selected more frequently coarse substrate (e.g. boulders) but it appeared also over sandy substrate, whereas A. multispinis and G. brasiliensis selected preferably boulders. The range of 0.65-0.85 m3/s was found as the optimum to meet the needs of the three fish species. Our results agree with the necessary objective information to perform grounded management actions in the frame of a management program aiming at ecosystem conservation. Thereby it can be considered a successful pilot study in environmental flow assessment in an Atlantic Forest stream of Brazil.},
  author    = {Marcus Rodrigues da Costa and Tailan Moretti Mattos and Victor Hugo Fernandes and Francisco Mart\'{\i}nez-Capel and Rafael Mu\~{n}oz-Mas and Francisco Gerson Ara\'{u}jo},
  doi       = {10.1590/1982-0224-20140170},
  issn      = 19820224,
  issue     = 4,
  journal   = {Neotropical Ichthyology},
  keywords  = {Habitat modeling,Habitat suitability curves,Neotropical fish},
  month     = 10,
  pages     = {685--698},
  publisher = {Sociedade Brasileira de Ictiologia},
  title     = {Application of the physical habitat simulation for fish species to assess environmental flows in an Atlantic Forest Stream in South-eastern Brazil},
  volume    = 13,
  year      = 2015
}

@article{Daly1915,
  author  = {Reginald A . Daly},
  issue   = 4,
  journal = {Proceedings of the American Academy of Arts and Sciences},
  pages   = {157--251},
  title   = {The Glacial-Control Theory of Coral Reefs},
  volume  = 51,
  url     = {http://www.jstor.org/s},
  year    = 1915
}

@article{Dam2019,
  abstract  = {The task of recreating a real world location in a virtual environment is never easy, and a high degree of similarity is crucial for specialized training and simulation sessions, which are becoming ever more employed in the military to improve training methods. Allowing the users to recognize the location in the virtual environment through the use of real maps, for example, increases user engagement, helping to increase the overall quality of the training session. One factor that must be accounted for is the availability of data to perform the creation of these virtual environments, especially in locations such as areas with low population density or small cities in South America. In this paper we present a method to enable the creation, with limited data availability, of a very large, high quality, and optimized environment for ground-level simulations using Unity 3D, one of the current state of the art game engines.},
  author    = {Peter Dam and Fernanda Duarte and Alberto Raposo},
  doi       = {10.1109/SBGames.2019.00031},
  isbn      = 9781728146379,
  issn      = 21596662,
  journal   = {Brazilian Symposium on Games and Digital Entertainment, SBGAMES},
  keywords  = {real world,serious games,simulation,terrain generation,training,virtual environment},
  pages     = {173--181},
  publisher = {IEEE},
  title     = {Terrain Generation Based on Real World Locations for Military Training and Simulation},
  volume    = {2019-Octob},
  year      = 2019
}

@article{Damiand2001,
  author  = {Guillaume Damiand},
  journal = {No\^{u}s},
  title   = {Th\`{e}se D\'{e}finition et \'{e}tude d'un mod\`{e}le topologique minimal de repr\'{e}sentation d'images 2d et 3d},
  year    = 2001
}

@book{Damiand2004,
  abstract = {In this paper, we define the two-dimensional topological map, a model which represents both topological and geometrical information of a two-dimensional labeled image. Since this model is minimal, complete, and unique, we can use it to define efficient image processing algorithms. The topological map is the last level of a map hierarchy. Each level represents the region boundaries of the image and is defined from the previous one in the hierarchy, thus giving a simple constructive definition. This model is similar to two existing structures but the main innovation of our approach is the progressive definition based on the successive map levels. These different maps can easily be extended in order to define the topological map in any dimension. Furthermore we provide an optimal extraction algorithm which extracts the different maps of the hierarchy in a single image scan. This algorithm is based on local configurations called precedes. Due to our constructive definition, different configurations are factorized which simplifies the implementation. \textcopyright{} 2003 Elsevier Inc. All rights reserved.},
  author   = {Guillaume Damiand and Yves Bertrand and Christophe Fiorio},
  doi      = {10.1016/j.cviu.2003.09.001},
  isbn     = 3346741850,
  issn     = 10773142,
  issue    = 2,
  journal  = {Computer Vision and Image Understanding},
  keywords = {Combinatorial map,Image representation,Interpixel boundaries,Segmentation,Topological model},
  pages    = {111--154},
  title    = {Topological model for two-dimensional image representation: Definition and optimal extraction algorithm},
  volume   = 93,
  year     = 2004
}

@article{Damiand2008,
  abstract = {In this paper, we define the three-dimensional topological map, a model which represents both the topological and geometrical information of a three-dimensional labeled image. Since this model describes the image's topology in a minimal way, we can use it to define efficient image processing algorithms. The topological map is the last level of map hierarchy. Each level represents the region boundaries of the image and is defined from the previous level in the hierarchy, thus giving a simple constructive definition. This model is an extension of the similar model defined for 2D images. Progressive definition based on successive map levels allows us to extend this model to higher dimension. Moreover, with progressive definition, we can study each level separately. This simplifies the study of disconnection cases and the proofs of topological map properties. Finally, we provide an incremental extraction algorithm which extracts any map of the hierarchy in a single image scan. Moreover, we show that this algorithm is very efficient by giving the results of our experiments made on artificial images. \textcopyright{} 2007 Elsevier Inc. All rights reserved.},
  author   = {Guillaume Damiand},
  doi      = {10.1016/j.cviu.2007.09.007},
  issn     = 10773142,
  issue    = 3,
  journal  = {Computer Vision and Image Understanding},
  keywords = {3D image representation,Combinatorial map,Intervoxel boundaries,Structure for image processing,Topological model},
  pages    = {260--289},
  title    = {Topological model for 3D image representation: Definition and incremental extraction algorithm},
  volume   = 109,
  year     = 2008
}

@book{Darwin1842,
  author    = {Charles Darwin},
  title     = {Charles Darwin 1842},
  year      = 1842,
  doi       = {10.1017/CBO9781107325098.003},
  isbn      = 9781107325098,
  journal   = {The Structure and Distribution of Coral Reefs},
  month     = 9,
  pages     = {5--40},
  publisher = {Cambridge University Press},
  url       = {https://www.cambridge.org/core/product/identifier/CBO9781107325098A008/type/book\_part},
  abstract  = {Darwin, Charles (1842), The Structure and Distribution of Coral Reefs. Being the first part of the geology of the voyage of the Beagle, under the command of Capt. Fitzroy, R.N. during the years 1832 to 1836, London: Smith Elder and Co},
  issn      = {02666235},
  issue     = {May},
  volume    = 12
}

@inbook{Darwin1845,
  author  = {Charles Darwin},
  doi     = {10.1144/GSL.JGS.1845.001.01.82},
  issn    = {0370-291X},
  issue   = 1,
  journal = {Quarterly Journal of the Geological Society},
  month   = 2,
  pages   = {381--389},
  title   = {The structure and distribution of coral reefs - Chap V : Notices of new books},
  volume  = 1,
  url     = {https://www.lyellcollection.org/doi/10.1144/GSL.JGS.1845.001.01.82},
  year    = 1845
}

@inbook{Darwin2013,
  abstract  = {Seiring dengan kemajuan ilmu pengetahuan dan teknologi yang menjadi pusat perhatian dunia. Maka manusia dituntut untuk menciptakan peralatan-peralatan canggih untuk teknologi muktahir. Baik itu dalam bidang bisnis, perdagangan, kesehatan, militer, pendidikan, komunikasi dan budaya maupun bidang-bidang lainnya. Maka teknologi ini membawa perubahan pada peralatan-peralatan yang dulunya bekerja secara analog mulai dikembangkan secara digital, dan bahkan yang bekerjanya secara manual sekarang banyak dikembangkan secara otomatis, seperti kamera digital, handycam, dan sebagainya, dalam pembacaan pengukuran juga sudah dikembangkan ke dalam teknik digital. Contohnya perangkat Load Cell. Dan keuntungan menggunakan Load Cell adalah untuk mempermudah dalam pembacaan data untuk meminimalkan kesalahan dalam pembacaan data yang disebabkan adanya human error.Pada pemilihan Load Cell bertujuan untuk memilih kecocokan dalam membuat rancang bangun alat uji tarik kapasitas 3 ton, dimana dalam pemilihan ini kami memilih jenis load cell ``S'' karna alat yang kita rancang adalah uji tarik bukan uji tekan. Dengan kapasitas load cell 5 ton. Untuk membuat jarak aman dalam pengujian specimen ST41. Load Cell menggunakan system perangkat elektronik pengolahan data yang menjadi sebuah kurva tegangan regangan. Data-data yang diperoleh tersebut berupa besarnya pembebanan hasil dari pengujian specimen ST41. Kata},
  author    = {Charles Darwin},
  doi       = {10.1017/CBO9781107325098.009},
  isbn      = 2013206534,
  journal   = {The Structure and Distribution of Coral Reefs},
  month     = 9,
  pages     = {149--205},
  publisher = {Cambridge University Press},
  title     = {The structure and distribution of coral reefs - Appendix},
  url       = {https://www.cambridge.org/core/product/identifier/CBO9781107325098A014/type/book\_part},
  year      = 2013,
  volume    = {i}
}

@inbook{Darwin2016,
  abstract = {Seiring dengan kemajuan ilmu pengetahuan dan teknologi yang menjadi pusat perhatian dunia. Maka manusia dituntut untuk menciptakan peralatan-peralatan canggih untuk teknologi muktahir. Baik itu dalam bidang bisnis, perdagangan, kesehatan, militer, pendidikan, komunikasi dan budaya maupun bidang-bidang lainnya. Maka teknologi ini membawa perubahan pada peralatan-peralatan yang dulunya bekerja secara analog mulai dikembangkan secara digital, dan bahkan yang bekerjanya secara manual sekarang banyak dikembangkan secara otomatis, seperti kamera digital, handycam, dan sebagainya, dalam pembacaan pengukuran juga sudah dikembangkan ke dalam teknik digital. Contohnya perangkat Load Cell. Dan keuntungan menggunakan Load Cell adalah untuk mempermudah dalam pembacaan data untuk meminimalkan kesalahan dalam pembacaan data yang disebabkan adanya human error.Pada pemilihan Load Cell bertujuan untuk memilih kecocokan dalam membuat rancang bangun alat uji tarik kapasitas 3 ton, dimana dalam pemilihan ini kami memilih jenis load cell ``S'' karna alat yang kita rancang adalah uji tarik bukan uji tekan. Dengan kapasitas load cell 5 ton. Untuk membuat jarak aman dalam pengujian specimen ST41. Load Cell menggunakan system perangkat elektronik pengolahan data yang menjadi sebuah kurva tegangan regangan. Data-data yang diperoleh tersebut berupa besarnya pembebanan hasil dari pengujian specimen ST41. Kata},
  author   = {Charles Darwin},
  isbn     = 2013206534,
  journal  = {The Structure and Distribution of Coral Reefs},
  pages    = {1--23},
  title    = {The structure and distribution of coral reefs - Preface},
  year     = 2016
}

@inbook{Darwin2017,
  author  = {Charles Darwin},
  isbn    = 9781107325098,
  journal = {The Structure and Distribution of Coral Reefs},
  pages   = 2017,
  title   = {The structure and distribution of coral reefs - Errata},
  year    = 2017
}

@inbook{Darwin2018,
  author   = {Charles Darwin},
  isbn     = 6103544947,
  issue    = 2,
  journal  = {Journal of Controlled Release},
  keywords = {jel classification,l25,m11,performance,supply chain integration,supply chain management},
  pages    = {430--439},
  title    = {The structure and distribution of coral reefs - Supplementary maps},
  volume   = 11,
  year     = 2018
}

@inbook{Darwin2019,
  author  = {Charles Darwin},
  isbn    = 9781107325098,
  title   = {The structure and distribution of coral reefs - Chap V: Theory of the formation of the different classes of coral-reefs},
  year    = 2019,
  journal = {The Structure and Distribution of Coral Reefs},
  pages   = {119--148},
  volume  = {ii}
}

@article{DaSilva2001,
  abstract  = {The dynamics of the vegetated beds of the estuary of the Patos Lagoon was investigated using a simulation model for two important benthic primary producers (the widgeon grass Ruppia maritima and its epiphytes). The model, of deterministic characteristics, simulated two development cycles of the beds from summer 1992/1993 to 1993/1994. Model validation and calibration were accomplished by using R. maritima biomass collected in shallow bays of the Paros Lagoon estuary during the two simulated cycles. The model simulated the seasonal variations in the biomass of blades, stems, roots plus rhizomes, seeds and fruit of R. maritima, by using the experimental components method, and the epiphytes biomass, by using the compartmental system method, all expressed in g dry wt. (gDW) m-2. The model accurately reproduced the processes of building and decay of R. maritima biomass, representing the maximum values observed in the environment. Plant height and its phenological stage were two important attributes included in the model. They were important to control the processes of light attenuation, beginning of the epiphytes installation and the removal of the grass by hydrodynamic action. Bending of the grass and biomass removal were very important to the model results and they seemed to be the primary factors that control the plant decay in late summer. Ecological modeling has proved to be a powerful tool for the proposition of new control mechanisms for the dynamics of the vegetated beds of the estuary of the Paros Lagoon.},
  author    = {Eduardo Teixeira Da Silva and Milton L. Asmus},
  doi       = {10.1016/S0304-3800(00)00425-7},
  issn      = {03043800},
  issue     = {2-3},
  journal   = {Ecological Modelling},
  keywords  = {Biomass partition,Epiphytes,Hydrodynamic action,Phenological development,Ruppia maritima,Simulation model},
  month     = 2,
  pages     = {161--179},
  publisher = {Elsevier},
  title     = {A dynamic simulation model of the widgeon grass Ruppia maritima and its epiphytes in the estuary of the Patos Lagoon, RS, Brazil},
  volume    = 137,
  year      = 2001
}

@article{daSilva2020,
  abstract  = {Spur-and-groove (SAG) morphology characterizes the fore reef of many coral reefs worldwide. Although the existence and geometrical properties of SAG have been well documented, an understanding of the hydrodynamics over them is limited. Here, the three-dimensional flow patterns over SAG formations, and a sensitivity of those patterns to waves, currents, and SAG geometry were characterized using the physics-based Delft3D-FLOW and SWAN models. Shore-normal shoaling waves over SAG formations were shown to drive two circulation cells: a cell on the lower fore reef with offshore flow over the spurs and onshore flow over the grooves, except near the seabed where velocities were always onshore, and a cell on the upper fore reef with offshore surface velocities and onshore bottom currents, which result in depth-averaged onshore and offshore flow over the spurs and grooves, respectively. The mechanism driving this flow results from the net of the radiation stress gradients and pressure gradient, which is balanced by the Reynolds stress gradients and bottom friction that differ over the spur and over the groove. Waves were the primary driver of variations in modelled flow over SAG, with the flow strength increasing for increasing wave heights and periods. Spur height, SAG wavelength, and the water depth at peak spur height were the dominant influences on the hydrodynamics, with spur heights directly proportional to the strength of SAG circulation cells. SAG formations with shorter SAG wavelengths only presented one circulation cell on the shallower portion of the reef, as opposed to the two circulation cells for longer SAG wavelengths. SAG formations with peak spur heights occurring in shallower water had stronger circulation than those with peak spur heights occurring in deeper water. These hydrodynamic patterns also likely affect coral and reef development through sediment and nutrient fluxes.},
  author    = {Renan F. da Silva and Curt D. Storlazzi and Justin S. Rogers and Johan Reyns and Robert McCall},
  doi       = {10.1007/s00338-020-02011-8},
  issn      = 14320975,
  issue     = 6,
  journal   = {Coral Reefs},
  keywords  = {(3D) modelling,Coral reef,Currents,Delft3D,Spur-and-groove,Waves},
  pages     = {1841--1858},
  publisher = {Springer Berlin Heidelberg},
  title     = {Modelling three-dimensional flow over spur-and-groove morphology},
  volume    = 39,
  url       = {https://doi.org/10.1007/s00338-020-02011-8},
  year      = 2020
}

@article{Davies1977,
  author  = {P J Davies and D W Kinsey},
  journal = {Marine Geology},
  title   = {Holocene reef growth -- One Tree Island, Great Barrier Reef},
  volume  = 24,
  year    = 1977
}

@article{Davis1914,
  author  = {W. M. Davis},
  doi     = {10.2307/201744},
  issn    = {01905929},
  issue   = 10,
  journal = {Bulletin of the American Geographical Society},
  pages   = 721,
  title   = {The Home Study of Coral Reefs. Part III},
  volume  = 46,
  url     = {https://www.jstor.org/stable/201744?origin=crossref},
  year    = 1914
}

@article{Davis1922,
  author  = {W. M. Davis},
  doi     = {10.2307/2560592},
  issn    = {00045608},
  issue   = 1922,
  journal = {Annals of the Association of American Geographers},
  pages   = 97,
  title   = {The Barrier Reef of Tagula, New Guinea},
  volume  = 12,
  url     = {http://links.jstor.org/sici?sici=0004-5608\%281922\%2912\%3C97\%3ATBROTN\%3E2.0.CO\%3B2-P\&origin=crossref},
  year    = 1922
}

@article{Davis2002b,
  abstract = {We present an approach for recognizing human walking movements using low-level motion regularities and constraints. Biomechanical features for classification are automatically extracted from video sequences of walkers. A multiplicative classification rule using statistical distances is then used to determine whether an unknown motion is consistent with normal walking patterns. Recognition results are shown distinguishing walking examples across multiple speeds from other non-walking locomotions. \textcopyright{} 2002 IEEE.},
  author   = {James W. Davis and Stephanie R. Taylor},
  doi      = {10.1109/icpr.2002.1044702},
  issn     = 10514651,
  issue    = 1,
  journal  = {Proceedings - International Conference on Pattern Recognition},
  pages    = {315--318},
  title    = {Analysis and recognition of walking movements},
  volume   = 16,
  url      = {https://sci-hub.mksa.top/10.1109/icpr.2002.1044702},
  year     = 2002
}

@article{Davis2017,
  abstract = {Fourier transforms have been used in the analysis of landscapes that exhibit the influence of cyclic structures or other morphogenetic controls. Two-dimensional Fourier transforms have been most successful when modeling features with a high frequency over the sample space. This research focuses on applications of 2D discrete Fourier transforms for karst and spur and groove coral reefs, using ArcGIS geoprocessing tools extended with Python NumPy numerical methods. Ten-meter digital elevation data from Puerto Rico and Kentucky holokarst landscapes and five-meter bathymetry from more unidirectional spur and groove coral reefs at Midway Atoll were analyzed. Our method identifies the dominant contributing waves in frequency space, and analyzed power contributions by 5\textdegree{} and 15\textdegree{} azimuth bins. A limiting factor in this analysis is the spatial extent of consistent morphology in the landscape. In contrast to time-domain Fourier analysis, dominant landform frequencies can thus be of low magnitude, creating an imprecise estimate of wave morphometry and direction since this is derived from the combination of inverted x and y frequency values, and the limited frequency grain inherent in the discrete model degrades precision in the solution. Simulated karst and spur \& groove landscapes were used to evaluate the grain of waveform orientation solutions.},
  author   = {Jerry D. Davis and Joseph D. Chojnacki},
  doi      = {10.1111/tgis.12277},
  issn     = 14679671,
  issue    = 3,
  journal  = {Transactions in GIS},
  pages    = {521--545},
  title    = {Two-dimensional discrete Fourier transform analysis of karst and coral reef morphologies},
  volume   = 21,
  year     = 2017
}

@inproceedings{DeCarpentier,
  author    = {Giliam J. P. de Carpentier and Rafael Bidarra},
  city      = {New York, NY, USA},
  doi       = {10.1145/1536513.1536532},
  isbn      = 9781605584379,
  booktitle = {Proceedings of the 4th International Conference on Foundations of Digital Games},
  month     = 4,
  pages     = {55--62},
  publisher = {ACM},
  title     = {Interactive GPU-based procedural heightfield brushes},
  volume    = 8,
  url       = {https://dl.acm.org/doi/10.1145/1536513.1536532},
  year      = 2009
}

@article{DeGoes2017,
  abstract = {We introduce a new technique for real-Time physically based volume sculpting of virtual elastic materials. Our formulation is based on the elastic response to localized force distributions associated with common modeling primitives such as grab, scale, twist, and pinch. The resulting brush-like displacements correspond to the regularization of fundamental solutions of linear elasticity in infinite 2D and 3D media. These deformations thus provide the realism and plausibility of volumetric elasticity, and the interactivity of closed-form analytical solutions. To finely control our elastic deformations, we also construct compound brushes with arbitrarily fast spatial decay. Furthermore, pointwise constraints can be imposed on the displacement field and its derivatives via a single linear solve. We demonstrate the versatility and efficiency of our method with multiple examples of volume sculpting and image editing.},
  author   = {Fernando De Goes and Doug L. James},
  doi      = {10.1145/3072959.3073595},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Linear elasticity,Sculpting brushes},
  pages    = {401--411},
  title    = {Regularized Kelvinlets: Sculpting Brushes based on Fundamental Solutions of Elasticity},
  volume   = 36,
  year     = 2017
}

@article{DeGoes2019,
  abstract = {In this work, we present an extension of the regularized Kelvinlet technique suited to non-smooth, cusp-like edits. Our approach is based on a novel multi-scale convolution scheme that layers Kelvinlet deformations into a finite but spiky solution, thus offering physically based volume sculpting with sharp falloff profiles. We also show that the Laplacian operator provides a simple and effective way to achieve elastic displacements with fast far-field decay, thereby avoiding the need for multi-scale extrapolation. Finally, we combine the multi-scale convolution and Laplacian machinery to produce Sharp Kelvinlets, a new family of analytic fundamental solutions of linear elasticity with control over both the locality and the spikiness of the brush profile. Closed-form expressions and reference implementation are also provided.},
  author   = {Fernando De Goes and Doug L. James},
  doi      = {10.1145/3329715.3338884},
  isbn     = 9781450367998,
  journal  = {Proceedings - DigiPro 2019: ACM Digital Production Symposium},
  keywords = {Linear elasticity,Profile control,Regularized kelvinlets,Sculpting brushes},
  title    = {Sharp kelvinlets: Elastic deformations with cusps and localized falloffs},
  year     = 2019
}

@article{DeGroot2014,
  abstract = {Texture mapping is an essential component for creating 3D models and is widely used in both the game and the movie industries. Creating texture maps has always been a complex task and existing methods carefully balance flexibility with ease of use. One difficulty in using texturing is the repeated placement of individual textures over larger areas. In this paper, we propose a method which uses decals to place images onto a model. Our method allows the decals to compete for space and to deform as they are being pushed by other decals. A spherical field function is used to determine the position and the size of each decal and the deformation applied to fit the decals. The decals may span multiple objects with heterogeneous representations. Our method does not require an explicit parametrization of the model. As such, varieties of patterns, including repeated patterns like rocks, tiles and scales can be mapped. We have implemented the method using the GPU where placement, size and orientation of thousands of decals are manipulated in real time. \textcopyright{} 2013 The Authors Computer Graphics Forum \textcopyright{} 2013 The Eurographics Association and John Wiley \& Sons Ltd.},
  author   = {Erwin De Groot and Brian Wyvill and Lo\"{\i}c Barthe and Ahmad Nasri and Paul Lalonde},
  doi      = {10.1111/cgf.12260},
  issn     = 14678659,
  issue    = 1,
  journal  = {Computer Graphics Forum},
  keywords = {GPU,decals,implicit surfaces,parameterization,texture mapping},
  pages    = {141--151},
  title    = {Implicit decals: Interactive editing of repetitive patterns on surfaces},
  volume   = 33,
  url      = {https://hal.archives-ouvertes.fr/hal-00876004/document},
  year     = 2014
}

@article{DeKemp2003,
  abstract = {Interpreting the geometry of geological objects is a standard activity of field-based geologists. We present new graphics tools that will aid in extending this activity from 2-D geological mapping into a 3-D environment. Much of the existing 3-D geological modeling software supports the construction of objects with the input of dense control data. However, for regional mapping and near mine exploration work, sparse data is the norm. Tools are required therefore, which give the expert interpreter full control of the graphics objects, while at the same time constraining interpretations to specific control data from field observations. We present the initial results of a software design and programming project for the visualization of complex regional scale geologic objects using B\'{e}zier-based graphics tools that are optimized for sparse data interpretation. We also introduce the concept of a structural ribbon, which is a 3-D extended map trace, along with methods for the optimization of surface construction using graphical grip frames.},
  author   = {Eric A. De Kemp and Kevin Boyce Sprague},
  doi      = {10.1023/A:1022822227691},
  issn     = 13846175,
  issue    = 1,
  journal  = {GeoInformatica},
  keywords = {3-D B\'{e}zier,Grip frames,Interpolation,Ribbons,Structural geology,Surface modeling},
  pages    = {55--71},
  title    = {Interpretive tools for 3-D structural geological modeling part I: B\'{e}zier-based curves, ribbons and grip frames},
  volume   = 7,
  year     = 2003
}

@article{Dembogurski2013,
  abstract = {This paper presents an application that allows the generation of virtual terrains interactively, using augmented reality markers. This application also allows the user to navigate in the generated virtual environment. To demonstrate how the process is done, a terrain generation scenario was chosen. Virtual objects were augmented using markers and the detection is done through the ARToolKit framework. A particle system was used to simulate deformation to better incorporate the needs of terrain generation. The deformation itself follows an interparticle force between the particles attached to a movable physical marker and the particles attached to a fixed multi-marker representing the mesh. A viscous force is also used to generate a plastic material effect ensuring permanent deformation. The resulting application although conceptually simple and easy to use, can produce an immersive output environment that the user can freely navigate.},
  author   = {Renan Augusto Dembogurski and Bruno Jos\'{e} Dembogurski and Jos\'{e} Luiz Ribeiro De Souza Filho and Dhiego Oliveira Sad and Rodrigo De Souza Silva and Marcelo Bernardes Vieira},
  doi      = {10.5753/jis.2012.619},
  issue    = 3,
  journal  = {Journal on Interactive Systems},
  keywords = {2014,a evas\~{a}o em cursos,all content following this,de gamifica\c{c}\~{a}o para diminuir,de gradua\c{c}\~{a}o view project,enhancement of the downloaded,file,page was uploaded by,rodrigo l,s,silva on 25 june,the user has requested},
  pages    = 1,
  title    = {Interactive Virtual Terrain Generation using Augmented Reality Markers},
  volume   = 3,
  year     = 2013
}

@article{DeReffye1981,
  author   = {P de Reffye},
  journal  = {Cafe Cacao The},
  keywords = {ET,growth model,plant architecture,simulation,stochastic model},
  pages    = {83--103},
  title    = {Modele mathematique aleatoire et simulation de la croissance et de l'architecture du cafeier robusta. 1re partie. Etude du fonctionnement des meristemes et de la croissance des axes vegetatifs},
  volume   = 25,
  url      = {https://agritrop.cirad.fr/454168/1/De Reffye 1981-2.pdf},
  year     = 1981
}

@article{Desbenoit2004,
  abstract = {This paper presents a system for modeling lichens and simulating their propagation and growth in a virtual scene. Lichens colonize almost every substrate in nature and play an important role in the visual appearance of a natural object. The propagation of lichens over the substrate is performed by an Open Diffusion Limited Aggregation model constrained by the characteristics of the environment. The designer can control the development of lichens with simple parameters. Rendering the complex geometry and texture of lichens is achieved by instantiating three dimensional lichen models stored in an atlas of shapes created after real world images. The lichens obtained by our approach considerably increase the realism of complex natural scenes.},
  author   = {Brett Desbenoit and Eric Galin and Samir Akkouche},
  doi      = {10.1111/j.1467-8659.2004.00765.x},
  issn     = {01677055},
  issue    = {3 SPEC. ISS.},
  journal  = {Computer Graphics Forum},
  keywords = {Ecosystem simulation,Environment sensitive morphogenesis,Lichen growth,Plant modeling},
  pages    = {341--350},
  title    = {Simulating and modeling lichen growth},
  volume   = 23,
  url      = {https://perso.liris.cnrs.fr/eric.galin/Articles/2004-lichen.pdf},
  year     = 2004
}

@article{Desbenoit2006,
  abstract = {This paper presents a system for modeling autumn leaves covering vegetation and monuments. We simulate the coloring and aging process by a stochastic model that represents the probability of evolution of a leaf according to the characteristics of the environment.We distribute leaves over the ground by approximating their complex move- ment by trajectory templates such as fluttering, rolling and tumbling. Leaves stack onto the ground in successive layers so as to improve the collision detection step.},
  author   = {Brett Desbenoit and Eric Galin and Samir Akkouche and J\'{e}r\^{o}me Grosjean},
  journal  = {EG - EuroGraphics},
  keywords = {aging and weathering,autumn coloring,ecosystem simulation},
  title    = {Modeling autumn sceneries},
  url      = {https://www.iut-arles.univ-provence.fr/web/brett-desbenoit/sites/brett-desbenoit/IMG/pdf/leaves-2006-2.pdf},
  year     = 2006
}

@article{DeWitt2011,
  author  = {Tyler De Witt and Christian Lessig and Eugene Fiume},
  doi     = {10.1145/XXXXXXX.YYYYYYY},
  journal = {ACM Trans. Graph},
  title   = {Fluid Simulation using Laplacian Eigenfunctions},
  volume  = {VV},
  year    = 2011
}

@article{Dey2018,
  abstract  = {Terrain generation is a fundamental requirement of many computer graphics simulations, including computer games, flight simulators and environments in feature films. There has been a considerable amount of research in this domain, which ranges between fully automated and semi-automated methods. Voxel representations of 3D terrains can create rich features that are not found in other forms of terrain generation techniques, such as caves and overhangs. In this article, we introduce a semi-automated method of generating features for volumetric terrains using a rule-based procedural generation system. Features are generated by selecting subsets of a voxel grid as input symbols to a grammar, composed of user-created operators. This results in overhangs and caves generated from a set of simple rules. The feature generation runs on the CPU and the GPU is utilised to extract a robust mesh from the volumetric dataset.},
  author    = {Rahul Dey and Jason G. Doig and Christos Gatzidis},
  doi       = {10.1016/j.entcom.2018.04.003},
  issn      = 18759521,
  journal   = {Entertainment Computing},
  keywords  = {Grammar,Procedural generation,Terrain,Voxels},
  month     = 8,
  pages     = {128--136},
  publisher = {Elsevier B.V.},
  title     = {Procedural feature generation for volumetric terrains using voxel grammars},
  volume    = 27,
  url       = {https://linkinghub.elsevier.com/retrieve/pii/S1875952117301349},
  year      = 2018
}

@article{Dey2021,
  author = {Rahul Dey},
  title  = {Procedural Generation of Features for Volumetric Terrains using a Rule-Based Approach},
  year   = 2021
}

@inproceedings{DiasFernandes2018,
  author    = {Gabriel Dias Fernandes and Antonio Ramires Fernandes},
  doi       = {10.1109/ITCGI.2018.8602928},
  isbn      = {978-1-5386-8228-9},
  issue     = 1,
  booktitle = {2018 International Conference on Graphics and Interaction (ICGI)},
  month     = 11,
  pages     = {1--8},
  publisher = {IEEE},
  title     = {Space Colonisation for Procedural Road Generation},
  url       = {https://ieeexplore.ieee.org/document/8602928/},
  year      = 2018
}

@misc{Diaz-Pernil_noDate,
  abstract = {Sudoku is a very popular puzzle which consists on placing several numbers in a squared grid according to some simple rules. In this paper we present an efficient family of P systems which solve sudoku puzzles of any order verifying a specific property. The solution is searched by using a simple human-style method. If the sudoku cannot be solved by using this strategy, the P system detects this drawback and then the computations stops and returns No. Otherwise, the P system encodes the solution and returns Yes in the last computation step.},
  author   = {Daniel D\'{\i}az-Pernil and Carlos M Fern\'{a}ndez-M\'{a}rquez and Manuel Garc\'{\i}a-Quismondo and Miguel A Guti\'{e}rrez-Naranjo and Miguel A Mart\'{\i}nez-Del-Amor},
  title    = {A Cellular Sudoku Solver}
}

@article{Dietrich1982,
  author  = {William E. Dietrich},
  issue   = 6,
  journal = {Water Resorces Reaserch},
  pages   = {1615--1626},
  title   = {Settling Velocity of Natural Particles},
  volume  = 18,
  url     = {papers3://publication/uuid/53387056-6D82-48C0-B3D0-29238B6AC606},
  year    = 1982
}

@article{Dingwell2000,
  abstract = {<p>Characterizing locomotor dynamics is essential for understanding the neuromuscular control of locomotion. In particular, quantifying dynamic stability during walking is important for assessing people who have a greater risk of falling. However, traditional biomechanical methods of defining stability have not quantified the resistance of the neuromuscular system to perturbations, suggesting that more precise definitions are required. For the present study, average maximum finite-time Lyapunov exponents were estimated to quantify the local dynamic stability of human walking kinematics. Local scaling exponents, defined as the local slopes of the correlation sum curves, were also calculated to quantify the local scaling structure of each embedded time series. Comparisons were made between overground and motorized treadmill walking in young healthy subjects and between diabetic neuropathic (NP) patients and healthy controls (CO) during overground walking. A modification of the method of surrogate data was developed to examine the stochastic nature of the fluctuations overlying the nominally periodic patterns in these data sets. Results demonstrated that having subjects walk on a motorized treadmill artificially stabilized their natural locomotor kinematics by small but statistically significant amounts. Furthermore, a paradox previously present in the biomechanical literature that resulted from mistakenly equating variability with dynamic stability was resolved. By slowing their self-selected walking speeds, NP patients adopted more locally stable gait patterns, even though they simultaneously exhibited greater kinematic variability than CO subjects. Additionally, the loss of peripheral sensation in NP patients was associated with statistically significant differences in the local scaling structure of their walking kinematics at those length scales where it was anticipated that sensory feedback would play the greatest role. Lastly, stride-to-stride fluctuations in the walking patterns of all three subject groups were clearly distinguishable from linearly autocorrelated Gaussian noise. As a collateral benefit of the methodological approach taken in this study, some of the first steps at characterizing the underlying structure of human locomotor dynamics have been taken. Implications for understanding the neuromuscular control of locomotion are discussed.</p>},
  author   = {Jonathan B. Dingwell and Joseph P. Cusumano},
  doi      = {10.1063/1.1324008},
  issn     = {1054-1500},
  issue    = 4,
  journal  = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  month    = 12,
  pages    = {848--863},
  title    = {Nonlinear time series analysis of normal and pathological human walking},
  volume   = 10,
  url      = {https://pubs.aip.org/cha/article/10/4/848/134404/Nonlinear-time-series-analysis-of-normal-and},
  year     = 2000
}

@article{Dobrin2013,
  abstract = {The aims of this study were to detect the presence of impacted lower mandibular third molars (IW) and the medical complications among outpatients at Taif Uni. KSA, throughout (2012). The study was concerned with the determination of type of impaction, physical signs and predominant microorganisms. The examined complained students (No.=113) with age (18-26yrs.), were subjected for clinical, dental and microbial examinations. Total impacted wisdoms (IW) were 49.6\%. According to the site, (Uni. and Bi.) had prevalence of 67.9 and 32.1\%, respectively. According to the position, (MA. and V.) displayed incidence of 64.3 and 35.7\%, respectively. The most common complaints were pain 76.8\%, pericoronitis 62.5\%, periodontal pocketing 57.1\%, trismus 51.8\%, cheek biting 39.3\%, cellulitis 32.1\% and abscess formation 19.6\%. The accompanied vital signs were septic S.T. 55.4\%, lymphadenitis 76.8\% and fever 66.1\%. The aerobic and facultative anaerobic isolates were Strept. Viridans, Corynebacterium spp. Haemophilus spp. Strept. mutans, CNS, Staph. aureus, Strept. pneumoniae, E. coli, Strept. pyogenes and Pseudomonas spp.. with incidence of 90.5, 60.8, 56.8, 52.7, 45.9, 25.7, 23, 23, 14.9 and 10.8\% and anaerobic isolates were Prevotella spp. Fusobacterium spp. Actinomyces spp. Bacteroides spp. Lactobacillus spp. Campylobacter spp. and Clostridium spp. had incidence of 98.6, 90.5, 81.1, 81.1, 70.3, 54 and 41.9\% respectively. \textcopyright{} IDOSI Publications, 2013.},
  author   = {Adam Dobrin},
  doi      = {10.5829/idosi.wasj.2013.21.1.71197},
  issn     = 18184952,
  issue    = 1,
  journal  = {World Applied Sciences Journal},
  keywords = {Fever,Impacted Wisdom,Pericoronitis,Periodontal,Septic S. T. Lymphadenitis,Trismus},
  pages    = {21--29},
  title    = {A Review of Properties and Variations of Voronoi Diagrams},
  volume   = 21,
  url      = {https://www.whitman.edu/documents/academics/mathematics/dobrinat.pdf},
  year     = 2013
}

@inproceedings{Dodik2022,
  abstract  = {<p>Concerns that algorithms may discriminate against certain groups have led to numerous efforts to `blind' the algorithm to race. We argue that this intuitive perspective is misleading and may do harm. Our primary result is exceedingly simple, yet often overlooked. A preference for fairness should not change the choice of estimator. Equity preferences can change how the estimated prediction function is used (e.g., different threshold for different groups) but the function itself should not change. We show in an empirical example for college admissions that the inclusion of variables such as race can increase both equity and efficiency.</p>},
  author    = {Ana Dodik and Silvia Sell\'{a}n and Theodore Kim and Amanda Phillips},
  city      = {New York, NY, USA},
  doi       = {10.1145/3532836.3536227},
  isbn      = 9781450393713,
  booktitle = {Special Interest Group on Computer Graphics and Interactive Techniques Conference Talks},
  month     = 8,
  pages     = {1--2},
  publisher = {ACM},
  title     = {Sex and Gender in the Computer Graphics Research Literature},
  volume    = 108,
  url       = {https://dl.acm.org/doi/10.1145/3532836.3536227},
  year      = 2022
}

@article{Dominguez2005,
  abstract = {The present study assesses coastal vulnerability to erosion processes along a 23-km-long coastal sector that presents different morphological features and grades of human occupation. Seven photogrammetric flights, at different scales, were used for reconstructing the coastal evolution from 1956 to 2001. Several sources were compiled to assess human activities and land uses in the coastal zones that were mapped and divided into four different types. As a further step, coastal vulnerability to erosion was assessed combining the potential coastal retreat with land-use type. More than one third of the studied coast presents a very high-medium risk level and many human structures and activities at Sanl\'{u}car village and La Ballena beach will be threatened by erosional processes in the near future. \textcopyright{} Springer-Verlag 2005.},
  author   = {L. Dom\'{\i}nguez and G. Anfuso and F. J. Gracia},
  doi      = {10.1007/s00254-005-1235-0},
  issn     = {09430105},
  issue    = 8,
  journal  = {Environmental Geology},
  keywords = {Aerial photos,Land use,Vulnerability},
  pages    = {1037--1044},
  title    = {Vulnerability assessment of a retreating coast in SW Spain},
  volume   = 47,
  year     = 2005
}

@article{Dong2018,
  abstract = {Mesh plays an indispensable role in dense realtime reconstruction essential in robotics. Efforts have been made to maintain flexible data structures for 3D data fusion, yet an efficient incremental framework specifically designed for online mesh storage and manipulation is missing. We propose a novel framework to compactly generate, update, and refine mesh for scene reconstruction upon a volumetric representation. Maintaining a spatial-hashed field of cubes, we distribute vertices with continuous value on discrete edges that support O(1) vertex accessing and forbid memory redundancy. By introducing Hamming distance in mesh refinement, we further improve the mesh quality regarding the triangle type consistency with a low cost. Lock-based and lock-free operations were applied to avoid thread conflicts in GPU parallel computation. Experiments demonstrate that the mesh memory consumption is significantly reduced while the running speed is kept in the online reconstruction process.},
  author   = {Wei Dong and Jieqi Shi and Weijie Tang and Xin Wang and Hongbin Zha},
  doi      = {10.1109/ICRA.2018.8463157},
  isbn     = 9781538630815,
  issn     = 10504729,
  issue    = {May},
  journal  = {Proceedings - IEEE International Conference on Robotics and Automation},
  pages    = {6323--6330},
  title    = {An Efficient Volumetric Mesh Representation for Real-Time Scene Reconstruction Using Spatial Hashing},
  year     = 2018
}

@article{Doran2010,
  author  = {Jonathon Doran and Ian Parberry},
  issue   = 2,
  journal = {IEEE Transactions on Computational Intelligence and AI in Games},
  pages   = {111--119},
  title   = {Using Software Agents},
  volume  = 2,
  year    = 2010
}

@article{Doran2010a,
  abstract = {Procedural terrain generation is used to create landforms for applications such as computer games and flight simulators. While most of the existing work has concentrated on algorithms that generate terrain without input from the user, we explore a more controllable system that uses intelligent agents to generate terrain elevation heightmaps according to designer-defined constraints. This allows the designer to create procedural terrain that has specific properties. \textcopyright{} 2010 IEEE.},
  author   = {Jonathon Doran and Ian Parberry},
  doi      = {10.1109/TCIAIG.2010.2049020},
  issn     = {1943068X},
  issue    = 2,
  journal  = {IEEE Transactions on Computational Intelligence and AI in Games},
  keywords = {Agents,procedural content generation,terrain},
  pages    = {111--119},
  title    = {Controlled procedural terrain generation using software agents},
  volume   = 2,
  url      = {https://ianparberry.com/pubs/terrain.pdf},
  year     = 2010
}

@article{Doran2010b,
  author  = {Jonathon Doran and Ian Parberry},
  issue   = 2,
  journal = {IEEE Transactions on Computational Intelligence and AI in Games},
  pages   = {111--119},
  title   = {Controlled Procedural Terrain Generation Using Software Agents},
  volume  = 2,
  year    = 2010
}

@article{Dorin1998,
  abstract = {A physically based system of interacting polyhedral objects is used to model self-assembly and spontaneous organization of complex structures. The surfaces of the polyhedra in the simulation are covered with bonding sites in states akin to those of cellular automata. The bonding sites interact with sites on neighbouring polyhedra to apply forces of attraction and repulsion between bodies and to trigger transitions in their states. Using only these mechanisms, the elements exhibit chaining, membrane and cluster formation, and differentiation/segregation. Examples of each of these phenomena are given along with explanations as to how they are formed. Assembly without the guidance of an external agent or central control is in-frequently used in the construction of complex artificial structures, but is the norm for biological construction. This paper presents a model by which the construction of complex structures may be simulated using multiple reactive, artificial agents, acting independently under artificial physical and chemical laws.},
  author   = {Alan Dorin},
  doi      = {10.1007/10693067\_6},
  isbn     = 3540654771,
  issn     = 16113349,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Artificial life,Assembly,Cellular automata,Molecular dynamics,Organization,Physical modelling,Self},
  pages    = {74--87},
  title    = {Physically based, self-organizing cellular automata},
  volume   = 1544,
  url      = {https://users.monash.edu/~aland/PAPERS/DAI98forWWW.pdf},
  year     = 1998
}

@article{Dormans2010,
  abstract = {This paper investigates strategies to generate levels for action adventure games. This genre relies more strongly on well-designed levels than rule-driven genres such as strategy or roleplaying games for which procedural level generation has been successful in the past. The approach outlined by this paper distinguishes between missions and spaces as two separate structures that need to be generated in two individual steps. It discusses the merits of different types of generative grammars for each individual step in the process. Copyright 2010 ACM.},
  author   = {Joris Dormans},
  doi      = {10.1145/1814256.1814257},
  isbn     = 9781450300230,
  journal  = {Workshop on Procedural Content Generation in Games, PC Games 2010, Co-located with the 5th International Conference on the Foundations of Digital Games},
  keywords = {Action adventure games,Level design,Procedural generation},
  title    = {Adventures in level design: Generating missions and spaces for action adventure games},
  year     = 2010
}

@article{Dormans2011b,
  abstract = {This paper frames the process of designing a level in a game as a series of model transformations. The transformations correspond to the application of particular design principles, such as the use of locks and keys to transform a linear mission into a branching space. It shows that by using rewrite systems, these transformations can be formalized and automated. The resulting automated process is highly controllable: it is a perfect match for a mixed-initiative approach to level generation where human and computer collaborate in designing levels. An experimental prototype that implements these ideas is presented. \textcopyright{} ACM.},
  author   = {Joris Dormans},
  doi      = {10.1145/2000919.2000921},
  isbn     = 9781450308724,
  journal  = {ACM International Conference Proceeding Series},
  title    = {Level design as model transformation: A strategy for automated content generation},
  year     = 2011
}

@article{Dormans2011f,
  abstract  = {This paper investigates strategies to generate levels for action-adventure games. For this genre, level design is more critical than for rule-driven genres such as simulation or rogue-like role-playing games, for which procedural level generation has been successful in the past. The approach outlined by this article distinguishes between missions and spaces as two separate structures that need to be generated in two individual steps. It discusses the merits of different types of generative grammars for each individual step in the process. Notably, the approach acknowledges that the online generation of levels needs to be tailored strictly to the actual experience of a player. Therefore, the approach incorporates techniques to establish and exploit player models in actual play. \textcopyright{} 2011 IEEE.},
  author    = {Joris Dormans and Sander Bakkes},
  doi       = {10.1109/TCIAIG.2011.2149523},
  issn      = {1943068X},
  issue     = 3,
  journal   = {IEEE Transactions on Computational Intelligence and AI in Games},
  keywords  = {Game AI,game design,generative grammars,real-time generated game environments},
  note      = {This paper is really focused on action games, considering keeping the player in the action. Most of the parts are not interesting in our case. Need to focus on small parts:},
  pages     = {216--228},
  publisher = {IEEE},
  title     = {Generating missions and spaces for adaptable play experiences},
  volume    = 3,
  year      = 2011
}

@article{Droxler2021,
  author   = {Andr\'{e} W Droxler and St\'{e}phan J Jorry},
  doi      = {https://doi.org/10.1146/annurev-marine-122414- 034137},
  journal  = {Annual Review of Marine Science},
  keywords = {at-topped bank,atoll origin,indian ocean,karsti cation,maldives,paci c ocean,plio-pleistocene,sea level},
  title    = {The Origin of Modern Atolls : Challenging Darwin's Deeply Ingrained Theory},
  year     = 2021
}

@article{Duan,
  abstract = {We introduce OmniSource, a novel framework for leveraging web data to train video recognition models. OmniSource overcomes the barriers between data formats, such as images, short videos, and long untrimmed videos for webly-supervised learning. First, data samples with multiple formats, curated by task-specific data collection and automatically filtered by a teacher model, are transformed into a unified form. Then a joint-training strategy is proposed to deal with the domain gaps between multiple data sources and formats in webly-supervised learning. Several good practices, including data balancing, resampling, and cross-dataset mixup are adopted in joint training. Experiments show that by utilizing data from multiple sources and formats, OmniSource is more data-efficient in training. With only 3.5M images and 800K minutes videos crawled from the internet without human labeling (less than 2\% of prior works), our models learned with OmniSource improve Top-1 accuracy of 2D- and 3D-ConvNet baseline models by 3.0\% and 3.9\%, respectively, on the Kinetics-400 benchmark. With OmniSource, we establish new records with different pretraining strategies for video recognition. Our best models achieve 80.4\%, 80.5\%, and 83.6 Top-1 accuracies on the Kinetics-400 benchmark respectively for training-from-scratch, ImageNet pre-training and IG-65M pre-training.},
  author   = {Haodong Duan and Yue Zhao and Yuanjun Xiong and Wentao Liu and Dahua Lin},
  month    = 3,
  title    = {Omni-sourced Webly-supervised Learning for Video Recognition},
  url      = {http://arxiv.org/abs/2003.13042},
  year     = 2020
}

@article{Duff1992,
  abstract = {Recursive subdivision using interval arithmetic allows us to render CSG combinations of implicit function surfaces with or without anti-aliasing. Related algorithms will solve the collision detection problem for dynamic simulation, and allow us to compute mass, center of gravity, angular moments and other integral properties required for Newtonian dynamics. Our hidden surface algorithms run in 'constant time.' Their running times are nearly independent of the number of primitives in a scene, for scenes in which the visible details are not much smaller than the pixels. The collision detection and integration algorithms are utterly robust - collisions are never missed due to numerical error and we can provide guaranteed bounds on the values of integrals. CR Categories and Subject Descriptors: G.1.0 [Numerical Analysis] Numerical Algorithms I.3.3 [Picture and Image Generation] Display algorithms, Viewing algorithms, I.3.5 [Computational Geometry and Object Modeling] Curve, surface, solid and object representations, I.3.5 [Computational Geometry and Object Modeling] Hierarchy and geometric transformations. I.3.7 [Three-Dimensional Graphics and Realism] Visible line/surface algorithms, Animation},
  author   = {Tom Duff},
  doi      = {10.1145/142920.134027},
  isbn     = {0897914791},
  issn     = {00978930},
  issue    = 2,
  journal  = {Computer Graphics (ACM)},
  pages    = {131--138},
  title    = {Interval arithmetic and recursive subdivision for implicit functions and constructive solid geometry},
  volume   = 26,
  url      = {https://dl.acm.org/doi/pdf/10.1145/142920.134027},
  year     = 1992
}

@inproceedings{Dunbabin2020,
  abstract  = {This paper provides an overview of demonstrated and emerging work applying Uncrewed Maritime Systems (UMS) to coral reef conservation. It blends theoretical analysis and current field results with a focus on recent developments in Australia. Here a combination of Autonomous Underwater Vehicles (AUVs) and Uncrewed Surface Vehicles (USVs) are being used to support restoration of coral communities on the Great Barrier Reef. In 2018 and 2019, UMS were evaluated to assist in the 'planting' of coral larvae during the reef's annual sexual reproduction periods. Scientific results on actual coral larval settlement and recruitment, and hence coral community restoration using these techniques is showing promise but are beyond the scope of this paper. This paper focuses on the technical challenges and opportunities around employing AUVs and USVs for reef restoration at scale. These include: reduction in platform cost, management of larvae supply, precision of larvae placement and user interface/autonomy. This paper examines the field use of the existing prototype robots from recent on-reef trials and hypothesizes solutions to increase efficiency of larval distribution.},
  author    = {Matthew Dunbabin and Justin Manley and Peter L. Harrison},
  doi       = {10.1109/IEEECONF38699.2020.9389173},
  isbn      = 9781728154466,
  booktitle = {2020 Global Oceans 2020: Singapore - U.S. Gulf Coast},
  month     = 10,
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Uncrewed Maritime Systems for Coral Reef Conservation},
  year      = 2020
}

@article{Dunyach2013,
  abstract = {We present an adaptive isotropic remeshing technique that is fast enough to be used in interactive applications, such as mesh deformation or mesh sculpting. Previous real-time remeshing techniques are either not adaptive, hence requiring too many triangles, or make compromises in terms of triangle quality. High quality adaptive remeshing techniques are too slow for interactive applications. In this short paper we present a simple extension of a uniform remeshing approach that results in an efficient, yet high quality, curvature-adaptive remeshing.},
  author   = {Marion Dunyach},
  journal  = {Eurographics short \ldots{}},
  pages    = {1--4},
  title    = {Adaptive remeshing for real-time mesh deformation},
  url      = {http://www.graphics.uni-bielefeld.de/publications/eg13-remeshing.pdf},
  year     = 2013
}

@article{Duvall2019,
  abstract = {Seafloor topography affects a wide range of physical and biological processes; therefore, collapsing the three-dimensional structure of the bottom to roughness metrics is a common challenge in studies of marine systems. Here we assessed the properties captured by metrics previously proposed for the seafloor, as well as metrics developed to characterize other types of rough surfaces. We considered three classes of metrics: properties of the bottom elevation distribution (e.g., standard deviation), length scale ratios (e.g., rugosity), and metrics that describe how topography varies with spatial scale (e.g., H\"{o}lder exponents). The metrics were assessed using idealized topography and natural seafloor topography data from airborne lidar measurements of a coral reef. We illustrate that common roughness metrics (e.g., rugosity) can have the same value for topographies that are geometrically very different, limiting their utility. Application of the wavelet leaders technique to the reef data set demonstrates that the topography has a power law scaling behavior, but it is multifractal so a distribution of H\"{o}lder exponents is needed to describe its scaling behavior. Using principal component analysis, we identify three dominant modes of topographic variability, or ways metrics covary, among and within reef zones. Collectively, the results presented here show that coral reef topography is both multiscale and multifractal. While individual metrics that capture specific topography properties relevant to a given process may be suitable for some studies, many applications will require a set of metrics that includes statistics that capture how topography varies with spatial scale.},
  author   = {Melissa S. Duvall and James L. Hench and Johanna H. Rosman},
  doi      = {10.1029/2018JC014859},
  issn     = 21699291,
  issue    = 7,
  journal  = {Journal of Geophysical Research: Oceans},
  keywords = {Moorea,coral reef,fractal Brownian motion,multifractal,rugosity,topographic complexity},
  pages    = {5021--5038},
  title    = {Collapsing Complexity: Quantifying Multiscale Properties of Reef Topography},
  volume   = 124,
  year     = 2019
}

@inproceedings{Dvorak2007,
  abstract  = {This paper presents a method for a physically based real-time terrain deformation. The motivation originates from the fact that there exist many deformable models, but the terrain deformation is a special problem in the field of computer graphics. OpenSceneGraph toolkit provides an excellent environment for the large terrain visualization and it was accepted as a standard for many graphic specialists. Therefore, the main goal of this method is the local deformation ability of some large terrain, which is represented by a sub-graph of OpenSceneGraph scene. However, the technique may be easily adaptable to any terrain representation. The results show a great potential of the used method and thus there is outlined the future work at the end. \textcopyright{} 2007 IEEE.},
  author    = {Radim Dvo\v{r}\'{a}k and Martin Drahansk\'{y}},
  doi       = {10.1109/ICIG.2007.88},
  isbn      = {0769529291},
  booktitle = {Proceedings of the 4th International Conference on Image and Graphics, ICIG 2007},
  pages     = {1020--1025},
  title     = {Real-time terrain deformations},
  year      = 2007
}

@article{Ecormier-nocca2020,
  author = {Pierre Ecormier-nocca},
  title  = {Cr\'{e}ation d'\'{e}cosyst\`{e}mes coh\'{e}rents et anim\'{e}s : Apprentissage efficace \`{a} partir de donn\'{e}es partielles},
  url    = {https://tel.archives-ouvertes.fr/tel-03086483/document},
  year   = 2020
}

@article{Ecormier-Nocca2021,
  abstract = {We present a novel method for authoring landscapes with flora and fauna while considering their mutual interactions. Our algorithm outputs a steady-state ecosystem in the form of density maps for each species, their daily circuits, and a modified terrain with eroded trails from a terrain, climatic conditions, and species with related biological information. We introduce the Resource Access Graph, a new data structure that encodes both interactions between food chain levels and animals traveling between resources over the terrain. A novel competition algorithm operating on this data progressively computes a steady-state solution up the food chain, from plants to carnivores. The user can explore the resulting landscape, where plants and animals are instantiated on the fly, and interactively edit it by over-painting the maps. Our results show that our system enables the authoring of consistent landscapes where the impact of wildlife is visible through animated animals, clearings in the vegetation, and eroded trails. We provide quantitative validation with existing ecosystems and a user-study with expert paleontologist end-users, showing that our system enables them to author and compare different ecosystems illustrating climate changes over the same terrain while enabling relevant visual immersion into consistent landscapes.},
  author   = {Pierre Ecormier-Nocca and Guillaume Cordonnier and Philippe Carrez and Anne Marie Moigne and Pooran Memari and Bedrich Benes and Marie Paule Cani},
  doi      = {10.1145/3450626.3459952},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {ecosystems,natural phenomena},
  title    = {Authoring consistent landscapes with flora and fauna},
  volume   = 40,
  url      = {https://www-sop.inria.fr/reves/Basilic/2021/ECCMMBC21/Authoring\_Consistent\_Landscapes\_with\_Flora\_and\_Fauna.pdf},
  year     = 2021
}

@article{Edinger2000,
  abstract = {Massive coral growth rates may be poor indicators of coral reef health where coral reefs are subject to combined eutrophication and sedimentation. Massive coral growth (vertical extension) rates on polluted reefs were not different from extension rates on unpolluted reefs, while live coral cover was low and bioerosion intensity high, leading to net reef erosion and death of the polluted reefs. These combined patterns of coral growth rates, coral cover and bioerosion were documented on reefs aected by landbased pollution in the Java Sea, South Sulawesi and Ambon, Indonesia. Acid-insoluble content in coral skeletons re\textasciimacron{}ected land-based pollution stress on reefs more reliably than did coral extension rates. Coral skeletal density was lower on polluted Java Sea reefs than on unpolluted reefs used as reference sites, but coral calci\textregistered{}- cation rates were not signi\textregistered{}cantly dierent. The most eutrophied Java Sea reefs had net carbonate loss, indicating net reef erosion, while a fringing reef adjacent to mangroves and two unpolluted coral cays both had positive net carbonate production. Coral growth and reef growth were decoupled, in that coral growth rates did not reliably predict rates of reef accretion. The apparently paradoxical combination of normal to rapid coral growth and net reef erosion on polluted reefs illustrates the need for a whole-reef perspective on coral reef health},
  author   = {Evan N. Edinger and Gino V. Limmon and Jamaluddin Jompa and Wisnu Widjatmoko and Jeffrey M. Heikoop and Michael J. Risk},
  doi      = {10.1016/S0025-326X(99)00237-4},
  issn     = {0025326X},
  issue    = 5,
  journal  = {Marine Pollution Bulletin},
  keywords = {bioindicators,coral growth rates,coral reef health,eutrophication,indonesia,sedimentation},
  month    = 5,
  pages    = {404--425},
  title    = {Normal Coral Growth Rates on Dying Reefs: Are Coral Growth Rates Good Indicators of Reef Health?},
  volume   = 40,
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0025326X99002374},
  year     = 2000
}

@article{Edyvean1987,
  abstract = {Growth rates of Lithophyllum incrustans, a rock-encrusting coralline red alga, have been studied at three sites on the coast of Pembroke, south-west Wales. Horizontal and vertical growth rates and calcium carbonate deposition rates were determined. There are some significant differences between sites, especially in vertical growth rates which include the formation of reproductive tissue. The data indicates that L. incrustans is, on average, 2-25 years old before reproduction is initiated. Growth rates of this alga were found to be similar to other arctic and temperate encrusting red algae, but an order of magnitude less than those in the tropics. \textcopyright{} 1987 British Phycological Society.},
  author   = {R. G.J. Edyvean and H. Ford},
  doi      = {10.1080/00071618700650161},
  issn     = {00071617},
  issue    = 2,
  journal  = {British Phycological Journal},
  pages    = {139--146},
  title    = {Growth rates of lithophyllum incrustans (Corallinales, rhodophyta) from south west wales},
  volume   = 22,
  year     = 1987
}

@article{Eisemann2006,
  abstract = {This sketch paper presents an overview of "Fast Scene Voxelization and Applications" published at the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games. It introduces slicemaps that correspond to a GPU friendly voxel representation of a scene. This voxelization is done at run-time in the order of milliseconds, even for complex and dynamic scenes containing more than 1M polygons. Creation and storage is performed on the graphics card avoiding unnecessary data transfer. Regular but also deformed grids are possible, in particular to better fit the scene geometry. Several applications are demonstrated: shadow calculation, refraction simulation and shadow volume culling/clamping.},
  author   = {Elmar Eisemann and Xavier D\'{e}coret},
  doi      = {10.1145/1179849.1179859},
  isbn     = 1595933646,
  journal  = {ACM SIGGRAPH 2006: Sketches, SIGGRAPH '06},
  keywords = {gpu,refraction,shadows,voxelization},
  title    = {Fast scene voxelization and applications},
  url      = {https://graphics.tudelft.nl/Publications-new/2006/ED06d/voxels05-final.pdf},
  year     = 2006
}

@inproceedings{Eisemann2008,
  abstract  = {In this paper, we present a single-pass technique to voxelize the interior of watertight 3D models with high resolution grids in realtime during a single rendering pass. Further, we develop a filtering algorithm to build a density estimate that allows the deduction of normals from the voxelized model. This is achieved via a dense packing of information using bitwise arithmetic. We demonstrate the versatility of the method by presenting several applications like translucency effects, CSG operations, interaction for particle simulations, and morphological operations. The speed of our method opens up the road for previously impossible approaches in realtime: 300,000 polygons are voxelized into a grid of one billion voxels at > 90Hz with a recent graphics card.},
  author    = {Elmar Eisemann and Xavier Decoret},
  isbn      = 9781568814230,
  issn      = {07135424},
  booktitle = {Proceedings - Graphics Interface},
  keywords  = {Applications,GPU,Real-time,Solid voxelization},
  pages     = {73--80},
  title     = {Single-pass GPU solid voxelization for real-time applications},
  url       = {https://graphics.tudelft.nl/Publications-new/2008/ED08c/solidvoxelizationAuthorVersion.pdf},
  year      = 2008
}

@article{Elter,
  abstract = {This study aims to find out and analyze the contribution of regional taxes to regional original income (PAD) and regional tax growth in 2013-2017. The location of this study was conducted at the Regional Financial and Asset Agency in Bantul Regency. This type of research is qualitative descriptive. Data analysis techniques using ratio analysis. The results showed that local tax revenues and local revenue (PAD) in Bantul Regency experienced a significant increase. The contribution of local taxes to local revenue is "quite good", averaging 32.645\%. The largest regional tax contribution is dominated by the Tax Transfer of Land and Building Rights (BPHTB). Regional tax growth and regional original income in that year were positively correlated, on average 18.75\% and 18.35\%},
  author   = {HERVE ELTER and PASCAL LIENHARDT},
  doi      = {10.1142/S021865439400013X},
  issn     = {0218-6543},
  issue    = {02},
  journal  = {International Journal of Shape Modeling},
  month    = 12,
  pages    = {191--217},
  title    = {CELLULAR COMPLEXES AS STRUCTURED SEMI-SIMPLICIAL SETS},
  volume   = {01},
  url      = {http://www.worldscientific.com/doi/abs/10.1142/S021865439400013X},
  year     = 1994
}

@article{Emilien2013,
  author  = {Arnaud Emilien and Pierre Poulin and Marie-paule Cani and Ulysse Vimont},
  issue   = 1,
  journal = {Revue Electronique Francophone d'Informatique Graphique},
  pages   = {1--12},
  title   = {Design de cascades r\'{e}alistes : une m\'{e}thode pour combiner contr\^{o}le interactif et mod\`{e}le proc\'{e}dural},
  volume  = 8,
  url     = {http://liris.cnrs.fr/~egfr/BestPapers/Troisieme2013\_Arnaud-Emilien.pdf},
  year    = 2014
}

@article{Emilien2015,
  abstract = {Combining procedural generation and user control is a fundamental challenge for the interactive design of natural scenery. This is particularly true for modelling complex waterfall scenes where, in addition to taking charge of geometric details, an ideal tool should also provide a user with the freedom to shape the running streams and falls, while automatically maintaining physical plausibility in terms of flow network, embedding into the terrain, and visual aspects of the waterfalls. We present the first solution for the interactive procedural design of coherent waterfall scenes. Our system combines vectorial editing, where the user assembles elements to create a waterfall network over an existing terrain, with a procedural model that parametrizes these elements from hydraulic exchanges; enforces consistency between the terrain and the flow; and generates detailed geometry, animated textures and shaders for the waterfalls and their surroundings. The tool is interactive, yielding visual feedback after each edit.},
  author   = {Arnaud Emilien and Pierre Poulin and Marie-Paule Cani and Ulysse Vimont},
  doi      = {10.1111/cgf.12515},
  issn     = {0167-7055},
  issue    = 6,
  journal  = {Computer Graphics Forum},
  keywords = {3,5,acm ccs,computational geometry and object,computer graphics,i,mesh generation,modelling-physically based modelling,natural phenomena},
  month    = 9,
  pages    = {22--35},
  title    = {Interactive Procedural Modelling of Coherent Waterfall Scenes},
  volume   = 34,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12515},
  year     = 2015
}

@article{Emilien2015a,
  abstract = {We present a novel approach for the interactive synthesis and editing of virtual worlds. Our method is inspired by painting operations and uses methods for statistical example-based synthesis to automate content synthesis and deformation. Our real-time approach takes a form of local inverse procedural modeling based on intermediate statistical models: selected regions of procedurally and manually constructed example scenes are analyzed, and their parameters are stored as <italic>distributions</italic> in a palette, similar to colors on a painter's palette. These <italic>distributions</italic> can then be interactively applied with brushes and combined in various ways, like in painting systems. Selected regions can also be moved or stretched while maintaining the consistency of their content. Our method captures both distributions of elements and structured objects, and models their interactions. Results range from the interactive editing of 2D artwork maps to the design of 3D virtual worlds, where constraints set by the terrain's slope are also taken into account.},
  author   = {Arnaud Emilien and Ulysse Vimont and Marie-Paule Cani and Pierre Poulin and Bedrich Benes},
  doi      = {10.1145/2766975},
  issn     = {0730-0301},
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Computer graphics,Interactive modeling,Inverse procedural modeling,Painting systems,Virtual worlds},
  month    = 7,
  pages    = {1--11},
  title    = {WorldBrush},
  volume   = 34,
  url      = {https://dl.acm.org/doi/10.1145/2766975},
  year     = 2015
}

@book{Engebretsen2020,
  author    = {Martin Engebretsen and Helen Kennedy and Jill Walker and Giorgia Aiello and Torgeir Uberg and Eef Masson and Karin van and Salla-Maaria Laaksonen and Juho Pa\"a\"kko\"nen and Mikael Snaprud and Andrea Velazquez and Arran L. and Christopher Birchall and Daniela Geenen and Maranke Wieringa and Jill Simpson and Wibke Weber and Elise Seip T\o{}nnessen and Catherine D'Ignazio and Rahul Bhargava and Lulu Pinney and Arlene Archer and Travis Noakes and Sara Brinch and Tuomo Hiippala and Jonathan Gray and Verena Elisabeth Lechner and Aria Alamalhodaei and Alexandra Alberda and Anna Feigenbaum and John P. Wihbey and Sarah J. Jackson and Pedro M. Cruz and Brooke Foucault Welles and Rosemary Lucy Hill and Britta Ricker and Menno-Jan Kraak and Yuri Engelhardt and Anna Berti Suman and Miren Gutie\'rrez and Alberto Cairo},
  doi       = {10.5117/9789463722902},
  isbn      = 9789463722902,
  publisher = {Amsterdam University Press},
  title     = {Data Visualization in Society},
  url       = {https://www.aup.nl/en/book/9789463722902},
  year      = 2020
}

@misc{Ensimag2016,
  author = {Ensimag},
  pages  = {2--5},
  title  = {TP 2 : Lissage laplacien},
  url    = {https://team.inria.fr/imagine/files/2015/09/tp\_lissage.pdf},
  year   = 2016
}

@article{Ershov2003,
  abstract = {In the paper we present LGS - a geometric constraint solver developed, at LEDAS Ltd. We review different approaches in geometric constraint solving, present our one, describe in details LGS architecture and the ideas behind it. The main idea of LGS is to decompose the initial problem into a set of simpler ones, to map each instance to a class of problems, and to apply a specialized algorithm to each class. We emphasize key differences of our approach: extendible hierarchy of problem classes, new decomposition techniques, a broad range of numerical algorithms. \textcopyright{} Springer-Verlag Berlin Heidelberg 2003.},
  author   = {Alexey Ershov and Ilia Ivanov and Serge Preis and Eugene Rukoleev and Dmitry Ushakov},
  doi      = {10.1007/978-3-540-39866-0\_42},
  issn     = {03029743},
  issue    = {January 1994},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  pages    = {423--430},
  title    = {LGS: Geometric constraint solver},
  volume   = 2890,
  url      = {https://www.cs.purdue.edu/homes/cmh/distribution/papers/Constraints/CAD95.pdf},
  year     = 2003
}

@article{Escudero2021,
  abstract = {Coral reefs are increasingly recognized for their shoreline protection services. The hydrodynamic performance of this ecosystem is comparable to artificial low-crested structures often used in coastal protection, whose objective is to emulate the former. Coral reefs also provide other important environmental services (e.g., food production, habitat provision, maintenance of biodiversity and social and cultural services) and leave almost no ecological footprint when conservation and restoration actions are conducted to maintain their coastal protection service. However, studies have focused on their flood protection service, but few have evaluated the morphological effects of coral reefs through their ability to avoid or mitigate coastal erosion. In this paper, we investigate the relation between shoreline change, reefs' geometry and hydrodynamic parameters to elucidate the physics related to how the Mesoamerican Reef in Mexico protects sandy coastlines from erosion. Using numerical wave propagation and historical shoreline change calculated from satellite imagery, a direct correlation was found between shoreline movement, the depths and widths of reef flats, changes in the wave energy flux, and the radiation stresses of breaking waves. The findings indicate that the most remarkable efficacy in preventing beach erosion is due to reefs with shallow crests, wide reef flats, a dissipative lagoon seabed, located at \sim{}300 m from the coastline. The results provide essential insights for reef restoration projects focused on erosion mitigation and designing artificial reefs in microtidal sandy beaches. Results are limited to wave-dominated coasts.},
  author   = {Mireille Escudero and Borja G. Reguero and Edgar Mendoza and Fernando Secaira and Rodolfo Silva},
  doi      = {10.3389/fmars.2021.684732},
  issn     = 22967745,
  issue    = {September},
  journal  = {Frontiers in Marine Science},
  keywords = {beach erosion mitigation,coastal protection,coral reefs,nature-based solutions,radiation stress,wave energy},
  pages    = {1--17},
  title    = {Coral Reef Geometry and Hydrodynamics in Beach Erosion Control in North Quintana Roo, Mexico},
  volume   = 8,
  year     = 2021
}

@article{Euler1998,
  abstract = {Current developments in 3-D Earth Modeling are having a significant impact on the practice of reservoir model construction, seismic inversion, and velocity analysis. From seimic surveys, acquired and interpreted by geophysicists, geological objects are generated. These objects (horizons and faults) are edited and modified as necessary. Once the set of horizons and faults--the structural framework--has been validated, it is used to build a reservoir or velocity model. One difficulty of model building lies in finding the intersections between geological objects. Those intersections have to be clearly defined and controlled by structural information. We present in this article a new work-flow for building a sealed topologically consistent structural framework.},
  author   = {Nicolas Euler and Charles H. Sword and Jean Claude Dulac},
  doi      = {10.1190/1.1820562},
  journal  = {1998 SEG Annual Meeting},
  title    = {A new tool to seal a 3D earth model: A cut with constraints},
  year     = 1998
}

@inproceedings{Faiez2018,
  abstract  = {To immerse a person is to give him the feeling of being present in a virtual space. To concatenate immersive with analytic we obtain "The immersive analytics". Immersive Analysis is an area that explores new interaction and display technologies for analytics to support multi-discipline data reasoning. Monitoring systems and routing algorithms are two disciplines that have greatly beneficiated from this area since that the image is the basis on which we build our decision in this kind of systems. Since these techniques increase the human capacity for analysis and to understand heterogeneous, massive and often multiform data sets, and because a good detection of routing or performance degradation anomalies depends on a good data analysis, using a visual analysis system we show in this article how immersive analysis immerse the user in his task to better support data analysis allowing him to provide clear and timely information to make the right decision specially in emergencies.},
  author    = {Hanen Faiez and Jalel Akaichi},
  city      = {New York, New York, USA},
  doi       = {10.1145/3330089.3330114},
  isbn      = 9781450361019,
  booktitle = {Proceedings of the 7th International Conference on Software Engineering and New Technologies - ICSENT 2018},
  keywords  = {Immersive Analytics,Monitoring systems,Routing Protocol},
  month     = 12,
  pages     = {1--5},
  publisher = {ACM Press},
  title     = {Best Road Based Immersive Visualization Framework for patient in emergency},
  url       = {http://dl.acm.org/citation.cfm?doid=3330089.3330114},
  year      = 2018
}

@misc{Fanello2013,
  abstract = {Sparsity has been showed to be one of the most important properties for visual recognition purposes. In this paper we show that sparse representation plays a fundamental role in achieving one-shot learning and real-time recognition of actions. We start off from RGBD images, combine motion and appearance cues and extract state-of-the-art features in a computationally efficient way. The proposed method relies on descriptors based on 3D Histograms of Scene Flow (3DHOFs) and Global Histograms of Oriented Gradient (GHOGs); adaptive sparse coding is applied to capture high-level patterns from data. We then propose a simultaneous on-line video segmentation and recognition of actions using linear SVMs. The main contribution of the paper is an effective real-time system for one-shot action modeling and recognition; the paper highlights the effectiveness of sparse coding techniques to represent 3D actions. We obtain very good results on three different data sets: a benchmark data set for one-shot action learning (the ChaLearn Gesture Data Set), an in-house data set acquired by a Kinect sensor including complex actions and gestures differing by small details, and a data set created for human-robot interaction purposes. Finally we demonstrate that our system is effective also in a human-robot interaction setting and propose a memory game, "All Gestures You Can", to be played against a humanoid robot.},
  author   = {Sean Ryan Fanello and Ilaria Gori and Giorgio Metta and Francesca Odone},
  journal  = {Journal of Machine Learning Research},
  keywords = {human robot interaction,one-shot action learning,real-time action recognition,sparse representation},
  pages    = {2617--2640},
  title    = {Keep It Simple And Sparse: Real-Time Action Recognition Giorgio Metta},
  volume   = 14,
  year     = 2013
}

@article{Faraj2011,
  author = {Noura Faraj},
  title  = {Expressive rendering of animated hair},
  year   = 2011
}

@article{Faraj2017,
  abstract = {Structural properties are important clues for non-photorealistic representations of digital images. Therefore, image analysis tools have been intensively used either to produce stroke-based renderings or to yield abstractions of images. In this work, we propose to use a hierarchical and geometrical image representation, called a topographic map, made of shapes organized in a tree structure. There are two main advantages of this analysis tool. Firstly, it is able to deal with all scales, so that every shape of the input image is represented. Secondly, it accounts for the inclusion properties within the image. By iteratively performing simple local operations on the shapes (removal, rotation, scaling, replacement\cdots{}), we are able to generate abstract renderings of digital photographs ranging from geometrical abstraction and painting-like effects to style transfer, using the same framework. In particular, results show that it is possible to create abstract images evoking Malevitchs Suprematist school, while remaining grounded in the structure of digital images, by replacing all the shapes in the tree by simple geometric shapes.},
  author   = {Noura Faraj and Gui Song Xia and Julie Delon and Yann Gousseau},
  doi      = {10.1145/3092919.3092930},
  isbn     = 9781450350815,
  journal  = {Proceedings - Non-Photorealistic Animation and Rendering, NPAR 2017 - Part of Expressive 2017},
  keywords = {Hierarchical,Image abstraction,Image processing,Image representation,Morphological,Picture/image generation},
  title    = {A generic framework for the structured abstraction of images},
  year     = 2017
}

@inproceedings{Farhad,
  author    = {Farhad Pourpanah and Bin Zhang and Rui Ma and Qi Hao},
  doi       = {10.1109/ICSENS.2018.8589618},
  isbn      = {978-1-5386-4707-3},
  booktitle = {2018 IEEE SENSORS},
  month     = 10,
  pages     = {1--4},
  publisher = {IEEE},
  title     = {Non-Intrusive Human Motion Recognition Using Distributed Sparse Sensors and the Genetic Algorithm Based Neural Network},
  url       = {https://ieeexplore.ieee.org/document/8589618/},
  year      = 2018
}

@inproceedings{Fedkiw2001,
  abstract  = {In this paper, we propose a new approach to numerical smoke simulation for computer graphics applications. The method pro- posed here exploits physics unique to smoke in order to design a numerical method that is both fast and efficient on the relatively coarse grids traditionally used in computer graphics applications (as compared to the much finer grids used in the computational fluid dynamics literature). We use the inviscid Euler equations in our model, since they are usually more appropriate for gas mod- eling and less computationally intensive than the viscous Navier- Stokes equations used by others. In addition, we introduce a physically consistent vorticity confinement term to model the small scale rolling features characteristic of smoke that are absent on most coarse grid simulations. Our model also correctly handles the inter- action of smoke with moving objects.},
  author    = {Ronald Fedkiw and Henrik Wann Jensen},
  booktitle = {SIGGRAPH 2001 Conference Proceedings, Annual Conference Series},
  note      = {This paper is cited by Josh Stam \&quot;Real-time fluid dynamics for video games\&quot; as a way to control the small vortex created in the fluid simulation. At this point my water simulation is not realistic as there is a lot of vortex. Should check this for improvements.},
  pages     = {15--22},
  title     = {Visual Simulation of Smoke},
  year      = 2001
}

@article{Feichtenhofer,
  abstract = {This paper presents X3D, a family of efficient video networks that progressively expand a tiny 2D image classification architecture along multiple network axes, in space, time, width and depth. Inspired by feature selection methods in machine learning, a simple stepwise network expansion approach is employed that expands a single axis in each step, such that good accuracy to complexity trade-off is achieved. To expand X3D to a specific target complexity, we perform progressive forward expansion followed by backward contraction. X3D achieves state-of-the-art performance while requiring 4.8x and 5.5x fewer multiply-adds and parameters for similar accuracy as previous work. Our most surprising finding is that networks with high spatiotemporal resolution can perform well, while being extremely light in terms of network width and parameters. We report competitive accuracy at unprecedented efficiency on video classification and detection benchmarks. Code will be available at: https://github.com/facebookresearch/SlowFast},
  author   = {Christoph Feichtenhofer},
  month    = 4,
  title    = {X3D: Expanding Architectures for Efficient Video Recognition},
  url      = {http://arxiv.org/abs/2004.04730},
  year     = 2020
}

@misc{Felixchenfy,
  author = {Felixchenfy},
  title  = {felixchenfy/Realtime-Action-Recognition: Apply ML to the skeletons from OpenPose; 9 actions; multiple people.},
  url    = {https://github.com/felixchenfy/Realtime-Action-Recognition}
}

@article{Ferraris2010,
  abstract = {This publication proposes a novel approach to automatically colour and texture a given terrain mesh in real time. Through the use of weighting rules, a simple syntax allows for the generation of texture and colour values based on the elevation and angle of a given vertex. It is through this combination of elevation and angle that complex features such as ridges, hills and mountains can be described, with the mesh coloured and textured accordingly. The implementation of the approach is done entirely on the GPU using 2D lookup textures, delivering a great performance increase over typical approaches that pass colour and weighting information in the fragment shader. In fact, the rule set is abstracted enough to be used in conjunction with any colouring/texturing approach that uses weighting values to dictate which surfaces are depicted on the mesh},
  author   = {John Ferraris and Christos Gatzidis and Feng Tian},
  doi      = {10.20870/ijvr.2010.9.4.2787},
  issn     = {1081-1451},
  issue    = 4,
  journal  = {International Journal of Virtual Reality},
  pages    = {21--28},
  title    = {Automating Terrain Texturing in Real-Time Using a Rule-Based Approach},
  volume   = 9,
  year     = 2010
}

@article{Fifield1992,
  abstract = {Over the years, we have modified the exercise to suit our needs, and we encourage you to tailor it to your situation. It may be particularly effective to combine the hands-on nature of the exercise with the speed and flexibility of computer simulations. But no matter what method we choose, if one of our goals as instructors is to help students construct an understanding of evolution, we must give them the opportunity to explore the causes and consequences of natural selection. \textcopyright{} 1992, National Association of Biology Teachers. All rights reserved.},
  author   = {Steve Fifield and Bruce Fall},
  doi      = {10.2307/4449461},
  issn     = {00027685},
  issue    = 4,
  journal  = {American Biology Teacher},
  pages    = {230--235},
  title    = {A Hands-On Simulation of Natural Selection in an Imaginary Organism, Platysoma apoda},
  volume   = 54,
  year     = 1992
}

@article{Fiorio1996,
  abstract = {In this paper a ``topologically consistent'' representation for images is presented. It is called the Frontiers Topological Graph and is derived from the combinatorial maps model. Thus it establishes a link between image analysis and image synthesis. An efficient algorithm which constructs the Frontiers Topological Graph is developed.},
  author   = {Christophe Fiorio},
  doi      = {10.1007/3-540-62005-2\_13},
  isbn     = 9783540620051,
  issn     = 16113349,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Combinatorial map,Graph,Image representation,Topology},
  pages    = {151--162},
  title    = {A topologically consistent representation for image analysis: The frontiers topological graph},
  volume   = 1176,
  url      = {https://link.springer.com/content/pdf/10.1007/3-540-62005-2\_13.pdf},
  year     = 1996
}

@article{Fischer2020,
  abstract = {Advances in computer technology and increasing usage of computer graphics in a broad field of applications lead to rapidly rising demands regarding size and detail of virtual landscapes. Manually creating huge, realistic looking terrains and populating them densely with assets is an expensive and laborious task. In consequence, (semi-)automatic procedural terrain generation is a popular method to reduce the amount of manual work. However, such methods are usually highly specialized for certain terrain types and especially the procedural generation of landscapes composed of different biomes is a scarcely explored topic. We present a novel system, called AutoBiomes, which is capable of efficiently creating vast terrains with plausible biome distributions and therefore different spatial characteristics. The main idea is to combine several synthetic procedural terrain generation techniques with digital elevation models (DEMs) and a simplified climate simulation. Moreover, we include an easy-to-use asset placement component which creates complex multi-object distributions. Our system relies on a pipeline approach with a major focus on usability. Our results show that our system allows the fast creation of realistic looking terrains.},
  author   = {Roland Fischer and Philipp Dittmann and Ren\'{e} Weller and Gabriel Zachmann},
  doi      = {10.1007/s00371-020-01920-7},
  isbn     = {0037102001},
  issn     = {01782789},
  issue    = {10-12},
  journal  = {Visual Computer},
  keywords = {Biomes,Climate simulation,Digital elevation models,Procedural content generation,Terrain generation,Virtual worlds},
  pages    = {2263--2272},
  title    = {AutoBiomes: procedural generation of multi-biome landscapes},
  volume   = 36,
  url      = {https://www.researchgate.net/profile/Gabriel-Zachmann/publication/343196448\_AutoBiomes\_procedural\_generation\_of\_multi-biome\_landscapes/links/5f258e7da6fdcccc43a058a8/AutoBiomes-procedural-generation-of-multi-biome-landscapes.pdf},
  year     = 2020
}

@misc{Fleming2021,
  abstract = {Procedural generation is a particularly interesting feature that appears in some video games. This concept is a type of algorithm that was designed to allow a computer to generate specific content in a seemingly random manner, such as 3-dimensional and 2-dimensional assets in video games. Although, most players do not have a great understanding of how they work, only that when used in games, the algorithm is directly tied to a line of text and numbers called a seed. The question is, how does it work, and more importantly, why would one use either procedural generation or newer content generating algorithms that have come up in recent years like machine learning when creating digital assets?},
  author   = {Nicholaus Fleming},
  title    = {Procedural Generation Algorithms and Why Use Them Over Machine Learning},
  year     = 2021
}

@article{Florinsky2018,
  author  = {I V Florinsky and S V Filippov and A S Abramova and Yu A Zarayskaya and E V Selezneva and I V Florinsky and S V Filippov},
  issue   = {June},
  journal = {Proceedings of the 7th International Conference on Cartography \& GIS},
  pages   = {166--173},
  title   = {Towards geomorphometric modelling of the topography of the Arctic Ocean floor},
  volume  = 1,
  year    = 2018
}

@article{Flotynski2017,
  abstract = {An indispensable element of any practical 3D/VR/AR application is synthetic three-dimensional (3D) content. Such content is characterized by a variety of features--geometry, structure, space, appearance, animation and behaviour--which makes the modelling of 3D content a much more complex, difficult and time-consuming task than in the case of other types of content. One of the promising research directions aiming at simplification of modelling 3D content is the use of the semantic web approach. The formalism provided by semantic web techniques enables declarative knowledge-based modelling of content based on ontologies. Such modelling can be conducted at different levels of abstraction, possibly domain-specific, with inherent separation of concerns. The use of semantic web ontologies enables content representation independent of particular presentation platforms and facilitates indexing, searching and analysing content, thus contributing to increased content re-usability. A range of approaches have been proposed to permit semantic representation and modelling of synthetic 3D content. These approaches differ in the methodologies and technologies used as well as their scope and application domains. This paper provides a review of the current state of the art in representation and modelling of 3D content based on semantic web ontologies, together with a classification, characterization and discussion of the particular approaches.},
  author   = {Jakub Floty\'{n}ski and Krzysztof Walczak},
  doi      = {10.1111/cgf.13083},
  issn     = 14678659,
  issue    = 8,
  journal  = {Computer Graphics Forum},
  keywords = {1,2,3,5,7,acm ccs,artificial,augmented and virtual realities,computer graphics,graphical user interfaces,gui,h,i,information interfaces and presentation,multimedia information systems,three-dimensional graphics and realism,user interfaces,virtual reality},
  pages    = {329--353},
  title    = {Ontology-Based Representation and Modelling of Synthetic 3D Content: A State-of-the-Art Review},
  volume   = 36,
  year     = 2017
}

@article{Forest2010,
  author  = {Vincent Forest and Loic Barthe and Mathias Paulin},
  doi     = {10.1080/2151237X.2009.10129283},
  issn    = {2151-237X},
  issue   = 3,
  journal = {Journal of Graphics, GPU, and Game Tools},
  month   = 1,
  pages   = {21--34},
  title   = {Real-Time Hierarchical Binary-Scene Voxelization},
  volume  = 14,
  url     = {http://www.tandfonline.com/doi/abs/10.1080/2151237X.2009.10129283},
  year    = 2009
}

@article{Forster1958,
  abstract = {A brief description is given of the commonest sessile animals observed by diving from twelve positions near Plymouth, including three offshore reefs. The coelenterate Corynactis viridis is generally abundant on shaded rock surfaces. Many sessile species, even where common, tend to be dispersed in scattered patches or colonies; from this it is suggested that their distribution is affected by predation from browsing animals, particularly Echinus esculentus.},
  author   = {G.R. Forster},
  doi      = {10.1017/S0025315400023821},
  issn     = {0025-3154},
  issue    = 2,
  journal  = {Journal of the Marine Biological Association of the United Kingdom},
  month    = 6,
  pages    = {473--482},
  title    = {Underwater Observations on the Fauna of Shallow Rocky Areas in the Neighbourhood of Plymouth},
  volume   = 37,
  url      = {https://www.cambridge.org/core/product/identifier/S0025315400023821/type/journal\_article},
  year     = 1958
}

@unpublished{Fougerolle,
  abstract = {We propose an efficient method to polygonize CSG trees of globally deformed supershapes. More generally , our approach can handle primitives with both parametric and implicit representations. An implicit equation with guaranteed differential properties is obtained by simple combinations of the primitives' implicit representations using R-functions theory. The surface of the object, corresponding to the zero-set of its implicit equation, is efficiently and accurately polygonized using the primitives' parametric forms and sharp edges are accurately preserved.},
  author   = {Yohan D Fougerolle and Andrei Gribok and Sebti Foufou and Fr\'{e}d\'{e}ric Truchetet and Mongi A Abidi},
  title    = {Constructive Solid Geometry using Supershapes}
}

@article{Frade2008,
  abstract = {Terrain generation algorithms can provide a realistic scenario for video game experience and can help keep users interested in playing by providing new landscapes each time they play. Nowadays there are a wide range of techniques for terrain generation, but all of them are focused on providing realistic terrains. This paper proposes a new technique, Genetic Terrain Programming, based on evolutionary design with GP to allow game designers to evolve terrains according to their aesthetic feelings or desired features. The developed application produces Terrains Programs that will always generate different terrains, but consistently with the same features (e.g. valleys, lakes). \textcopyright{} 2008 Springer-Verlag Berlin Heidelberg.},
  author   = {Miguel Frade and F. Fernandez De Vega and Carlos Cotta},
  doi      = {10.1007/978-3-540-78761-7\_52},
  isbn     = 3540787607,
  issn     = {03029743},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Evolutionary art,Genetic programming,Terrain generation,Video games},
  pages    = {485--490},
  title    = {Modelling video games' Landscapes by means of Genetic Terrain Programming - A new approach for improving users' experience},
  volume   = {4974 LNCS},
  year     = 2008
}

@article{Frade2008a,
  abstract = {Nowadays there are a wide range of techniques for terrain generation, but are focused on providing realistic terrains often neglecting the aesthetic appeal. The Genetic Terrain Programming technique, based on evolutionary design with Genetic Programming, allows designers to evolve terrains according to their aesthetic feelings or desired features. This technique evolves TPs (Terrain Programmes) that are capable of generating different terrains, but consistently with the same features. This paper presents a study about the perseverance of terrain features of the TPs across different LODs (Levels Of Detail). Results showed it is possible to use low LODs during the evolutionary phase without compromising results and the terrain features generated by a TPs are scale invariant.},
  author   = {Miguel Frade and F. Fernandez De Vega and Carlos Cotta},
  doi      = {10.5176/978-981-08-8227-3\_cgat08-43},
  isbn     = 9789810806934,
  journal  = {Computer Games and Allied Technology 08, CGAT 08 - Animation, Multimedia, IPTV and Edutainment, Proceedings},
  keywords = {Evolutionary systems,Genetic terrain programming,Level of detail,Terrain generator},
  pages    = {323--330},
  title    = {Genetic terrain programming an aesthetic approach to terrain generation},
  year     = 2008
}

@article{Frade2009,
  abstract = {Although a number of terrain generation techniques have been proposed during the last few years, all of them have some key constraints. Modelling techniques depend highly upon designer's skills, time, and effort to obtain acceptable results, and cannot be used to automatically generate terrains. The simpler methods allow only a narrow variety of terrain types and offer little control on the outcome terrain. The Genetic Terrain Programming technique, based on evolutionary design with Genetic Programming, allows designers to evolve terrains according to their aesthetic feelings or desired features. This technique evolves Terrain Programmes (TPs) that are capable of generating a family of terrainsdifferent terrains that consistently present the same morphological characteristics. This paper presents a study about the persistence of morphological characteristics of terrains generated with different resolutions by a given TP. Results show that it is possible to use low resolutions during the evolutionary phase without compromising the outcome, and that terrain macrofeatures are scale invariant.},
  author   = {Miguel Frade and F. Fernandez De Vega and Carlos Cotta},
  doi      = {10.1155/2009/125714},
  issn     = 16877047,
  issue    = 1,
  journal  = {International Journal of Computer Games Technology},
  title    = {Breeding terrains with genetic terrain programming: The evolution of terrain generators},
  volume   = 2009,
  year     = 2009
}

@article{Fradin2002,
  author   = {David Fradin and Daniel Meneveaux and Pascal Lienhardt},
  journal  = {Actes des journ\'{e}es AFIG - Association Fran\c{c}aise d'Informatique Graphique},
  keywords = {gmaps},
  pages    = {199--210},
  title    = {Partition de l'espace et hi\'{e}rarchie de cartes g\'{e}n\'{e}ralis\'{e}es : application aux complexes architecturaux},
  url      = {http://xlim-sic.labo.univ-poitiers.fr/mr-archi/papers/Modeleur - AFIG2002.pdf},
  year     = 2002
}

@article{Fradin2006,
  abstract = {This paper presents a topology-based representation dedicated to complex indoor scenes. It accounts for memory management and performances during modelling, visualization and lighting simulation. We propose to enlarge a topological model (called generalized maps) with multipartition and hierarchy. Multipartition allows the user to group objects together according to semantics. Hierarchy provides a coarse-to-fine description of the environment. The topological model we propose has been used for devising a modeller prototype and generating efficient data structure in the context of visualization, global illumination and 1 GHz wave propagation simulation. We presently handle buildings composed of up to one billion triangles. \textcopyright{} 2006 The Eurographics Association and Blackwell Publishing Ltd.},
  author   = {David Fradin and Daniel Meneveaux and Pascal Lienhardt},
  doi      = {10.1111/j.1467-8659.2006.00931.x},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {Geometric modelling,Hierarchical model,Large buildings,Partitions,Visualization},
  pages    = {149--162},
  title    = {A hierarchical topology-based model for handling complex indoor scenes},
  volume   = 25,
  year     = 2006
}

@article{Frank2006,
  abstract = {Structured grids like Cartesian or stratigraphic grids are state-of-the-art for three dimensional modeling of the subsurface and a set of advanced visualization and modeling tools are available for these types of grids. However, tetrahedral meshes are becoming more and more important for geo-modeling applications since they can conform to complex geometries and provide more flexibility in terms of mesh resolution. Therefore, techniques for visualizing and modeling tetrahedral meshes need to be developed. Geological models are rich in information of different nature like topology of fault blocks, geological properties, geophysical data (e.g. seismic), stratigraphic layers or distances to geological interfaces like faults or to artifacts (e.g. wells). For an optimal interpretation, these layers of information can be combined into a single image using multi-texture capabilities of modern graphics hardware. An image consists of a set of user-defined iso-value surfaces and crosssections. Boolean operations of Constructive Solid Geometry with constant complexity are directly performed on the graphics hardware and allow complex geological and geometrical conditional queries. The computation and rendering of the iso-value surfaces is performed in real time on models with up to several hundred thousand cells on normal consumer hardware.},
  author   = {Tobias Frank},
  isbn     = 9782960064407,
  journal  = {IAMG 2006 - 11th International Congress for Mathematical Geology: Quantitative Geology from Multiple Sources},
  keywords = {Geological co-rendering,Tetrahedral meshes,Visualization},
  pages    = {12--15},
  title    = {Geological information retrieval using tetrahedral meshes},
  url      = {https://www.ring-team.org/publications/2006/IAMG06\_S14\_12.pdf},
  year     = 2006
}

@article{Franke2007a,
  abstract = {We present an adaptive unstructured triangular grid finite element approach for effectively simulating plane-wave diffusive electromagnetic fields in 2-D conductivity structures. The most striking advantage of irregular grids is their potential to incorporate arbitrary geometries including surface and seafloor topography. Adaptive mesh refinement strategies using an a posteriori error estimator yield most efficient numerical solutions since meshes are only refined where required. We demonstrate the robustness of this approach by comparison with analytical solutions and previously published numerical simulations. Maximum errors may systematically be reduced to, for example, 0.8 per cent for the apparent resistivity and 0.2\textdegree{} in the phase. An additional accuracy study of the thickness of the air layer in E-polarization suggests to keep a minimum thickness depending on lateral conductivity contrasts within the earth. Furthermore, we point out the new quality and flexibility of our simulation technique by addressing two marine magnetotelluric applications. In the first case, we discuss topographic effects associated with a synthetic sinusoidal sea bottom model and in the second case, we show a close-to-reality scenario using real bathymetry data from the East Pacific Rise at 17\textdegree{}S. \textcopyright{} 2007 The Authors Journal compilation \textcopyright{} 2007 RAS.},
  author   = {Antje Franke and Ralph Uwe B\"{o}rner and Klaus Spitzer},
  doi      = {10.1111/j.1365-246X.2007.03481.x},
  issn     = {0956540X},
  issue    = 1,
  journal  = {Geophysical Journal International},
  keywords = {Adaptive unstructured grids,Electromagnetic modelling,Electromagnetics,Finite element methods,Marine topography},
  pages    = {71--86},
  title    = {Adaptive unstructured grid finite element simulation of two-dimensional magnetotelluric fields for arbitrary surface and seafloor topography},
  volume   = 171,
  year     = 2007
}

@article{Freiknecht2017,
  abstract = {This survey presents algorithms for the automatic generation of content for virtual worlds, in particular for games. After a definition of the term procedural content generation, the algorithms to generate realistic objects such as landscapes and vegetation, road networks, buildings, living beings and stories are introduced in detail. In our discussion, we emphasize a good compromise between the realism of the objects and the performance of the algorithms. The survey also assesses each generated object type in terms of its applicability in games and simulations of virtual worlds.},
  author   = {Jonas Freiknecht and Wolfgang Effelsberg},
  doi      = {10.3390/mti1040027},
  issn     = 24144088,
  issue    = 4,
  journal  = {Multimodal Technologies and Interaction},
  keywords = {Multimedia content creation,Procedural content generation,Serious games,Virtual worlds},
  pages    = {1--34},
  title    = {A survey on the procedural generation of virtual worlds},
  volume   = 1,
  year     = 2017
}

@article{Fridenfalk2016,
  abstract = {This paper presents new methods for the generation of hexagonal patterns, based on cellular automata in small-sized regular hexagonal modular spaces. The patterns are intended to be used for procedural content generation in computer games, but could also be applied for diverse ends, such as logotype design and architecture.},
  author   = {M Fridenfalk},
  journal  = {SIGRAD},
  title    = {Pattern Generation with Cellular Automata in Hexagonal Modular Spaces},
  year     = 2016
}

@article{Fu2022,
  abstract = {Coastal erosion vulnerability assessment is widely used to assess the loss degree of coastal zone caused by erosion, and plays an important role in coastal natural resources protection, planning, management and decision-making. Based on the natural and social characteristics of the east coast of Qiongdong and the coastal erosion vulnerability index (CVI) method, this study selected 8 assessment indicators, such as shoreline change rate (U1). The Delphi method and the entropy weight method were used to calculate the comprehensive index weight, combined with CVI method and geographic information system (GIS) technology, to quantitatively evaluate the temporal and spatial distribution characteristics of typical coastal erosion vulnerability such as coral reefs in the east of Hainan Island. The study area was divided into 5 grades: very low (31\%), low (10\%), moderate (28\%), high (24\%) and high vulnerability (7\%), and the overall performance was moderate erosion vulnerability. The research showed that the interannual downward rate erosion of beach (U3) and the rate of change of the isobath (U2) of the beach were the main controlling factors affecting the vulnerability of coastal erosion in the study area, and the coastal dynamic factor had a greater impact than the other two factors. As a natural barrier, the coral reefs in the study area had good wave absorption and energy reduction, and the coral reef coasts showed low coastal erosion vulnerability, due to the complex hydrodynamic characteristics, estuary coasts is the most vulnerable areas. The verification results of the ROC-AUC method showed that the accuracy of erosion vulnerability was 68.9\%, which provided an important reference for the ecological restoration of tropical coral reef biological coasts and the development and management of the Hainan Qiongdong coastal zone.},
  author   = {Guo Wei Fu and Chao Cao and Kai Zhe Fu and Yan Wei Song and Kun Yuan and Xiao Ming Wan and Zi Ang Zhu and Zhao Fan Wang and Zan Hui Huang},
  doi      = {10.3389/fmars.2022.1061769},
  issn     = 22967745,
  issue    = {December},
  journal  = {Frontiers in Marine Science},
  keywords = {Hainan Island,coastal erosion vulnerability,coral reef coast,human activities,index method},
  pages    = {1--19},
  title    = {Characteristics and evaluation of coastal erosion vulnerability of typical coast on Hainan Island},
  volume   = 9,
  year     = 2022
}

@article{Fukao2010,
  abstract = {We propose that background Love and Rayleigh waves in a frequency range 5-20 mHz are generated primarily by ocean infragravity waves in the same frequency range by a linear coupling process with seafloor topography. Wavelengths of infragravity waves in this frequency range are on the order of 10 to 40 km in the deep ocean. The seafloor topography with wavelengths of this order is dominated by abyssal hills, which are the most widespread physiographic forms on Earth, covering as much as 85\% of the Pacific floor. Interaction of infragravity waves in the deep ocean with these hills generates a random distribution of point-like tangential forces on the seafloor which may be large enough to excite Love and Rayleigh waves simultaneously. We quantify this idea by using the known statistical property of hills distribution in the Pacific and by noting that heights of abyssal hills are an order of magnitude smaller than depths of the deep ocean, so that the topography-related phase velocity change can be neglected. The model is reasonably consistent with the Love to Rayleigh wave amplitude ratio reported at 10-20 mHz and the observed background Rayleigh wave spectrum with a characteristic plateau around 8 mHz. Contribution of topographic coupling in shallow, coastal seas is not included in our simple model but should be important, especially at frequencies above 20 mHz. \textcopyright{} 2010 by the American Geophysical Union.},
  author   = {Yoshio Fukao and Kiwamu Nishida and Naoki Kobayashi},
  doi      = {10.1029/2009JB006678},
  issn     = 21699356,
  issue    = 4,
  journal  = {Journal of Geophysical Research: Solid Earth},
  keywords = {http://dx.doi.org/10.1029/2009JB006678, doi:10.102},
  pages    = {1--10},
  title    = {Seafloor topography, ocean infragravity waves, and background Love and Rayleigh waves},
  volume   = 115,
  year     = 2010
}

@unpublished{Gailleton2023,
  abstract = {Landscape Evolution Models (LEMs) are prime tools to simulate the evolution of source-to-sink systems through ranges of spatial and temporal scales. Plethora of different empirical laws have been successfully applied to describe the different parts of these systems: fluvial erosion, sediment transport and deposition, hillslope diffusion, or hydrology. Numerical frameworks exist to facilitate the combination of different subsets of laws, mostly by superposing grids of fluxes calculated independently. However the exercise becomes increasingly challenging when the different laws are interconnected: for exam-5 ple when a lake breaks the upstream-downstream continuum of the amount of sediment and water it receives and transmits; or when erosional efficiency depends of the composition of a sediment flux affected by multiple processes. In this contribution, we present a method mixing the advantages of cellular-automata and graph theory to address such cases. We demonstrate how the former guarantees finite knowledge of all fluxes independently from the process-law implemented in the model while the latter offer a wide range of tools to process numerical landscapes, including landscapes with closed basins. We provide 10 three scenario largely benefiting from our method: i) one where lake systems are primary controls on Landscape evolution, ii) one where sediment provenance is closely monitored through the stratigraphy and iii) one where heterogeneous provenance influences fluvial incision dynamically. We finally outline the way forward to make this method more generic and flexible.},
  author   = {Boris Gailleton and Luca Malatesta and Guillaume Cordonnier and Jean Braun},
  doi      = {10.5194/egusphere-2022-1394},
  title    = {CHONK 1.0: landscape evolution framework: cellular automata meets graph theory},
  url      = {https://doi.org/10.5194/egusphere-2022-1394},
  year     = 2023
}

@article{Gain2009,
  abstract = {Procedural methods for terrain synthesis are capable of creating realistic depictions of heightfield terrains with little user intervention. However, users often do wish to intervene in controlling the placement and shape of landforms, but without sacrificing realism. In this paper, we present a sketching interface to procedural terrain generation. This system enables users to draw the silhouette, spine and bounding curves of both extruding (hills and mountains) and embedding landforms (river courses and canyons). Terrain is interactively generated to match the sketched constraints using multiresolution surface deformation. In addition, the wavelet noise characteristics of silhouette strokes are propagated to the surrounding terrain. With terrain sketching users can interactively create or modify landscapes incorporating varied and complex land-forms. Copyright \textcopyright{} 2009 by the Association for Computing Machinery, Inc.},
  author   = {James Gain and Patrick Marais and Wolfgang Stra\ss{}er},
  doi      = {10.1145/1507149.1507155},
  isbn     = 9781605584294,
  issue    = 212,
  journal  = {Proceedings of I3D 2009: The 2009 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
  pages    = {31--38},
  title    = {Terrain sketching},
  volume   = 1,
  year     = 2009
}

@article{Gain2015,
  abstract = {The challenge in terrain synthesis for virtual environments is to provide a combination of precise user control over landscape form, with interactive response and visually realistic results. We present a system that builds on parallel pixel-based texture synthesis to enable interactive creation of an output terrain from a database of heightfield exemplars. We also provide modelers with control over height and surrounding slope by means of constraint points and curves; a paint-by-numbers interface for specifying the local character of terrain; coherence controls that allow localization of changes to the synthesized terrain; and copy-paste functionality to directly transplant terrain regions. Together these contributions provide a level of realism that, based on user experiments, is indistinguishable from real source terrains; user control sufficient for precise placement of a variety of landforms, such as cliffs, ravines and mesas; and synthesis times of 165ms for a 10242 terrain grid.},
  author   = {James Gain and B. Merry and Patrick Marais},
  doi      = {10.1111/cgf.12545},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  pages    = {105--116},
  title    = {Parallel, Realistic and Controllable Terrain Synthesis},
  volume   = 34,
  year     = 2015
}

@article{Gain2017,
  abstract = {One challenge in portraying large-scale natural scenes in virtual environments is specifying the attributes of plants, such as species, size and placement, in a way that respects the features of natural ecosystems, while remaining computationally tractable and allowing user design. To address this, we combine ecosystem simulation with a distribution analysis of the resulting plant attributes to create biome-specific databases, indexed by terrain conditions, such as temperature, rainfall, sunlight and slope. For a specific terrain, interpolated entries are drawn from this database and used to interactively synthesize a full ecosystem, while retaining the fidelity of the original simulations. A painting interface supplies users with semantic brushes for locally adjusting ecosystem age, plant density and variability, as well as optionally picking from a palette of precomputed distributions. Since these brushes are keyed to the underlying terrain properties a balance between user control and real-world consistency is maintained. Our system can be be used to interactively design ecosystems up to 5 \texttimes{} 5 km2 in extent, or to automatically generate even larger ecosystems in a fraction of the time of a full simulation, while demonstrating known properties from plant ecology such as succession, self-thinning, and underbrush, across a variety of biomes.},
  author   = {James Gain and H. Long and Guillaume Cordonnier and Marie-Paule Cani},
  doi      = {10.1111/cgf.13107},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {1.3.7 [Computer Graphics]: Three-dimensional graph,Categories and Subject Descriptors (according to A},
  pages    = {63--73},
  title    = {EcoBrush: Interactive Control of Visually Consistent Large-Scale Ecosystems},
  volume   = 36,
  url      = {https://hal.archives-ouvertes.fr/hal-01519852/file/ecobrush.pdf},
  year     = 2017
}

@article{Galili2008,
  abstract = {Underwater archaeological investigations in Israel have recovered instruments intended to be operated under water from a vessel on the surface, at depths and times beyond the ability of free divers. Some of these remotely-operated devices, including salvaging-rings, coral-harvesting devices, and grapnels, are described, classified and discussed. These humble but efficient instruments, the prototypes of sophisticated modern instruments, fulfilled necessary tasks in antiquity and are still being used today by traditional fishermen. \textcopyright{} 2008 The Authors. Journal Compilation \textcopyright{} 2008 Nautical Archaeology Society.},
  author   = {Ehud Galili and Baruch Rosen},
  doi      = {10.1111/j.1095-9270.2008.00187.x},
  issn     = 10572414,
  issue    = 2,
  journal  = {International Journal of Nautical Archaeology},
  keywords = {Grapnel,Lead,Red coral,Salvaging,Shipwreck},
  pages    = {283--294},
  title    = {Ancient remotely-operated instruments recovered under water off the Israeli coast},
  volume   = 37,
  year     = 2008
}

@article{Galin2010,
  abstract  = {In this paper, we propose an automatic method for generating roads based on a weighted anisotropic shortest path algorithm. Given an input scene, we automatically create a path connecting an initial and a final point. The trajectory of the road minimizes a cost function that takes into account the different parameters of the scene including the slope of the terrain, natural obstacles such as rivers, lakes, mountains and forests. The road is generated by excavating the terrain along the path and instantiating generic parameterized models. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
  author    = {\'{E}ric Galin and Adrien Peytavie and N. Mar\'{e}chal and \'{E}ric Gu\'{e}rin},
  doi       = {10.1111/j.1467-8659.2009.01612.x},
  issn      = 14678659,
  issue     = 2,
  journal   = {Computer Graphics Forum},
  keywords  = {Discrete anisotropic shortest path,Procedural modeling,Road generation},
  month     = 5,
  note      = {Peut-\^{e}tre pour cr\'{e}er des \&quot;chemins\&quot; pour le robot (voir presentation ppt de Karen)},
  pages     = {429--438},
  publisher = {Blackwell Publishing Ltd},
  title     = {Procedural generation of roads},
  volume    = 29,
  url       = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8659.2009.01612.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01612.x https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01612.x},
  year      = 2010
}

@article{Galin2019,
  abstract = {<p>Terrains are a crucial component of three-dimensional scenes and are present in many Computer Graphics applications. Terrain modeling methods focus on capturing landforms in all their intricate detail, including eroded valleys arising from the interplay of varied phenomena, dendritic mountain ranges, and complex river networks. Set against this visual complexity is the need for user control over terrain features, without which designers are unable to adequately express their artistic intent. This article provides an overview of current terrain modeling and authoring techniques, organized according to three categories: procedural modeling, physically-based simulation of erosion and land formation processes, and example-based methods driven by scanned terrain data. We compare and contrast these techniques according to several criteria, specifically: the variety of achievable landforms; realism from both a perceptual and geomorphological perspective; issues of scale in terms of terrain extent and sampling precision; the different interaction metaphors and attendant forms of user-control, and computation and memory performance. We conclude with an in-depth discussion of possible research directions and outstanding technical and scientific challenges.</p>},
  author   = {Eric Galin and Eric Gu\'{e}rin and Adrien Peytavie and Guillaume Cordonnier and Marie-Paule Cani and Bedrich Benes and James Gain},
  doi      = {10.1111/cgf.13657},
  issn     = {0167-7055},
  issue    = 2,
  journal  = {Computer Graphics Forum},
  month    = 5,
  pages    = {553--577},
  title    = {A Review of Digital Terrain Modeling},
  volume   = 38,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13657},
  year     = 2019
}

@article{Galzin1998,
  abstract = {The 9 km2 uplifted lagoon of Taiaro Atoll (15\textdegree{}45'S, 144\textdegree{}38'W) is hypersaline due to its isolation from the ocean, yet it contains a high diversity of fish. The question unifying our expedition was to discover whether these assemblages could be self-sustaining despite very limited contact with the ocean. Although we were constrained by time, collections of fish larvae showed that some species can complete their life-cycle within the lagoon, while others differed genetically between the lagoon and the ocean, consistent with restricted gene flow. The lagoon contained few oceanic species of zooplankton, confirming its general isolation, but nevertheless some fish species may depend upon infrequent colonisation from the ocean (when large waves drive water over the normally dry reef crest). Isotopic signatures in fish otoliths suggest the basis for a more definitive and inclusive test of the sources of the lagoonal assemblage.},
  author   = {R. Galzin and S. Planes and M. Adjeroud and C. Chauvet and P. J. Doherty and J. Poupin},
  doi      = {10.1007/s003380050087},
  issn     = {07224028},
  issue    = 1,
  journal  = {Coral Reefs},
  keywords = {Coral reef fishes,Hydrodynamics,Larval dispersal,Life cycle,Surveys},
  month    = 4,
  pages    = {15--21},
  title    = {Objectives and background to the 1994 Franco-Australian expedition to Taiaro Atoll (Tuamotu Archipelago, French Polynesia)},
  volume   = 17,
  year     = 1998
}

@article{Gamito2001,
  abstract = {Overhangs have been a major stumbling block in the context of terrain synthesis models. These models resort invariably to a heightfield paradigm, which immediately precludes the existence of any type of overhang. This article presents a new technique for the generation of surfaces, with the ability to model overhangs in a procedural way. This technique can be used generally to model landscape elements, not only terrains but also the surface of the sea. The technique applies non-linear deformations to an initial heightfield surface. The deformations occur after the surface has been displaced along some specified vector field. The method is conceptually simple and enhances greatly the class of landscapes synthesized with procedural models.},
  author   = {MN Gamito and Forest Kenton Musgrave},
  issue    = {May},
  journal  = {10th Portuguese Computer Graphics \ldots{}},
  keywords = {adaptive level of detail,procedural models,ray-tracing,surface deformation,surface overhangs},
  title    = {Procedural landscapes with overhangs},
  url      = {http://virtual.inesc-id.pt/virtual/10epcg/actas/pdfs/gamito.pdf},
  year     = 2001
}

@article{Gao2018,
  abstract = {In this paper, we present a mixed explicit and semi-implicit Material Point Method for simulating particle-laden flows. We develop a Multigrid Preconditioned fluid solver for the Locally Averaged Navier Stokes equation. This is discretized purely on a semi-staggered standard MPM grid. Sedimentation is modeled with the Drucker-Prager elastoplasticity flow rule, enhanced by a novel particle density estimation method for converting particles between representations of either continuum or discrete points. Fluid and sediment are two-way coupled through a momentum exchange force that can be easily resolved with two MPM background grids. We present various results to demonstrate the efficacy of our method.},
  author   = {Ming Gao and Andre Pradhana and Xuchen Han and Qi Guo and Grant Kot and Eftychios Sifakis and Chenfanfu Jiang},
  doi      = {10.1145/3197517.3201309},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Material point method (MPM),Multiphase,Particlefluid interaction,Sediment transport,Sedimentation},
  title    = {Animating fluid sediment mixture in particle-laden flows},
  volume   = 37,
  year     = 2018
}

@article{Gardiner2017,
  author      = {Robert C Jr Gardiner},
  issue       = 443,
  institution = {Nova Southeastern University},
  title       = {Variable Patterns in Spur and Groove Reef Morphology Explained by Physical Controls and their Relevance for Platform-Top Sedimentology},
  url         = {http://nsuworks.nova.edu/occ\_stuetd/443},
  year        = 2017
}

@article{Garland1997,
  abstract = {Many applications in computer graphics require complex, highly detailed models. However, the level of detail actually necessary may vary considerably. To control processing time, it is often desirable to use approximations in place of excessively detailed models. We have developed a surface simplification algorithm which can rapidly produce high quality approximations of polygonal models. The algorithm uses iterative contractions of vertex pairs to simplify models and maintains surface error approximations using quadric matrices. By contracting arbitrary vertex pairs (not just edges), our algorithm is able to join unconnected regions of models. This can facilitate much better approximations, both visually and with respect to geometric error. In order to allow topological joining, our system also supports non-manifold surface models.},
  author   = {Michael Garland and Paul S. Heckbert},
  doi      = {10.1145/258734.258849},
  isbn     = {0897918967},
  journal  = {Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1997},
  keywords = {level of detail,mutiresolution modeling,non-manifold,pair contraction,surface simplification},
  pages    = {209--216},
  title    = {Surface simplification using quadric error metrics},
  year     = 1997
}

@article{Garrote2018,
  abstract = {This paper presents a hybrid 3D-like grid-based mapping approach, that we called HMAP, used as a reliable and efficient 3D representation of the environment surrounding a mobile robot. Considering 3D point-clouds as input data, the proposed mapping approach addresses the representation of height-voxel (HVoxel) elements inside the HMAP, where free and occupied space is modeled through HVoxels, resulting in a reliable method for 3D representation. The proposed method corrects some of the problems inherent to the representation of complex environments based on 2D and 2.5D representations, while keeping an updated grid representation. Additionally, we also propose a complete pipeline for SLAM based on HMAPs. Indoor and outdoor experiments were carried out to validate the proposed representation using data from a Microsoft Kinect One (indoor) and a Velodyne VLP-16 LiDAR (outdoor). The obtained results show that HMAPs can provide a more detailed view of complex elements in a scene when compared to a classic 2.5D representation. Moreover, validation of the proposed SLAM approach was carried out in an outdoor dataset with promising results, which lay a foundation for further research in the topic.},
  author   = {Luis Garrote and Cristiano Premebida and David Silva and Urbano J. Nunes},
  doi      = {10.1109/IROS.2018.8594113},
  isbn     = 9781538680940,
  issn     = 21530866,
  journal  = {IEEE International Conference on Intelligent Robots and Systems},
  pages    = {1197--1203},
  title    = {HMAPs - Hybrid Height- Voxel Maps for Environment Representation},
  url      = {http://home.isr.uc.pt/~cpremebida/files\_cp/HMAPs\_Hybrid Height Voxel Maps for Environment Representation.pdf},
  year     = 2018
}

@article{Gasch2020,
  abstract  = {Terrain is an essential part of any outdoor environment and, consequently, many techniques have appeared that deal with the problem of its automatic generation, such as procedural modeling. One form to create terrains is using noise functions because its low computational cost and its random result. However, the randomness of these functions also makes it difficult to have any control over the result obtained. In order to solve the problem of lack of control, this paper presents a new method noise-based that allows procedural terrains creation with elevation constraints (GPS routes, points of interest and areas of interest). For this, the method establishes the restrictions as fixed values in the heightmap function and creates a system of equations to obtain all points that they depend this restrictions. In this way, the terrain obtained maintains the random noise, but including the desired restrictions. The paper also includes how we apply this method on large terrain models without losing resolution or increasing the computational cost excessively. The results show that our method makes it possible to integrate this kind of constraints with high accuracy and realism while preserving the natural appearance of the procedural generation.},
  author    = {Cristina Gasch and Miguel Chover and Inmaculada Remolar and Cristina Rebollo},
  doi       = {10.1007/s11042-020-09476-3},
  issn      = 15737721,
  issue     = {41-42},
  journal   = {Multimedia Tools and Applications},
  keywords  = {GPS routes,Perlin noise,Procedural generation,Terrain modelling},
  pages     = {31125--31146},
  publisher = {Multimedia Tools and Applications},
  title     = {Procedural modelling of terrains with constraints},
  volume    = 79,
  year      = 2020
}

@article{Gascuel1993,
  abstract = {This paper presents an implicit deformable model, based on iso-surfaces of potential fields generated by skeletons, that provides elegant and unified formulations for both geometric parameters such as shape or deformation and physical properties such as rigidity. The model is especially designed to improve collision and contact processing for non-rigid objects. In particular, it generates and maintains exact contact surfaces during interactions.},
  author   = {Marie Paule Gascuel},
  doi      = {10.1145/166117.166157},
  isbn     = {0897916018},
  journal  = {Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1993},
  keywords = {Animation,Collision detection,Collision response,Deformation,Implicit surface,Simulation},
  pages    = {313--320},
  title    = {An implicit formulation for precise contact modeling between flexible solids},
  url      = {https://dl.acm.org/doi/pdf/10.1145/166117.166157},
  year     = 1993
}

@article{GashGarcia2021,
  abstract = {that allow generating complex environments, although they do not usually allow control of the final result. However, these environments need real-time visualization techniques that can handle all the generated geometry interactively. In this sense, the main objective of the thesis is to present a series of methods developed with the intention of controlling the final result in procedural generation and improving the visualization of natural environments. On one side, a new method of procedural terrain generation based on noise functions is presented, which results in a pseudo-random terrain that precisely complies with the height restrictions given in advance. In addition to this, a user-assisted process tree and plant distribution method is introduced, which uses biological constraints on plant species. Finally, to improve the visualization of natural environments. On one side, a new method of procedural terrain generation based on noise functions is presented, which results in a pseudo-random terrain that precisely complies with the height restrictions given in advance. In addition to this, a user-assisted process tree and plant distribution method is introduced, which uses biological constraints on plant species. Finally, to improve the visualization of natural environments, a technique is presented to simplify the foliage of natural elements. This technique is based on mutual information from the point of view and a continuous multiresolution model that uses this technique to display different resolutions of the element according to its importance in the scene, allowing interactive visualization of the natural environment.},
  author   = {Cristina Gash Garcia},
  isbn     = 2019106426,
  note     = {Use of height maps (only ?)},
  title    = {Procedural Generation of Natural Environnements},
  year     = 2021
}

@article{Gaucherel2012,
  abstract = {Patchy landscapes driven by human decisions and/or natural forces are still a challenge to be understood and modelled. No attempt has been made up to now to describe them by a coherent framework and to formalize landscape changing rules. Overcoming this lacuna was our first objective here, and this was largely based on the notion of Rewriting Systems, also called Formal Grammars. We used complicated scenarios of agricultural dynamics to model landscapes and to write their corresponding driving rule equations. Our second objective was to illustrate the relevance of this landscape language concept for landscape modelling through various grassland managements, with the final aim to assess their respective impacts on biological conservation. For this purpose, we made the assumptions that a higher grassland appearance frequency and higher land cover connectivity are favourable to species conservation. Ecological results revealed that dairy and beef livestock production systems are more favourable to wild species than is hog farming, although in different ways. Methodological results allowed us to efficiently model and formalize these landscape dynamics. This study demonstrates the applicability of the Rewriting System framework to the modelling of agricultural landscapes and, hopefully, to other patchy landscapes. The newly defined grammar is able to explain changes that are neither necessarily local nor Markovian, and opens a way to analytical modelling of landscape dynamics. \textcopyright{} 2012 Gaucherel et al.},
  author   = {C\'{e}dric Gaucherel and Fr\'{e}d\'{e}ric Boudon and Thomas Houet and Mathieu Castets and Christophe Godin},
  doi      = {10.1371/journal.pone.0046064},
  issn     = 19326203,
  issue    = 9,
  journal  = {PLoS ONE},
  pmid     = 23049935,
  title    = {Understanding Patchy Landscape Dynamics: Towards a Landscape Language},
  volume   = 7,
  url      = {https://halshs.archives-ouvertes.fr/halshs-00750971/file/Gaucherel\_al-PONE.pdf},
  year     = 2012
}

@article{Ge1999,
  abstract = {The numerical approach to solving geometric constraint problems is indispensable for building a practical CAD system. The most commonly-used numerical method is the Newton-Raphson method. It is fast, but has the instability problem: the method requires good initial values. To overcome this problem, recently the homotopy method has been proposed and experimented with. According to the report, the homotopy method generally works much better in terms of stability. In this paper we use the numerical optimization method to deal with the geometric constraint solving problem. The experimental results based on our implementation of the method show that this method is also much less sensitive to the initial value. Further, a distinctive advantage of the method is that under- and over-constrained problems can be handled naturally and efficiently. We also give many instructive examples to illustrate the above advantages.},
  author   = {Jian Xin Ge and Shang Ching Chou and Xiao Shan Gao},
  doi      = {10.1016/S0010-4485(99)00074-3},
  issn     = {00104485},
  issue    = 14,
  journal  = {CAD Computer Aided Design},
  keywords = {optimization method,parametric design,variational geometry},
  pages    = {867--879},
  title    = {Geometric constraint satisfaction using optimization methods},
  volume   = 31,
  year     = 1999
}

@article{Geiss2007,
  author  = {Ryan Geiss and Michael Thompson},
  journal = {Managing},
  title   = {Cascades by NVIDIA},
  year    = 2007
}

@article{Gelas2009,
  author   = {Arnaud Gelas and S\'{e}bastien Valette and R\'{e}my Prost and Wieslaw L. Nowinski},
  doi      = {10.1016/j.cag.2009.03.016},
  issn     = {00978493},
  issue    = 3,
  journal  = {Computers \& Graphics},
  keywords = {implicit surface,meshing,restricted delaunay,variational approach},
  month    = 6,
  pages    = {312--320},
  title    = {Variational implicit surface meshing},
  volume   = 33,
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0097849309000326},
  year     = 2009
}

@article{Genevaux2015,
  abstract = {We introduce a compact hierarchical procedural model that combines feature-based primitives to describe complex terrains with varying level of detail. Our model is inspired by skeletal implicit surfaces and defines the terrain elevation function by using a construction tree. Leaves represent terrain features and they are generic parametrized skeletal primitives, such as mountains, ridges, valleys, rivers, lakes or roads. Inner nodes combine the leaves and subtrees by carving, blending or warping operators. The elevation of the terrain at a given point is evaluated by traversing the tree and by combining the contributions of the primitives. The definition of the tree leaves and operators guarantees that the resulting elevation function is Lipschitz, which speeds up the sphere tracing used to render the terrain. Our model is compact and allows for the creation oflarge terrains with a high level of detail using a reduced set of primitives. We show the creation of different kinds of landscapes and demonstrate that our model allows to efficiently control the shape and distribution oflandform features. Keywords:},
  author   = {Jean-David G\'{e}nevaux and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin and Cyril Briquet and Fran\c{c}ois Grosbellet and Bed\v{r}ich Bene\v{s}},
  doi      = {https://doi.org/10.1111/cgf.12530},
  keywords = {Computational geometry and Object modeling surface,Interaction techniques,Methodology and Techniques Graphics data structure,object representations},
  title    = {Terrain Modelling from Feature Primitives},
  year     = 2015
}

@article{Genevaux2016,
  author   = {Jean-David G\'{e}nevaux and Fran\c{c}ois Grosbellet and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin and Cyril Briquet},
  keywords = {implicit surface,natural phenomena,procedural modelling,terrain modelling},
  title    = {Mod\'{e}lisation de terrains par primitives},
  year     = 2016
}

@article{Genevaux2020,
  abstract = {<p>We present a framework that allows quick and intuitive modeling of terrains using concepts inspired by hydrology. The terrain is generated from a simple initial sketch, and its generation is controlled by a few parameters. Our terrain representation is both analytic and continuous and can be rendered by using varying levels of detail. The terrain data are stored in a novel data structure: a construction tree whose internal nodes define a combination of operations, and whose leaves represent terrain features. The framework uses rivers as modeling elements, and it first creates a hierarchical drainage network that is represented as a geometric graph over a given input domain. The network is then analyzed to construct watersheds and to characterize the different types and trajectories of rivers. The terrain is finally generated by combining procedural terrain and river patches with blending and carving operators.</p>},
  author   = {Jean-David G\'{e}nevaux and \'{E}ric Galin and Eric Gu\'{e}rin and Adrien Peytavie and Bedrich Benes},
  doi      = {10.1145/2461912.2461996},
  issn     = {0730-0301},
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  month    = 7,
  pages    = {1--13},
  title    = {Terrain generation using procedural models based on hydrology},
  volume   = 32,
  url      = {https://dl.acm.org/doi/10.1145/2461912.2461996},
  year     = 2013
}

@article{Georgiades2009,
  abstract  = {AQUA is an underwater hexapod robot that uses its paddles to propel itself and control its orientation. To aid in the vehicle development, a simulation was needed to predict the motion of the robot based on its paddle oscillations. The most difficult aspect of this simulation was the characterization of the forces generated by the paddles oscillating in the water. In this work, a model predicting the forces produced by an oscillating rigid paddle was developed and validated experimentally. Tests were performed on an experimental setup, which was designed and built to measure the forces and torques produced by a paddle oscillating in a water tank. Also, the forces produced by a flexible fin were determined experimentally and were compared to those generated by the rigid paddle. Finally, a simulation of the AQUA robot was developed, based on the validated rigid paddle model. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
  author    = {Christina Georgiades and Meyer Nahon and Martin Buehler},
  doi       = {10.1016/j.oceaneng.2008.10.005},
  issn      = {00298018},
  issue     = 1,
  journal   = {Ocean Engineering},
  keywords  = {Biomimetic,Dynamics,Paddles,Underwater robot},
  month     = 1,
  pages     = {39--47},
  publisher = {Pergamon},
  title     = {Simulation of an underwater hexapod robot},
  volume    = 36,
  year      = 2009
}

@article{Gero1994a,
  abstract = {This paper focuses on that form of learning that relates to exploration, rather than generalization. It uses the notion of exploration as the modification of state spaces within which search and decision making occur. It demonstrates that the genetic algorithm formalism provides a computational construct to carry out this learning. The process is exemplified using a shape grammar for a beam section. A new shape grammar is learned that produces a new state space for the problem. This new state space has improved characteristics. \textcopyright{} 1994, Cambridge University Press. All rights reserved.},
  author   = {John S. Gero and Sushil J. Louis and Sourav Kundu},
  doi      = {10.1017/S089006040000069X},
  issn     = 14691760,
  issue    = 2,
  journal  = {Artificial Intelligence for Engineering, Design, Analysis and Manufacturing},
  keywords = {Evolution,Genetic Algorithms,Learning,Shape Grammars},
  pages    = {83--94},
  title    = {Evolutionary learning of novel grammars for design improvement},
  volume   = 8,
  year     = 1994
}

@article{Ghadiyaram2019,
  abstract = {Current fully-supervised video datasets consist of only a few hundred thousand videos and fewer than a thousand domain-specific labels. This hinders the progress towards advanced video architectures. This paper presents an in-depth study of using large volumes of web videos for pre-training video models for the task of action recognition. Our primary empirical finding is that pre-training at a very large scale (over 65 million videos), despite on noisy social-media videos and hashtags, substantially improves the state-of-the-art on three challenging public action recognition datasets. Further, we examine three questions in the construction of weakly-supervised video action datasets. First, given that actions involve interactions with objects, how should one construct a verb-object pre-training label space to benefit transfer learning the most? Second, frame-based models perform quite well on action recognition; is pre-training for good image features sufficient or is pre-training for spatio-temporal features valuable for optimal transfer learning? Finally, actions are generally less well-localized in long videos vs. short videos; since action labels are provided at a video level, how should one choose video clips for best performance, given some fixed budget of number or minutes of videos?},
  author   = {Deepti Ghadiyaram and Matt Feiszli and Du Tran and Xueting Yan and Heng Wang and Dhruv Mahajan},
  month    = 5,
  title    = {Large-scale weakly-supervised pre-training for video action recognition},
  url      = {http://arxiv.org/abs/1905.00561},
  year     = 2019
}

@article{Gilbert1988,
  abstract = {Ocean floor topography can be characterized as a signal related to lithospheric cooling by comparing the shape of its power spectrum with that of a fractal process. Power spectra of Seabeam profiles along a flowline in the South Atlantic are calculated; the data are resampled, pre-whitened by first differencing, tapered with a Hanning window, and passed to a FFT. The effect of the pre-whitening are removed and the spectra are smoothed. The spectra of ocean floor topologic residuals are curved (power increases less rapidly with increasing wavelength) at wavelengths greater than several 10's of kilometers and straight at shorter wavelengths.},
  author   = {Lewis E. Gilbert and Alberto Malinverno},
  isbn     = 9780415475976,
  issue    = 12,
  journal  = {Geophysical research letters},
  pages    = {1401--1404},
  title    = {A characterization of the spectral density of residual ocean floor topography},
  volume   = 15,
  year     = 1988
}

@article{Gille2004,
  abstract = {Seafloor topoeraphu influences ocean circulation in two basic ways. First, it steers ocean flows. Second, it provides barriers that prevent deep waters from mixing, except within deep passageways that connect ocean basins or in hydraulically contrilled overflow regions. This paper explores the impact of both these processes on ocean circulation. The examples high-lighted here were among the broad range of topics explored at a workshop on "Ocean Circulation, Bathymetry~ and Climate," held at Scripps Institution of Oceanography in October 2002.},
  author   = {Sarah T. Gille and Joseph E. Metzger and Robin Tokmakjan},
  issue    = 1,
  journal  = {Oceanography},
  title    = {Sea Floor Topography and Ocean Circulation},
  volume   = 17,
  year     = 2004
}

@article{Given2011,
  author  = {Barbara A. Given and Marcia Grant},
  doi     = {10.1016/j.soncn.2011.02.001},
  issn    = {07492081},
  issue   = 2,
  journal = {Seminars in Oncology Nursing},
  pages   = {91--92},
  pmid    = 21514478,
  title   = {Introduction},
  volume  = 27,
  url     = {https://cs.brown.edu/people/rtamassi/gdhandbook/chapters/force-directed.pdf},
  year    = 2011
}

@article{Glardon2006,
  abstract = {A common problem in virtual character computer animation concerns the preservation of the basic foot-floor constraint (or footplant), consisting in detecting it before enforcing it. This paper describes a system capable of generating motion while continuously preserving the footplants for a real-time, dynamically evolving context. This system introduces a constraint detection method that improves classical techniques by adaptively selecting threshold values according to motion type and quality. The footplants are then enforced using a numerical inverse kinematics solver. As opposed to previous approaches, we define the footplant by attaching to it two effectors whose position at the beginning of the constraint can be modified, in order to place the foot on the ground, for example. However, the corrected posture at the constraint beginning is needed before it starts to ensure smoothness between the unconstrained and constrained states. We, therefore, present a new approach based on motion anticipation, which computes animation postures in advance, according to time-evolving motion parameters, such as locomotion speed and type. We illustrate our on-line approach with continuously modified locomotion patterns, and demonstrate its ability to correct motion artifacts, such as foot sliding, to change the constraint position and to modify from a straight to a curved walk motion.},
  author   = {Pascal Glardon and Ronan Boulic and Daniel Thalmann},
  doi      = {10.1007/s00371-006-0376-9},
  journal  = {Visual Comput},
  keywords = {Animation with constraints \cdot{},Human body simulation,Motion anticipation \cdot{}},
  pages    = {194--209},
  title    = {Robust on-line adaptive footplant detection and enforcement for locomotion},
  volume   = 22,
  year     = 2006
}

@inbook{Glynn2015,
  abstract  = {This volume investigates the effects of human activities on coral reefs, which provide important life-supporting systems to surrounding natural and human communities. It examines the self-reinforcing ecological, economic and technological mechanisms that degrade coral reef ecosystems around the world. Topics include reefs and limestones in Earth history; the interactions between corals and their symbiotic algae; diseases of coral reef organisms; the complex triangle between reef fishes, seaweeds and corals; coral disturbance and recovery in a changing world. In addition, the authors take key recent advances in DNA studies into account which provides new insights into the population biology, patterns of species distributions, recent evolution and vulnerabilities to environmental stresses. These DNA analyses also provide new understandings of the limitations of coral responses and scales of management necessary to sustain coral reefs in their present states. Coral reefs have been essential sources of food, income and resources to humans for millennia. This book details the delicate balance that exists within these ecosystems at all scales, from geologic time to cellular interactions and explores how recent global and local changes influence this relationship. It will serve as an indispensable resource for all those interested in learning how human activities have affected this vital ecosystem around the world.},
  author    = {Peter W. Glynn and Derek P. Manzello},
  city      = {Dordrecht},
  doi       = {10.1007/978-94-017-7249-5\_4},
  isbn      = 9789401772495,
  journal   = {Coral Reefs in the Anthropocene},
  pages     = {67--97},
  publisher = {Springer Netherlands},
  title     = {Bioerosion and Coral Reef Growth: A Dynamic Balance},
  url       = {http://link.springer.com/10.1007/978-94-017-7249-5\_4},
  year      = 2015
}

@article{Gobron2001,
  abstract = {This article describes a method for modeling the propagation of cracks on any 3D surface. This method allows almost any type of cracks on any type of triangulated 3D object. Our model's main advantage is that it proposes a semi-physical solution, making it both user controllable and easily extensible. We first introduce the general development of cracks. We then present our original model of spectrum stress, followed by a description of the mutual interaction between cracks and stresses. Then, we describe special rendering techniques including the multi-thickness anti-aliasing linked-segment method and the crack mirror special effect. The final section presents intermediate graphical results that review the entire model as well as a set of different crack patterns using various types of material such as concrete, ceramic, mud, and glaze.},
  author   = {St\'{e}phane Gobron and Norishige Chiba},
  doi      = {10.1007/s003710100099},
  issn     = {01782789},
  issue    = 5,
  journal  = {Visual Computer},
  keywords = {Cellular automaton,Cracking,Hyper-texture,Multi-layer modeling,Simulation},
  month    = 6,
  pages    = {287--309},
  title    = {Crack pattern simulation based on 3D surface cellular automata},
  volume   = 17,
  year     = 2001
}

@article{Goffe2011,
  abstract = {The uprising number of applications that involve very large images with resolutions greater than 30,000 \texttimes{} 30,000 raises major memory management issues. Firstly, the amount of data usually prevents such images from being processed globally and therefore, designing a global image partition raises several issues. Secondly, a multiresolution approach is necessary since an analysis only based on the highest resolution may miss global features revealed at lower resolutions. This article introduces the tiled top-down pyramidal framework which addresses these two main constraints. Our model provides a full representation of multiresolution images with both geometrical and topological relationships. The advantage of a top-down construction scheme is twofold: the focus of attention only refines regions of interest which results in a reduction of the amount of required memory and in a refinement process that may take into account hierarchical features from previous segmentations. Moreover, the top-down model is combined with decomposition in tiles to provide an accurate memory bounding while allowing global analysis of large images. \textcopyright{} 2011 Wiley Periodicals, Inc.},
  author   = {Romain Goffe and Luc Brun and Guillaume Damiand},
  doi      = {10.1002/ima.20270},
  issn     = 10981098,
  issue    = 1,
  journal  = {International Journal of Imaging Systems and Technology},
  keywords = {combinatorial map,irregular pyramid,tiled data structure,topological model},
  pages    = {28--36},
  title    = {Tiled top-down combinatorial pyramids for large images representation},
  volume   = 21,
  url      = {https://hal.archives-ouvertes.fr/hal-00567701v2/document},
  year     = 2011
}

@article{Goldberg2016,
  abstract = {There is only one published list of atolls of the world (Bryan, 1953) and it is the source of the often-quoted figure that there are 425 or ``more than 400'' of them. However, the original compendium included many banks and other reefs without lagoons. A re-examination of Bryan's data, along with charts, satellite photographs and updated literature suggests that the number of atolls is indeed ``more than 400,'' despite the deletion of more than 100 of his entries. There are 439 atolls identified in the present summary, but the list is broadly constructed, inclusive, and not limited to those known to have formed on subsiding volcanic platforms. In addition, 171 of those listed (39\%) are primarily subtidal atoll reefs with little or no island development. These particular atolls comprise 96\% of those from Fiji, 94\% of those in the South China Sea, and 62\% of those in Indonesia. With few exceptions, all of these reef systems are specifically identified and verified using Google Earth, Landsat or other satellite imagery, making this group an important and under-appreciated element of atoll geomorphology. Eliminating atoll reefs from consideration reduces the list of atolls to 268. Of these, 104 are closed and lack a direct passage connecting the lagoon and the surrounding ocean. Closed lagoons are typical of atolls in French Polynesia (53 of 78 with lagoons), even though most of them are euhaline and are open to exchange of ocean water by indirect mechanisms. By contrast, many atolls in the central Pacific, including most of those in Tuvalu, the Phoenix Islands and the Line Islands, have developed isolated lagoons containing hypersaline, brackish, and even fresh water. The location and type of atoll (atoll reef, and atolls that are open, closed, or closed with altered lagoon salinity/oxygen) are specified on maps and tables appended to this work, and a photographic record of all but two of 439 atolls has been assembled as a supplement. This list is by no means complete. There are numerous atolls or atoll-like structures that do not have a satellite record or an adequate description on charts or in the literature. This is especially true of Indonesia, Fiji and islands east of Papua New Guinea where further exploration is likely to increase the number of entries.},
  author   = {Walter M. Goldberg},
  doi      = {10.5479/si.0077-5630.610},
  issn     = {00775630},
  issue    = 610,
  journal  = {Atoll Research Bulletin},
  pages    = {1--47},
  title    = {Atolls of the world: Revisiting the original checklist},
  volume   = 2016,
  year     = 2016
}

@article{Gomez2023,
  abstract = {This paper shows a way to play the game of Go using cellular automata. To do this, we consider the best move depending on the player's style: offensive, defensive, or neutral. The best move is characterized by the importance of the next points: Chain growth, growth of degrees of freedom , reduction of opponent's degrees of freedom or capture of oppo-nent's stones. We use cellular automata to compute these problems for each possible move and determine the next move. We also use cellular automata to evaluate the board at each moment and determine which player wins in the endgame.},
  author   = {Jos\'{e} Manuel Gomez Soto and Diego Delgado Avila},
  journal  = {Journal of Cellular Automata},
  keywords = {Cellular automata,game of Go},
  pages    = {1--21},
  title    = {The Game of Go: A Cellular Automata Approach},
  volume   = {0},
  year     = 2023
}

@article{Gonzalez-Rivero2016,
  abstract = {Ecological measurements in marine settings are often constrained in space and time, with spatial heterogeneity obscuring broader generalisations. While advances in remote sensing, integrative modelling and meta-analysis enable generalisations from field observations, there is an underlying need for high-resolution, standardised and geo-referenced field data. Here, we evaluate a new approach aimed at optimising data collection and analysis to assess broad-scale patterns of coral reef community composition using automatically annotated underwater imagery, captured along 2 km transects. We validate this approach by investigating its ability to detect spatial (e.g., across regions) and temporal (e.g., over years) change, and by comparing automated annotation errors to those of multiple human annotators. Our results indicate that change of coral reef benthos can be captured at high resolution both spatially and temporally, with an average error below 5\%, among key benthic groups. Cover estimation errors using automated annotation varied between 2\% and 12\%, slightly larger than human errors (which varied between 1\% and 7\%), but small enough to detect significant changes among dominant groups. Overall, this approach allows a rapid collection of in-situ observations at larger spatial scales (km) than previously possible, and provides a pathway to link, calibrate, and validate broader analyses across even larger spatial scales (10-10,000 km2).},
  author   = {Manuel Gonz\'{a}lez-Rivero and Oscar Beijbom and Alberto Rodriguez-Ramirez and Tadzio Holtrop and Yeray Gonz\'{a}lez-Marrero and Anjani Ganase and Chris Roelfsema and Stuart Phinn and Ove Hoegh-Guldberg},
  doi      = {10.3390/rs8010030},
  issn     = 20724292,
  issue    = 1,
  journal  = {Remote Sensing},
  keywords = {Coral reefs,Monitoring,Support vector machine,XL Catlin Seaview Survey},
  title    = {Scaling up ecological measurements of coral reefs using semi-automated field image collection and analysis},
  volume   = 8,
  year     = 2016
}

@article{Gosselin2019,
  abstract = {Plants live in constantly moving fluid, whether air or water. In response to the loads associated with fluid motion, plants bend and twist, often with great amplitude. These large deformations are not found in traditional engineering application and thus necessitate new specialized scientific developments. Studying fluid-structure interaction (FSI) in botany, forestry, and agricultural science is crucial to the optimization of biomass production for food, energy, and construction materials. FSIs are also central in the study of the ecological adaptation of plants to their environment. This review paper surveys the mechanics of FSI on individual plants. I present a short refresher on fluid mechanics then dive into the statics and dynamics of plant-fluid interactions. For every phenomenon considered, I examine the appropriate dimensionless numbers to characterize the problem, discuss the implications of these phenomena on biological processes, and propose future research avenues. I cover the concept of reconfiguration while considering poroelasticity, torsion, chirality, buoyancy, and skin friction. I also assess the dynamical phenomena of wave action, flutter, and vortex-induced vibrations.},
  author   = {Fr\'{e}d\'{e}rick P. Gosselin},
  doi      = {10.1093/jxb/erz288},
  issn     = 14602431,
  issue    = 14,
  journal  = {Journal of Experimental Botany},
  keywords = {Aerodynamics,Current,Drag,Elasticity,Flow-induced vibrations,Fluid-structure interactions,Hydrodynamics,Loads,Pollen release and capture,Reconfiguration,Waves,Wind},
  pages    = {3533--3548},
  pmid     = 31198946,
  title    = {Mechanics of a plant in fluid flow},
  volume   = 70,
  url      = {https://arxiv.org/ftp/arxiv/papers/1905/1905.08055.pdf},
  year     = 2019
}

@article{Gourlay1994,
  abstract = {Wave transformation of regular waves was measured in a laboratory model of a fringing reef with a steep face and an outer reef-top slope gradually decreasing in the landward direction. Data was obtained for various wave conditions and water levels. A nonlinearity parameter, Fco = g1.25Ho0.5T2.5/hc1.75, based upon one proposed by Swart and Loubser (1979), is proposed as a suitable parameter for classifying wave transformation regimes on this reef. In particular, when Fco > 150, waves plunge on the reef edge and the amount of wave energy reaching a shore or structure is small \leqslant{} 16\%. When Fin co \leqslant{} 100, waves spill on the reef-top but the greater part of their energy is transmitted over the reef-top. The maximum values of the wave height to water depth ratio on the reef-top were found to be consistent with Nelson's analyses for laboratory and field data which indicate that the maximum stable wave height to depth ratio H/d on a horizontal bottom never exceeds 0.55 for shallow water waves (Fc > 500). The experimental data confirms that the maximum value of H/d decreases when Fc decreases but that it also increases when the bottom slope increases.},
  author   = {M.R. Gourlay},
  doi      = {10.1016/0378-3839(94)90013-2},
  issn     = {03783839},
  issue    = {1-2},
  journal  = {Coastal Engineering},
  month    = 5,
  pages    = {17--42},
  title    = {Wave transformation on a coral reef},
  volume   = 23,
  year     = 1994
}

@article{Gourmel2013,
  abstract = {<p> We introduce a new family of binary composition operators that solves four major problems of constructive implicit modeling: suppressing bulges when two shapes merge, avoiding unwanted blending at a distance, ensuring that the resulting shape keeps the topology of the union, and enabling sharp details to be added without being blown up. The key idea is that field functions should not only be combined based on their values, but also on their <italic>gradients</italic> . We implement this idea through a family of <italic>C</italic> <sup>\infty{}</sup> composition operators evaluated on the GPU for efficiency, and illustrate it by applications to constructive modeling and animation. </p>},
  author   = {Olivier Gourmel and Loic Barthe and Marie-Paule Cani and Brian Wyvill and Adrien Bernhardt and Mathias Paulin and Herbert Grasberger},
  doi      = {10.1145/2451236.2451238},
  issn     = {0730-0301},
  issue    = 2,
  journal  = {ACM Transactions on Graphics},
  month    = 4,
  pages    = {1--12},
  title    = {A gradient-based implicit blend},
  volume   = 32,
  url      = {https://dl.acm.org/doi/10.1145/2451236.2451238},
  year     = 2013
}

@article{Grabiner2001,
  abstract  = {Objective: To extend recent findings describing the effect of age on spatial and temporal gait variables. Design: Experimental. Setting: A gait analysis laboratory. Participants: Two experiments with healthy nonfallers were conducted. Experiment 1 included 33 subjects (n = 15, 72.13 \pm{} 3.96yr; n = 18, 25.06 \pm{} 4.02yr); and experiment 2 included 24 subjects (n = 14, 75.57 \pm{} 6.15yr; n = 10; 28.10 \pm{} 3.48yr). Interventions: The effect of age, walking velocity, shoe condition, and performance of an attention-splitting task on gait variables was investigated. Main Outcome Measures: Temporal and spatial gait variables were quantified using an instrumented surface across which subjects walked. The independent variables were walking velocity variability, stride length variability, stride width variability, and stride time variability. Results: Stride width variability of older adults was significantly larger than that of younger adults in both experiments. The remaining gait variables demonstrated nonsystematic or no age-related differences. Conclusions: With the exception of stride width variability, the variability of the remaining gait variables of interest were insensitive to the speed at which subjects walked, whether the subjects were wearing shoes or not, and performing an attention-splitting task while walking. These findings contribute to an emerging interpretive framework established by similar work published by others regarding gait variability. \textcopyright{} 2001 by the American Congress of Rehabilitation Medicine and the American Academy of Physical Medicine and Rehabilitation.},
  author    = {Penny C. Grabiner and S. Tina Biswas and Mark D. Grabiner},
  doi       = {10.1053/apmr.2001.18219},
  issn      = {00039993},
  issue     = 1,
  journal   = {Archives of Physical Medicine and Rehabilitation},
  keywords  = {Biomechanics,Gait,Rehabilitation,Walking},
  month     = 1,
  pages     = {31--35},
  publisher = {W.B. Saunders},
  title     = {Age-related changes in spatial and temporal gait variables},
  volume    = 82,
  year      = 2001
}

@article{Grasset-Simon2006,
  abstract = {Graph pyramids are often used for representing irregular image pyramids. For the 2D case, combinatorial pyramids have been recently defined in order to explicitly represent more topological information than graph pyramids. The main contribution of this work is the definition of pyramids of n-dimensional (nD) generalized maps. This extends the previous works to any dimension, and generalizes them in order to represent any type of pyramid constructed by using any removal and/or contraction operations. We give basic algorithms that allow to build an nD generalized pyramid that describes a multi-level segmented image. A pyramid of nD generalized maps can be implemented in several ways. We propose three possible representations and give conversion algorithms. \textcopyright{} 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
  author   = {Carine Grasset-Simon and Guillaume Damiand and Pascal Lienhardt},
  doi      = {10.1016/j.patcog.2005.10.004},
  issn     = {00313203},
  issue    = 4,
  journal  = {Pattern Recognition},
  keywords = {Hierarchical data structure,Irregular pyramid,Multi-level segmented image,Pyramid of generalized maps},
  pages    = {527--538},
  title    = {ND generalized map pyramids: Definition, representations and basic operations},
  volume   = 39,
  year     = 2006
}

@misc{Greene1989,
  abstract = {A novel stochastic modeling technique is described which operates on a voxel data base in which objects are represented as collections of voxel records. Models are "grown" from predefined geometric elements according to rules based on simple relationships like intersection, proximity, and occlusion which can be evaluated more quickly and easily in voxel space than with analytic geometry. Growth is probabilistic: multiple trials are attempted in which an element's position and orientation are randomly perturbed, and the trial which best fits a set of rules is selected. The term voxel space automata is introduced to describe growth processes that sense and react to a voxel environment. Applications include simulation of plant growth, for which voxel representation facilitates sensing the environment. Illumination can be effidently estimated at each plant "node" at each growth iteration by casting rays into the voxel environment , allowing accurate simulation of reaction to light including heliotropism.},
  author   = {Ned Greene},
  issue    = 3,
  journal  = {Computer Graphics},
  keywords = {CR Categories: 135 [Computer Graphics]: Computational Geometry and Object Modeling-Curve,automata,heliotropism,illumination,radiosity,solid and object representation 137 [Computer Graphics]: Three-Dimensional Graphics and Realism 16 [Simulation and Modeling]: Applications Additional Keywords and Phrases: Voxel,stochastic processes,surface},
  title    = {VOXEL SPACE AUTOMATA: MODELING WITH STOCHASTIC GROWTH PROCESSES IN VOXEL SPACE},
  volume   = 23,
  year     = 1989
}

@misc{Greuter,
  abstract = {We present an approach to procedural generation of 'pseudo infi-nite' virtual cities in real-time. The cities contain geometrically varied buildings that are generated as needed. The building generation parameters are created by a pseudo random number generator , seeded with an integer derived from the building's position. The varied building geometries are extruded from a set of floor plans. The floor plans for each building are created by combining randomly generated polygons in an iterative process. A display list caching and frustum filling approach manages the generation of buildings and the use of system resources. This approach has been implemented on commodity PC hardware, resulting in interactive frame rates.},
  author   = {Stefan Greuter and Jeremy Parker and Nigel Stewart and Geoff Leach},
  keywords = {CR Categories: I35 [Computational Geometry and Obj,E1 [Data Structures]: Lists,G3 [Probability and Statistics]: Random number gen,I37 [Three-Dimensional Graphics and Realism]: Virt,LRU caching,Trees,architecture,procedural generation,view frustum filling},
  title    = {Real-time Procedural Generation of 'Pseudo Infinite' Cities}
}

@inproceedings{Greuter2003,
  abstract  = {We present an approach to procedural generation of pseudo infinite virtual cities in real-time. The cities contain geometrically varied buildings that are generated as needed. The building generation parameters are created by a pseudo random number generator, seeded with an integer derived from the buildings position. The varied building geometries are extruded from a set of floor plans. The floor plans for each building are created by combining randomly generated polygons in an iterative process. A display list caching and frustum filling approach manages the generation of buildings and the use of system resources. This approach has been implemented on commodity PC hardware, resulting in interactive frame rates.},
  author    = {Stefan Greuter and Jeremy Parker and Nigel Stewart and Geoff Leach},
  city      = {New York, New York, USA},
  doi       = {10.1145/604487.604490},
  isbn      = 1581135785,
  booktitle = {Proceedings of the 1st international conference on Computer graphics and interactive techniques in Austalasia and South East Asia  - GRAPHITE '03},
  keywords  = {architecture,frustum filling,lru caching,procedural generation,real-time,view},
  pages     = 87,
  publisher = {ACM Press},
  title     = {Real-time procedural generation of `pseudo infinite' cities},
  url       = {http://portal.acm.org/citation.cfm?doid=604471.604490},
  year      = 2003
}

@article{Griffiths2009,
  abstract = {Aim: To investigate whether the biogeographical regions proposed by J. W. Hedgpeth and widely adopted by other authors hold true, are an oversimplification or with further data might show a unified Antarctic province. Location: Southern Hemisphere. Methods: The distributions of 1318 species of bivalves, 4656 species of gastropods, 1465 species of cheilostome and 167 species of cyclostome bryozoans were analysed for 29 regions in the Southern Hemisphere, including South American, South African, Tasmanian, New Zealand, sub-Antarctic and Antarctic regions. We present data on species richness, rates of endemism, patterns of radiation, faunal similarities and multivariate biogeographical analyses. Results: The most striking pattern to emerge from our data set of species counts per region was a strong east-west hemispheric asymmetry, with high species numbers in New Zealand, Tasmania and South Africa and low numbers in South America. In contrast, no difference was found in richness between the east and west parts of the Southern Ocean. We compared findings in our model taxa with published data on ascidians, cephalopods and pycnogonids. Further evidence of strong faunal links between the Antarctic and South America is reported in this study, although we found little evidence for a biogeographical relationship between the Antarctic or South America and New Zealand/Tasmania. Strong evidence exists for a long-term influence of the Antarctic Circumpolar Current upon the distribution of Southern Ocean benthos. This is demonstrated by the reduced prevalence of South American species in the Antarctic and sub-Antarctic with increasing distance from South America in the direction of the current. Three of our four study taxa (bivalves, cheilostomes and cyclostomes) show the Southern Ocean as a 'single functional unit' with no evidence for a biogeographical split between east and west. Main conclusions: Unlike the biogeographical schemes previously proposed, we show that biogeographical regions in the Southern Ocean differ depending upon the class of animals being considered. Despite this we suggest that some general rules are viable, including species endemism rates of around 50\%, a single Antarctic province and a definite distinction between the sub-Antarctic islands influenced by South America and those of New Zealand. \textcopyright{} 2008 British Antarctic Survey.},
  author   = {Huw J. Griffiths and David K.A. Barnes and Katrin Linse},
  doi      = {10.1111/j.1365-2699.2008.01979.x},
  issn     = {03050270},
  issue    = 1,
  journal  = {Journal of Biogeography},
  keywords = {Antarctic,Bryozoa,Continental shelf,Continental slope,Endemism,Magellanic,Mollusca,Pycnogonida,Richness,Zoogeography},
  pages    = {162--177},
  title    = {Towards a generalized biogeography of the Southern Ocean benthos},
  volume   = 36,
  year     = 2009
}

@article{Grim1997,
  abstract = {In the spatialized Prisoner's Dilemma, players compete against their immediate neighbors and adopt a neighbor's strategy should it prove locally superior. Fields of strategies evolve in the manner of cellular automata (Nowak and May, 1993; Mar and St. Denis, 1993a,b; Grim 1995, 1996). Often a question arises as to what the eventual outcome of an initial spatial configuration of strategies will be: Will a single strategy prove triumphant in the sense of progressively conquering more and more territory without opposition, or will an equilibrium of some small number of strategies emerge? Here it is shown, for finite configurations of Prisoner's Dilemma strategies embedded in a given infinite background, that such questions are formally undecidable: there is no algorithm or effective procedure which, given a specification of a finite configuration, will in all cases tell us whether that configuration will or will not result in progressive conquest by a single strategy when embedded in the given field. The proof introduces undecidability into decision theory in three steps: by (1) outlining a class of abstract machines with familiar undecidability results, by (2) modelling these machines within a particular family of cellular automata, carrying over undecidability results for these, and finally by (3) showing that spatial configurations of Prisoner's Dilemma strategies will take the form of such cellular automata.},
  author   = {Patrick Grim},
  journal  = {Theory and Decision},
  keywords = {Prisoner's Dilemma,Undecidability,cellular automata,computability,decision theory,game the-ory},
  pages    = {53--80},
  title    = {THE UNDECIDABILITY OF THE SPATIALIZED PRISONER'S DILEMMA},
  volume   = 42,
  year     = 1997
}

@article{Gros2022,
  abstract = {Human activity puts our oceans under multiple stresses, whose impacts are already significantly affecting biodiversity and physicochemical properties. Consequently, there is an increased international focus on the conservation and sustainable use of oceans, including the protection of fragile benthic biodiversity hotspots in the deep sea, identified as vulnerable marine ecosystems (VMEs). International VME risk assessment and conservation efforts are hampered because we largely do not know where VMEs are located. VME distribution modelling has increasingly been recommended to extend our knowledge beyond sparse observations. Nevertheless, the adoption of VME distribution models in spatial management planning and conservation remains limited. This work critically reviews VME distribution modelling studies, and recommends promising avenues to make VME models more relevant and impactful for policy and management decision making. First, there is an important interplay between the type of VME data used to build models and how the generated maps can be used in making management decisions, which is often ignored by model-builders. Overall, there is a need for more precise VME data for production of reliable models. We provide specific guidelines for seven common applications of VME distribution modelling to improve the matching between the modelling and the user need. Second, the current criteria to identify VME often rely on subjective thresholds, which limits the transparency, transferability and effective applicability of distribution models in protection measures. We encourage scientists towards founding their models on: (i) specific and quantitative definitions of what constitute a VME, (ii) site conservation value assessment in relation to VME multi-taxon spatial predictions, and (iii) explicitly mapping vulnerability. Along with the recent increase in both deep-sea biological and environmental data quality and quantity, these modelling recommendations can lead towards more cohesive summaries of VME's spatial distributions and their relative vulnerability, which should facilitate a more effective protection of these ecosystems, as has been mandated by numerous international agreements.},
  author   = {Charley Gros and Jan Jansen and Piers K. Dunstan and Dirk C. Welsford and Nicole A. Hill},
  doi      = {10.3389/fmars.2022.870145},
  issn     = 22967745,
  issue    = {June},
  journal  = {Frontiers in Marine Science},
  keywords = {environmental impact assessment,habitat suitability model,marine conservation,species distribution model,vulnerable marine ecosystems},
  pages    = {1--12},
  title    = {Vulnerable, but Still Poorly Known, Marine Ecosystems: How to Make Distribution Models More Relevant and Impactful for Conservation and Management of VMEs?},
  volume   = 9,
  year     = 2022
}

@article{Grosbellet2016,
  abstract = {We propose a novel approach for authoring large scenes with automatic enhancement of objects to create geometric decoration details such as snow cover, icicles, fallen leaves, grass tufts or even trash. We introduce environmental objects that extend an input object geometry with a set of procedural effects that defines how the object reacts to the environment, and by a set of scalar fields that defines the influence of the object over of the environment. The user controls the scene by modifying environmental variables, such as temperature or humidity fields. The scene definition is hierarchical: objects can be grouped and their behaviours can be set at each level of the hierarchy. Our per object definition allows us to optimize and accelerate the effects computation, which also enables us to generate large scenes with many geometric details at a very high level of detail. In our implementation, a complex urban scene of 10~000 m <sup>2</sup> , represented with details of less than 1 cm, can be locally modified and entirely regenerated in a few seconds.},
  author   = {Francois Grosbellet and Adrien Peytavie and \'{E}ric Gu\'{e}rin and \'{E}ric Galin and St\'{e}phane M\'{e}rillou and Bedrich Benes},
  doi      = {10.1111/cgf.12726},
  issn     = {0167-7055},
  issue    = 1,
  journal  = {Computer Graphics Forum},
  month    = 2,
  pages    = {296--308},
  title    = {Environmental Objects for Authoring Procedural Scenes},
  volume   = 35,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12726},
  year     = 2016
}

@article{Guan2014,
  abstract  = {Vision-based approaches have been widely applied in motion classification. However, their applicability is often limited by much higher data-loads and computational costs, particularly in the case of constrained recourses. In this paper, a compressive sensing based approach is investigated for motion classification by using pyroelectric infrared (PIR) sensors. We represent a human motion as a spatio-temporal energy sequence (STES) and extract it from an infrared radiation domain. To generate this sequence, a mask is used to divide the object space into small meshes, from which the human-motion induced variances in the infrared radiation will be used to construct a feature. Because of the sparsity of STES, a hardware prototype that is composed of a PIR sensor array and a visibility mask is designed for measuring STES compressively, and a nearest neighbor classifier is then used for classification in the compressive measurement domain. To evaluate the proposed approach, we recorded 360 compressive STESs of ten aerobic exercises performed by six persons. Encouraging experimental results validate the feasibility and efficacy of our approach. \textcopyright{} 2014 Elsevier B.V. All rights reserved.},
  author    = {Qiuju Guan and Caiyong Li and Xuemei Guo and Guoli Wang},
  doi       = {10.1016/j.patrec.2014.07.018},
  issn      = {01678655},
  journal   = {Pattern Recognition Letters},
  keywords  = {Compressive sensing,Human behavior understanding,Motion classification,Pyroelectric infrared sensors},
  month     = 11,
  pages     = {231--237},
  publisher = {Elsevier},
  title     = {Compressive classification of human motion using pyroelectric infrared sensors},
  volume    = 49,
  year      = 2014
}

@article{Guerin2012,
  author = {\'{E}ric Gu\'{e}rin},
  title  = {Mod\'{e}lisation de terrains virtuels Sp\'{e}cialit\'{e}},
  url    = {https://hal.archives-ouvertes.fr/tel-01635126/file/HDR-EricGuerin-Finale.pdf},
  year   = 2012
}

@article{Guerin2016,
  abstract = {<p>Digital landscape realism often comes from the multitude of details that are hard to model such as fallen leaves, rock piles or entangled fallen branches. In this article, we present a method for augmenting natural scenes with a huge amount of details such as grass tufts, stones, leaves or twigs. Our approach takes advantage of the observation that those details can be approximated by replications of a few similar objects and therefore relies on mass-instancing. We propose an original structure, the Ghost Tile, that stores a huge number of overlapping candidate objects in a tile, along with a pre-computed collision graph. Details are created by traversing the scene with the Ghost Tile and generating instances according to user-defined density fields that allow to sculpt layers and piles of entangled objects while providing control over their density and distribution.</p>},
  author   = {Eric Gu\'{e}rin and Eric Galin and Fran\c{c}ois Grosbellet and Adrien Peytavie and Jean-David G\'{e}nevaux},
  doi      = {10.1111/cgf.13023},
  issn     = {0167-7055},
  issue    = 7,
  journal  = {Computer Graphics Forum},
  month    = 10,
  pages    = {257--267},
  title    = {Efficient modeling of entangled details for natural scenes},
  volume   = 35,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13023},
  year     = 2016
}

@article{Guerin2016a,
  abstract = {In this paper, we present a simple and efficient method to represent terrains as elevation functions built from linear combinations of landform features (atoms). These features can be extracted either from real world data-sets or procedural primitives, or from any combination of multiple terrain models. Our approach consists in representing the elevation function as a sparse combination of primitives, a concept which we call Sparse Construction Tree, which blends the different landform features stored in a dictionary. The sparse representation allows us to represent complex terrains using combinations of atoms from a small dictionary, yielding a powerful and compact terrain representation and synthesis tool. Moreover, we present a method for automatically learning the dictionary and generating the Sparse Construction Tree model. We demonstrate the efficiency of our method in several applications: inverse procedural modeling of terrains, terrain amplification and synthesis from a coarse sketch.},
  author   = {\'{E}ric Gu\'{e}rin and Julie Digne and \'{E}ric Galin and Adrien Peytavie},
  doi      = {10.1111/cgf.12821},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  pages    = {177--187},
  title    = {Sparse representation of terrains for procedural modeling},
  volume   = 35,
  year     = 2016
}

@article{Guerin2017,
  abstract = {Authoring virtual terrains presents a challenge and there is a strong need for authoring tools able to create realistic terrains with simple user-inputs and with high user control. We propose an example-based authoring pipeline that uses a set of terrain synthesizers dedicated to specific tasks. Each terrain synthesizer is a Conditional Generative Adversarial Network trained by using real-world terrains and their sketched counterparts. The training sets are built automatically with a view that the terrain synthesizers learn the generation from features that are easy to sketch. During the authoring process, the artist first creates a rough sketch of the main terrain features, such as rivers, valleys and ridges, and the algorithm automatically synthesizes a terrain corresponding to the sketch using the learned features of the training samples. Moreover, an erosion synthesizer can also generate terrain evolution by erosion at a very low computational cost. Our framework allows for an easy terrain authoring and provides a high level of realism for a minimum sketch cost. We show various examples of terrain synthesis created by experienced as well as inexperienced users who are able to design a vast variety of complex terrains in a very short time.},
  author   = {\'{E}ric Gu\'{e}rin and Julie Digne and \'{E}ric Galin and Adrien Peytavie and Christian Wolf and Bed\v{r}ich Bene\v{s} and Beno\^{\i}t Martinez},
  doi      = {10.1145/3130800.3130804},
  issn     = 15577368,
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {Deep Learning,Procedural modeling,Terrain generation},
  title    = {Interactive example-based terrain authoring with conditional generative adversarial networks},
  volume   = 36,
  year     = 2017
}

@article{Guerin2022,
  abstract = {<p>Digital terrains are a foundational element in the computer-generated depiction of natural scenes. Given the variety and complexity of real-world landforms, there is a need for authoring solutions that achieve perceptually realistic outcomes without sacrificing artistic control. In this paper, we propose setting aside the elevation domain in favour of modelling in the gradient domain. Such a slope-based representation is height independent and allows a seamless blending of disparate landforms from procedural, simulation, and real-world sources. For output, an elevation model can always be recovered using Poisson reconstruction, which can include Dirichlet conditions to constrain the elevation of points and curves.</p>},
  author   = {Eric Gu\'{e}rin and Adrien Peytavie and Simon Masnou and Julie Digne and Basile Sauvage and James Gain and Eric Galin},
  doi      = {10.1111/cgf.14460},
  issn     = {0167-7055},
  issue    = 2,
  journal  = {Computer Graphics Forum},
  month    = 5,
  pages    = {85--95},
  title    = {Gradient Terrain Authoring},
  volume   = 41,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.14460},
  year     = 2022
}

@article{Guerrero2022,
  abstract  = {Procedural material graphs are a compact, parameteric, and resolution-independent representation that are a popular choice for material authoring. However, designing procedural materials requires significant expertise and publicly accessible libraries contain only a few thousand such graphs. We present MatFormer, a generative model that can produce a diverse set of high-quality procedural materials with complex spatial patterns and appearance. While procedural materials can be modeled as directed (operation) graphs, they contain arbitrary numbers of heterogeneous nodes with unstructured, often long-range node connections, and functional constraints on node parameters and connections. MatFormer addresses these challenges with a multi-stage transformer-based model that sequentially generates nodes, node parameters, and edges, while ensuring the semantic validity of the graph. In addition to generation, MatFormer can be used for the auto-completion and exploration of partial material graphs. We qualitatively and quantitatively demonstrate that our method outperforms alternative approaches, in both generated graph and material quality.},
  author    = {Paul Guerrero and Milo\v{s} Ha\v{s}an and Kalyan Sunkavalli and Radom\'{\i}r Mech and Tamy Boubekeur and Niloy J. Mitra},
  doi       = {10.1145/3528223.3530173},
  issn      = 15577368,
  issue     = 4,
  journal   = {ACM Transactions on Graphics},
  keywords  = {Generative models,Node graphs,Procedural materials,Transformers},
  publisher = {Association for Computing Machinery},
  title     = {MatFormer: A Generative Model for Procedural Materials},
  volume    = 41,
  url       = {https://arxiv.org/pdf/2207.01044.pdf},
  year      = 2022
}

@misc{Guilcher1965,
  author      = {Andr\'{e} Guilcher and L\'{e}opold Berthois and Yolande Le Calvez and Ren\'{e} Battistini and Alain Crosnier},
  city        = {Paris},
  institution = {Office de la Recherche Scientifique et Technique Outre-Mer},
  title       = {Les r\'{e}cifs coralliens et le lagon de l'\^{\i}le de Mayotte},
  url         = {https://horizon.documentation.ird.fr/exl-doc/pleins\_textes/pleins\_textes\_2/memoires/10967.pdf},
  year        = 1965
}

@article{Guillen2008,
  abstract = {The analysis of multiple data sets is required to select a realistic 3D geological model among an infinite number of possibilities. An inverse method that aims at describing the 3D geometry of geological objects is presented. The method takes into account the geology and the physical properties of rocks, while respecting the topological properties of an a priori model. The a priori model is built from the geological data set and its geometry is largely dependent upon assumptions about inaccessible geology at depth. This method, referred to as "total litho-inversion" is a generalised 3D inversion that results in quantifying the lithology and the distribution of rock property in a probabilistic way. Its application is demonstrated through (i) a simple synthetic case and (ii) the relative distribution characterization of granites and diorites in an orogenic domain. \textcopyright{} 2008 Elsevier B.V. All rights reserved.},
  author   = {A. Guillen and Ph Calcagno and G. Courrioux and A. Joly and P. Ledru},
  doi      = {10.1016/j.pepi.2008.06.014},
  issn     = {00319201},
  issue    = {1-4},
  journal  = {Physics of the Earth and Planetary Interiors},
  keywords = {3D geology,Gravity,Inverse problem,Magnetism,Metropolis,Potential field,Probability,Tensors},
  pages    = {158--169},
  title    = {Geological modelling from field data and geological knowledge. Part II. Modelling validation using gravity and magnetic data inversion},
  volume   = 171,
  url      = {https://hal.archives-ouvertes.fr/hal-00532156/document},
  year     = 2008
}

@article{Gumusay2019,
  abstract  = {Seagrass meadows are key elements of marine ecosystems as they affect the physical, chemical and biological environment and provide habitats for fish and invertebrates. Human activities have caused a deterioration in seagrass which has led to unstable benthic habitats; therefore, to prevent major decline, seagrass distribution must be mapped and monitored. Acoustic systems allow researchers, scientists and decision makers to collect high-resolution datasets such as bathymetry, backscatter and sub-bottom profiles. These systems are able to characterise the properties of the seafloor including plants, sediments and habitats. In this review, we examine seagrass mapping, monitoring and detection applications using acoustic systems in the literature. Although there are various methodologies for data collection, processing, classification and validation, these are limited to certain seagrass species or study areas. Further worldwide research is required to achieve consistent seagrass detection systems with data acquisition, pre-processing, classification and post-processing.},
  author    = {Mustafa Umit Gumusay and Tolga Bakirman and Inci Tuney Kizilkaya and Nedim Onur Aykut},
  doi       = {10.1080/22797254.2018.1544838},
  issn      = 22797254,
  issue     = 1,
  journal   = {European Journal of Remote Sensing},
  keywords  = {Seagrass,acoustics,backscatter,bathymetry,detection,mapping,monitoring},
  pages     = {1--29},
  publisher = {Taylor \& Francis},
  title     = {A review of seagrass detection, mapping and monitoring applications using acoustic systems},
  volume    = 52,
  url       = {https://doi.org/10.1080/22797254.2018.1544838},
  year      = 2019
}

@article{Guzdial2016,
  abstract = {We present an approach to generate novel computer game levels that blend different game concepts in an unsupervised fashion. Our primary contribution is an analogical reasoning process to construct blends between level design models learned from gameplay videos. The models represent probabilistic relationships between elements in the game. An analogical reasoning process maps features between two models to produce blended models that can then generate new level chunks. As a proof-of-concept we train our system on the classic platformer game Super Mario Bros. due to its highly-regarded and well understood level design. We evaluate the extent to which the models represent stylistic level design knowledge and demonstrate the ability of our system to explain levels that were blended by human expert designers.},
  author   = {Matthew Guzdial and Mark Riedl},
  isbn     = 9782746691551,
  journal  = {Proceedings of the 7th International Conference on Computational Creativity, ICCC 2016},
  pages    = {354--361},
  title    = {Learning to blend computer game levels},
  url      = {https://arxiv.org/pdf/1603.02738.pdf},
  year     = 2016
}

@article{Hachette2022,
  abstract  = {The implicit skinning is a geometric interactive skinning method, for skeleton-based animations, enabling plausible deformations at joints while resolving skin self-collisions. Even though requiring a few user interactions to be adequately parameterized, some efforts have to be spent on the edition of the shapes at joints In this research, we introduce a dedicated optimization framework for automatically adjusting the shape of the surfaces generating the deformations at joints when they are rotated during an animation. This approach directly fits in the implicit skinning pipeline and it has no impact on the algorithm performance during animation. Starting from the mesh partition of the mesh representing the animated character, we propose a dedicated hole filling algorithm based on a particle system and a power crust meshing. We then introduce a procedure optimizing the shape of the filled mesh when it rotates at the joint level. This automatically generates plausible skin deformation when joints are rotated without the need of extra user editing.},
  author    = {Olivier Hachette and Florian Canezin and Rodolphe Vaillant and Nicolas Mellado and Lo\"{\i}c Barthe},
  doi       = {10.1016/j.cag.2021.10.018},
  issn      = {00978493},
  journal   = {Computers and Graphics (Pergamon)},
  keywords  = {Geometric modeling,Shape deformation,Skinning},
  pages     = {300--308},
  publisher = {Elsevier Ltd.},
  title     = {Automatic shape adjustment at joints for the implicit skinning},
  volume    = 102,
  url       = {https://doi.org/10.1016/j.cag.2021.10.018},
  year      = 2022
}

@article{Haetinger2020,
  abstract = {We present a novel approach for image deformation and video time warping. Our technique involves the inversion of the nonlinear regularized Kelvinlet equations, leading to higher quality results and time/space efficiency compared to naive solutions. Inversion is performed by a per-pixel optimization process, being inherently parallel and achieving real-time performance in Full HD videos (over 300 fps). We demonstrate our method on a variety of images and videos, in addition to discussing some important technical and theoretical details.},
  author   = {Guilherme G. Haetinger and Eduardo S.L. Gastal},
  doi      = {10.1109/SIBGRAPI51738.2020.00025},
  isbn     = 9781728192741,
  journal  = {Proceedings - 2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images, SIBGRAPI 2020},
  keywords = {image and video processing,image warping,interpolation,time warp,video retiming},
  pages    = {124--131},
  title    = {Regularized Kelvinlet Inversion for Real-Time Image Deformation and Video Time Warping},
  year     = 2020
}

@article{Hahne2016,
  abstract  = {\textcopyright{} 2016 Optical Society of America. Recent developments in computational photography enabled variation of the optical focus of a plenoptic camera after image exposure, also known as refocusing. Existing ray models in the field simplify the camera's complexity for the purpose of image and depth map enhancement, but fail to satisfyingly predict the distance to which a photograph is refocused. By treating a pair of light rays as a system of linear functions, it will be shown in this paper that its solution yields an intersection indicating the distance to a refocused object plane. Experimental work is conducted with different lenses and focus settings while comparing distance estimates with a stack of refocused photographs for which a blur metric has been devised. Quantitative assessments over a 24 m distance range suggest that predictions deviate by less than 0.35 \% in comparison to an optical design software. The proposed refocusing estimator assists in predicting object distances just as in the prototyping stage of plenoptic cameras and will be an essential feature in applications demanding high precision in synthetic focus or where depth map recovery is done by analyzing a stack of refocused photographs.},
  author    = {Christopher Hahne and Amar Aggoun and Vladan Velisavljevic and Susanne Fiebig and Matthias Pesch},
  doi       = {10.1364/oe.24.021521},
  issn      = {1094-4087},
  issue     = 19,
  journal   = {Optics Express},
  keywords  = {(1101758) Computational imaging,(1103010) Image reconstruction techniques,(1105200) Photography,OCIS codes: (0803620) Lens system design},
  month     = 9,
  pages     = 21521,
  publisher = {The Optical Society},
  title     = {Refocusing distance of a standard plenoptic camera},
  volume    = 24,
  url       = {http://www.trioptics.com/knowledge-base/mtf-and-image-quality/.23.C.Hahne,\%22Zemaxarchivefilecontainingplenopticcameradesign,\%22figsharehttp://dx.doi.org/10.6084/m9.figshare.3381082.http://dx.doi.org/10.6084/m9.figshare.3362152.},
  year      = 2016
}

@inbook{Halbwachs2000,
  author = {Yvon Halbwachs and \O{}yvind Hjelle},
  doi    = {10.1007/978-3-642-57172-5\_11},
  pages  = {339--356},
  title  = {Generalized Maps in Geological Modeling: Object-Oriented Design of Topological Kernels},
  url    = {http://link.springer.com/10.1007/978-3-642-57172-5\_11},
  year   = 2000
}

@article{Hallock1997,
  abstract = {To seafarers, a reef is a submerged hazard to navigation, usually a ridge of rocks or sand at or near the surface of the water. This is why the Exxon Valdez could hit a "reef" in Prince William Sound, Alaska, thousands of miles from the nearest coral reef. Historically, tropical waters were particularly treacherous for mariners because reefs constructed by coral communities may lurk just below the surface in otherwise open seas. In both calm seas and storms, often the first indication that a reef was nearby was when a ship ran aground. The earliest European "settlers" in the Florida Keys made their living salvaging shipwrecks. Today the most visible indication of many Pacific atolls is a rusting freighter.},
  author   = {Pamela Hallock},
  doi      = {10.1007/978-1-4615-5995-5\_2},
  journal  = {Life and Death of Coral Reefs},
  pages    = {13--42},
  title    = {Reefs and Reef Limestones in Earth History},
  url      = {https://www.marine.usf.edu/reefslab/documents/evol\_ecol2007/Hallock\_Reefhistory.pdf},
  year     = 1997
}

@article{Hanan1992,
  abstract = {In this dissertation, parametric L-systems are presented as the foundation of a computer graphics tool for simulating and visualizing the development of plants. L-systems were introduced in 1968 by Aristid Lindenmayer as a mathematical model of multicellular organisms. They employ a parallel string-rewriting mechanism to describe the development of branching structures. The resulting strings can be interpreted geometrically and visualized using computer graphics techniques to create both realistic and schematic images of the modelled structures. The formalism can be applied for a variety of scientific, educational, and commercial purposes. Parametric L-systems extend the original concept of L-systems by associating numerical parameters with the symbols representing plant components. This allows easy quantification of geometric attributes of a model, and provides a simple means for the expression of continuous processes, such as diffusion of hormones and the resulting distribution of concentrations. Formal definitions are proposed for context- free and context-sensitive parametric L-systems with either deterministic or stochastic application of production rules. The practical value of parametric L-systems is demonstrated in this dissertation by examples that include models of plants ranging from algae to trees. Model de- velopment is controlled by lineage mechanisms, with information passed from parent to child module. This mechanism is combined in some models with endogenous in- teraction, where information flows through a growing structure. Selected models are suitable for simulating time-lapse photography through computer animation. Extensions to the formalism of parametric L-systems incorporate useful features of other programming languages and provide techniques for creating hierarchical models.},
  author   = {James Scott Hanan},
  isbn     = {0-315-83871-X},
  pages    = 178,
  title    = {Parametric L-systems and their Application to the Modelling and Visualization of Plants},
  url      = {http://algorithmicbotany.org/papers/hanan.dis1992.pdf},
  year     = 1992
}

@article{Hapke2005,
  abstract = {High-resolution historical (1942) and recent (1994) digital terrain models were derived from aerial photographs along the Big Sur coastline in central California to measure the long-term volume of material that enters the nearshore environment. During the 52-year measurement time period, an average of 21 000 \pm{} 3100 m3 km-1 a-1 of material was eroded from nine study sections distributed along the coast, with a low yield of 1000 \pm{} 240 m3 km-1 a-1 and a high of 46 700 \pm{} 7300 m3 km-1 a-1. The results compare well with known volumes from several deep-seated landslides in the area and suggest that the processes by which material is delivered to the coast are episodic in nature. In addition, a number of parameters are investigated to determine what influences the substantial variation in yield along the coast. It is found that the magnitude of regional coastal landslide sediment yield is primarily related to the physical strength of the slope-forming material. Coastal Highway 1 runs along the lower portion of the slope along this stretch of coastline, and winter storms frequently damage the highway. The California Department of Transportation is responsible for maintaining this scenic highway while minimizing the impacts to the coastal ecosystems that are part of the Monterey Bay National Marine Sanctuary. This study provides environmental managers with critical background data on the volumes of material that historically enter the nearshore from landslides, as well as demonstrating the application of deriving historical digital terrain data to model landscape evolution. Published in 2005 by John Wiley \& Sons, Ltd.},
  author   = {C. J. Hapke},
  doi      = {10.1002/esp.1168},
  issn     = {01979337},
  issue    = 6,
  journal  = {Earth Surface Processes and Landforms},
  keywords = {Big Sur,Coastal landslides,Digital terrain models,Marine sanctuary,Material yield,Photogrammetry,Rock strength},
  pages    = {679--697},
  title    = {Estimation of regional material yield from coastal landslides based on historical digital terrain modelling},
  volume   = 30,
  year     = 2005
}

@article{Harman2003,
  abstract = {Differences in the diversity of fish species between granite and limestone reefs, as well as high- and low-relief limestone reefs, were investigated at Hamelin Bay, south-western Australia. It was found that there were significant differences in the presence and abundance of fish species between granite reefs and limestone reefs. Granite reefs were characterized by greater numbers of Coris auricularis (western king wrasse) and Parma mccullochi (common scalyfin), whereas limestone reefs had greater numbers of the fish species Odax cyanomelas (herring cale), Pempheris klunzingeri (rough bullseye) and Kyphosus sydneyanus (common buffalo bream). A significant difference in fish diversity was also found between high-relief and low-relief limestone reefs in the same area. More species were found on the high-relief reefs than low-relief reefs. Complementing differences in fish assemblages, significant differences were found in algal assemblages from the different habitats. This was mainly owing to a dominance of Ecklonia radiata on low-relief limestone reefs. Ecklonia radiata was less dominant on granite reefs and on high-relief limestone reefs, where there was a lower overall algal biomass and a higher total number of species.},
  author   = {Nicole Harman and Euan S. Harvey and Gary A. Kendrick},
  doi      = {10.1071/MF02040},
  issn     = 13231650,
  issue    = 2,
  journal  = {Marine and Freshwater Research},
  keywords = {Fish diversity,Habitat,Marine protected areas,Substrate complexity},
  pages    = {177--184},
  title    = {Differences in fish assemblages from different reef habitats at Hamelin Bay, south-western Australia},
  volume   = 54,
  year     = 2003
}

@book{Harmon2001,
  abstract  = {In this interdisciplinary review of the latest in modeling of soil erosion and landscape evolution based on 1999 workshops, 17 contributed chapters by international experts unearth the complex natural processes impacted by land use. Such models serve as the basis for decision support systems for public land managers, with the accent here on issues facing the US Army's Land Management System (LMS). Harmon (Army Research Laboratory, Research Triangle Park, NC) and Doe (Center for Environmental Management of Military Land, Colorado State U., Fort Collins) provide context for soil erosion processes, best management practices, modeling approaches, and linking models to reality. The final section treats model successes, limitations, and future LMS directions. Annotation copyrighted by Book News Inc., Portland, OR. Introduction to Soil Erosion and Landscape Evolution Modeling -- Soil Erosion Management and Model Development -- Soil Erosion Processes -- Models and Modeling Approaches -- Linking Reality and Modeling -- Erosion Problems on U.S. Army Training Lands -- Regulatory Controls -- Plant Material Development and Use on Military Lands -- Physical Erosion and Sediment Controls -- Applying Science in Erosion and Sediment Control -- Effects of Freeze-Thaw Cycling on Soil Erosion -- Effects of Soil Freeze-Thaw Cycling -- Future Research Needs -- Determination of Slope Displacement Mechanisms and Causes -- Bluff Geometry and Stratigraphy -- Ground Water Conditions -- Soil Characteristics -- Slope Displacement Monitoring Methods -- Displacement Models -- Causes of Displacement -- Processes of Bluff Failure -- Limit Equilibrium Analyses -- Using Cosmogenic Nuclide Measurements in Sediments to Understand Background Rates of Erosion and Sediment Transport -- Methods -- Cosmogenic Nuclide Systematics and Interpretative Models -- Implications Of Sediment Cosmogenic Nuclide Measurements -- Erosion Modeling -- Empirical Models -- Process-Based Models -- Model Testing -- Model Validation -- Model Application -- The Water Erosion Prediction Project (WEPP) Model -- WEPP Model Development History -- WEPP Hillslope Model Component -- WEPP Model Watershed Component -- Model Validation Study Results -- Data and Model Uncertainty: Impacts on Model Evaluation and Application -- WEPP Model Status and Current Activities.},
  author    = {R. S. (Russell S.) Harmon and William W. Doe},
  isbn      = {0306467186},
  pages     = 540,
  publisher = {Kluwer Academic/Plenum Publishers},
  title     = {Landscape erosion and evolution modeling},
  year      = 2001
}

@misc{Harris,
  abstract = {Harris GF, Wertsch JJ. Procedures for gait analysis. Arch Phys Med Rehabil 1994;75:216-25. l Observational gait analysis is clinically useful with videotape slow-motion replay and freeze-frame, offering significant improvement over unaided visual observation. Any form of observational gait analysis, however, has limited precision and is more descriptive than quantitative. This article reviews procedures that are available for gait analysis. Gait analysis systems have evolved from tine with manual digitization, electrogoniometry, and video technology to sophisticated automated tracking systems. When used in conjunction with biomechanical models, these systems allow quantitative analysis of many specific gait characteristics such as joint moments and powers (kinetic analysis), joint angles, angular velocities, and angular accelerations (kinematic analysis). Analysis of dynamic electromyographic activity and energy consumption adds useful clinical information to gait analysis. The combination of a careful clinical assessment and gait analysis can be a powerful tool for the clinician. 0 1993 by the American Congress qf Rehabilitation Medicine and the American Academy of Physical Medicine and Rehabilitation Gait analysis-the systematic analysis of locomotion-is},
  author   = {Gerald F. Harris and Jacqueline J. Wertsch},
  title    = {Procedures for Gait Analysis}
}

@unpublished{Hartley2022,
  author = {Marc Hartley and Christophe Fiorio and Nicolas Mellado and Noura Faraj},
  pages  = {1--6},
  title  = {Algorithmes d'\'{e}rosion pour la g\'{e}n\'{e}ration de terrains 3D},
  year   = 2022
}

@inproceedings{Hartley2023,
  author    = {Marc Hartley and Noura Faraj and Nicolas Mellado and Christophe Fiorio},
  booktitle = {SMI},
  title     = {Flexible Terrain Erosion : A Fluid Simulation-Independent Approach for 3D Terrain Procedural Generation Compatible with Multiple Representations},
  year      = 2023
}

@article{Hartley2024,
  abstract  = {In this paper, we present a novel particle-based method for simulating erosion on various terrain representations, including height fields, voxel grids, material layers, and implicit terrains. Our approach breaks down erosion into two key processes--terrain alteration and material transport--allowing for flexibility in simulation. We utilize independent particles governed by basic particle physics principles, enabling efficient parallel computation. For increased precision, a vector field can adjust particle speed, adaptable for realistic fluid simulations or user-defined control. We address material alteration in 3D terrains with a set of equations applicable across diverse models, requiring only per-particle specifications for size, density, coefficient of restitution, and sediment capacity. Our modular algorithm is versatile for real-time and offline use, suitable for both 2.5D and 3D terrains.},
  author    = {Marc Hartley and Nicolas Mellado and Christophe Fiorio and Noura Faraj},
  doi       = {10.1007/s00371-024-03444-w},
  issn      = {01782789},
  journal   = {Visual Computer},
  keywords  = {Erosion processes,Natural phenomena,Procedural modeling,Terrain morphing},
  month     = 7,
  publisher = {Springer Science and Business Media Deutschland GmbH},
  title     = {Flexible terrain erosion},
  year      = 2024
}

@article{Hatanaka2016,
  abstract  = {Background: Although changes to gait are an important clinical feature of progressive supranuclear palsy (PSP), systematic analyses have not been well examined, especially in comparison to Parkinson's disease (PD). Methods: The characteristics of gait in 20 PSP patients (14 males and 6 females) were evaluated in comparison to 124 PD patients (64 males and 60 females) and 24 controls, that is, healthy age-matched adults (5 males and 19 females). Gait in patients was recorded in a 10-m walking test at a self-selected speed. During this time, patients felt most comfortable while wearing a new portable triaxial accelerometer rhythmogram device. Gait variables among the 3 groups were compared. Results: Both PSP and PD patients shared the following similar hypokinetic gait characteristics: decreased velocity, step length, cadence and mean acceleration. Step time and variability in step time were mutually related. However, among the 3 groups, PSP patients showed characteristically low vertical displacement and a higher acceleration than PD patients at the same cadence. Conclusion: Although PSP and PD patients showed similar hypokinetic gait, a reduced vertical displacement characterized walking in PSP patients, differing substantially from the characteristics of walking displayed by PD patients.},
  author    = {Noriko Hatanaka and Kota Sato and Nozomi Hishikawa and Mami Takemoto and Yasuyuki Ohta and Toru Yamashita and Koji Abe},
  doi       = {10.1159/000445111},
  issn      = 14219913,
  issue     = {5-6},
  journal   = {European Neurology},
  keywords  = {Acceleration,Gait,Parkinson's disease,Progressive supranuclear palsy,Vertical displacement},
  month     = 7,
  pages     = {282--289},
  pmid      = 27288001,
  publisher = {S. Karger AG},
  title     = {Comparative Gait Analysis in Progressive Supranuclear Palsy and Parkinson's Disease},
  volume    = 75,
  url       = {https://www.karger.com/Article/FullText/445111 https://www.karger.com/Article/Abstract/445111},
  year      = 2016
}

@article{Hawick2014,
  abstract = {Coastal flooding and associated land erosion are important environmental issues that are difficult to model for large scale systems. Cellular automaton models are attractive as computational simple and inexpensive individual cell calculations can be scaled up to model relatively large area models. We explore combinations of diffusional and injective cellular automaton models for water/land incursion and erosion problems. The Kawasaki site exchange automaton and the Invasion Percolation models form the basis of our hybrid automaton model. We explore some quantitative statistical metrics and discuss development directions of a hybrid model that supports both steady erosion as well as rapid water incursion and soil/land removal.},
  author   = {Ken A. Hawick},
  doi      = {10.2316/P.2014.821-005},
  journal  = {Proceedings of the IASTED International Conference on Environmental Management and Engineering, EME 2014},
  keywords = {Beach area transport,Complex systems,Emergence,Flooding,Soil erosion,Water incursion},
  pages    = {158--165},
  title    = {Modelling flood incursion and coastal erosion using cellular automata simulations},
  year     = 2014
}

@article{He,
  abstract = {This paper presents the details of the flux-ordered thinning algorithm, which we refer to as the Hamilton-Jacobi Skeleton (HJS). It computes the skeleton of any binary 2D shape. It is based on the observation that the skeleton points have low average outward flux of the gradient of the distance transform. The algorithm starts by computing the distance function and approximating the flux values for all pixels inside the shape. Then a procedure called homotopy preserving thinning iteratively removes points with high flux while preserving the homotopy of the shape. In this paper, we implement the distance transform using a fast sweeping algorithm. We present numerical experiments to show the performance of HJS applied to various shapes. We point out that HJS serves as a multi-scale shape representation, a homotopy classifier, and a deficiency detector for binary 2D shapes. We also quantitatively evaluate the shape reconstructed from the medial axis obtained by HJS. Source Code The reviewed source code and documentation for this algorithm are available at the web page of this article 1. See the README.txt file for usage instructions in the archive.},
  author   = {Yuchen He and Sung Ha Kang and Luis \'{A}lvarez},
  doi      = {10.5201/ipol.2021.296},
  issn     = {2105-1232},
  journal  = {Image Processing On Line},
  keywords = {2D shape,distance transform,skeleton,thinning algorithm},
  month    = 2,
  pages    = {18--36},
  title    = {Finding the Skeleton of 2D Shape and Contours: Implementation of Hamilton-Jacobi Skeleton},
  volume   = 11,
  url      = {https://www.ipol.im/pub/art/2021/296/?utm\_source=doi},
  year     = 2021
}

@article{He2007,
  abstract = {MEOW is a biogeographic classification of the world's coasts and shelves. It is the first ever comprehensive marine classification system with clearly defined boundaries and definitions and was developed to closely link to existing regional systems. The ecoregions nest within the broader biogeographic tiers of Realms and Provinces. See the maps.},
  author   = {Fox He and Allen Gr and Lourie Sa and Martin Kd},
  journal  = {World},
  pages    = {1--6},
  title    = {Marine Ecoregions of the World},
  url      = {https://www.conservationgateway.org/ConservationPractices/Marine/Documents/Spalding et al MEOW.pdf},
  year     = 2007
}

@article{Helbostad2003,
  abstract  = {The aim of this paper was to investigate the effect of speed dependency on lateral gait parameters. In 36 healthy elderly (mean age=72.5 years, S.D.=3.2 years), walking at four different self-administered speeds, mediolateral trunk acceleration and step width (SW), but not step-width variability (SWV), were found to have quadratic relations to gait speed. Normalizing for speed by curvilinear interpolation, and controlling for subject characteristics, disclosed smaller SW (adjusted R2=0.41, P<0.001), but larger SWV (adjusted R2=0.26, P=0.01) with increasing age in multiple regression models. These relations were camouflaged at preferred speed. \textcopyright{} 2002 Elsevier Science B.V. All rights reserved.},
  author    = {Jorunn L. Helbostad and Rolf Moe-Nilssen},
  doi       = {10.1016/S0966-6362(02)00197-2},
  issn      = {09666362},
  issue     = 2,
  journal   = {Gait and Posture},
  keywords  = {Gait speed,Healthy elderly,Lateral balance control,Mediolateral trunk acceleration,Step width,Step-width variability},
  month     = 10,
  pages     = {27--36},
  pmid      = 14654205,
  publisher = {Elsevier},
  title     = {The effect of gait speed on lateral balance control during walking in healthy elderly},
  volume    = 18,
  year      = 2003
}

@article{Henry2014,
  author    = {Joseph Henry and Hubert P. H. Shum and Taku Komura},
  doi       = {10.1109/TVCG.2013.116},
  issn      = {1077-2626},
  issue     = 2,
  journal   = {IEEE Transactions on Visualization and Computer Graphics},
  month     = 2,
  pages     = {211--222},
  publisher = {IEEE},
  title     = {Interactive Formation Control in Complex Environments},
  volume    = 20,
  url       = {http://ieeexplore.ieee.org/document/6582419/},
  year      = 2014
}

@article{Heppell2012,
  abstract  = {Many spawning aggregations of marine fishes have been fished beyond the point of sustainability, leading to increased calls for protection through seasonal and/or site-specific fishery closures. Once a closure has been put in place, monitoring the aggregation is imperative in order to learn whether protection leads to the recovery of the population. Current methods for monitoring the status of spawning aggregations rely largely on counts, either subsample or census, usually combined with capturing a subset of the fish to assess individual traits such as length and weight. Handling fish during the spawning aggregation can be stressful for the fish, and can ultimately lead to decreased spawning success, increased susceptibility to predators, or increased mortality through capture trauma or infection. Here we present a novel analysis for monitoring fish on a spawning aggregation that does not require the capture and handling of fish. Following a recovering aggregation of Nassau grouper (. Epinephelus striatus) over seven spawning seasons, we show that length-distribution data can be collected by divers using a video-based system with parallel lasers calibrated to a specific distance apart, and subsequently use those data to monitor changes in the size distribution over time. We detected recruitment of new fish to the grouper spawning aggregation in the fourth year of monitoring. In addition to tracking size distribution trends over time, the length distribution information could be combined with an established length-weight regression and an estimate of total abundance to estimate spawning stock biomass. We qualitatively cross-validate this method with census data to evaluate its effectiveness in monitoring the recovery or decline of aggregating species that can be visually observed. \textcopyright{} 2012 Elsevier Ltd.},
  author    = {Scott A. Heppell and Brice X. Semmens and Stephanie K. Archer and Christy V. Pattengill-Semmens and Philippe G. Bush and Croy M. McCoy and Selina S. Heppell and Bradley C. Johnson},
  doi       = {10.1016/j.biocon.2012.06.002},
  issn      = {00063207},
  journal   = {Biological Conservation},
  keywords  = {Length analysis,Length distribution,Marine protected area,Monitoring,Nassau grouper,Population recovery,Spawning aggregation},
  pages     = {119--127},
  publisher = {Elsevier Ltd},
  title     = {Documenting recovery of a spawning aggregation through size frequency analysis from underwater laser calipers measurements},
  volume    = 155,
  url       = {http://dx.doi.org/10.1016/j.biocon.2012.06.002},
  year      = 2012
}

@article{HIMANN1988,
  abstract = {Self-paced walking was used as a measure of the neuromuscular slowing observed with aging. The effects of age on the choice of speed of walking, stride length, and step frequency were described for 289 males and 149 females aged 19 to 102 yr. These subjects were asked to walk at three self-selected paces (slow, normal, and fast) over an 80-m indoor course. Sixty-two years coincided with an accelerated decline in speed of walking. Before 62 yr, there was a 1 to 2\% per decade decline in normal walking speed. After 63 yr, females showed a 12.4\% per decade decrease and males showed a 16-1\% per decade decrease. The eldest group (63 yr and older) had a significantly slower speed of walking and smaller step length than the younger groups (19 to 39 and 40 to 62 yr) for all paces. Heart rate at the three paces was not changed across age. In a multiple regression analysis, the only significant independent variable for walking speed at all three paces was (age)3, which accounted for 19 to 38\% of the variance. When the population was divided into two age ranges (19 to 62 and 63 to 102 yr), walking speed was associated with height before 62 yr and with height and age after 62 yr. \textcopyright{} 1989 by the American College of Sports Medicine.},
  author   = {Joan E. Himann and David A. Cunningham and Peter A. Rechnitzer and Donald H. Paterson},
  doi      = {10.1249/00005768-198820020-00010},
  issn     = {0195-9131},
  issue    = 2,
  journal  = {Medicine \& Science in Sports \& Exercise},
  keywords = {Fitness in elderly,Self-paced walking},
  month    = 4,
  pages    = {161--166},
  title    = {Age-related changes in speed of walking},
  volume   = 20,
  url      = {http://journals.lww.com/00005768-198820020-00010},
  year     = 1988
}

@article{Hnaidi2010,
  abstract = {<p>This paper presents a diffusion method for generating terrains from a set of parameterized curves that characterize the landform features such as ridge lines, riverbeds or cliffs. Our approach provides the user with an intuitive vector-based feature-oriented control over the terrain. Different types of constraints (such as elevation, slope angle and roughness) can be attached to the curves so as to define the shape of the terrain. The terrain is generated from the curve representation by using an efficient multigrid diffusion algorithm. The algorithm can be efficiently implemented on the GPU, which allows the user to interactively create a vast variety of landscapes.</p>},
  author   = {Houssam Hnaidi and Eric Gu\'{e}rin and Samir Akkouche and Adrien Peytavie and Eric Galin},
  doi      = {10.1111/j.1467-8659.2010.01806.x},
  issn     = {0167-7055},
  issue    = 7,
  journal  = {Computer Graphics Forum},
  keywords = {Terrain modeling,gradient and height field diffusion,vector graphics},
  month    = 9,
  pages    = {2179--2186},
  title    = {Feature based terrain generation using diffusion equation},
  volume   = 29,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2010.01806.x},
  year     = 2010
}

@article{Hochberg2021,
  abstract = {It is incontrovertible that many coral reefs are in various stages of decline and may be unable to withstand the effects of global climate change, jeopardizing vital ecosystem goods and services to hundreds of millions of people around the world. An estimated 50\% of the world's corals have already been lost, and those remaining may be lost by 2030 under the ``business as usual'' CO2 emissions scenario. However, the foundation of these predictions is a surprisingly sparse dataset, wherein ~0.01–0.1\% of the world's reef area has been quantitatively surveyed. Further, the available data comprise observations at the 1–10 m scale, which are not evenly spaced across reefs, but often clustered in areas representing focused survey effort. This impedes modeling and predicting the impact of a changing environment at the ecosystem scale. Here we highlight deficiencies in our current understanding of the relationship between coral reefs and their environments. Specifically, we conduct a meta-analysis using estimates of coral cover from a variety of local surveys, quantitatively relating reef condition to a suite of biogeophysical forcing parameters. We find that readily available public data for coral cover exhibit unexpected trends (e.g., a positive correlation between coral cover and multi-year cumulative thermal stress), contrary to prevailing scientific expectations. We illustrate a significant gap in our current understanding, and thereby prediction, of coral reefs at the ecosystem scale that can only be remedied with uniform, high-density data across vast coral reef regions, such as that from remote sensing.},
  author   = {Eric J. Hochberg and Michelle M. Gierach},
  doi      = {10.3389/fmars.2021.727038},
  issn     = 22967745,
  issue    = {August},
  journal  = {Frontiers in Marine Science},
  keywords = {biogeophysical forcing,climate change,coral cover,coral reefs,ecosystem scale,remote sensing},
  pages    = {1--10},
  title    = {Missing the Reef for the Corals: Unexpected Trends Between Coral Reef Condition and the Environment at the Ecosystem Scale},
  volume   = 8,
  year     = 2021
}

@article{Hoffman2001,
  abstract = {We systematically design two new decomposition-recombination (DR) planners, geared to perform well with respect to several performance measures. The DR-planning problem and the performance measures were formally defined in Part I of this paper to closely reflect specific requirements of CAD/CAM applications. As expected, in analysis and comparison based on all of these performance measures, one of the new DR-planners, the modified frontier algorithm (MFA), represents a significant improvement over existing planners based on SR (constraint shape recognition) and MM (maximum matching) that were analyzed in Part I. We also present salient heuristics and data structures used in the implementation of MFA. \textcopyright{} 2001 Academic Press.},
  author   = {Christoph M. Hoffman and Andrew Lomonosov and Meera Sitharam},
  doi      = {10.1006/jsco.2000.0403},
  issn     = {07477171},
  issue    = 4,
  journal  = {Journal of Symbolic Computation},
  pages    = {409--427},
  title    = {Decomposition Plans for Geometric Constraint Problems, Part II: New Algorithms},
  volume   = 31,
  year     = 2001
}

@article{Hollander2011,
  abstract = {Level-of-Detail structures are a key component for scalable rendering. Built from raw 3D data, these structures are often defined as Bounding Volume Hierarchies, providing coarse-to-fine adaptive approximations that are well-adapted for many-view rasterization. Here, the total number of pixels in each view is usually low, while the cost of choosing the appropriate LoD for each view is high. This task represents a challenge for existing GPU algorithms. We propose ManyLoDs, a new GPU algorithm to efficiently compute many LoDs from a Bounding Volume Hierarchy in parallel by balancing the workload within and among LoDs. Our approach is not specific to a particular rendering technique, can be used on lazy representations such as polygon soups, and can handle dynamic scenes. We apply our method to various many-view rasterization applications, including Instant Radiosity, Point-Based Global Illumination, and reflection / refraction mapping. For each of these, we achieve real-time performance in complex scenes at high resolutions.},
  author   = {Matthias Holl\"{a}nder and Tobias Ritschel and Elmar Eisemann and Tamy Boubekeur},
  doi      = {10.1111/j.1467-8659.2011.01982.x},
  issn     = 14678659,
  issue    = 4,
  journal  = {Computer Graphics Forum},
  keywords = {GPU,Level-of-detail,Many-view,Multi-view,Real-time},
  pages    = {1233--1240},
  title    = {ManyLoDs: Parallel many-view level-of-detail selection for real-time global illumination},
  volume   = 30,
  url      = {https://perso.telecom-paristech.fr/boubek/papers/ManyLoDs/ManyLoDs.pdf},
  year     = 2011
}

@article{Honda1971,
  abstract = {An attempt was made to describe the multifarious form of erect trees by a few parameters. Trees were approximated by the tree-like body which was made up of repeated bifurcations of branches. Three-dimensional positions of the end-points of the branches could be calculated using suitable but tentative solid geometrical assumptions which included some parameters : branching angle and relative ratio of the branch lengths. The branching angle and the relative ratio of the branch lengths were well demonstrated to have great effects upon the whole form of the tree-like body. The whole form of actual trees, therefore, was speculated to be affected also by their branching angle and relative ratio of their branch lengths. This attempt had a relationship to the problems of the morphogenetic process in living organisms and, in general, of the pattern-generation by generation rules.},
  author   = {H Honda},
  journal  = {Journal of Theoretical Biology},
  pages    = {331--338},
  title    = {Description of the form of trees by the parameters of the tree-like body},
  volume   = 31,
  year     = 1971
}

@article{Hong2013,
  abstract  = {In this paper, we develop a skeleton-based technique to model implicit surfaces using 2-D piecewise algebraic splines, which allows the construction of generalized cylinders with arbitrary cross-sections. Our method is based on smooth blending of a set of locally constructed general cylinders corresponding to different cross-sections along a given skeleton. Firstly, freeform cross-sections are reconstructed implicitly using the 2-D piecewise algebraic splines, and then, different cross-section profiles are weighted and summed up along the skeleton using the Partial Shape Preserving (PSP) spline basis functions. In addition, the smooth piecewise polynomial blending operations is employed to blend the branches of implicitly constructed generalized cylinders together. The implicit generalized cylinders constructed using our method is model free, and can achieve extremely high smoothness and accuracy. \textcopyright{} 2013 IEEE.},
  author    = {Qingqi Hong},
  doi       = {10.1109/CISP.2013.6745253},
  isbn      = 9781479927647,
  issue     = {Cisp},
  journal   = {Proceedings of the 2013 6th International Congress on Image and Signal Processing, CISP 2013},
  keywords  = {Generalized cylinders,Implicit surfaces,Modelling,Skeleton},
  pages     = {686--691},
  publisher = {IEEE},
  title     = {A skeleton-based technique for modelling implicit surfaces},
  volume    = 2,
  year      = 2013
}

@article{Hoppe1993,
  abstract = {We present a method for solving the following problem: Given a set of data points scattered in three dimensions and an initial triangular meshM0, produce a mesh M, of the same topological type as M0, that fits the data well and has a small number of vertices. Our approach is to minimize an energy function that explicitly models the competing desires of conciseness of representation and fidelity to the data. We show that mesh optimization can be effectively used in at least two applications: surface reconstruction from unorganized points, and mesh simplification (the reduction of the number of vertices in an initially dense mesh of triangles).},
  author   = {Hugues Hoppe and Tony DeRose and Tom Duchampy and John McDonaldz and Werner Stuetzlez},
  doi      = {10.1145/166117.166119},
  isbn     = {0897916018},
  journal  = {Proceedings of the 20th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1993},
  keywords = {Geometric modeling,Model simplification,Range data analysis,Surface fitting,Three-dimensional shape recovery},
  pages    = {19--26},
  title    = {Mesh optimization},
  volume   = {d},
  year     = 1993
}

@article{Horna2009,
  abstract  = {Virtual architectural (indoor) scenes are often modeled in 3D for various types of simulation systems. For instance, some authors propose methods dedicated to lighting, heat transfer, acoustic or radio-wave propagation simulations. These methods rely in most cases on a volumetric representation of the environment, with adjacency and incidence relationships. Unfortunately, many buildings data are only given by 2D plans and the 3D needs varies from one application to another. To face these problems, we propose a formal representation of consistency constraints dedicated to building interiors and associated with a topological model. We show that such a representation can be used for: (i) reconstructing 3D models from 2D architectural plans (ii) detecting automatically geometrical, topological and semantical inconsistencies (iii) designing automatic and semi-automatic operations to correct and enrich a 2D plan. All our constraints are homogeneously defined in 2D and 3D, implemented with generalized maps and used in modeling operations. We explain how this model can be successfully used for lighting and radio-wave propagation simulations. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
  author    = {S. Horna and Daniel Meneveaux and Guillaume Damiand and Yves Bertrand},
  doi       = {10.1016/j.cad.2008.11.006},
  issn      = {00104485},
  issue     = 1,
  journal   = {CAD Computer Aided Design},
  keywords  = {3D modeling,Architecture,G-maps,Indoor building,Reconstruction,Topological model},
  pages     = {13--27},
  publisher = {Elsevier Ltd},
  title     = {Consistency constraints and 3D building reconstruction},
  volume    = 41,
  url       = {http://dx.doi.org/10.1016/j.cad.2008.11.006 https://hal.archives-ouvertes.fr/hal-00440844/file/CAD\_consistency constraints and 3D buildings reconstruction.pdf},
  year      = 2009
}

@article{Hornby2002,
  abstract = {One of the main limitations of scalability in body-brain evolution systems is the representation chosen for encoding creatures. This paper defines a class of representations called generative representations, which are identified by their ability to reuse elements of the genotype in the translation to the phenotype. This paper presents an example of a generative representation for the concurrent evolution of the morphology and neural controller of simulated robots, and also introduces GENRE, an evolutionary system for evolving designs using this representation. Applying GENRE to the task of evolving robots for locomotion and comparing it against a non-generative (direct) representation shows that the generative representation system rapidly produces robots with significantly greater fitness. Analyzing these results shows that the generative representation system achieves better performance by capturing useful bias from the design space and by allowing viable large scale mutations in the phenotype. Generative representations thereby enable the encapsulation, coordination, and reuse of assemblies of parts.},
  author   = {Gregory S. Hornby and Jordan B. Pollack},
  doi      = {10.1162/106454602320991837},
  issn     = 10645462,
  issue    = 3,
  journal  = {Artificial life},
  keywords = {body-brain evolution,generative},
  pages    = {223--246},
  pmid     = 12537684,
  title    = {Creating high-level components with a generative representation for body-brain evolution.},
  volume   = 8,
  year     = 2002
}

@article{Hornus2003,
  author  = {Samuel Hornus and Alexis Angelidis and Marie-paule Cani},
  journal = {The Visual Computer},
  pages   = {94--104},
  title   = {Implicit Modelling Using Subdivision-curves},
  volume  = 19,
  url     = {https://inria.hal.science/inria-00510180v1/document},
  year    = 2003
}

@misc{Hossain,
  abstract = {Figure 1: Lightfield rendering to demonstrate focus at different depths. The left image is focused at a far plane near the tree while the right image is focused near flowers at a closer distance from the camera. Abstract We report a simulation platform for a lightfield camera. Our methods may be applied to develop and refine future lightfield acquisition systems. Furthermore, the rendering pipeline of PBRT has been augmented to include our camera simulator, permitting the generation of refocus-able computer-generated artwork. We demonstrate our simulation platform on various imaging scenarios that may prove challenging for more conventional imaging models.},
  author   = {Zahid Hossain and Adam Spilfogel Backer and Yanlin Chen},
  keywords = {imaging sys-tems and applications,lightfield,realistic camera simulation},
  title    = {CS348b Project: Light Field Camera Simulation}
}

@article{Hsu2017,
  abstract = {Gait velocity and stride length are critical health indicators for older adults. A decade of medical research shows that they provide a predictor of future falls, hospitalization, and functional decline among seniors. However, currently these metrics are measured only occasionally during medical visits. Such infrequent measurements hamper the opportunity to detect changes and intervene early in the impairment process. In this paper, we develop a sensor that uses radio signals to continuously measure gait velocity and stride length at home. Our sensor hangs on a wall like a picture frame. It does not require the monitored person to wear or carry a device on her body. Our approach builds on recent advances in wireless systems which have shown that one can locate people based on how their bodies impact the surrounding radio signals. We demonstrate the accuracy of our method by comparing it to the gold standard in clinical tests, and the VICON motion tracking system. Our experience from deploying the sensor in 14 homes indicates comfort with the technology and a high acceptance rate.},
  author   = {Chen Yu Hsu and Yuchen Liu and Zachary Kabelac and Rumen Hristov and Dina Katabi and Christine Liu},
  doi      = {10.1145/3025453.3025937},
  isbn     = 9781450346559,
  journal  = {Conference on Human Factors in Computing Systems - Proceedings},
  keywords = {Continuous monitoring,Device-free sensing,Gait velocity,Stride length,Wireless sensing},
  pages    = {2116--2126},
  title    = {Extracting gait velocity and stride length from surrounding radio signals},
  volume   = {2017-May},
  year     = 2017
}

@article{Hu2019,
  abstract = {We propose a robust 2D meshing algorithm, TriWild, to generate curved triangles reproducing smooth feature curves, leading to coarse meshes designed to match the simulation requirements necessary by applications and avoiding the geometrical errors introduced by linear meshes. The robustness and effectiveness of our technique are demonstrated by batch processing an SVG collection of 20k images, and by comparing our results against state of the art linear and curvilinear meshing algorithms. We demonstrate for our algorithm the practical utility of computing diffusion curves, fluid simulations, elastic deformations, and shape inflation on complex 2D geometries.},
  author   = {Yixin Hu and Teseo Schneider and Xifeng Gao and Qingnan Zhou and Alec Jacobson and Denis Zorin and Daniele Panozzo},
  doi      = {10.1145/3306346.3323011},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Curved Triangulation,Mesh Generation,Robust Geometry Processing},
  title    = {Triwild: Robust triangulation with curve constraints},
  volume   = 38,
  url      = {https://cims.nyu.edu/gcl/papers/2019-TriWild.pdf},
  year     = 2019
}

@article{Huang2009a,
  abstract = {We consolidate an unorganized point cloud with noise, outliers, non-uniformities, and in particular interference between close-by surface sheets as a preprocess to surface generation, focusing on reliable normal estimation. Our algorithm includes two new developments. First, a weighted locally optimal projection operator produces a set of denoised, outlier-free and evenly distributed particles over the original dense point cloud, so as to improve the reliability of local PCA for initial estimate of normals. Next, an iterative framework for robust normal estimation is introduced, where a priority-driven normal propagation scheme based on a new priority measure and an orientation-aware PCA work complementarily and iteratively to consolidate particle normals. The priority setting is reinforced with front stopping at thin surface features and normal flipping to enable robust handling of the close-by surface sheet problem. We demonstrate how a point cloud that is wellconsolidated by our method steers conventional surface generation schemes towards a proper interpretation of the input data. \textcopyright{} 2009, ACM. All rights reserved.},
  author   = {Hui Huang and Dan Li and Uri Ascher and Hao Zhang and Daniel Cohen-Or},
  doi      = {10.1145/1618452.1618522},
  issn     = 15577368,
  issue    = 5,
  journal  = {ACM Transactions on Graphics},
  pages    = {1--7},
  title    = {Consolidation of Unorganized Point Clouds for Surface Reconstruction},
  volume   = 28,
  year     = 2009
}

@article{Huang2013,
  abstract = {We present a robust and efficient approach to directly slicing implicit solids. Different from prior slicing techniques that reconstruct contours on the slicing plane by tracing the topology of intersected line segments, which is actually not robust, we generate contours by a topology guaranteed contour extraction on binary images sampled from given solids and a subsequent contour simplification algorithm which has the topology preserved and the geometric error controlled. The resultant contours are free of self-intersection, topologically faithful to the given r-regular solids and with shape error bounded. Therefore, correct objects can be fabricated from them by rapid prototyping. Moreover, since we do not need to generate the tessellated B-rep of given solids, the memory cost our approach is low - only the binary image and the finest contours on one particular slicing plane need to be stored in-core. Our method is general and can be applied to any implicit representations of solids. Copyright \textcopyright{} 2013 by ASME.},
  author   = {Pu Huang and Charlie C.L. Wang and Yong Chen},
  doi      = {10.1115/1.4024067},
  issn     = 15309827,
  issue    = 2,
  journal  = {Journal of Computing and Information Science in Engineering},
  keywords = {Direct slicing,Implicit representation,Self-intersection free,Solid,Topologically faithful},
  title    = {Intersection-free and topologically faithful slicing of implicit solid},
  volume   = 13,
  url      = {https://mewangcl.github.io/pubs/JCISEImpSlicing.pdf},
  year     = 2013
}

@article{Hudak2011,
  abstract = {In this paper we present a particle-based method for large scale long time progressive simulation of terrain erosion containing wet granular particles. The wetting process and the propagation through granular material is based on defining the wetness value for each particle representing the amount of water absorbed by granular particles and stored between them, as was originally proposed by Rungjiratananon [RSKN08]. We extend this model by adding a non homogeneous material to simulate differences between different types of soil-like granular material, based on physical constants like stability, plasticity and wetness. With this approach we can create a physical animation of erosion process like mass movement or mass wasting. \textcopyright{} The Eurographics Association 2011.},
  author   = {M. Hud\'{a}k and R. \v{D}urikovi\v{c}},
  doi      = {10.2312/LocalChapterEvents/TPCG/TPCG11/009-016},
  isbn     = 9783905673838,
  journal  = {Theory and Practice of Computer Graphics 2011, TPCG 2011 - Eurographics UK Chapter Proceedings},
  pages    = {9--16},
  title    = {Terrain models for mass movement erosion},
  url      = {https://diglib.eg.org/bitstream/handle/10.2312/LocalChapterEvents.TPCG.TPCG11.009-016/009-016.pdf?sequence=1},
  year     = 2011
}

@article{Huijser2010,
  abstract  = {Due to the increase in magnitude and level of detail of next-gen games, the time required to manually design a game level has increased dramatically. This paper introduces procedural natural systems, a novel approach aimed at reducing the time needed to design large-scale natural phenomena for game levels. The concept of natural systems separates the shape of a natural phenomenon from its footprint, allowing a designer to edit either of them separately. Various procedural techniques are used to combine the shape and footprint of a natural system, as well as to tweak these in real-time in a game world. We conclude that natural systems provide a solid foundation for intuitive, flexible and efficient procedural generation of significant portions of a game level. \textcopyright{} 2010 IEEE.},
  author    = {Remco Huijser and Jeroen Dobbe and Willem F. Bronsvoort and Rafael Bidarra},
  doi       = {10.1109/SBGAMES.2010.31},
  isbn      = 9780769543598,
  journal   = {Proceedings - 2010 Brazilian Symposium on Games and Digital Entertainment, SBGames 2010},
  keywords  = {Game level design,Natural systems,Procedural content generation},
  pages     = {189--198},
  publisher = {IEEE},
  title     = {Procedural natural systems for game level design},
  year      = 2010
}

@article{Hyun2004,
  abstract  = {Brualdi et al. introduced the concept of poset codes, and gave an example of poset structure which admits the extended binary Hamming code to be a double-error-correcting perfect P-code. Our study is motivated by this example. In this paper we classify all poset structures which admit the extended binary Hamming code to be a double or triple-error-correcting perfect P-code. \textcopyright{} 2004 Elsevier B.V. All rights reserved.},
  author    = {Jong Yoon Hyun and Hyun Kwang Kim},
  doi       = {10.1016/j.disc.2004.07.010},
  issn      = {0012365X},
  issue     = {1-3},
  journal   = {Discrete Mathematics},
  keywords  = {Extended Hamming code,Perfect P-code,Poset codes,Strongly perfect P-code},
  month     = 11,
  pages     = {37--47},
  publisher = {North-Holland},
  title     = {The poset structures admitting the extended binary Hamming code to be a perfect code},
  volume    = 288,
  year      = 2004
}

@article{Igarashi2005,
  abstract = {We present an interactive system that lets a user move and deform a two-dimensional shape without manually establishing a skeleton or freeform deformation (FFD) domain beforehand. The shape is represented by a triangle mesh and the user moves several vertices of the mesh as constrained handles. The system then computes the positions of the remaining free vertices by minimizing the distortion of each triangle. While physically based simulation or iterative refinement can also be used for this purpose, they tend to be slow. We present a two-step closed-form algorithm that achieves real-time interaction. The first step finds an appropriate rotation for each triangle and the second step adjusts its scale. The key idea is to use quadratic error metrics so that each minimization problem becomes a system of linear equations. After solving the simultaneous equations at the beginning of interaction, we can quickly find the positions of free vertices during interactive manipulation. Our approach successfully conveys a sense of rigidity of the shape, which is difficult in space-warp approaches. With a multiple-point input device, even beginners can easily move, rotate, and deform shapes at will. Copyright \textcopyright{} 2005 by the Association for Computing Machinery, Inc.},
  author   = {Takeo Igarashi and Tomer Moscovich and John F. Hughes},
  doi      = {10.1145/1073204.1073323},
  issn     = {07300301},
  issue    = 3,
  journal  = {ACM Transactions on Graphics},
  keywords = {Animation,Deformation,Image Editing,Interaction,Mesh Editing,Shape Manipulation},
  pages    = {1134--1141},
  title    = {As-rigid-as-possible shape manipulation},
  volume   = 24,
  url      = {https://graphics.stanford.edu/courses/cs468-07-winter/Papers/imh-rpsm-05.pdf},
  year     = 2005
}

@article{Iosa2013,
  abstract  = {In nature, many physical and biological systems have structures showing harmonic properties. Some of them were found related to the irrational number \'{\i} \mathrm{\mu}\'{\i}\textonequarter{} known as the golden ratio that has important symmetric and harmonic properties. In this study, the spatiotemporal gait parameters of 25 healthy subjects were analyzed using a stereophotogrammetric system with 25 retroreflective markers located on their skin. The proportions of gait phases were compared with \'{\i} \mathrm{\mu}\'{\i}\textonequarter{}, the value of which is about 1.6180. The ratio between the entire gait cycle and stance phase resulted in 1.620 \pm{} 0.058, that between stance and the swing phase was 1.629 \pm{} 0.173, and that between swing and the double support phase was 1.684 \pm{} 0.357. All these ratios did not differ significantly from each other (\'{\i} \mathrm{\mu}\'{\i}\textdegree{}\ensuremath{^1} = 0.870, \'{\i} \mathrm{\mu}\'{\i}\pm{} = 0.422, repeated measure analysis of variance) or from \'{\i} \mathrm{\mu}\'{\i}\textonequarter{} (\'{\i} \mathrm{\mu}\'{\i}\pm{} = 0.670, 0.820, 0.422, resp., t-tests). The repetitive gait phases of physiological walking were found in turn in repetitive proportions with each other, revealing an intrinsic harmonic structure. Harmony could be the key for facilitating the control of repetitive walking. Harmony is a powerful unifying factor between seemingly disparate fields of nature, including human gait.},
  author    = {Marco Iosa and Augusto Fusco and Fabio Marchetti and Giovanni Morone and Carlo Caltagirone and Stefano Paolucci and Antonella Peppe},
  doi       = {10.1155/2013/918642},
  journal   = {BioMed Research International},
  publisher = {Hindawi Publishing Corporation},
  title     = {The Golden Ratio of Gait Harmony: Repetitive Proportions of Repetitive Gait Phases},
  volume    = 2013,
  url       = {http://dx.},
  year      = 2013
}

@article{Isheden2022,
  author = {Sebastian Isheden},
  title  = {Hydraulic Erosion Simulation on the GPU for 3D terrains},
  url    = {https://www.diva-portal.org/smash/get/diva2:1646074/FULLTEXT01.pdf},
  year   = 2022
}

@inproceedings{Isola2017,
  abstract  = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
  author    = {Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A Efros},
  doi       = {10.1109/CVPR.2017.632},
  isbn      = {978-1-5386-0457-1},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = 7,
  pages     = {5967--5976},
  publisher = {IEEE},
  title     = {Image-to-Image Translation with Conditional Adversarial Networks},
  url       = {http://arxiv.org/abs/1611.07004 http://ieeexplore.ieee.org/document/8100115/},
  year      = 2017
}

@article{Ito2003,
  abstract = {Research on methods for representing natural objects and phenomena by computer graphics (CG) has been steadily broadening the scope of represented objects in recent years. Among such research, visual simulation of rocky scenery is an important issue that has a wide range of applications related to visual contents, such as in landscape simulation. In the early days of research on terrain scenery representation, a great deal of techniques for representing terrain shapes and rocky textures mainly using noise generation methods such as the midpoint displacement method and FFT were reported. In the natural rocky scenery, cracks called "joints" are an important visual feature. After cracking base rocks by joints, the change of the rock shapes according to some factors, such as eliminating rock pieces by weathering or moving by gravity, determines the consequent rocky scenery. In order to create such rocky scenery, we propose a rocky scenery modelling method based on joint formation and rock elimination/movement simulation.},
  author   = {T. Ito and T. Fujimoto and K. Muraoka and N. Chiba},
  doi      = {10.1109/CGI.2003.1214475},
  isbn     = {0769519466},
  issn     = 15301052,
  issue    = {July 2014},
  journal  = {Proceedings of Computer Graphics International Conference, CGI},
  keywords = {Character generation,Chemicals,Computational modeling,Computer graphics,Indium tin oxide,Noise generators,Noise shaping,Shape,Surface cracks,Surface topography},
  pages    = {244--247},
  title    = {Modeling rocky scenery taking into account joints},
  volume   = {2003-Janua},
  year     = 2003
}

@article{Iwasaki2010,
  abstract = {The visual simulation of natural phenomena has been widely studied. Although several methods have been proposed to simulate melting, the flows of meltwater drops on the surfaces of objects are not taken into account. In this paper, we propose a particle-based method for the simulation of the melting and freezing of ice objects and the interactions between ice and fluids. To simulate the flow of meltwater on ice and the formation of water droplets, a simple interfacial tension is proposed, which can be easily incorporated into common particle-based simulation methods such as Smoothed Particle Hydrodynamics. The computations of heat transfer, the phase transition between ice and water, the interactions between ice and fluids, and the separation of ice due to melting are further accelerated by implementing our method using CUDA. We demonstrate our simulation and rendering method for depicting melting ice at interactive frame-rates. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
  author   = {K. Iwasaki and H. Uchida and Y. Dobashi and T. Nishita},
  doi      = {10.1111/j.1467-8659.2010.01810.x},
  issn     = 14678659,
  issue    = 7,
  journal  = {Computer Graphics Forum},
  pages    = {2215--2223},
  title    = {Fast particle-based visual simulation of ice melting},
  volume   = 29,
  year     = 2010
}

@article{Jabin2008,
  abstract = {The aim of this paper is to derive and analyze the mathematical properties of a new continuous size-structured model for red coral (Corallium rubrum, L.) growth. Since historical Leslie models 4 are often used to deal with some ecological problems, a new approach is here proposed and give some promising results. The main advantage of using continuous model is that we hope to describe precisely the mass mortality events, observed in Mediterranean sea, and its consequences on red coral dynamics. Simulations' studies allow us to qualitatively discuss some questions about red coral populations dynamics. The development of this method should be useful for the study of the conservation of red coral populations.},
  author   = {P.-E. Jabin and V. Lemesle and D. Aurelle},
  doi      = {10.1142/S0218202508003248},
  issn     = {0218-2025},
  issue    = 11,
  journal  = {Mathematical Models and Methods in Applied Sciences},
  keywords = {asymptotic analysis,conservation biology,population dynamics,size-structured continuous model},
  month    = 11,
  pages    = {1927--1944},
  title    = {A continuous size-structured red coral growth model},
  volume   = 18,
  url      = {https://www.worldscientific.com/doi/pdf/10.1142/S0218202508003248 https://www.worldscientific.com/doi/abs/10.1142/S0218202508003248},
  year     = 2008
}

@article{Jacobson2015,
  author  = {Alec Jacobson},
  journal = {SIGGRAPH Course 2014},
  pages   = {1--28},
  title   = {Skinning: Real-time Shape Deformationart II: Automatic Skinning via Constrained Energy Optimization},
  url     = {http://skinning.org/automatic-methods.pdf},
  year    = 2015
}

@inproceedings{Jafari2011,
  abstract  = {The modelling of the wind resource over arbitrary topography is required to optimize the micrositing of wind turbines. Most solvers use classical body-fitted grid for simulations. In such an approach, to cover the wind rose using a rectangular domain, a dedicated mesh must be generated for each direction. Moreover, over complex terrain, additional numerical errors are introduced in the solver due to coordinate transformations. To overcome these challenges and to facilitate the grid generation process, an immersed boundary method is developed in connection with a RANS solver in order to simulate turbulent atmospheric flows over arbitrary topography. In this method, a Cartesian grid is used and the boundary condition on the terrain surface is modelled within the solver using a "direct forcing" approach. With the immersed boundary method a rectangular grid can be used to simulate the flow field for all wind directions and only a rotation of the digital elevation map is required. Ghost cells are used to enforce the desired boundary condition at the immersed surface. The immersed boundary method developed in this work is used to simulate the flow in connection with both Baldwin-Lomax and k\ensuremath{\omega} turbulence models. The performance of the method is examined for the flow over a two-dimensional hill. Results are compared with experimental data as well as a classical body-fitted grid to isolate the effect of the boundary conditions. The comparisons show good agreement among all the results. The results for the three-dimensional wind flow simulation over the Askervein Hill test case are also presented, and show the capability of the immersed boundary method in a full-scale scenario.},
  author    = {S Jafari and N Chokani and R S Abhari},
  booktitle = {Proceedings of ASME Turbo Expo},
  keywords  = {GT2011-46240},
  title     = {Terrain effects on wind flow: simulations with an immersed boundary method},
  url       = {http://asme.org/terms},
  year      = 2011
}

@article{Jaiswal2019,
  abstract = {A real-time multibody model of an off-road vehicle can be used to analyze the dynamics of tasks, such as loading and/or transferring material from deformable ground. This analysis requires an accurate description of the mechanics, hydraulic actuators, and the terrain. The objective of this paper is to introduce a novel, real-time capable, deformable terrain/soil model that can interact with the mechanics of a multibody system model and the dynamics of a hydraulics model. To this end, a tractor is modeled by using a semi-recursive multibody formulation based on velocity transformation. The hydraulic actuation of the tractor's front-loader is modeled by using the lumped fluid theory. The tractor loads and transfers sand material from a deformable sand field (the ground), which is modeled by combining mesh-based and particle-based soil representation approaches for the real-time simulation of soil deformation. The work cycle of the tractor model follows a 3D maneuver that is used to load and transfer sand material. During the digging and dumping operations, the static sand field is converted into sand particles and vice versa respectively. For the presented work cycle, the real-time capability of the system is analyzed and determined. Furthermore, the dynamic actuator forces in the hydraulic cylinders are compared with the static actuator forces. The introduced real-time capable tractor simulation model can be utilized in product development and other product processes.},
  author   = {Suraj Jaiswal and Pasi Korkealaakso and Rafael Aman and Jussi Sopanen and Aki Mikkola},
  doi      = {10.1109/ACCESS.2019.2956164},
  issn     = 21693536,
  journal  = {IEEE Access},
  keywords = {Deformable soil/terrain model,hydraulic actuators,multibody system dynamics,real-time simulation,semi-recursive formulation,vehicle dynamics},
  pages    = {172694--172708},
  title    = {Deformable Terrain Model for the Real-Time Multibody Simulation of a Tractor with a Hydraulically Driven Front-Loader},
  volume   = 7,
  year     = 2019
}

@article{Jako2011,
  abstract = {Computer games, TV series, movies, simulators and many other computer graphics applications are using external scenes where a realistic looking terrain is a vital part of the view. Creating such terrains are not a simple task neither manually nor automatically. In this paper we propose a method that generates realistic virtual terrainsby simulation of hydraulic and thermal erosion on a predefined height field terrain. The model is designed to beexecuted interactively on parallel architectures like graphics processors.},
  author   = {Bal\'{a}zs J\'{a}k\'{o} and Bal\'{a}zs T\'{o}th},
  issue    = {July},
  keywords = {GLSL,GPU,erosion,hydraulic erosion,navier-stokes,terrain,thermal erosion},
  pages    = 4,
  title    = {Fast Hydraulic and Thermal Erosion on GPU},
  year     = 2011
}

@article{Jayadevan2019,
  abstract  = {Decomposing a point cloud into its components and extracting curve skeletons from point clouds are two related problems. Decomposition of a shape into its components is often obtained as a byproduct of skeleton extraction. In this work, we propose to extract curve skeletons, from unorganized point clouds, by decomposing the object into its parts, identifying part skeletons and then linking these part skeletons together to obtain the complete skeleton. We believe it is the most natural way to extract skeletons in the sense that this would be the way a human would approach the problem. Our parts are generalized cylinders (GCs). Since, the axis of a GC is an integral part of its definition, the parts have natural skeletal representations. We use translational symmetry, the fundamental property of GCs, to extract parts from point clouds. We demonstrate how this method can handle a large variety of shapes. We compare our method with state of the art methods and show how a part based approach can deal with some of the limitations of other methods. We present an improved version of an existing point set registration algorithm and demonstrate its utility in extracting parts from point clouds. We also show how this method can be used to extract skeletons from and identify parts of noisy point clouds. A part based approach also provides a natural and intuitive interface for user interaction. We demonstrate the ease with which mistakes, if any, can be fixed with minimal user interaction with the help of a graphical user interface.},
  author    = {Vijai Jayadevan and Edward Delp and Zygmunt Pizlo},
  journal   = {arXiv},
  keywords  = {3D object segmentation,3D point clouds,3D shape decomposition,Curve skeleton extraction,Translational symmetry,registration},
  month     = 12,
  publisher = {arXiv},
  title     = {Skeleton Extraction from 3D Point Clouds by Decomposing the Object into Parts},
  url       = {http://arxiv.org/abs/1912.11932},
  year      = 2019
}

@article{Jensen2017,
  abstract = {A novel bulk microphysics scheme that predicts the evolution of ice properties, including aspect ratio (shape), mass, number, size, and density is described, tested, and demonstrated. The scheme is named the Ice-Spheroids Habit Model with Aspect-Ratio Evolution (ISHMAEL). Ice is modeled as spheroids and is nucleated as one of two species depending on nucleation temperature. Microphysical process rates determine how shape and other ice properties evolve. A third aggregate species is also employed, diversifying ice properties in the model. Tests of ice shape evolution during vapor growth and riming are verified against wind tunnel data, revealing that the model captures habit-dependent riming and its effect on fall speed. Lagrangian parcel studies demonstrate that the bulk model captures ice property evolution during riming and melting compared with a bin model. Finally, the capabilities of ISHMAEL are shown in a 2D kinematic framework with a simple updraft. A direct result of predicting ice shape evolution is that various states of ice from unrimed to lightly rimed to densely rimed can be modeled without converting ice mass between predefined ice categories (e.g., snow and graupel). This leads to a different spatial precipitation distribution compared with the traditional method of separating snow and graupel and converting between the two categories, because ice in ISHMAEL sorts in physical space based on the amount of rime, which controls the thickness and therefore fall speed. Predicting these various states of rimed ice leads to a reduction in vapor growth rate and an increase in riming rate in a simple updraft compared with the traditional approach.},
  author   = {Anders A. Jensen and Jerry Y. Harrington and Hugh Morrison and Jason A. Milbrandt},
  doi      = {10.1175/JAS-D-16-0350.1},
  issn     = 15200469,
  issue    = 6,
  journal  = {Journal of the Atmospheric Sciences},
  keywords = {Cloud microphysics,Cloud parameterizations,Clouds,Ice crystals,Ice loss/growth,Ice particles},
  pages    = {2081--2104},
  title    = {Predicting ice shape evolution in a bulk microphysics model},
  volume   = 74,
  year     = 2017
}

@article{Jermann2008,
  author  = {Christophe Jermann and Hiroshi Hosobe},
  journal = {7e Conf\'{e}rence Internationale de MOd\'{e}lisation et SIMulation},
  title   = {Une approche orient\'{e}e hi\'{e}rarchie de contraintes pour la r\'{e}solution de probl\`{e}mes de contraintes g\'{e}om\'{e}triques},
  year    = 2008
}

@article{Ji2010,
  abstract = {This paper presents a novel modeling system, called B-Mesh, for generating base meshes of 3D articulated shapes. The user only needs to draw a one-dimensional skeleton and to specify key balls at the skeletal nodes. The system then automatically generates a quad dominant initial mesh. Further subdivision and evolution are performed to refine the initial mesh and generate a quad mesh which has good edge flow along the skeleton directions. The user can also modify and manipulate the shape by editing the skeleton and the key balls and can easily compose new shapes by cutting and pasting existing models in our system. The mesh models generated in our system greatly benefit the sculpting operators for sculpting modeling and skeleton-based animation. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
  author   = {Zhongping Ji and Ligang Liu and Yigang Wang},
  doi      = {10.1111/j.1467-8659.2010.01805.x},
  issn     = 14678659,
  issue    = 7,
  journal  = {Computer Graphics Forum},
  pages    = {2169--2177},
  title    = {B-Mesh: A modeling system for base meshes of 3D articulated shapes},
  volume   = 29,
  year     = 2010
}

@article{Jiang2012,
  abstract  = {Level set method can be effectively used to solve topology problems during the evolution of curves while the previous algorithms cannot deal with them. In recent years, there are many image segmentation algorithms based on level set method. For different applications of image processing, people have put forward the corresponding solutions, and a large number of researchers also continue to improve and enhance the efficiency and effectiveness of these algorithms. In this article, according to the development of the image segmentation methods based on level set, an overview is given for readers of different backgrounds in this field to use, and their characteristics are discussed.},
  author    = {Xin Jiang and Renjie Zhang and Shengdong Nie},
  doi       = {10.1016/j.phpro.2012.05.143},
  issn      = 18753892,
  journal   = {Physics Procedia},
  pages     = {840--845},
  publisher = {Elsevier BV},
  title     = {Image Segmentation Based on Level Set Method},
  volume    = 33,
  year      = 2012
}

@article{Jobling2010,
  abstract = {The book closes with two special-topic chapters;   and mammals in Polar Seas, and harvesting living  resources. These two chapters, although containing some interesting material, may be considered a bit of an anomaly.},
  author   = {Malcolm Jobling},
  doi      = {10.1007/s10499-009-9275-1},
  isbn     = 9780763753696,
  issn     = {0967-6120},
  issue    = 4,
  journal  = {Aquaculture International},
  pages    = {709--710},
  title    = {J. Morrissey and J. L. Sumich: Introduction to the Biology of Marine Life, 9th edn.},
  volume   = 18,
  year     = 2010
}

@article{Johnson2005,
  abstract = {Modern and abandoned Pleistocene rocky shores are described for several of the Seychelles Islands in order to examine the range of erosional features typical of granite shores in a tropical setting and to gauge the prospects for their preservation at unconformities in the rock record. The proportion of sandy beaches to rocky shores is estimated for each of the various islands under consideration, including Mah\'{e}, Praslin, Ronde, La Digue, Grande S\oe{}ur, and Cocos. Aspects of physical geography related to the position of reefs and the variable width of lagoons that surround and buffer the islands is considered with respect to the regional pattern of prevailing winds and oceanic circulation. Literature on the erosion of granite landforms is reviewed and applied to the Seychelles Inner Islands and the Seychelles Bank on which they sit. Outcrops of Pleistocene limestone closely associated with granite surfaces were searched for body fossils that represent an intertidal rocky-shore biota. Coralline red algae and vermetid gastropods are the primary components of laminated limestone attached directly to granite surfaces as protective bioconstructions. Cemented limestone rubble includes the body fossils of a dozen different kinds of invertebrates also found extant on modern granite shores in the Seychelles. Among them are gastropods that represent a range of different life styles, as well as corals.},
  author   = {Markes E. Johnson and B. Gudveig Baarli},
  doi      = {10.2112/05-0019.1},
  issn     = {07490208},
  issue    = 5,
  journal  = {Journal of Coastal Research},
  keywords = {Bornhardts,Coralline red algae,Corals,Gastropods,Inselbergs,Intertidal biotas,Isotope substage 5e,Monadnocks,Nubbins,Rillenstein,Tafoni},
  pages    = {867--879},
  title    = {Erosion and burial of granite rocky shores in the recent and late pleistocene of the Seychelles Islands: Physical and biological perspectives},
  volume   = 21,
  year     = 2005
}

@article{Johnson2018,
  author    = {Markes E Johnson and B Gudveig Baarli and M\'{a}rio Cach\~{a}o and Eduardo Mayoral and Ricardo S Ramalho and Ana Santos and Carlos M da Silva},
  doi       = {10.1016/j.earscirev.2018.03.008},
  issn      = {0012-8252},
  issue     = {November 2017},
  journal   = {Earth-Science Reviews},
  keywords  = {Carbonate deposits (rhodoliths and corals),Coastal geomorphology,Oceanic islands,Subsidence,Unconformities,Uplift},
  pages     = {17--36},
  publisher = {Elsevier},
  title     = {On the rise and fall of oceanic islands : Towards a global theory following the pioneering studies of Charles Darwin and James Dwight Dana},
  volume    = 180,
  url       = {https://doi.org/10.1016/j.earscirev.2018.03.008},
  year      = 2018,
  abstract  = {To truly understand the visual world our models should be able not only to recognize images but also generate them. To this end, there has been exciting recent progress on generating images from natural language descriptions. These methods give stunning results on limited domains such as descriptions of birds or flowers, but struggle to faithfully reproduce complex sentences with many objects and relationships. To overcome this limitation we propose a method for generating images from scene graphs, enabling explicitly reasoning about objects and their relationships. Our model uses graph convolution to process input graphs, computes a scene layout by predicting bounding boxes and segmentation masks for objects, and converts the layout to an image with a cascaded refinement network. The network is trained adversarially against a pair of discriminators to ensure realistic outputs. We validate our approach on Visual Genome and COCO-Stuff, where qualitative results, ablations, and user studies demonstrate our method's ability to generate complex images with multiple objects.},
  isbn      = 9781538664209
}

@article{Jokiel2015,
  abstract = {Nine coral survey methods were compared at ten sites in various reef habitats with different levels of coral cover in K\={a}ne'ohe Bay, O'ahu, Hawai'i. Mean estimated coverage at the different sites ranged from less than 10\% cover to greater than 90\% cover. The methods evaluated include line transects, various visual and photographic belt transects, video transects and visual estimates. At each site 25 m transect lines were laid out and secured. Observers skilled in each method measured coral cover at each site. The time required to run each transect, time required to process data and time to record the results were documented. Cost of hardware and software for each method was also tabulated. Results of this investigation indicate that all of the methods used provide a good first estimate of coral cover on a reef. However, there were differences between the methods in detecting the number of coral species. For example, the classic "quadrat" method allows close examination of small and cryptic coral species that are not detected by other methods such as the "towboard" surveys. The time, effort and cost involved with each method varied widely, and the suitability of each method for answering particular research questions in various environments was evaluated. Results of this study support the finding of three other comparison method studies conducted at various geographic locations throughout the world. Thus, coral cover measured by different methods can be legitimately combined or compared in many situations. The success of a recent modeling effort based on coral cover data consisting of observations taken in Hawai'i using the different methods supports this conclusion.},
  author   = {Paul L. Jokiel and Ku'ulei S. Rodgers and Eric K. Brown and Jean C. Kenyon and Greta Aeby and William R. Smith and Fred Farrell},
  doi      = {10.7717/peerj.954},
  issn     = 21678359,
  issue    = 5,
  journal  = {PeerJ},
  keywords = {Coral cover,Coral reefs,Hawaii,Methods comparison},
  title    = {Comparison of methods used to estimate coral cover in the Hawaiian Islands},
  volume   = 2015,
  year     = 2015
}

@book{Jolly1974,
  author  = {Alison Jolly and R. Battistini and G. Richard-Vindard},
  doi     = {10.2307/3544},
  isbn    = 9789401571616,
  issn    = {00218790},
  issue   = 3,
  journal = {The Journal of Animal Ecology},
  pages   = 906,
  title   = {Biogeography and Ecology in Madagascar},
  volume  = 43,
  url     = {https://cloudflare-ipfs.com/ipfs/bafykbzaced547uh2nhkuhh4kdxu2eh7bv6o4lip7liepdi3jsfqp2oq7c2vbg?filename=\%28Monographiae Biologicae 21\%29 R. Battistini \%28auth.\%29\%2C R. Battistini\%2C G. Richard-Vindard \%28eds.\%29 - Biogeography and Ecology in Madagascar-},
  year    = 1974
}

@book{Jones1973,
  author   = {O.A. Jones and Robert Endean},
  keywords = {tributors},
  title    = {Biology and geology of coral reefs. Volume I: Geology 1},
  url      = {https://cloudflare-ipfs.com/ipfs/bafykbzaceakbeam64ev4xr7hw2hjxto7uxeo3ij55zvna7osguxwfqkzfvxim?filename=Owen Arthur Jones (Auth.) - Biology and Geology of Coral Reefs. Geology 1 (1973, Academic press).pdf},
  year     = 1973,
  doi      = {10.1016/b978-0-12-395526-5.50012-2}
}

@book{Jones1977,
  author = {O.A. Jones and Robert Endean},
  title  = {Biology and geology of coral reefs. Volume IV: Geology 2},
  url    = {https://cloudflare-ipfs.com/ipfs/bafykbzaceb5pizxwkpo6ppg3uiaqfriwdp6jnbruthzqfhj4pyydqysm6pblk?filename=O.A. Jones (Eds.) - Biology and Geology of Coral Reefs. Geology 2 (1977).pdf},
  year   = 1977,
  isbn   = {0123896029}
}

@article{Jones2010,
  abstract = {We address the problem of directable weathering of exposed concave rock for use in computer-generated animation or games. Previous weathering models that admit concave surfaces are computationally inefficient and difficult to control. In nature, the spheroidal and cavernous weathering rates depend on the surface curvature. Spheroidal weathering is fastest in areas with large positive mean curvature and cavernous weathering is fastest in areas with large negative mean curvature. We simulate both processes using an approximation of mean curvature on a voxel grid. Both weathering rates are also influenced by rock durability. The user controls rock durability by editing a durability graph before and during weathering simulation. Simulations of rockfall and colluvium deposition further improve realism. The profile of the final weathered rock matches the shape of the durability graph up to the effects of weathering and colluvium deposition. We demonstrate the top-down directability and visual plausibility of the resulting model through a series of screenshots and rendered images. The results include the weathering of a cube into a sphere and of a sheltered inside corner into a cavern as predicted by the underlying geomorphological models. \textcopyright{} 2010 IEEE.},
  author   = {Matthew Beardall and Joseph Butler and McKay Farley and Michael D. Jones},
  doi      = {10.1109/TVCG.2009.39},
  isbn     = 2008050068,
  issn     = 10772626,
  issue    = 1,
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {Modeling packages,Physically based modeling},
  pages    = {81--94},
  pmid     = 19910663,
  title    = {Directable weathering of concave rock using curvature estimation},
  volume   = 16,
  url      = {https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=1109\&context=facpub},
  year     = 2010
}

@article{Jones2017,
  author  = {Bruce D. Jones and John R. Williams},
  doi     = {10.1108/EC-02-2016-0052},
  issn    = {0264-4401},
  issue   = 4,
  journal = {Engineering Computations},
  month   = 6,
  pages   = {1204--1216},
  title   = {Fast computation of accurate sphere-cube intersection volume},
  volume  = 34,
  url     = {https://www.emerald.com/insight/content/doi/10.1108/EC-02-2016-0052/full/html},
  year    = 2017
}

@article{Ju2002,
  abstract = {This paper describes a new method for contouring a signed grid whose edges are tagged by Hermite data (i.e; exact intersection points and normals). This method avoids the need to explicitly identify and process "features" as required in previous Hermite contouring methods. Using a new, numerically stable representation for quadratic error functions, we develop an octree-based method for simplifying contours produced by this method. We next extend our contouring method to these simpli\textsterling{}ed octrees. This new method imposes no constraints on the octree (such as being a restricted octree) and requires no "crack patching". We conclude with a simple test for preserving the topology of the contour during simplification. Copyright \textcopyright{} 2002 by the Association for Computing Machinery, Inc.},
  author   = {Tao Ju and Frank Losasso and Scott Schaefer and Joe Warren},
  doi      = {10.1145/566570.566586},
  isbn     = 1581135211,
  journal  = {Proceedings of the 29th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '02},
  keywords = {contouring,crack prevention,implicit functions,polyhedral simplification,quadratic error functions},
  pages    = {339--346},
  title    = {Dual contouring of hermite data},
  year     = 2002
}

@article{Jueterbock2021,
  abstract = {Due to rising global surface temperatures, Arctic habitats are becoming thermally suitable for temperate species. Whether a temperate species can immigrate into an ice-free Arctic depends on its ability to tolerate extreme seasonal fluctuations in daylength. Thus, understanding adaptations to polar light conditions can improve the realism of models predicting poleward range expansions in response to climate change. Plant adaptations to polar light have rarely been studied and remain unknown in seagrasses. If these ecosystem engineers can migrate polewards, seagrasses will enrich biodiversity, and carbon capture potential in shallow coastal regions of the Arctic. Eelgrass (Zostera marina) is the most widely distributed seagrass in the northern hemisphere. As the only seagrass species growing as far north as 70\textdegree{}N, it is the most likely candidate to first immigrate into an ice-free Arctic. Here, we describe seasonal (and diurnal) changes in photosynthetic characteristics, and in genome-wide gene expression patterns under strong annual fluctuations of daylength. We compared PAM measurements and RNA-seq data between two populations at the longest and shortest day of the year: (1) a Mediterranean population exposed to moderate annual fluctuations of 10–14 h daylength and (2) an Arctic population exposed to high annual fluctuations of 0–24 h daylength. Most of the gene expression specificities of the Arctic population were found in functions of the organelles (chloroplast and mitochondrion). In winter, Arctic eelgrass conserves energy by repressing respiration and reducing photosynthetic energy fluxes. Although light-reactions, and genes involved in carbon capture and carbon storage were upregulated in summer, enzymes involved in CO2 fixation and chlorophyll-synthesis were upregulated in winter, suggesting that winter metabolism relies not only on stored energy resources but also on active use of dim light conditions. Eelgrass is unable to use excessive amounts of light during summer and demonstrates a significant reduction in photosynthetic performance under long daylengths, possibly to prevent photoinhibition constrains. Our study identified key mechanisms that allow eelgrass to survive under Arctic light conditions and paves the way for experimental research to predict whether and up to which latitude eelgrass can potentially migrate polewards in response to climate change.},
  author   = {Alexander Jueterbock and Bernardo Duarte and James Coyer and Jeanine L. Olsen and Martina Elisabeth Luise Kopp and Irina Smolina and Sophie Arnaud-Haond and Zi Min Hu and Galice Hoarau},
  doi      = {10.3389/fpls.2021.745855},
  issn     = {1664462X},
  issue    = {December},
  journal  = {Frontiers in Plant Science},
  keywords = {Arctic light,carbon capture,climate change,daylength,eelgrass (Zostera marina),energy storage,photosynthesis,respiration},
  title    = {Adaptation of Temperate Seagrass to Arctic Light Relies on Seasonal Acclimatization of Carbon Capture and Metabolism},
  volume   = 12,
  year     = 2021
}

@book{Kaandorp2001,
  author   = {J A Kaandorp and J E K\"{u}bler},
  isbn     = {3-540-67700-33},
  keywords = {Fractal},
  pages    = 189,
  title    = {The Algorithmic Beauty of Seeweeds, Sponges, and Corals},
  url      = {https://beckassets.blob.core.windows.net/product/readingsample/540349/9783540677000\_excerpt\_001.pdf},
  year     = 2001
}

@article{Kalfaoglu,
  abstract = {In this work, we combine 3D convolution with late temporal modeling for action recognition. For this aim, we replace the conventional Temporal Global Average Pooling (TGAP) layer at the end of 3D convolutional architecture with the Bidirectional Encoder Representations from Transformers (BERT) layer in order to better utilize the temporal information with BERT's attention mechanism. We show that this replacement improves the performances of many popular 3D convolution architectures for action recognition, including ResNeXt, I3D, SlowFast and R(2+1)D. Moreover, we provide the-state-of-the-art results on both HMDB51 and UCF101 datasets with 85.10\% and 98.69\% top-1 accuracy, respectively. The code is publicly available.},
  author   = {M. Esat Kalfaoglu and Sinan Kalkan and A. Aydin Alatan},
  keywords = {3D Convolution,Action Recognition,BERT,Late Tem-poral Modeling,Temporal Attention},
  month    = 8,
  title    = {Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition},
  url      = {http://arxiv.org/abs/2008.01232},
  year     = 2020
}

@article{Kamal2007,
  abstract = {In this paper, we propose a novel approach towards parametrically controlled artificial terrain generation. Our proposed method focuses on generation of terrains having mountains of prespecified height and spread of base region and peak nearly at a prespecified location. Means of performing advanced tuning on the terrain to produce unusual artifacts on the terrain is also demonstrated and how our algorithm performs better in comparison with the well known terrain generation algorithms when used to solve the same problem is observed. Copyright \textcopyright{} 2007 by the Association for Computing Machinery, Inc.},
  author   = {K. Raiyan Kamal and Yusuf Sarwar Uddin},
  doi      = {10.1145/1321261.1321264},
  isbn     = 9781595939128,
  issue    = 212,
  journal  = {Proceedings - GRAPHITE 2007, 5th International Conference on Computer Graphics and Interactive Techniques in Australasia and Southeast Asia},
  keywords = {controlled terrain generation,parametric control,terrain generation},
  pages    = {17--23},
  title    = {Parametrically controlled terrain generation},
  volume   = 1,
  year     = 2007
}

@book{Kampis2009,
  abstract = {10th Europian Conference, ECAL 2009, Budapest, Hungary September 2009},
  author   = {George Kampis and Istavan Karsai},
  doi      = {10.1007/978-3-642-21314-4},
  isbn     = 9783642208317,
  journal  = {Media},
  note     = {Read at p. 278},
  pages    = 524,
  title    = {Advances in Artificial Life, Darwin Meets von Neumann},
  url      = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=tWsy\_aPMjVcC\&amp;oi=fnd\&amp;pg=PP2\&amp;dq=Multi-Agent-Based+Simulation+XI+InternationalWorkshop,+MABS+2010+Toronto,+Canada,+May+11,+2010+Revised+Selected+Papers\&amp;ots=6I26mOjTGO\&amp;sig=NjOhain2FrF8zFti},
  year     = 2009
}

@article{Kant1992,
  abstract    = {The author introduces a method to optimize the required area, minimum angle and number of bends of planar drawings of graphs on a grid. The main tool is a new type of ordering on the vertices and faces of triconnected planar graphs. With this method linear time and space algorithms can be designed for many graph drawing problems. He shows that every triconnected planar graph G can be drawn convexly with straight lines on an (2n-4)(n-2) grid. If G has maximum degree four (three), then G can be drawn orthogonal with at most (/sup 3n//2)+3 (at most (n/2)+1) bends on an nn grid ((n/2)(n/2) grid, respectively). If G has maximum degree d, then G can be drawn planar on an (2n-6)(3n-6) grid with minimum angle larger than 1//sub d-2/ radians and at most 5n-15 bends. These results give in some cases considerable improvements over previous results, and give new bounds in other cases. Several other results, e.g. concerning visibility representations, are included.},
  author      = {Goos Kant},
  doi         = {10.1109/SFCS.1992.267814},
  isbn        = {0818629002},
  issn        = {02725428},
  issue       = {October},
  journal     = {Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS},
  pages       = {101--110},
  title       = {Drawing planar graphs using the canonical ordering},
  volume      = {1992-Octob},
  year        = 1992,
  institution = {Utrecht University},
  keywords    = {Performance analysis,Performance indices,Property investment},
  url         = {https://builtsurvey.utm.my/}
}

@article{Kapp2020,
  abstract  = {In computer graphics populating a large-scale natural scene with plants in a fashion that both reflects the complex interrelationships and diversity present in real ecosystems and is computationally efficient enough to support iterative authoring remains an open problem. Ecosystem simulations embody many of the botanical influences, such as sunlight, temperature, and moisture, but require hours to complete, while synthesis from statistical distributions tends not to capture fine-scale variety and complexity. Instead, we leverage real-world data and machine learning to derive a canopy height model (CHM) for unseen terrain provided by the user. Trees in the canopy layer are then fitted to the resulting CHM through a constrained iterative process that optimizes for a given distribution of species, and, finally, an understorey layer is synthesised using distributions derived from biome-specific undergrowth simulations. Such a hybrid data-driven approach has the advantage that it incorporates subtle biotic, abiotic, and disturbance factors implicitly encoded in the source data and evidences accepted biological behaviour, such as self-thinning, climatic adaptation, and gap dynamics.},
  author    = {Konrad Kapp and James Gain and Eric Gu\'{e}rin and Eric Galin and Adrien Peytavie},
  doi       = {10.1145/3414685.3417848},
  issn      = 15577368,
  issue     = 6,
  journal   = {ACM Transactions on Graphics},
  keywords  = {ecosystem simulation,natural phenomena},
  month     = 11,
  publisher = {Association for Computing Machinery},
  title     = {Data-driven authoring of large-scale ecosystems},
  volume    = 39,
  year      = 2020
}

@inbook{Karavelas2002,
  author = {Menelaos I. Karavelas and Mariette Yvinec},
  doi    = {10.1007/3-540-45749-6\_52},
  pages  = {586--598},
  title  = {Dynamic Additively Weighted Voronoi Diagrams in 2D},
  url    = {http://link.springer.com/10.1007/3-540-45749-6\_52},
  year   = 2002
}

@article{Karpenko2002,
  author  = {Olga Karpenko and John F. Hughes and Ramesh Raskar},
  doi     = {10.1111/1467-8659.00709},
  issn    = {0167-7055},
  issue   = 3,
  journal = {Computer Graphics Forum},
  pages   = {585--594},
  title   = {Free-form sketching with variational implicit surfaces},
  volume  = 21,
  year    = 2002
}

@article{Karwolowski2002,
  author      = {Radoslaw Mateusz Karwolowski},
  institution = {University of Calgary},
  title       = {Improving the Process of Plant Modeling : The L + C Modeling Language},
  url         = {http://algorithmicbotany.org/papers/radekk.dis2002.pdf},
  year        = 2002
}

@misc{Kass1988,
  abstract  = {A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching. We have used snakes successfully for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest.},
  author    = {Michael Kass and Andrew Witkin and Demetri Terzopoulos},
  journal   = {International Journal of Computer Vision},
  pages     = {321--331},
  publisher = {KIuwer Academic Publishers},
  title     = {Snakes: Active Contour Models},
  year      = 1988
}

@article{Kaufman1993,
  author    = {A. Kaufman and D. Cohen and R. Yagel},
  doi       = {10.1109/MC.1993.274942},
  issn      = {0018-9162},
  issue     = 7,
  journal   = {Computer},
  month     = 7,
  pages     = {51--64},
  publisher = {IEEE},
  title     = {Volume graphics},
  volume    = 26,
  url       = {http://ieeexplore.ieee.org/document/274942/},
  year      = 1993
}

@article{Kavan2014,
  author  = {Ladislav Kavan},
  issue   = 3,
  journal = {SIGGRAPH Course 2014 -- Skinning: Real-time Shape Deformation},
  pages   = {1--11},
  title   = {Part I: Direct Skinning Methods and Deformation Primitives},
  url     = {https://skinning.org/direct-methods.pdf},
  year    = 2014
}

@article{Kelley1988,
  abstract = {The major process affecting the configuration and evolution of terrain is erosion by flowing water. Landscapes thus reflect the branching patterns of river and stream networks. The network patterns contain information that is characteristic of the landscape's topographic features. It is therefore possible to create an approximation to natural terrain by simulating the erosion of stream networks on an initially uneroded surface. Empirical models of stream erosion were used us a basis for the model presented here. Stream networks of various sizes and shapes are created by the model from a small number of initial parameters. The eroded surface is represented as a surface under tension, using the tension parameter to shape the profiles of valleys created by the stream networks. The model can be used to generate terrain databases for flight simulation and computer animation applications.},
  author   = {Alex D. Kelley and Michael C. Malin and Gregory M. Nielson},
  doi      = {10.1145/54852.378519},
  isbn     = {0897912756},
  issue    = {July},
  journal  = {Proceedings of the 15th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1988},
  keywords = {Database amplification,Drainage network simulation,Erosion models,Structural models,Surfaces under tension},
  pages    = {263--268},
  title    = {Terrain simulation using a model of stream erosion},
  volume   = {M},
  year     = 1988
}

@article{Kelly2007a,
  abstract = {Contemporary 3D games are often situated within large urban environments. This necessitates a time-consuming and expensive content creation process involving the modelling of vast amounts of geometric detail: including terrain, roads, buildings, and other as- sociated features. We present a system called Citygen that aims to automate as much of this as possible by employing procedural generation methods to rapidly create the urban geometry typical of a modern city. Procedural methods have long been used within the graphics and game development communities to generate natural phenomena such as plants and trees. We employ these methods to generate the underlying road networks that form the structure of cities and urban neighbourhoods. These road networks are automatically mapped to any supplied terrain model, and adapt themselves to the specific geometry of the underlying terrain. Building footprints are automatically extracted from the resulting model and buildings can then be inserted either procedurally or by hand. Our system is unique in that it is designed to allow developers hands- on interactive control over the generation process. We achieve this by providing an interface allowing the user to directly manipulate geometric elements such as road intersection nodes, and to directly control and specify many aspects of the procedural generation. The results are updated in real time, thus facilitating an interactive design process.},
  author   = {George Kelly and Hugh McCabe},
  isbn     = 9781902560182,
  journal  = {Fifth International Conference on Game Design and Technology},
  note     = {Peut-\^{e}tre \`{a} associer \`{a} la simulation de karst de A. Peytavie},
  pages    = {8–16},
  title    = {Citygen: An interactive system for procedural city generation},
  url      = {http://www.citygen.net/files/citygen\_gdtw07.pdf},
  year     = 2007
}

@article{Kench2022,
  abstract  = {Sea-level rise is expected to outpace the capacity of coral reefs to grow and maintain their wave protection function, exacerbating coastal flooding and erosion of adjacent shorelines and threatening coastal communities. Here we present a new method that yields highly-resolved direct measurements of contemporary reef accretion on a Maldivian atoll reef rim, the critical zone that induces wave breaking. Results incorporate the suite of physical and ecological processes that contribute to reef accumulation and show growth rates vary from 6.6 \pm{} 12.5 mm.y-1 on the reef crest, and up to 3.1 \pm{} 10.2 mm.y-1, and -0.5 \pm{} 1.8 mm.yr-1 on the outer and central reef flat respectively. If these short-term results are maintained over decades, the reef crest could keep pace with current sea-level rise. Findings highlight the need to resolve contemporary reef accretion at the critical wave dissipation zone to improve predictions of future reef growth, and re-evaluate exposure of adjacent shorelines to coastal hazards.},
  author    = {Paul S. Kench and Edward P. Beetham and Tracey Turner and Kyle M. Morgan and Susan D. Owen and Roger F. McLean},
  doi       = {10.1038/s43247-021-00338-w},
  issn      = 26624435,
  issue     = 1,
  journal   = {Communications Earth and Environment},
  pages     = {1--12},
  publisher = {Springer US},
  title     = {Sustained coral reef growth in the critical wave dissipation zone of a Maldivian atoll},
  volume    = 3,
  year      = 2022
}

@inproceedings{Kent1992,
  abstract  = {Techniques that transform one two-dimensionaf image into another have gained widespread use m recent yeara. Extending these tech- niques to transform pairs of 3D objects, as opposed to 2D images of the objects, providea several advsntagea, including the ability to sn- imate the objects independently of the transformation. This paper presents an algorithm for computing such transformations. The al- gorithm merges the topological structures of a pair of 3D polyhedral models into a common vertex/edgeJface network. This allows trsms- formations from one object to the other to be easily computed by in- terpolating between corresponding v\@ex positions.},
  author    = {James R. Kent and Wayne E. Carlson and Richard E. Parent},
  city      = {New York, NY, USA},
  doi       = {10.1145/133994.134007},
  isbn      = {0897914791},
  issue     = {July},
  booktitle = {Proceedings of the 19th annual conference on Computer graphics and interactive techniques},
  keywords  = {computer-aidedgeo-,computeranimation,interpolation,metric design,shape trans-},
  month     = 7,
  pages     = {47--54},
  publisher = {ACM},
  title     = {Shape transformation for polyhedral objects},
  url       = {https://dl.acm.org/doi/10.1145/133994.134007},
  year      = 1992
}

@article{Kessing2012,
  abstract = {Current game worlds often fall short in providing consistency between the visual representation of the world and the way it feels, behaves, and reacts. This problem partly originates from the goal-oriented and cost-effective nature of the game development process, which mostly favors ad hoc solutions for one particular game, rather than investing in concepts like reusability and emergent gameplay. In broader terms, we observe that game worlds miss semantics, and we argue that its deployment has the potential to bring about the consistency missing in their content. Therefore, we present a novel approach aimed at enriching virtual entities in game worlds with information about their roles, how they relate to others, and how they can affect and interact with players, NPCs, and with each other. We discuss several requirements to achieve these goals, and introduce a semantic model to represent game worlds. In order to support and validate this model, we have developed Entika, a framework to facilitate the deployment of semantics during game development, as well as its maintenance during run-time. Furthermore, we briefly discuss several applications that demonstrate the power of this semantic model for game worlds. After careful evaluation of our semantic game world model and framework, we conclude that a semantically rich world representation can substantially assist designers in creating much more consistent game worlds.},
  author   = {Jassin Kessing and Tim Tutenel and Rafael Bidarra},
  doi      = {10.1145/2538528.2538530},
  journal  = {3rd Workshop on Procedural Content Generation in Games, PCG 2012, Organized in Conjunction with the Foundations of Digital Games Conference, FDG 2012},
  keywords = {Game worlds,Object interaction,Semantics},
  pages    = {40--48},
  title    = {Designing semantic game worlds},
  year     = 2012
}

@article{Khan2015,
  abstract = {This paper presents an extension of the standard occupancy grid for 3D environment mapping. The presented approach adds a fusion process after the occupancy update which modifies the resolution of the grid cells in an incremental manner. Consequently, the proposed approach requires fewer grid cells for 3D representation in comparison to a standard occupancy grid. The resolution adaptation process is based on the occupancy probabilities of the grid cells and leads to the relaxation of the cubic grid cell assumption common to most 3D occupancy grids. The aim of this paper is to show the advantage of the proposed incremental fusion process which leads to the approximation of the 3D environment using rectangular cuboids. Evaluation on a large scale dataset and comparison to the state of the art shows that the proposed approach has faster access time for all occupied grid cells and requires a smaller number of cells for 3D environment representation.},
  author   = {Sheraz Khan and Dirk Wollherr and Martin Buss},
  doi      = {10.1109/ICRA.2015.7139480},
  isbn     = 9781479969234,
  issn     = 10504729,
  issue    = {June},
  journal  = {Proceedings - IEEE International Conference on Robotics and Automation},
  pages    = {2132--2139},
  title    = {Adaptive rectangular cuboids for 3D mapping},
  volume   = {2015-June},
  url      = {https://mediatum.ub.tum.de/doc/1271436/1271436.pdf},
  year     = 2015
}

@article{Kim2019,
  abstract = {This paper describes graph-based Wave Function Collapse algorithm for procedural content generation. The goal of this system is to enable a game designer to procedurally create key content elements in the game level through simple association rule input. To do this, we propose a graph-based data structure that can be easily integrated with a navigation mesh data structure in a three-dimensional world. With our system, if the user inputs the minimum association rule, it is possible to effectively perform procedural content generation in the three-dimensional world. The experimental results show that the Wave Function Collapse algorithm, which is a texture synthesis algorithm, can be extended to a non-grid shape with high controllability and scalability.},
  author   = {Hwanhee Kim and Seongtaek Lee and Hyundong Lee and Teasung Hahn and Shinjin Kang},
  doi      = {10.1109/CIG.2019.8848019},
  isbn     = 9781728118840,
  issn     = 23254289,
  issue    = {October},
  journal  = {IEEE Conference on Computatonal Intelligence and Games, CIG},
  keywords = {Procedural Content Generation (PCG),Wave Function Collapse (WFC)},
  pages    = {1--5},
  title    = {Automatic generation of game content using a graph-based wave function collapse algorithm},
  volume   = {2019-Augus},
  year     = 2019
}

@article{Kim2020,
  abstract = {This paper describes graph-based Wave Function Collapse algorithm for procedural content generation. The goal of this system is to enable a game designer to procedurally create key content elements in the game level through simple association rule input. To do this, we propose a graph-based data structure that can be easily integrated with a navigation mesh data structure in a three-dimensional world. With our system, if the user inputs the minimum association rule, it is possible to effectively perform procedural content generation in the three-dimensional world. The experimental results show that the Wave Function Collapse algorithm, which is a texture synthesis algorithm, can be extended to non-grid shape content with high controllability and scalability.},
  author   = {Hwanhee Kim and Teasung Hahn and Sookyun Kim and Shinjin Kang},
  doi      = {10.1587/transinf.2019EDP7295},
  issn     = {0916-8532},
  issue    = 8,
  journal  = {IEICE Transactions on Information and Systems},
  keywords = {Game Content,Navigation Mesh,Procedural Content Generation (PCG),Voronoi Diagram,Wave Function Collapse (WFC)},
  month    = 8,
  pages    = {1901--1910},
  title    = {Graph Based Wave Function Collapse Algorithm for Procedural Content Generation in Games},
  volume   = {E103.D},
  url      = {https://www.jstage.jst.go.jp/article/transinf/E103.D/8/E103.D\_2019EDP7295/\_article},
  year     = 2020
}

@inproceedings{Kingma2015,
  abstract  = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  author    = {Diederik P. Kingma and Jimmy Lei Ba},
  booktitle = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
  month     = 12,
  publisher = {International Conference on Learning Representations, ICLR},
  title     = {Adam: A method for stochastic optimization},
  url       = {https://arxiv.org/abs/1412.6980v9},
  year      = 2015
}

@article{Kingon2013,
  abstract    = {This dissertation starts by evaluating the applicability of using a commercially available, cost-effective, sidescan sonar system to detect benthic habitats, in particular hardbottom habitats, in the nearshore northeastern Gulf of Mexico. To illustrate the capability of low-cost devices in mapping benthic habitats, I tested the Humminbird 997c SI unit marketed to fishermen at a cost of approximately ,000) Marine Sonic system. This analysis verified that the classification results of sand and hardbottom habitats based on data collected using the Humminbird sidescan system were similar to those produced using the traditional and more expensive Marine Sonic sidescan equipment. Thirty-three sites in total were then mapped with the Humminbird system and sampled using dive surveys. Seascape pattern metrics were calculated from the classified Humminbird sidescan maps. The dive survey data included measurements of the geomorphology, physical attributes of the water column (e.g. temperature, depth, and visibility), and coverage and heights of the benthic biota. The coverage and heights of the biota were compared to the geomorphology, seascape, and water column variables to identify patterns in the distribution and community composition of the sessile organisms. Within the study area, visibility was found to vary with longitude. Sites in the east showed higher visibility than sites in the west and this may be driving the community patterns that were identified. Relationships were identified between the four most abundant taxa (sponges, hard corals, brown algae, and red algae) and the geomorphology, physical, and seascape variables. However, the relationships were often complicated and the biota did not strictly follow gradients or boundaries in substrate or geoform (physical feature or landform), even though these features are often used to classify habitats and biotopes. The percent cover of rock was a significant geomorphology variable for red algae and hard coral coverage while geoforms were related to the heights of sponges and brown algae. Seascape metrics also had significant effects on the sessile biota particularly related to patch edges, heterogeneity, core areas, nearest neighbor distances, and the percent cover of hardbottom. Despite the fact that sessile organisms do not move much, if at all following their planktonic larval stage, the surrounding seascape contributes to the patterns we see in their distribution, coverage, and heights. The third chapter focuses on applying a new classification standard to the benthic habitats in the nearshore northeastern Gulf of Mexico. The United States Geological Survey (USGS) has a standardized system for classifying terrestrial and aquatic habitats found across the U.S. which has been in place for almost 40 years. This classification standard does not include marine and most coastal habitats. Therefore, marine researchers developed a number of classification systems for coastal and marine habitats relevant to their local or regional studies in U.S. waters. A national standardized method for classifying marine and coastal habitats was not adopted until recently. The Coastal and Marine Ecological Classification Standard (CMECS) developed by the Federal Geographic Data Committee was approved last year and is intended to fill the gap in U.S. marine habitat classification standards. Since the classification standard is in its infancy, it has not been applied in many geographic areas. My third chapter is the first study to apply the CMECS to the benthic habitats in the nearshore northeastern Gulf of Mexico off the coast of northwest Florida. Hardbottom and sand habitats are characteristic of this area. In the previous chapter, the underwater surveys revealed that the dominant taxa at the sites within the study area were hard corals, sponges, and macroalgae. I used CMECS to broadly classify the sites where the surveys were completed. I found that habitat heterogeneity and a wide variety of environmental characteristics influenced the distribution of taxa at the local scale. This made applying CMECS at scales finer than the composite study area unfeasible without major modifications. CMECS worked well for classifying the broad scale in this region but was not appropriate for classifying complex fine-scale biotopes. (Abstract shortened by UMI.)},
  author      = {Kelly Kingon},
  isbn        = 9781303433153,
  institution = {Florida State University},
  keywords    = {0329:Ecology,0368:Physical geography,0799:Remote sensing,Biological sciences,Classification systems,Earth sciences,Ecology,Gulf of Mexico,Hardbottom,Physical geography,Remote sensing,Sessile biota,Sidescan sonar,Spatial analysis},
  title       = {Mapping, classification, and spatial variation of hardbottom habitats in the northeastern Gulf of Mexico},
  url         = {https://search.proquest.com/docview/1468443256?accountid=6180\%0Ahttp://dw2zn6fm9z.search.serialssolution.com?ctx\_ver=Z39.88-2004\&ctx\_enc=info:ofi/enc:UTF-8\&rfr\_id=info:sid/ProQuest+Dissertations+\%26+Theses+Global\&rft\_val\_fmt=info:ofi/fmt:kev:mtx:dissertat},
  year        = 2013
}

@inbook{Kinsey1979,
  author  = {D.W. Kinsey and P.J. Davies},
  journal = {Biogeochemical Cycling of Mineral-Forming Elements},
  pages   = {131--162},
  title   = {Carbon turnover, calcification and growth in coral reef},
  volume  = 3,
  year    = 1979
}

@article{Klette,
  author  = {Reinhard Klette},
  doi     = {10.1016/S1571-0653(04)00495-0},
  issn    = 15710653,
  journal = {Electronic Notes in Discrete Mathematics},
  month   = 3,
  pages   = {302--324},
  title   = {Combinatorics on Adjacency Graphs and Incidence Pseudographs},
  volume  = 12,
  url     = {https://linkinghub.elsevier.com/retrieve/pii/S1571065304004950},
  year    = 2003
}

@misc{Knoblauch,
  abstract = {Today's traffic environment is not well adapted to the needs of the older pedestrian. Unfortunately, except in the case of children, little is known about the characteristics and behavior of pedestrians. Although the simple fact that older pedestrians walk more slowly than younger ones is easily supported by field data, existing data on walking speeds and start-up time (i.e., the time from the onset of a Walk signal until the pedestrian steps off the curb) have many shortcomings. A series of field studies was conducted to quantify the walking speed and start-up time of pedestrians of various ages under different conditions. Sixteen crosswalks in four urban areas were studied. Data were collected on walking speeds and start-up times relative to site and environmental factors, including street width, posted speed, curb height, grade, number of vehicle travel lanes, signal cycle length, pedestrian-signal type, street functional classification, crosswalk type, and channelization. Data on a subject group of pedestrians who appeared to be 65 years of age or older and a control group of pedestrians under age 65 were collected. Results indicate a broad range of walking speeds among pedestrians. The 15th-percentile walking speed for younger pedestrians (ages 14 to 64) was 1.25 m/sec (4.09 ft/sec); for older pedestrians (ages 65 and over) it was 0.97 m/sec (3.19 ft/sec). For design purposes values of 1.22 m/sec (4 ft/sec) for younger pedestrians and 0.91 m/sec (3 ft/sec) for older pedestrians are appropriate. Results also indicated that walking rates are influenced by a variety of factors, including the functional classification and vehicle volumes on the street being crossed, the street width, weather conditions, the number of pedestrians crossing in a group, the signal cycle length, the timing of the various pedestrian-signal phases, whether right turn on red is allowed, pedestrian signals, medians , curb cuts, crosswalk markings, stop lines, and on-street parking. However, for each of these factors, the effect on crossing speeds, although statistically significant, is not meaningful for design. The older road user has received much attention during the past decade, and with good reason. The proportion of those over age 65 in the North American population is increasing and will continue to increase dramatically. Research related to older road users has also increased. In 1992 the Federal Highway Administration was sponsoring eight major research projects on older road users. An examination of these projects indicates that older drivers, not older pedestrians , receive the majority of attention in research related to older road users. Today's traffic environment is not well adapted to the needs of the older pedestrian. Unfortunately, except in the case of children, very little is known about the characteristics and behavior of pedestrians. The simple fact that older pedestrians walk more slowly than younger ones is easily supported by field data; however, the existing data on walking speeds and start-up time (i.e., the time from the TRANSPORTATION RESEARCH RECORD 1538 27 onset of a Walk signal until the pedestrian steps off the curb) have many shortcomings. For example, Dahlstedt (1) instructed a group of people aged 70 or older to cross an intersection at fast, very fast, or normal speed. Fast for about 60 percent of the group was less than 1.22 m/sec (4 ft/sec); normal for 90 percent of the group was also less than 1.22 m/sec (4 ft/sec), and the 85th-percentile speed was about 0.67 m/sec (2.2 ft/sec). The Manual on Uniform Traffic Control Devices (MUTCD) (2) suggests a walking speed of 1.22 m/sec (4 ft/sec) for traffic signal timing. A literature review by McGee, et al. (3) indicated that many pedestrians-perhaps 30 percent of the population, many of whom are older-do not normally walk that quickly. In fact, the Traffic Control Devices Handbook (TCDH) (4) also notes that one-third of all pedestrians cross more slowly, with 15 percent at or below 1.06 m/sec (3.5 ft/sec). TCDH states that "those having slower walking speeds have the moral and legal right to complete the crossing once they have entered the intersection." The Traffic Engineering Handbook (5) suggests that 0.91 to 0.99 m/sec (3 to 3.25 ft/sec) would be a more appropriate value to use for traffic signal timing. An Institute of Transportation Engineers committee concerned with pedestrian issues (6) conducted a survey at a Florida location with a large population of elderly pedestrians. The committee recommended 0.76 m/sec (2.5 ft/sec) as an appropriate walk speed (for locations with a high volume of elderly pedestrians), and found this speed to be adequate for 87 percent of pedestrians observed. However, walking speeds are influenced by environmental, traffic, and pedestrian characteristics. The effects of terrain on walking speeds are unknown, although it can be expected that the elderly would be affected more when walking up or down a grade than the young. Similarly, it can be expected that the elderly would react more strongly to higher vehicular densities and traffic speeds, out of a fear of traffic. Moore (7) noted that the closer the approaching vehicle, the faster the mean crossing time-1.52 m/sec (5 ft/sec) when the approaching vehicle was 3 sec away, 1.22 m/sec (4 ft/sec) when the approaching vehicle was not too close. Finally, pedestrian speed on sidewalks and crosswalks is strongly related to the number of pedestrians in the flow. The relationship between speed, flow, and space occupied (i.e., density) for a representative population group has been examined by Fruin (8) and others. However , the abilities of the elderly in crowds have not yet been documented. Because of the shortcomings in data on the walking speeds of older pedestrians a series of field studies was conducted to quantify the walking speed and start-up time of pedestrians of various ages under different environmental conditions.},
  author   = {Richard L Knoblauch and Martin T Pietrucha and Marsha Nitzburg},
  title    = {Field Studies of Pedestrian Walking Speed and Start-Up Time}
}

@article{Koca2014,
  abstract  = {Terrain rendering is a crucial part of many real-time applications. The easiest way to process and visualize terrain data in real time is to constrain the terrain model in several ways. This decreases the amount of data to be processed and the amount of processing power needed, but at the cost of expressivity and the ability to create complex terrains. The most popular terrain representation is a regular 2D grid, where the vertices are displaced in a third dimension by a displacement map, called a heightmap. This is the simplest way to represent terrain, and although it allows fast processing, it cannot model terrains with volumetric features. Volumetric approaches sample the 3D space by subdividing it into a 3D grid and represent the terrain as occupied voxels. They can represent volumetric features but they require computationally intensive algorithms for rendering, and their memory requirements are high. We propose a novel representation that combines the voxel and heightmap approaches, and is expressive enough to allow creating terrains with caves, overhangs, cliffs, and arches, and efficient enough to allow terrain editing, deformations, and rendering in real time.},
  author    = {\c{C}etin Koca and U\u{g}ur G\"{u}d\"{u}kbay},
  doi       = {10.1080/13658816.2014.900560},
  issn      = 13623087,
  issue     = 9,
  journal   = {International Journal of Geographical Information Science},
  keywords  = {caves,cliffs,heightmap,overhangs,terrain editing,terrain representation,terrain visualization,voxel},
  pages     = {1821--1847},
  publisher = {Taylor \& Francis},
  title     = {A hybrid representation for modeling, interactive editing, and real-time visualization of terrains with volumetric features},
  volume    = 28,
  url       = {http://dx.doi.org/10.1080/13658816.2014.900560 http://repository.bilkent.edu.tr/bitstream/handle/11693/26473/A hybrid representation for modeling\%2C interactive editing\%2C and real-time visualization of terrains with volumetric features.pdf?sequence=1},
  year      = 2014
}

@article{Kocurek2005,
  abstract = {The interpretation of aeolian dune-field patterns as self-organizing complex systems is a new paradigm in which pattern evolution may be addressed. Computer simulations, supported by field and experimental data, indicate that a given wind regime produces a simple dune-field pattern. Dune type and crest orientation are determined by wind regime and pattern ordering occurs through dune-dune interactions over time. Because dunes reorient only at their crest terminations with a change in wind regime, the rate of formation of a new pattern of small dunes is typically faster than the rate of reorientation of the existing pattern, resulting in the superposition of simple patterns to give rise to complex patterns. Complex patterns are distinct from spatial changes in a simple pattern, and from the type of superposition that characterizes compound/complex dunes. Complex patterns necessarily indicate a rate of pattern formation that is rapid compared to the rate of sediment accumulation on the depositional surface. \textcopyright{} 2005 Elsevier B.V. All rights reserved.},
  author   = {Gary Kocurek and Ryan C. Ewing},
  doi      = {10.1016/j.geomorph.2005.05.005},
  issn     = {0169555X},
  issue    = {1-4},
  journal  = {Geomorphology},
  keywords = {Aeolian,Complex systems,Sand-dune patterns,Self-organization},
  month    = 12,
  pages    = {94--105},
  title    = {Aeolian dune field self-organization - Implications for the formation of simple versus complex dune-field patterns},
  volume   = 72,
  year     = 2005
}

@article{Koelling2009,
  author    = {Martin Koelling and Jody Michael and Gilbert Camoin and Yasufumi Iryu and Edouard Bard and Claire Seard},
  doi       = {10.1016/j.gloplacha.2008.07.011},
  issn      = {0921-8181},
  issue     = {1-2},
  journal   = {Global and Planetary Change},
  pages     = {149--159},
  publisher = {Elsevier B.V.},
  title     = {SEALEX -- Internal reef chronology and virtual drill logs from a spreadsheet-based reef growth model},
  volume    = 66,
  url       = {http://dx.doi.org/10.1016/j.gloplacha.2008.07.011},
  year      = 2009
}

@article{Koenig2020,
  abstract = {While lateral boundary conditions are crucial for the physical modeling of ocean dynamics, their estimation may lack accuracy in coastal regions. Data-assimilation has long been used to improve accuracy, but most of the widely-used methods are difficult to implement. We tried a new and an easy-to-implement method to estimate boundary conditions. This method uses data assimilation with a stochastic gradient descent and successive approximations of the boundary conditions. We tested it with twin experiments and a more realistic setting on a tidal model in the lagoon of Ouano, in New-Caledonia. The method proved successful and provided good estimation of the boundary conditions with various settings of subsampling and noise for the pseudo-data in the twin experiments, but there were important oscillations in the experiments with more realistic settings. Here we present those results and discuss the use of our new and easy-to-implement method.},
  author   = {Guillaume Koenig and Clement Aldebert and Cristele Chevalier and Jean Luc Devenon},
  doi      = {10.1016/j.ocemod.2020.101709},
  issn     = 14635003,
  journal  = {Ocean Modelling},
  keywords = {Data assimilation,Parameters identification,Stochastic algorithms,Tidal modeling},
  pages    = {0--45},
  title    = {Identifying lateral boundary conditions for the M2 tide in a coastal model using a stochastic gradient descent algorithm},
  volume   = 156,
  year     = 2020
}

@article{Komosinski1999,
  abstract = {In this paper we describe our attempt to create a nature-like simulation model of artificial creatures. The model includes physical simulation of creatures, their interaction with the environment, their neural network control, and both directed and open-ended evolution. We describe a complex, three-dimensional simulation system, where various fitness criteria can be selected for evolving species, and a spontaneous evolution can be run. The work is still being developed, and we hope to make it a realistic model capable of producing real-life phenomena through an open-ended evolution in a life-like world of stick creatures.},
  author   = {Maciej Komosi\'{n}ski and Szymon Ulatowski},
  doi      = {10.1007/3-540-48304-7\_33},
  isbn     = 3540664521,
  issn     = 16113349,
  issue    = {September},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  pages    = {261--265},
  title    = {Framsticks: Towards a simulation of a nature-like world, creatures and evolution},
  volume   = 1674,
  url      = {https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=46e1984cde2545907a285cb412c6c97a0a5702ec},
  year     = 1999
}

@article{Koren2005,
  abstract = {The spectral approach for graph visualization computes the layout of a graph using certain eigenvectors of related matrices. Two important advantages of this approach are an ability to compute optimal layouts (according to specific requirements) and a very rapid computation time. In this paper, we explore spectral visualization techniques and study their properties from different points of view. We also suggest a novel algorithm for calculating spectral layouts resulting in an extremely fast computation by optimizing the layout within a small vector space. \textcopyright{} 2005 Elsevier Ltd. All rights reserved.},
  author   = {Y. Koren},
  doi      = {10.1016/j.camwa.2004.08.015},
  issn     = {08981221},
  issue    = {11-12},
  journal  = {Computers and Mathematics with Applications},
  keywords = {Eigenvectors,Fiedler vector,Force-directed layout,Graph drawing,Laplacian,Spectral graph theory},
  pages    = {1867--1888},
  title    = {Drawing graphs by eigenvectors: Theory and practice},
  volume   = 49,
  year     = 2005
}

@article{Korpinar2015,
  abstract = {In this paper, we study Bishop equations of parallel curves according to Bishop frame in Euclidean 3-space. We obtain a new characterization of parallel curve by using Bishop frame in E\{double-struck\}3.},
  author   = {Talat K\"{o}rpinar and Vedat Asil and Muhammed T. Sariaydin and Muhsin Incesu},
  doi      = {10.5269/bspm.v33i1.21712},
  issn     = 21751188,
  issue    = 1,
  journal  = {Boletim da Sociedade Paranaense de Matematica},
  keywords = {Bishop frame,Curves,Euclidean 3-space,Parallel curves},
  pages    = {33--39},
  title    = {A characterization for Bishop equations of parallel curves according to Bishop frame in E^3},
  volume   = 33,
  url      = {https://pdfs.semanticscholar.org/15a9/48a43730f644f23489796a8598018c2dcfab.pdf},
  year     = 2015
}

@article{Koschier2022,
  abstract = {Throughout the past decades, the graphics community has spent major resources on the research and development of physics simulators on the mission to computer-generate behaviors achieving outstanding visual effects or to make the virtual world indistinguishable from reality. The variety and impact of recent research based on Smoothed Particle Hydrodynamics (SPH) demonstrates the concept's importance as one of the most versatile tools for the simulation of fluids and solids. With this survey, we offer an overview of the developments and still-active research on physics simulation methodologies based on SPH that has not been addressed in previous SPH surveys. Following an introduction about typical SPH discretization techniques, we provide an overview over the most used incompressibility solvers and present novel insights regarding their relation and conditional equivalence. The survey further covers recent advances in implicit and particle-based boundary handling and sampling techniques. While SPH is best known in the context of fluid simulation we discuss modern concepts to augment the range of simulatable physical characteristics including turbulence, highly viscous matter, deformable solids, as well as rigid body contact handling. Besides the purely numerical approaches, simulation techniques aided by machine learning are on the rise. Thus, the survey discusses recent data-driven approaches and the impact of differentiable solvers on artist control. Finally, we provide context for discussion by outlining existing problems and opportunities to open up new research directions.},
  author   = {Dan Koschier and Jan Bender and Barbara Solenthaler and Matthias Teschner},
  doi      = {10.1111/cgf.14508},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Physical simulation},
  pages    = {737--760},
  title    = {A Survey on SPH Methods in Computer Graphics},
  volume   = 41,
  year     = 2022
}

@article{Krause-Jensen2014,
  abstract = {Warming occurs particularly fast in the Arctic and exerts profound effects on arctic ecosystems. Sea ice-associated ecosystems are projected to decline but reduced arctic sea ice cover also increases the solar radiation reaching the coastal seafloors with the potential for expansion of vegetated habitats, i.e., kelp forests and seagrass meadows. These habitats support key ecosystem functions, some of which may mitigate effects of climate change. Therefore, the likely expansion of vegetated coastal habitats in the Arctic will generate new productive ecosystems, offer habitat for a number of invertebrate and vertebrate species, including provision of refugia for calcifiers from possible threats from ocean acidification, contribute to enhance CO2 sequestration and protect the shoreline from erosion. The development of models allowing quantitative forecasts of the future of vegetated arctic ecosystems requires that key hypotheses underlying such forecasts be tested. Here we propose a set of three key testable hypotheses along with a research agenda for testing them using a broad diversity of approaches, including analyses of paleo-records, space-for-time substitutions and experimental studies. The research agenda proposed would provide a solid underpinning to guide forecasts on the spread of marine macrophytes onto the Arctic with climate change and contribute to balance our understanding of climate change impacts on the arctic ecosystem through a focus on the role of engineering species. Anticipating these changes in ecosystem structure and function is key to develop managerial strategies to maximize these ecosystem services in a future warmer Arctic.},
  author   = {Dorte Krause-Jensen and Carlos M. Duarte},
  doi      = {10.3389/fmars.2014.00077},
  issn     = 22967745,
  issue    = {DEC},
  journal  = {Frontiers in Marine Science},
  keywords = {Arctic,Climate change,Ecological function,Macroalgae,Marine vegetation,Sea-ice,Seagrasses,Warming},
  pages    = {1--10},
  title    = {Expansion of vegetated coastal ecosystems in the future Arctic},
  volume   = 1,
  year     = 2014
}

@misc{Krempf1927,
  author      = {Armand Krempf},
  institution = {Gouvernement g\'{e}n\'{e}ral de l'Indochine},
  title       = {La forme des r\'{e}cifs coralliens et le r\'{e}gime des vents alternants},
  url         = {https://aquadocs.org/bitstream/handle/1834/35861/memoire2.pdf?sequence=1},
  year        = 1927
}

@article{Krissek1993,
  abstract = {applicability for this approach.},
  author   = {Lawrence A. Krissek},
  doi      = {10.1016/0016-7037(93)90327-s},
  issn     = {00167037},
  issue    = 17,
  journal  = {Geochimica et Cosmochimica Acta},
  pages    = 4324,
  title    = {Essentials of oceanography},
  volume   = 57,
  url      = {https://www.oakton.edu/user/4/billtong/eas125/Powerpoint/EoO\_11e\_Lecture\_Ch13.pdf},
  year     = 1993
}

@article{Kristof2009,
  abstract = {This paper presents a new technique for modification of 3D terrains by hydraulic erosion. It efficiently couples fluid simulation using a Lagrangian approach, namely the Smoothed Particle Hydrodynamics (SPH) method, and a physically-based erosion model adopted from an Eulerian approach. The eroded sediment is associated with the SPH particles and is advected both implicitly, due to the particle motion, and explicitly, through an additional velocity field, which accounts for the sediment transfer between the particles. We propose a new donor-acceptor scheme for the explicit advection in SPH. Boundary particles associated to the terrain are used to mediate sediment exchange between the SPH particles and the terrain itself. Our results show that this particle-based method is efficient for the erosion of dense, large, and sparse fluid. Our implementation provides interactive results for scenes with up to 25,000 particles. \textcopyright{} 2008 The Eurographics Association and Blackwell Publishing Ltd.},
  author   = {Peter Kri\v{s}tof and Bed\v{r}ich Bene\v{s} and J. K\v{r}iv\'{a}nek and Ond\v{r}ej \v{S}t'ava},
  doi      = {10.1111/j.1467-8659.2009.01361.x},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  pages    = {219--228},
  title    = {Hydraulic erosion using smoothed particle hydrodynamics},
  volume   = 28,
  year     = 2009
}

@article{Kundu2003,
  abstract = {The problem of computing a random combinatorial structure such as balanced strings, trees, and flowcharts arises in a variety of applications, including the evaluation of heuristic algorithms which use these structures. The main challenge here is to assure that each instance of the possible structure has the same probability of selection. A brute-force method of first creating a list of all instances of the structure with a given size, say, and then choosing one from the list at random is typically impractical because of the very large number of instances. We provide here a unified approach, using context-free grammars as a backbone for defining the desired combinatorial structure, for efficiently generating a random instance of that structure. The algorithm typically takes a linear or quadractic amount of time in the size of the structure, following some initial computations which is also polynomial in the size of the structure. \textcopyright{} 2005 Elsevier Ltd. All rights reserved.},
  author   = {Sukhamay Kundu},
  doi      = {10.1016/S1571-0653(04)00551-7},
  issn     = 15710653,
  journal  = {Electronic Notes in Discrete Mathematics},
  pages    = 114,
  title    = {Random Generation of Combinatorial Structures using Context-Fee Grammars},
  volume   = 15,
  year     = 2003
}

@article{Lachat2019a,
  author  = {Elise Lachat},
  journal = {Traitement du signal et de l'image},
  pages   = 330,
  title   = {Relev\'{e} et consolidation de nuages de points issus de multiples capteurs pour la num\'{e}risation 3D du patrimoine},
  year    = 2019
}

@article{Lange2020,
  abstract = {Coral growth rates vary significantly with environmental conditions and are thus important indicators of coral health and reef carbonate production. Despite the importance of this metric, data are sparse for most coral genera and species globally, including for many key reef-building species. Traditional methods to obtain growth rates, such as coral coring or staining with Alizarin are destructive and only work for a limited number of species and morphological growth forms. Emerging approaches, using underwater photogrammetry to create digital models of coral colonies, are providing novel and non-invasive ways to explore colony-scale growth patterns and to address existing knowledge gaps. We developed an easy-to-follow workflow to construct three-dimensional (3D) models from overlapping photographs and to measure linear, radial and vertical extension rates of branching, massive and encrusting corals after aligning colony models from subsequent years. The method presented here was applied to measure extension rates for 46 colonies of nine coral species in the remote Chagos Archipelago, Indian Ocean. Proposed image acquisition and software settings produced 3D models of consistently high resolution and detail (precision~\leq{}~0.2~mm) and variability in growth measurements was small despite manual alignment, clipping and ruler placement (SD~\leq{}~0.9~mm). Measured extension rates for the Chagos Archipelago are similar to published rates in the Indo-Pacific where comparable data are available, and provide the first published rates for several species. For encrusting corals, the results emphasize the importance of differentiating between radial and vertical growth. Photogrammetry and 3D model comparisons provide a fast, easy, inexpensive and non-invasive method to quantify coral growth rates for a range of species and morphological growth forms. The simplicity of the presented workflow encourages its repeatability and permits non-specialists to learn photogrammetry with the goal of obtaining linear coral growth rates. Coral growth rates are essential metrics to quantify functional consequences of ongoing community changes on coral reefs and expanded datasets for key coral taxa will aid predictions of geographic variations in coral reef response to increasing global stressors.},
  author   = {Ines D. Lange and Chris T. Perry},
  doi      = {10.1111/2041-210X.13388},
  issn     = {2041210X},
  issue    = 6,
  journal  = {Methods in Ecology and Evolution},
  keywords = {3D model,Agisoft Metashape,Chagos Archipelago,CloudCompare,coral extension rates,coral growth rates,photogrammetry,structure-from-motion},
  pages    = {714--726},
  title    = {A quick, easy and non-invasive method to quantify coral growth rates using photogrammetry and 3D model comparisons},
  volume   = 11,
  year     = 2020
}

@article{Lassabe2007,
  abstract = {In this article, we present our research on the evolution of morphology and behavior of complex creatures in virtual environments. We propose to study the evolution of creatures faced with different situations from crawling and walking to more complex activities like climbing and skating. Our creatures use solid 3D blocks and graphtals like Karl Sims's creatures and a new type of controller based on classifier system. The results constitute a new step toward creatures adapted to more complex environments. \textcopyright{} 2007 IEEE.},
  author   = {Nicolas Lassabe and Herv\'{e} Luga and Yves Duthen},
  doi      = {10.1109/ALIFE.2007.367803},
  isbn     = {142440701X},
  journal  = {Proceedings of the 2007 IEEE Symposium on Artificial Life, CI-ALife 2007},
  pages    = {243--250},
  title    = {A new step for artificial creatures},
  year     = 2007
}

@article{Laurent2013,
  abstract = {This paper presents a 3D parametric fault representation for modeling the displacement field associated with faults in accordance with their geometry. The displacements are modeled in a canonical fault space where the near-field displacement is defined by a small set of parameters consisting of the maximum displacement amplitude and the profiles of attenuation in the surrounding space. The particular geometry and the orientation of the slip of each fault are then taken into account by mapping the actual fault onto its canonical representation. This mapping is obtained with the help of a curvilinear frame aligned both on the fault surface and slip direction.This formulation helps us to include more geological concepts in quantitative subsurface models during 3D structural modeling tasks. Its applicability is demonstrated in the framework of forward modeling and stochastic sequential fault simulations, and the results of our model are compared to observations of natural objects described in the literature. \textcopyright{} 2013 Elsevier B.V.},
  author   = {Gautier Laurent and Guillaume Caumon and Antoine Bouziat and Mark Jessell},
  doi      = {10.1016/J.TECTO.2013.01.015},
  issn     = {00401951},
  journal  = {Tectonophysics},
  keywords = {Fault,Kinematics,Parameterization,Structural modeling,Time integration},
  month    = 4,
  pages    = {83--93},
  title    = {A parametric method to model 3D displacements around faults with volumetric vector fields},
  volume   = 590,
  year     = 2013
}

@article{Layton2020,
  abstract = {Kelp forests dominate the rocky coasts of temperate Australia and are the foundation of the Great Southern Reef. Much like terrestrial forests, these marine forests create complex habitat for diverse communities of flora and fauna. Kelp forests also support coastal food-webs and valuable fisheries and provide a suite of additional ecosystem services. In many regions of Australia and around the world, kelp forests are in decline due to ocean warming, overgrazing, and pollution. One potential tool in the conservation and management of these important ecosystems is habitat restoration, the science and practice of which is currently undergoing substantial expansion. We summarize the present state of Australian kelp forests and emphasize that consideration of the initial drivers of kelp decline is a critical first step in restoration. With a focus on Australian examples, we review methods, implementation and outcomes of kelp forest restoration, and discuss suitable measures of success and the estimated costs of restoration activities. We propose a workflow and decision system for kelp forest restoration that identifies alternative pathways for implementation and acknowledges that under some circumstances restoration at scale is not possible or feasible. As a case study, we then apply the Society for Ecological Restoration's 5-star evaluation to Operation Crayweed, Australia's primary example of kelp forest restoration. Overall, no single method of kelp forest restoration is suitable for all situations, but outcomes can be optimized by ameliorating the driver(s) of kelp decline and achieving ongoing natural recruitment of kelp. Whilst scalability of kelp forest restoration to the seascape-scale remains a considerable challenge, the present review should provide a platform for future restoration efforts. However, it is also crucial to emphasize that the challenges of restoration place a high value on preventative conservation and protection of existing kelp forest ecosystems – prevention is invariably better than cure.},
  author   = {Cayne Layton and Melinda A. Coleman and Ezequiel M. Marzinelli and Peter D. Steinberg and Stephen E. Swearer and Adriana Verg\'{e}s and Thomas Wernberg and Craig R. Johnson},
  doi      = {10.3389/fmars.2020.00074},
  issn     = 22967745,
  issue    = {February},
  journal  = {Frontiers in Marine Science},
  keywords = {Great Southern Reef,canopy,ecosystem,habitat-forming,macroalga,rehabilitation},
  pages    = {1--12},
  title    = {Kelp Forest Restoration in Australia},
  volume   = 7,
  year     = 2020
}

@article{Le2014,
  abstract = {With the development of advanced computer vision and tracking techniques, deformed mesh sequences can be soundly reconstructed by markerless performance capture [De Aguiar et al. 2008b; Vlasic et al. 2008; Vlasic et al. 2009; Stoll et al. 2010], or by motion capture with dense markers [Park and Hodgins 2006; De Aguiar et al. 2007]. With the maturity of these high-quality capture techniques, researchers in computer graphics community have also explored the concept of using example poses (i.e., a sequence of deformed mesh frames) for character skinning, rigging and animation, which has become increasingly practical and useful in entertainment practice. For example, proxy bones (or called bones for simplicity) and corresponding skinning weights can be automatically extracted from a set of example poses [James and Twigg 2005; Kavan et al. 2010; Le and Deng 2012], and the resulting bones and skinning weights can be potentially used for many applications including mesh animation compression, hardware-accelerated skinning animation, collision detection, animation editing, and so on [James and Twigg 2005; Kavan et al. 2010]. Furthermore, different from a set of disconnected proxy bones, a skeletal rigging model can also be automatically extracted from example poses [Schaefer and Yuksel 2007; Hasler et al. 2010; Le and Deng 2014]. Since the skeleton extracted from example poses is compatible with game engines and popular animation software such as Maya and Blender, it can be directly used for various animation editing, compression, and rendering applications, which could help to substantially reduce production cost in industry practice. In linear blend skinning (LBS) model (or cage-based deformation), the deformed position of a surface vertex is influenced by a set of bones (or control points). Often, the number of bones that affect a vertex of the target mesh varies significantly, such as from one to tens of them. Meanwhile, with the availability and affordability of high-precision 3D scanning and acquisition devices, dense 3D mesh models with thousands or even millions of vertices have being commonly used in movie special effects, video games, and other entertainment industry practices. Therefore, skinning high-resolution 3D meshes on off-the-shelf computers has become an expensive computational task, in particular, for real-time graphics applications (such as video games) due to their real-time response requirement. Fortunately, modern GPU hardware can provide an unprecedented computing capability to handle massive parallel data processing. Researchers have strived to efficiently exploit the GPU computing power to accelerate skinning animation on GPU. In particular, one intensively studied solution is to impose the sparseness constraint on the skinning weights [James and Twigg 2005; Landreneau and Schaefer 2010; Le and Deng 2013] (that is, enforce no more than a fixed number of non-zero skinning weights for any vertex), while maximally retaining the visual quality of the reduced skinning animation. This process is called skinning weight reduction and compression. In the remainder of the course note, we will first describe a number of recent example-based skinning decomposition techniques that automatically extract proxy bones (flexible or rigid) and corresponding skinning weights from a set of example poses (Section 1). Then, we will further describe recent skeleton extraction algorithms that automatically extract skeletal rigging models from example poses (Section 2). Finally, we will describe a number of skinning weight reduction and compression approaches to balance the trade-off between skinning efficiency and quality (Section 3).},
  author   = {Binh H Le and Zhigang Deng},
  journal  = {SIGGRAPH Course 2014},
  pages    = {1--35},
  title    = {Siggraph course (skinning). Part IV: Mesh Animation Decomposition and Compression},
  url      = {https://skinning.org/decomposition-methods.pdf},
  year     = 2014
}

@article{LeBorgne2011,
  author  = {Robert Le Borgne and Richard Matear},
  issue   = {January 2014},
  journal = {Vulnerability of tropical Pacific fisheries and aquaculture to climate change},
  pages   = {189--250},
  title   = {Vulnerability of open ocean food webs in the tropical Pacific to climate change Val\'{e}rie Allain Pacific Community},
  url     = {https://www.researchgate.net/publication/236597538},
  year    = 2011
}

@misc{Lech,
  author = {Brenden Lech and Sasha Azad and Jennifer Welnitz and Joel Jonasson and Chris Martens},
  title  = {Designing a Combined World and Story Procedural Content Generation Engine},
  url    = {http://www.exag.org/archive/lech2021designing.pdf}
}

@article{Lee,
  abstract = {<p> We study the problem of optimal transport in tropical geometry and define the Wasserstein- <italic>p</italic> distances in the continuous metric measure space setting of the tropical projective torus. We specify the tropical metric--a combinatorial metric that has been used to study of the tropical geometric space of phylogenetic trees--as the ground metric and study the cases of <inline-formula> <alternatives> <tex-math>\$$p=1,2$\$</tex-math> <math> <mrow> <mi>p</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>2</mn> </mrow> </math> </alternatives> </inline-formula> in detail. The case of <inline-formula> <alternatives> <tex-math>\$\$p=1\$\$</tex-math> <math> <mrow> <mi>p</mi> <mo>=</mo> <mn>1</mn> </mrow> </math> </alternatives> </inline-formula> gives an efficient computation of the infinitely-many geodesics on the tropical projective torus, while the case of <inline-formula> <alternatives> <tex-math>\$\$p=2\$\$</tex-math> <math> <mrow> <mi>p</mi> <mo>=</mo> <mn>2</mn> </mrow> </math> </alternatives> </inline-formula> gives a form for Fr\'{e}chet means and a general inner product structure. Our results also provide theoretical foundations for geometric insight a statistical framework in a tropical geometric setting. We construct explicit algorithms for the computation of the tropical Wasserstein-1 and 2 distances and prove their convergence. Our results provide the first study of the Wasserstein distances and optimal transport in tropical geometry. Several numerical examples are provided. </p>},
  author   = {Wonjun Lee and Wuchen Li and Bo Lin and Anthea Monod},
  doi      = {10.1007/s41884-021-00046-6},
  issn     = {2511-2481},
  issue    = 1,
  journal  = {Information Geometry},
  month    = 7,
  pages    = {247--287},
  title    = {Tropical optimal transport and Wasserstein distances},
  volume   = 5,
  url      = {https://link.springer.com/10.1007/s41884-021-00046-6},
  year     = 2022
}

@article{Lee2002,
  abstract  = {This paper describes a representation of gait appearance for the purpose of person identification and classification. This gait representation is based on simple features such as moments extracted from orthogonal view video silhouettes of human walking motion. Despite its simplicity, the resulting feature vector contains enough information to perform well on human identification and gender classification tasks. We explore the recognition behaviors of two different methods to aggregate features over time under different recognition tasks. We demonstrate the accuracy of recognition using gait video sequences collected over different days and times and under varying lighting environments. In addition, we show results for gender classification based our gait appearance features using a support-vector machine. \textcopyright{} 2002 IEEE.},
  author    = {L. Lee and W. E.L. Grimson},
  doi       = {10.1109/AFGR.2002.1004148},
  isbn      = {0769516025},
  issue     = {Mld},
  journal   = {Proceedings - 5th IEEE International Conference on Automatic Face Gesture Recognition, FGR 2002},
  pages     = {155--162},
  publisher = {IEEE},
  title     = {Gait analysis for recognition and classification},
  year      = 2002
}

@inbook{Lee2015,
  author = {Richard Lee},
  note   = {Nice way to explain the Eulerian method (Jos Stam 2003)},
  pages  = {1--10},
  title  = {Fluid simulation overview},
  year   = 2015
}

@article{Lee2021,
  abstract = {Understanding coastal circulation and how it may alter in the future is important in island settings, especially in the South West Pacific, where communities rely heavily upon marine resources, and where sea level rise (SLR) is higher than the global average. In this study we explore the use of an unstructured-mesh finite-volume modelling approach to assist in filling the knowledge gaps with respect to coastal circulation in remote island locations--selecting the Vanuatu and New Caledonia archipelagos as our example study site. Past limited observations and modelling studies are leveraged to construct and verify a regional/coastal ocean model based on the Finite-Volume Community Ocean Model (FVCOM). Following verification with respect to tidal behaviour, we investigate how changes in wind speed and direction, and SLR, alter coastal water levels and coastal currents. Results showed tidal residual circulation was typically associated with flow separation at headlands and islands. Trade winds had negligible effect on water levels at the coast, however, wind-residual circulation was sensitive to both wind speed and direction. Wind-residual currents were typically strongest close to coastlines. Wind residual circulation patterns were strongly influenced by Ekman flow, while island blocking, topographic steering and geostrophic currents also appear to influence current patterns. Tidal amplitudes and phases were unchanged due to SLR of up to 2 m, while maximum current speeds altered by as much as 20 cm/s within some coastal embayments. Non-linear relationships between SLR and maximum current speeds were seen at some coastal reef platform sites. Under higher sea levels, tidal residual currents altered by less than \pm{}2 cm/s which is relatively significant given maximum tidal residual current speeds are typically below 10 cm/s. Our findings indicate that under higher sea levels, coastal processes governing sediment transport, pollutant dispersal and larval transport are likely to alter, which may have implications for coastal environments and ecosystems. Given winds influence coastal circulation and subsequent coastal processes, changes in trade winds due to climate change may act to further alter coastal processes. It is felt that the current modelling approach can be applied to other regions to help fill critical knowledge gaps.},
  author   = {Serena Blyth Lee and Fan Zhang and Charles James Lemckert and Rodger Tomlinson},
  doi      = {10.3389/fmars.2021.697741},
  issn     = 22967745,
  issue    = {September},
  journal  = {Frontiers in Marine Science},
  keywords = {circulation,constituents,residual,sea level rise,tidal},
  title    = {Investigations Exploring the Use of an Unstructured-Grid, Finite-Volume Modelling Approach to Simulate Coastal Circulation in Remote Island Settings--Case Study Region, Vanuatu/New Caledonia},
  volume   = 8,
  year     = 2021
}

@article{Lefebvre2006,
  abstract = {We explore using hashing to pack sparse data into a compact table while retaining efficient random access. Specifically, we design a perfect multidimensional hash function - one that is precomputed on static data to have no hash collisions. Because our hash function makes a single reference to a small offset table, queries always involve exactly two memory accesses and are thus ideally suited for parallel SIMD evaluation on graphics hardware. Whereas prior hashing work strives for pseudorandom mappings, we instead design the hash function to preserve spatial coherence and thereby improve runtime locality of reference. We demonstrate numerous graphics applications including vector images, texture sprites, alpha channel compression, 3D-parameterized textures, 3D painting, simulation, and collision detection. Copyright \textcopyright{} 2006 by the Association for Computing Machinery, Inc.},
  author   = {Sylvain Lefebvre and Hugues Hoppe},
  doi      = {10.1145/1179352.1141926},
  isbn     = 1595933646,
  journal  = {ACM SIGGRAPH 2006 Papers, SIGGRAPH '06},
  keywords = {3D-parameterized textures,adaptive textures,minimal perfect hash,multidimensional hashing,sparse data,vector images},
  pages    = {579--588},
  title    = {Perfect spatial hashing},
  url      = {https://hhoppe.com/perfecthash.pdf},
  year     = 2006
}

@article{Lehman2011,
  abstract = {An ambitious challenge in artificial life is to craft an evolutionary process that discovers a wide diversity of well-adapted virtual creatures within a single run. Unlike in nature, evolving creatures in virtual worlds tend to converge to a single morphology because selection therein greedily rewards the morphology that is easiest to exploit. However, novelty search, a technique that explicitly rewards diverging, can potentially mitigate such convergence. Thus in this paper an existing creature evolution platform is extended with multi-objective search that balances drives for both novelty and performance. However, there are different ways to combine performance-driven search and novelty search. The suggested approach is to provide evolution with both a novelty objective that encourages diverse morphologies and a local competition objective that rewards individuals outperforming those most similar in morphology. The results in an experiment evolving locomoting virtual creatures show that novelty search with local competition discovers more functional morphological diversity within a single run than models with global competition, which are more predisposed to converge. The conclusions are that novelty search with local competition may complement recent advances in evolving virtual creatures and may in general be a principled approach to combining novelty search with pressure to achieve. Copyright 2011 ACM.},
  author   = {Joel Lehman and Kenneth O. Stanley},
  doi      = {10.1145/2001576.2001606},
  isbn     = 9781450305570,
  journal  = {Genetic and Evolutionary Computation Conference, GECCO'11},
  keywords = {Artificial life,Natural evolution,Novelty search,Virtual creatures},
  pages    = {211--218},
  title    = {Evolving a diversity of creatures through novelty search and local competition},
  year     = 2011
}

@article{Lehman2020,
  abstract = {Evolution provides a creative fount of complex and subtle adaptations that often surprise the scientists who discover them. However, the creativity of evolution is not limited to the natural world: Artificial organisms evolving in computational environments have also elicited surprise and wonder from the researchers studying them. The process of evolution is an algorithmic process that transcends the substrate in which it occurs. Indeed, many researchers in the field of digital evolution can provide examples of how their evolving algorithms and organisms have creatively subverted their expectations or intentions, exposed unrecognized bugs in their code, produced unexpectedly adaptations, or engaged in behaviors and outcomes, uncannily convergent with ones found in nature. Such stories routinely reveal surprise and creativity by evolution in these digital worlds, but they rarely fit into the standard scientific narrative. Instead they are often treated as mere obstacles to be overcome, rather than results that warrant study in their own right. Bugs are fixed, experiments are refocused, and one-off surprises are collapsed into a single data point. The stories themselves are traded among researchers through oral tradition, but that mode of information transmission is inefficient and prone to error and outright loss. Moreover, the fact that these stories tend to be shared only among practitioners means that many natural scientists do not realize how interesting and lifelike digital organisms are and how natural their evolution can be. To our knowledge, no collection of such anecdotes has been published before. This article is the crowd-sourced product of researchers in the fields of artificial life and evolutionary computation who have provided first-hand accounts of such cases. It thus serves as a written, fact-checked collection of scientifically important and even entertaining stories. In doing so we also present here substantial evidence that the existence and importance of evolutionary surprises extends beyond the natural world, and may indeed be a universal property of all complex evolving systems.},
  author   = {Joel Lehman and Jeff Clune and Dusan Misevic},
  doi      = {10.1162/artl\_a\_00319},
  issn     = 15309185,
  issue    = 2,
  journal  = {Artificial Life},
  keywords = {Creativity,Digital evolution,Evolutionary computation,Experimental evolution,Genetic algorithms,Surprise},
  pages    = {274--306},
  pmid     = 32271631,
  title    = {The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities},
  volume   = 26,
  year     = 2020
}

@article{Lejeune2021a,
  abstract    = {Les robots autonomes sont principalement test\'{e}s par des exp\'{e}rimentations sur le terrain. Cette approche est co\^{u}teuse et peut pr\'{e}senter des risques. Une m\'{e}thode alternative consiste \`{a} r\'{e}aliser une partie des tests sur une plate-forme de simulation. Ceci soul\`{e}ve plusieurs d\'{e}fis : la g\'{e}n\'{e}ration d'environnements virtuels complexes, la v\'{e}rification automatis\'{e}e du comportement observ\'{e} (oracle de test), et la fid\'{e}lit\'{e} imparfaite de la simulation par rapport \`{a} des tests sur le terrain. Cette th\`{e}se est divis\'{e}e en deux parties ax\'{e}es autour de ces probl\'{e}matiques. Dans une premi\`{e}re partie, nos travaux abordent ces diff\'{e}rents points au travers du cas d'\'{e}tude d'un robot agricole, le robot Oz de la soci\'{e}t\'{e} Na\"{\i}o Technologies. Nous faisons en particulier une analyse comparative des fautes trouv\'{e}es en simula- tion et sur le terrain. La contribution principale de cette partie est de d\'{e}montrer la faisabilit\'{e} et l'efficacit\'{e} du test en simulation sur un cas industriel. Malgr\'{e} leur fid\'{e}lit\'{e} imparfaite, les tests en simulation r\'{e}v\`{e}lent la plupart des fautes trouv\'{e}es par les exp\'{e}rimentationsexp\'{e}rimentations avec le robot r\'{e}el, y compris celles ayant caus\'{e} la majorit\'{e} des d\'{e}faillances sur le terrain. Ils r\'{e}v\`{e}lent \'{e}galement une nouvelle faute pass\'{e}e inaper\c{c}ue sur le terrain mais confirm\'{e}e par l'industriel. Cependant, l'effort d'impl\'{e}mentation des tests virtuels se r\'{e}v\`{e}le important, avec notamment le d\'{e}veloppement d'un g\'{e}n\'{e}- rateur de donn\'{e}es sp\'{e}cifiques aux environnements 3D du robot. Ce constat a men\'{e} la suite de nos travaux vers l'\'{e}tude de la g\'{e}n\'{e}ration de tests. La deuxi\`{e}me partie de nos travaux introduit une nouvelle m\'{e}thode de g\'{e}- n\'{e}ration de test et un outil qui l'impl\'{e}mente. Elle se base sur un mod\`{e}le de donn\'{e}es purement d\'{e}claratif, en combinant la r\'{e}solution de contraintes SMT et l'\'{e}chantillonnage al\'{e}atoire. Bien que le point de d\'{e}part de ces travaux soit la g\'{e}n\'{e}ration d'environnements virtuels pour les syst\`{e}mes autonomes, notre m\'{e}thode de g\'{e}n\'{e}ration s'applique \`{a} un domaine bien plus large. Elle permet de produire des donn\'{e}es structur\'{e}es de tailles variables, tout en respectant des propri\'{e}t\'{e}s s\'{e}mantiques et en offrant de la diversit\'{e}. Nous avons \'{e}valu\'{e} notre m\'{e}thode sur quatre cas d'\'{e}tude venant de domaines d'application vari\'{e}s (le robot Oz, un syst\`{e}me de gestion de taxe, des images de d\'{e}grad\'{e} de gris et des structures arborescentes). Nos r\'{e}sultats montrent des donn\'{e}es g\'{e}n\'{e}r\'{e}es efficacement et couvrant bien l'espace des solutions. Notre m\'{e}thode est comp\'{e}titive au regard des approches existantes auxquelles nous l'avons compar\'{e}e.},
  author      = {Cl\'{e}ment Lejeune},
  institution = {Universit\'{e} Toulouse 3 Paul Sabatier},
  pages       = 170,
  title       = {G\'{e}n\'{e}ration et Analyse de tests pour les syst\`{e}mes autonomes},
  url         = {http://oatao.univ-toulouse.fr/9278/},
  year        = 2021
}

@article{Lemon2003,
  abstract = {Solid models of geologic structures are useful tools for geologists and engineers. Solid models completely and unambiguously define the stratigraphy for the site being modeled, including complex boundaries and embedded seams. Past research has focused on the "set operations" approach to create solid models. Whereas the set operations approach is flexible, it requires significant user intervention and is therefore difficult to use. A simple approach for generating solid models from borehole data, called the horizons method, is presented. The horizons method can be used to build solids directly from borehole data with minimal user intervention. The user first assigns horizon ids to each of the borehole contacts. The horizon ids represent the depositional sequence and increase from the bottom to the top of the boreholes. The solids are then built by interpolating each of the surfaces defined by the horizons and extruding the surface into a solid. In each case, the solid is built by extruding the solid from the current surface down to the uppermost surface defined by the top of all previous horizons. In cases where more control over the resulting solids is necessary, the horizons method can be easily modified to honor user-defined cross-sections in addition to the borehole data. \textcopyright{} 2003 Elsevier Science Ltd. All rights reserved.},
  author   = {Alan M. Lemon and Norman L. Jones},
  doi      = {10.1016/S0098-3004(03)00051-7},
  issn     = {00983004},
  issue    = 5,
  journal  = {Computers and Geosciences},
  keywords = {Cross-sections,Horizons method,Solid modeling,Stratigraphy modeling},
  pages    = {547--555},
  title    = {Building solid models from boreholes and user-defined cross-sections},
  volume   = 29,
  url      = {https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=5237\&context=facpub},
  year     = 2003
}

@article{Lenaerts2009,
  abstract = {Fluid animations in computer graphics show interactions with various kinds of objects. However, fluid flowing through a granular material such as sand is still not possible within current frameworks. In this paper, we present the simulation of fine granular materials interacting with fluids. We propose a unified Smoothed Particle Hydrodynamics framework for the simulation of both fluid and granular material. The granular volume is simulated as a continuous material sampled by particles. By incorporating previous work on porous flow in this simulation framework we are able to fully couple fluid and sand. Fluid can now percolate between sand grains and influence the physical properties of the sand volume. Our method demonstrates various new effects such as dry soil transforming into mud pools by rain or rigid sand structures being eroded by waves. \textcopyright{} 2008 The Eurographics Association and Blackwell Publishing Ltd.},
  author   = {Toon Lenaerts and Philip Dutr\'{e}},
  doi      = {10.1111/j.1467-8659.2009.01360.x},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  pages    = {213--218},
  title    = {Mixing fluids and granular materials},
  volume   = 28,
  year     = 2009
}

@article{Lengyel2010a,
  abstract = {This dissertation provides the theoretical basis and implementation details for a complete and practical real-time voxel-based terrain rendering system. We first present a modified Marching Cubes algorithm designed to eliminate choices arising from ambiguities in the original algorithm and its successors in order to facilitate a faster implementation and to simplify the design of a level-of-detail algorithm. The modified Marching Cubes algorithm is extended to operate on voxel data at multiple resolutions in such a way that triangle meshes produced at all levels of detail correctly match geometrical features. We introduce a robust method for seamlessly joining voxel-based terrain meshes of different levels of detail and establish a transition structure that both simplifies the triangulation problem and eliminates the potential for shading artifacts. Finally, we discuss methods for applying texture maps and advanced shading techniques to voxel-based terrain meshes. These methods are designed to be fast and compatible with the widest possible range of graphics hardware across multiple platforms.},
  author   = {E.S. Lengyel},
  keywords = {marching cubes,rendering,terrain,voxel},
  pages    = 148,
  title    = {Voxel-based terrain for real-time virtual simulations},
  url      = {http://gradworks.umi.com/34/04/3404919.html},
  year     = 2010
}

@article{Lewis2014,
  author  = {J P Lewis},
  issue   = {Figure 1},
  journal = {Siggraph 2014},
  pages   = {1--20},
  title   = {Siggraph course 2014 (skinning). Part III: Example-based Shape Deformation},
  url     = {https://skinning.org/example-based.pdf},
  year    = 2014
}

@article{Li2018,
  abstract = {In order to show a common natural landscape in winter, the charm of rime, an algorithm for rime growth simulation based on a physical approach is proposed in this paper. This algorithm mainly simulates two main kinds of rimes' growth, especially their morphology and direction, under the condition of surrounding factors, including the air pressure, temperature and wind. Firstly, this algorithm calculates the length of rime by using the icing conductor model which is established according to fluid mechanics and thermodynamic principles, a fractal method is introduced into our algorithm to simulate the morphology of the crystalline rime, and a segmentation method is for the simulation of the needle-like rime's morphology; After that, wind field is simulated by adopting the function of Perlin Noise. Finally, it analyzes the offset details of the rime growth in the wind according to its material mechanics knowledge. The wind force is used to calculate the deviation of rime. Experimental results show us that our algorithm in this paper can simulate two kinds of rime realistically, effectively and efficiently.},
  author   = {Ye Li and Meng Yang and Gang Yang},
  doi      = {10.1109/ICVRV.2018.00021},
  isbn     = 9781538684979,
  journal  = {Proceedings - 8th International Conference on Virtual Reality and Visualization, ICVRV 2018},
  keywords = {crystalline rime,growth simulation,needlelike rime,physical approach},
  pages    = {70--73},
  title    = {Physically-Based Algorithm for Natural Rime Growth Simulation},
  year     = 2018
}

@article{Li2021,
  abstract = {Since terrain procedural modeling is widely adopted for the virtual natural scene generations in the game design, movie industry, and digital arts, lots of advanced techniques have been explored by researchers to procedurally synthesize a large variety of different types of terrain and landscapes. In this paper, we present a novel approach to generate a special type of landscape – the Great Barrier Reef – an amazing natural landscape that is currently being ignored. We propose a hypothesis that the Great Barrier Reef is grown with the diffusion-limited aggregation (DLA) model and simulate the DLA process to generate the Great Barrier Reef procedurally. As presented in the results, the procedural Great Barrier Reef generated with our approach looks natural when compared to the photos of the real ones.},
  author   = {Wanwan Li},
  doi      = {10.1007/978-3-030-90439-5\_30},
  isbn     = 9783030904388,
  issn     = 16113349,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Diffusion-limited aggregation (DLA),Great Barrier Reef,Landscape,Procedural modeling,Terrain},
  pages    = {381--391},
  title    = {Procedural Modeling of the Great Barrier Reef},
  volume   = {13017 LNCS},
  year     = 2021
}

@article{Liapis2013,
  author  = {Antonio Liapis and Georgios N. Yannakakis and Julian Togelius},
  journal = {8th International Conference on the Foundations of Digital Games},
  title   = {Sentient Sketchbook : Computer-Assisted Game Level Authoring},
  year    = 2013
}

@article{Lidal2013,
  abstract  = {Developing structural geological models from exploratory subsea imaging is difficult and an ill-posed process. The structural geological processes that take place in the subsurface are both complex and time-dependent. We present Geological Storytelling, a novel graphical system for performing rapid and expressive geomodeling. Geologists can convey geological stories that externalize both their model and the reasoning process behind it through our simple, yet expressive sketch-based, flip-over canvases. This rapid modeling interface makes it easy to construct a large variety of geological stories, and our story tree concept facilitates easy management and the exploration of these alternatives. The stories are then animated and the geologists can examine and compare them to identify the most plausible models. Finally, the geological stories can be presented as illustrative animations of automatically synthesized 3D models, which efficiently communicate the complex geological evolution to non-experts and decision makers. Geological storytelling provides a complete pipeline from the ideas and knowledge in the mind of the geologist, through externalized artifacts specialized for discussion and knowledge dissemination among peer-experts, to automatically rendered illustrative 3D animations for communication to lay audience. We have developed geological storytelling in collaboration with domain experts that work with the modeling challenges on a daily basis. For evaluation, we have developed a geological storytelling prototype and presented it to experts and academics from the geosciences. In their feedback, they acknowledge that the rapid and expressive sketching of stories can make them explore more alternatives and that the 3D illustrative animations assist in communicating their models. \textcopyright{} 2013 Elsevier Ltd.},
  author    = {Endre M. Lidal and Mattia Natali and Daniel Patel and Helwig Hauser and Ivan Viola},
  doi       = {10.1016/j.cag.2013.01.010},
  issn      = {00978493},
  issue     = 5,
  journal   = {Computers and Graphics (Pergamon)},
  keywords  = {3D model synthesis,Alternatives exploration,Animation,Externalization of mental processes,Geology,Sketch-based modeling,Storytelling,Structural geological models},
  pages     = {445--459},
  publisher = {Elsevier},
  title     = {Geological storytelling},
  volume    = 37,
  url       = {http://dx.doi.org/10.1016/j.cag.2013.01.010},
  year      = 2013
}

@article{Lienhardt1991,
  author  = {Pascal Lienhardt},
  doi     = {10.1051/ita/1991250201711},
  issn    = {0988-3754},
  issue   = 2,
  journal = {RAIRO - Theoretical Informatics and Applications},
  pages   = {171--202},
  title   = {Subdivisions de surfaces et cartes g\'{e}n\'{e}ralis\'{e}es de dimension 2},
  volume  = 25,
  url     = {http://www.numdam.org/item/ITA\_1991\_\_25\_2\_171\_0.pdf},
  year    = 1991
}

@inbook{Lienhardt2011,
  author  = {Pascal Lienhardt and Laurent Fuchs},
  journal = {Informatique graphique, mod\'{e}lisation g\'{e}om\'{e}trique et animation},
  pages   = {49--93},
  title   = {Mod\`{e}les topologiques},
  url     = {https://hal.archives-ouvertes.fr/hal-00580707/document},
  year    = 2007
}

@article{Lindstrom2000,
  abstract = {We present an algorithm for out-of-core simplification of large polygonal datasets that are too complex to fit in main memory. The algorithm extends the vertex clustering scheme of Rossignac and Borrel [13] by using error quadric information for the placement of each cluster's representative vertex, which better preserves fine details and results in a low mean geometric error. The use of quadrics instead of the vertex grading approach in [13] has the additional benefits of requiring less disk space and only a single pass over the model rather than two. The resulting linear time algorithm allows simplification of datasets of arbitrary complexity. In order to handle degenerate quadrics associated with (near) flat regions and regions with zero Gaussian curvature, we present a robust method for solving the corresponding underconstrained least-squares problem. The algorithm is able to detect these degeneracies and handle them gracefully. Key features of the simplification method include a bounded Hausdorff error, low mean geometric error, high simplification speed (up to 100,000 triangles/second reduction), output (but not input) sensitive memory requirements, no disk space overhead, and a running time that is independent of the order in which vertices and triangles occur in the mesh.},
  author   = {Peter Lindstrom},
  doi      = {10.1145/344779.344912},
  isbn     = 1581132085,
  journal  = {SIGGRAPH 2000 - Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques},
  pages    = {259--262},
  title    = {Out-of-Core Simplification of Large Polygonal Models},
  year     = 2000
}

@article{Lipp2019,
  abstract = {Procedural modeling is used across many industries for rapid 3D content creation. However, professional procedural tools often lack artistic control, requiring manual edits on baked results, diminishing the advantages of a procedural modeling pipeline. Previous approaches to enable local artistic control require special annotations of the procedural system and manual exploration of potential edit locations. Therefore, we propose a novel approach to discover meaningful and non-redundant good edit locations (GELs). We introduce a bottom-up algorithm for finding GELs directly from the attributes in procedural models, without special annotations. To make attribute edits at GELs persistent, we analyze their local spatial context and construct a meta-locator to uniquely specify their structure. Meta-locators are calculated independently per attribute, making them robust against changes in the procedural system. Functions on meta-locators enable intuitive and robust multi-selections. Finally, we introduce an algorithm to transfer meta-locators to a different procedural model. We show that our approach greatly simplifies the exploration of the local edit space, and we demonstrate its usefulness in a user study and multiple real-world examples.},
  author   = {M. Lipp and M. Specht and C. Lau and P. Wonka and P. M\"{u}ller},
  doi      = {10.1111/cgf.13615},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Mesh geometry models},
  pages    = {13--25},
  title    = {Local Editing of Procedural Models},
  volume   = 38,
  year     = 2019
}

@article{Lisle2013,
  abstract = {The assumption is widely made that slip on faults occurs in the direction of maximum resolved shear stress, an assumption known as the Wallace-Bott hypothesis. This assumption is used to theoretically predict slip directions from known in situ stresses, and also as the basis of palaeostress inversion from fault-slip data. This paper examines different situations in relation to the appropriateness of this assumption. Firstly, it is shown that the magnitude of the shear stress resolved within a plane is a function with a poorly defined maximum direction, so that shear stress values greater than 90\% of the maximum occur within a wide angular range (\ss{} 26\textdegree{}) degrees. The situation of simultaneous movement on pairs of faults requires slip on each fault to be parallel to their mutual line of intersection. However, the resolved shear stresses arising from a homogeneous state of stress do not accord with such a slip arrangement except in the case of pairs of perpendicular faults. Where fault surfaces are non-planar, the directions of resolved shear stress in general give, according to the Wallace-Bott hypothesis, a set of slip directions of rigid fault blocks, which is generally kinematically incompatible. Finally, a simple model of a corrugated fault suggests that any anisotropy of the shear strength of the fault such as that arising from fault surface topography, can lead to a significant angular difference between the directions of maximum shear stress and the slip direction. These findings have relevance to the design of procedures used to estimate palaeostresses and the amount of data required for this type of analysis.},
  author   = {Richard J. Lisle},
  doi      = {10.2113/gssgfbull.184.4-5.299},
  issn     = {00379409},
  issue    = {4-5},
  journal  = {Bulletin de la Societe Geologique de France},
  keywords = {Brittle tectonics,Corrugated fault surfaces,Paleostresses,Slickenlines,Structural analysis},
  pages    = {299--306},
  title    = {A critical look at the Wallace-Bott hypothesis in fault-slip analysis},
  volume   = 184,
  url      = {https://d1wqtxts1xzle7.cloudfront.net/32558932/Pub\_122\_2013\_angelier\_tribute-with-cover-page-v2.pdf?Expires=1648732786\&Signature=L0M4r0k0mzuwSpbQrCnV5op3YzXa51zSUXhbtNgSpGjVyrOteljWOK3cbUeoK7Gi1dAKvV78~KsAKtvGeJ2DeikDSP07ugb1zD7k6i6ouk-biIr8m4B8AG14M3-b4K},
  year     = 2013
}

@article{Liu2017,
  abstract  = {Background and aim Overground gait assessment is limited by the analysis of multiple strides or both spatiotemporal gait characteristics, while fixed speed treadmill walking restricts natural gait speed variations. The Gait Real-time Analysis Interactive Lab (GRAIL)-based 6-minute walk test (6MWT) enables 3D motion analysis and self-paced treadmill walking, and could provide insight in gait alterations in patients with chronic obstructive pulmonary disease (COPD). The aim of this study is to compare spatiotemporal gait characteristics between patients with COPD and healthy elderly during the GRAIL-based 6MWT. Materials and methods Eighty COPD patients (60\% male; 62\pm{}7 years; FEV1:56\pm{}19\% predicted) and 38 healthy elderly (63\% male; 62\pm{}6 years; FEV1:119\pm{}17\% predicted) performed two GRAIL-based 6MWTs. Mean differences and coefficient of variation of spatiotemporal gait characteristics were calculated using the trial with the largest walk distance. Sub-analyses were conducted to account for walking speed differences between groups, and muscle strength and COPD severity within the patient group. Results COPD patients showed increased temporal gait characteristics, decreased stride and step lengths, and increased gait variability compared to healthy elderly (p<0.01). Stride length variability remained increased in COPD after correction for walking speed (MD:0.98\%, CI:0.36–1.61, p = 0.003). Reduced quadriceps strength did not translate into altered gait characteristics, while COPD severity is associated with stride time (left MD:-0.02s, CI:-0.04–0.01, p = 0.003; right MD:-0.02s, CI:-0.04–0.01, p = 0.003). Discussion COPD patients performed the GRAIL-based 6MWT differently compared to healthy elderly. Further research should use other variability measures to investigate gait characteristics in COPD, to assess subtle alterations in gait and to enable development of rehabilitation strategies to improve gait, and possibly balance and fall risk in COPD. Other lower limb muscle groups should be considered when investigating gait alterations in COPD. Conclusion COPD patients have different gait characteristics compared to healthy elderly. Independent of walking speed, COPD patients demonstrate increased stride length variability during the GRAIL-based 6MWT compared to healthy elderly.},
  author    = {Wai Yan Liu and Martijn A. Spruit and Jeannet M. Delbressine and Paul J.B. Willems and Frits M.E. Franssen and Emiel F.M. Wouters and Kenneth Meijer},
  doi       = {10.1371/journal.pone.0190099},
  issn      = 19326203,
  issue     = 12,
  journal   = {PLoS ONE},
  keywords  = {Body limbs,Chronic obstructive pulmonary disease,Dyspnea,Fatigue,Gait analysis,Geriatric care,Oxygen,Walking},
  month     = 12,
  pages     = {e0190099},
  pmid      = 29284059,
  publisher = {Public Library of Science},
  title     = {Spatiotemporal gait characteristics in patients with COPD during the Gait real-time analysis interactive lab-based 6-minute walk test},
  volume    = 12,
  url       = {https://doi.org/10.1371/journal.pone.0190099},
  year      = 2017
}

@article{Liu2022,
  abstract = {Several theories have been proposed to explain atoll formation. While karst dissolution during glacial periods and preferential coral reef accretion along raised bank margins during deglaciations and interglacials have been invoked to explain atoll formation, the respective roles of karst dissolution and reef margin construction in atoll formation have not been adequately evaluated by simulations. In this study, we conducted three-dimensional numerical simulations of the Quaternary development of Meiji Atoll in the southern South China Sea based on interpreted data from a 2020-m-deep borehole drilled on its northeast rim in 2018. Our results suggest that the origin of atolls is more likely due to spatially differential dissolution across margin and interior areas (i.e., minimal along margins and maximal in bank centers) rather than preferential reef accretion along margins of flat-topped banks. Preferential reef accretion along margins of flat-topped banks that can result in central lagoons and atoll morphology can hardly result in the formation of lagoonal patch reefs that reach mean sea level. Preferential reef accretion along margins is mainly predicated on the karst-induced morphology that has a central depression surrounded by raised rims, that is, using antecedent karst morphologies. If topographic highs in the lagoon are similar in elevation to the margins, reef accretion on these topographic highs can be similar to that observed on the margins, resulting in lagoonal patch reefs that reach mean sea level. Our simulation shows that spatially differential dissolution across margin and interior areas is a critical driver of worldwide central lagoons and atoll formation.},
  author   = {Jinlong Liu and Jody M. Webster and Tristan Salles and Shuhong Wang and Yikai Ma and Weihai Xu and Gang Li and Wen Yan},
  doi      = {10.1029/2022JF006812},
  issn     = 21699011,
  issue    = 8,
  journal  = {Journal of Geophysical Research: Earth Surface},
  keywords = {atoll origin,coral reef accretion,karst dissolution,numerical modeling},
  title    = {The Formation of Atolls: New Insights From Numerical Simulations},
  volume   = 127,
  year     = 2022
}

@article{Lobello2012,
  abstract = {We present a Multi-Resolution Dual method based on an incremental octree-based refinement strategy. Our solution is able to generate multi-resolution surfaces from segmented volumetric data. It extends the Dual Marching Cubes algorithm over a generalized octree and guarantees that the produced surfaces are always manifold by introducing a new cell-based criterion for dual vertices generation. Moreover, we propose a top-bottom refinement algorithm that is able to locally adapt the mesh resolution according to a curvature parameter. Our algorithm is suitable to process volumetric data sets and we show on different volumes that the produced surfaces are manifold and approximate well the original object.},
  author   = {Ricardo Uribe Lobello and Florent Dupont and Florence Denis},
  doi      = {10.5220/0003858801630168},
  isbn     = 9789898565020,
  issue    = {February},
  journal  = {GRAPP 2012 IVAPP 2012 - Proceedings of the International Conference on Computer Graphics Theory and Applications and International Conference on Information Visualization Theory and Applications},
  keywords = {Image-based modeling,Multi-resolution modeling,Surface modeling},
  pages    = {163--168},
  title    = {Multi-Resolution Dual contouring from volumetric data},
  year     = 2012
}

@inproceedings{Lock2018,
  abstract  = {Understanding complex physiological processes demands the integration of diverse insights derived from visual and quantitative analysis of bio-image data, such as microscopy images. This process is currently constrained by disconnects between methods for interpreting data, as well as by language barriers that hamper the necessary cross-disciplinary collaborations. Using immersive analytics, we leveraged bespoke immersive visualizations to integrate bio-images and derived quantitative data, enabling deeper comprehension and seamless interaction with multi-dimensional cellular information. We designed and developed a visualization platform that combines time-lapse confocal microscopy recordings of cancer cell motility with image-derived quantitative data spanning 52 parameters. The integrated data representations enable rapid, intuitive interpretation, bridging the divide between bio-images and quantitative information. Moreover, the immersive visualization environment promotes collaborative data interrogation, supporting vital cross-disciplinary collaborations capable of deriving transformative insights from rapidly emerging bio-image big data.},
  author    = {John G. Lock and Daniel Filonik and Robert Lawther and Nalini Pather and Katharina Gaus and Sarah Kenderdine and Tomasz Bednarz},
  city      = {New York, New York, USA},
  doi       = {10.1145/3284398.3284412},
  isbn      = 9781450360876,
  booktitle = {Proceedings of the 16th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry - VRCAI '18},
  keywords  = {Confocal Microscopy,High-Performance Visualization,Systems Microscopy,Visual and Immersive Analytics},
  month     = 12,
  pages     = {1--4},
  publisher = {ACM Press},
  title     = {Visual analytics of single cell microscopy data using a collaborative immersive environment},
  url       = {http://dl.acm.org/citation.cfm?doid=3284398.3284412},
  year      = 2018
}

@article{Longay2012,
  abstract = {TreeSketch is a system for modeling complex trees that look natural yet are creatively designed. The system inte- grates procedural tree generation with a multi-touch tablet interface that provides detailed control of tree form. The procedural component is based on the concept of tree self-organization and simulates competition of branches for space and light as the tree develops from a seedling. The modeler can control this process by directing growth with a procedural brush, changing parameters as the tree grows, interleaving controlled and autonomous growth, and editing generated forms. Complex trees can be created in a matter of seconds.},
  author   = {Steven Longay and Adam Runions and Fr\'{e}d\'{e}ric Boudon and Przemyslaw Prusinkiewicz},
  journal  = {The proceedings of the Eurographics Symposium on Sketch-Based Interfaces and Modeling},
  pages    = {107--120},
  title    = {TreeSketch : Interactive Procedural Modeling of Trees on a Tablet},
  url      = {http://algorithmicbotany.org/papers/TreeSketch.SBM2012.large.pdf},
  year     = 2012
}

@article{Longay2019,
  abstract = {Three-dimensional kinematics of the lower extremities are typically assessed with external markers attached to the segments of interest. However, these markers may move considerably with respect to the underlying bone, and thus, large errors may be introduced. The purpose of this study was to determine the three-dimensional skeletal tibiocalcaneal (ankle joint complex, AJC) and tibiofemoral (knee) motion during the stance phase of walking and running, and to compare this to the respective motion determined from external markers.\r\n\r\nMarker triads were attached to intracortical bone pins inserted into the calcaneus, tibia, and femur of five subjects. Additionally, external markers were attached to the shoe, shank, and thigh. For each subject, three walking and five running trials were filmed with three high speed cameras (50 Hz for walking, 200 Hz for running). Cardan angles were calculated to express the intersegmental knee and AJC motion. Knee flexion/extension, ab/adduction, and internal/external knee rotation as well as AJC plantar/dorsiflexion, ab/adduction and in/eversion were calculated both from skeletal and external markers.\r\n\r\nFor walking and running, it was found that the skeletal tibiocalcaneal (AJC) motions were well reflected when using external markers. However, the rotations were generally overestimated when using external markers. For instance, during running, the maximal initial eversion occurring from touchdown to midstance averaged 16.0 when using external markers. However, the same variable determined from skeletal markers was only 8.6.\r\n\r\nDuring walking and running, the skeletal knee flexion/extension was well represented with skin markers. For ab/adduction and internal/external knee rotation, the agreement between external and skeletal kinematics ranged from good to virtually no agreement. In some subjects, the errors exceeded the actual skeletal motion. Methodological problems were also identified with the determination of tibiofemoral kinematics. Internal/external knee rotation and particularly ab/adduction can be expected to be small, and thus, they are highly affected by cross-talk caused by uncertainties in defining the anatomical coordinate systems.\r\n\r\nThe results of this project suggest that (a) tibiocalcaneal motions are generally well represented with external markers, but absolute values have to be interpreted with caution, and that (b) knee rotations other than flexion/extension may be affected with substantial errors when using skin markers.},
  author   = {Steven Longay},
  doi      = {10.1007/978-1-349-95810-8\_1179},
  journal  = {The Grants Register 2019},
  pages    = {768--770},
  title    = {Interactive Procedural Modelling of Trees and Landscapes},
  url      = {http://algorithmicbotany.org/papers/longay.th2014.small.pdf},
  year     = 2019
}

@article{Lopes2017,
  abstract = {Current research on adaptive games has mainly focused on adjusting difficulty in a variety of ways, for example, by providing some control over adaptive game world generation. These methods, however, are mostly ad-hoc and require quite some technical skills. To the best of our knowledge, so far there has been no adaptive method that is truly generic and explicitly designed to actively include game designers in the content creation loop. In this article, we introduce a generic method that enables designers to author adaptivity of game world generation, in a very expressive and specific fashion. Our approach uses adaptation rules which build atop gameplay semantics in order to steer the on-line generation of game content. Designers create these rules by associating skill profiles, describing skill proficiency, with content descriptions, detailing the desired properties of specific game world content. This game content is then generated on-line using a rule matching and retrieval approach. We performed user studies with both designers and players, and concluded that adaptation rules provide game designers with a rich expressive range to effectively convey specific adaptive gameplay experiences to players.},
  author   = {Ricardo Lopes and Elmar Eisemann and Rafael Bidarra},
  issue    = {c},
  journal  = {IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES},
  keywords = {Netherlands,Rafael Bidarra,TU Delft},
  pages    = {1--14},
  title    = {Authoring adaptive game world generation},
  url      = {http://dx.doi.org/10.1109/TCIAIG.2017.2678759},
  year     = 2017
}

@article{Lorensen1987,
  abstract  = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
  author    = {William E. Lorensen and Harvey E. Cline},
  doi       = {10.1145/37401.37422},
  isbn      = {0897912276},
  issue     = 4,
  journal   = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1987},
  keywords  = {Computer graphics,Medical imaging,Surface reconstruction,surface reconstruction},
  month     = 8,
  pages     = {163--169},
  publisher = {Association for Computing Machinery, Inc},
  title     = {Marching cubes: A high resolution 3D surface construction algorithm},
  volume    = 21,
  year      = 1987
}

@article{Louis2019,
  author  = {Silvain Louis and David Andreu and Karen Godary-dejean and Lionel Lapierre and Silvain Louis and David Andreu and Karen Godary-dejean and Lionel Lapierre and H I L Simulator and Silvain L Ouis and David A Ndreu and Karen G Odary Ejean and Lionel L Apierre},
  journal = {CAR: Control Architectures of Robots},
  title   = {HIL Simulator for AUV with ContrACT},
  year    = 2019
}

@article{Lu2019,
  abstract = {Inspired by skeletal animation, a novel rigging-skinning flow control scheme is proposed to animate fluids intuitively and efficiently. The new animation pipeline creates fluid animation via two steps: fluid rigging and fluid skinning. The fluid rig is defined by a point cloud with rigid-body movement and incompressible deformation, whose time series can be intuitively specified by a rigid body motion and a constrained free-form deformation, respectively. The fluid skin generates plausible fluid flows by virtually fluidizing the point-cloud fluid rig with adjustable zero- and first-order flow features and at fixed computational cost. Fluid rigging allows the animator to conveniently specify the desired low-frequency flow motion through intuitive manipulations of a point cloud, while fluid skinning truthfully and efficiently converts the motion specified on the fluid rig into plausible flows of the animation fluid, with adjustable fine-scale effects. Besides being intuitive, the rigging-skinning scheme for fluid animation is robust and highly efficient, avoiding completely iterative trials or time-consuming nonlinear optimization. It is also versatile, supporting both particle- and grid- based fluid solvers. A series of examples including liquid, gas and mixed scenes are presented to demonstrate the performance of the new animation pipeline.},
  author   = {Jia Ming Lu and Xiao Song Chen and Xiao Yan and Chen Feng Li and Ming Lin and Shi Min Hu},
  doi      = {10.1111/cgf.13856},
  issn     = 14678659,
  issue    = 7,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Physical simulation},
  pages    = {501--512},
  title    = {A Rigging-Skinning Scheme to Control Fluid Simulation},
  volume   = 38,
  url      = {https://cg.cs.tsinghua.edu.cn/papers/CGF-2019-fluid.pdf},
  year     = 2019
}

@article{Luo2010,
  abstract = {The least-significant-bit (LSB)-based approach is a popular type of steganographic algorithms in the spatial domain. However, we find that in most existing approaches, the choice of embedding positions within a cover image mainly depends on a pseudorandom number generator without considering the relationship between the image content itself and the size of the secret message. Thus the smooth/flat regions in the cover images will inevitably be contaminated after data hiding even at a low embedding rate, and this will lead to poor visual quality and low security based on our analysis and extensive experiments, especially for those images with many smooth regions. In this paper, we expand the LSB matching revisited image steganography and propose an edge adaptive scheme which can select the embedding regions according to the size of secret message and the difference between two consecutive pixels in the cover image. For lower embedding rates, only sharper edge regions are used while keeping the other smoother regions as they are. When the embedding rate increases, more edge regions can be released adaptively for data hiding by adjusting just a few parameters. The experimental results evaluated on 6000 natural images with three specific and four universal steganalytic algorithms show that the new scheme can enhance the security significantly compared with typical LSB-based approaches as well as their edge adaptive ones, such as pixel-value-differencing-based approaches, while preserving higher visual quality of stego images at the same time. \textcopyright{} 2010 IEEE.},
  author   = {Weiqi Luo and Fangjun Huang and Jiwu Huang},
  doi      = {10.1109/TIFS.2010.2041812},
  issn     = 15566013,
  issue    = 2,
  journal  = {IEEE Transactions on Information Forensics and Security},
  keywords = {Content-based steganography,Least-significant-bit (LSB)-based steganography,Pixel-value differencing (PVD),Security},
  month    = 6,
  pages    = {201--214},
  title    = {Edge adaptive image steganography based on lsb matching revisited},
  volume   = 5,
  url      = {http://ieeexplore.ieee.org/document/5411758/},
  year     = 2010
}

@article{Lutz2023,
  abstract = {By-example aperiodic tilings are popular texture synthesis techniques that allow a fast, on-the-fly generation of unbounded and non-periodic textures with an appearance matching an arbitrary input sample called the ``exemplar''. But by relying on uniform random sampling, these algorithms fail to preserve the autocovariance function, resulting in correlations that do not match the ones in the exemplar. The output can then be perceived as excessively random. In this work, we present a new method which can well preserve the autocovariance function of the exemplar. It consists in fetching contents with an importance sampler taking the explicit autocovariance function as the probability density function (pdf) of the sampler. Our method can be controlled for increasing or decreasing the randomness aspect of the texture. Besides significantly improving synthesis quality for classes of textures characterized by pronounced autocovariance functions, we moreover propose a real-time tiling and blending scheme that permits the generation of high-quality textures faster than former algorithms with minimal downsides by reducing the number of texture fetches.},
  author   = {Nicolas Lutz and Basile Sauvage and Jean Michel Dischler},
  doi      = {10.1111/cgf.14766},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,Texturing,\textbullet{} Computing methodologies \rightarrow{} Rendering},
  pages    = {347--358},
  title    = {Preserving the autocovariance of texture tilings using importance sampling},
  volume   = 42,
  year     = 2023
}

@misc{LuXia,
  author = {Lu Xia and Chia-Chih Chen and J. K. Aggarwal},
  title  = {View Invariant Human Action Recognition Using Histograms of 3D Joints},
  url    = {http://cvrc.ece.utexas.edu/Publications/Xia\_HAU3D12.pdf}
}

@article{Ma2017,
  abstract = {Conventional pyroelectric infrared (PIR) motion sensors use paired elements for the detection of moving targets. This method makes them incapable of measuring thermal signals from static targets. We need an active sensor that can detect static thermal subjects. This paper presents our design of active PIR sensors. The proposed PIR sensing systems can actively detect static thermal targets by using three methods that are suitable to different applications: 1) a sensor that can be rotated by a self-controlled servo motor for the detection of moving or static thermal subjects nearby; 2) a sensor that is equipped with a mask for low-complexity posture recognition; and 3) a sensor that can be worn on the wrist for the recognition of surrounding subjects (this sensor is especially useful for blind users). Compressive sensing (CS) theory indicates that random down-sampling method can capture more accurate information of the original signal than the evenly spaced sampling. Based on CS theory, we have developed the random sampling structures for the active PIR systems, and have built a statistical feature space for human scenario recognition. The experimental results demonstrate that the active sensing system can efficiently measure the static thermal targets, and the random sampling scheme has a better recognition performance than the even sampling scheme.},
  author   = {Rui Ma and Fei Hu and Qi Hao},
  doi      = {10.1109/TSMC.2016.2578465},
  issn     = 21682232,
  issue    = 12,
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  keywords = {Active sensing,compressive sensing (CS),pyroelectric infrared (PIR) sensor,random sampling,situation recognition},
  pages    = {3340--3350},
  title    = {Active Compressive Sensing via Pyroelectric Infrared Sensor for Human Situation Recognition},
  volume   = 47,
  year     = 2017
}

@article{MaciejKomosinski2000,
  abstract = {A three-dimensional virtual world simulation is described, where evolutiontakesplaceanditispossibletoinvestigatebehaviorsofcreaturesin real-time.Bodiesofthesecreaturesaremadeofsticks,andtheirbrainsarebuilt fromartificialneurons.Therearenoconstraintsontopologyandcomplexityof neuralnetworks,aswellasonthesizeofmorphology.Themodelisinspiredby biology,soenergeticissuessuchasenergygainsandlossesarealsoconsidered. Theevolutionaryprocesscanbeguidedbysomepre-definedcriteria,however, itispossibletomimicspontaneousevolutionwhenthefitnessisdefinedasthe life span of the organisms. Interactions in the virtual world are discussed (includingthepossibilityofworldwide-distributedsimulation),andtheresults ofso-farexperimentsarepresented. 1Introduction},
  author   = {MaciejKomosinski},
  issue    = {July 2000},
  journal  = {Proceedings of 2nd International Conference on Virtual Worlds},
  pages    = {214--224},
  title    = {The World of Framsticks: Simulation, Evolution, Interaction},
  url      = {http://www.frams.alife.pl/},
  year     = 2000
}

@article{Mahdavi-Amiri2015,
  abstract = {The creation of a digital representation of the Earth and its associated data is a complex and difficult task. The incredible size of geospatial data and differences between data sets pose challenges related to big data, data creation, and data integration. Advances in globe representation and visualization have made use of Discrete Global Grid Systems (DGGSs) that discretize the globe into a set of cells to which data are assigned. DGGSs are well studied and important in the GIS, OGC, and Digital Earth communities but have not been well-introduced to the computer graphics community. In this paper, we provide an overview of DGGSs and their use in digitally representing the Earth, describe several current Digital Earth systems and their methods of Earth representation, and list a number of applications of Digital Earths with related works. Moreover, we discuss the key research areas and related papers from computer graphics that are useful for a Digital Earth system, such as advanced techniques for geospatial data creation and representation.},
  author   = {Ali Mahdavi-Amiri and Troy Alderson and Faramarz Samavati},
  doi      = {10.1016/j.cag.2015.08.005},
  issn     = {00978493},
  journal  = {Computers and Graphics (Pergamon)},
  keywords = {Digital Earth,Discrete Global Grid System,Geospatial visualization,Virtual Globe},
  pages    = {95--117},
  title    = {A Survey of Digital Earth},
  volume   = 53,
  url      = {https://www.sfu.ca/~amahdavi/files/survey\_C\_G-min.pdf},
  year     = 2015
}

@article{Malinverno1989,
  abstract = {Stochastic models can generate profiles that resemble topography by taking uncorrelated, zero-average noise as input, introducing some correlation in the time series of noise, and integrating the resulting correlated noise. The output profile will depict a nonstationary, randomly rough surface. Two models have been chosen for comparison: a fractal model, in which the noise is correlated even at large distances, and an autoregressive model of order 1, in which the correlation of the noise decays rapidly. Both models have as an end-member a random walk, which is the integration of uncorrelated noise. The models have been fitted to profiles of submarine topography, and the sample autocorrelation, power spectrum and variogram have been compared to the theoretical predictions. The results suggest that a linear system approach is a viable method to model and classify sea-floor topography. The comparison does not show substantial disagreement of the data with either the autoregressive or the fractal model, although a fractal model seems to give a better fit. However, the amplitudes predicted by a nonstationary fractal model for long wavelengths (of the order of 1000 km) are unreasonably large. When viewed through a large window, ocean floor topography is likely to have an expected value determined by isostasy, and to be stationary. Nonstationary models are best applied to wavelengths of the order of 100 km or less. \textcopyright{} 1989 Birkh\"{a}user-Verlag.},
  author   = {Alberto Malinverno},
  doi      = {10.1007/BF00874484},
  issn     = {00334553},
  issue    = {1-2},
  journal  = {Pure and Applied Geophysics PAGEOPH},
  keywords = {Autoregressive processes,fractals,roughness,stochastic modeling,time series analysis,topography},
  pages    = {139--155},
  title    = {Testing linear models of sea-floor topography},
  volume   = 131,
  year     = 1989
}

@article{Mallet1989,
  abstract = {Interpolation of a function ƒ(\cdot{}) known at some data points of RP is a common problem. Many computer applications (e.g., automatic contouring) need to perform interpolation only at the nodes of a given grid. Whereas most classical methods solve the problem by finding a function defined everywhere, the proposed method avoids explicitly computing such a function and instead produces values only at the grid points. For two-dimensional regular grids, a special case of this method is identical to the Briggs method (see ``Machine Contouring Using Minimum Curvature,'' Geophysics 17, 1 (1974)), while another special case is equivalent to a discrete version of thin plate splines (see J. Duchon, Fonctions Splines du type Plaque Mince en Dimention 2, S\'{e}minaire d'analyse num\'{e}rique, n 231, U.S.M.G., Grenoble, 1975; and J. Enriquez, J. Thomann, and M. Goupillot, Application of bidimensional spline functions to geophysics, Geophysics 48, 9 (1983)). \textcopyright{} 1989, ACM. All rights reserved.},
  author   = {Jean-Laurent Mallet},
  doi      = {10.1145/62054.62057},
  issn     = 15577368,
  issue    = 2,
  journal  = {ACM Transactions on Graphics (TOG)},
  keywords = {Interpolation,grid,smooth,splines},
  pages    = {121--144},
  title    = {Discrete Smooth Interpolation},
  volume   = 8,
  url      = {https://dl.acm.org/doi/pdf/10.1145/62054.62057},
  year     = 1989
}

@article{Mallet1992,
  abstract = {In such fields as geology and biology, a common problem is that of modelling complex surfaces that are defined by data of various types. Classical modelling techniques based on B\'{e}zier and spline interpolations can account for only some of these types of data. The paper proposes a different approach that is based on the discrete smooth interpolation method. In this approach, surfaces are modelled as 2D graphs whose node locations are determined for a wide variety of heterogeneous data. \textcopyright{} 1992.},
  author   = {Jean-Laurent Mallet},
  doi      = {10.1016/0010-4485(92)90054-E},
  issn     = {00104485},
  issue    = 4,
  journal  = {Computer-Aided Design},
  keywords = {geometric modelling,interpolation},
  pages    = {178--191},
  title    = {Discrete smooth interpolation in geometric modelling},
  volume   = 24,
  year     = 1992
}

@article{Mallet1997,
  abstract = {This paper presents a discrete technique specially designed for modeling the geometry and the properties of natural objects as those encountered in biology and geology. Contrary to classical Computer-Aided Design methods based on continuous (polynomial) functions, the proposed approach is based on a discretization of the objects close to the finite-element techniques used for solving differential equations. Each object is modeled as a set of interconnected nodes holding the geometry and the physical properties of the objects and the Discrete Smooth Interpolation method is used for fitting the geometry and the properties to complex data. Data are turned into linear constraints and some constraints related to typical information encountered in geology are presented.},
  author   = {Jean-Laurent Mallet},
  doi      = {10.1007/BF02769628},
  issn     = {08828121},
  issue    = 2,
  journal  = {Mathematical Geology},
  keywords = {DSI,Geometrical modeling,Interpolation},
  pages    = {199--219},
  title    = {Discrete modeling for natural objects},
  volume   = 29,
  year     = 1997
}

@article{Mallios2017,
  abstract = {This paper describes a data set collected with an autonomous underwater vehicle testbed in the unstructured environment of an underwater cave complex. The vehicle is equipped with two mechanically scanned imaging sonar sensors to simultaneously map the caves horizontal and vertical surfaces, a Doppler velocity log, two inertial measurement units, a depth sensor, and a vertically mounted camera imaging the sea floor for ground truth validation at specific points. The testbed collected the data in July 2013, guided by a human diver, to sidestep autonomous navigation in a complex environment. For ease of use, the original robot operating system bag files are provided together with a version combining imagery and human-readable text files for processing on other environments.},
  author   = {Angelos Mallios and Eduard Vidal and Ricard Campos and Marc Carreras},
  doi      = {10.1177/0278364917732838},
  issn     = 17413176,
  issue    = 12,
  journal  = {International Journal of Robotics Research},
  keywords = {Underwater robotics,acoustic imaging sonar,field and service robotics,simultaneous localization and mapping,underwater caves},
  pages    = {1247--1251},
  title    = {Underwater caves sonar data set},
  volume   = 36,
  year     = 2017
}

@misc{MARAK,
  abstract = {This paper introduces a new approach to erosions of models of terrains. This approach is based on two dimensional generalization of the rewriting process - array grammars. A height field representing the terrain is considered as the matrix and context sensitive rewriting of this matrix, represents the erosion process. This approach is quite general and allows us to use an arbitrary kind of erosion which can be expressed by means of rewriting productions.},
  author   = {Ivo Marak and Bedrich Benes and Pavel Slavik},
  isbn     = {80-7082-306-2},
  issue    = {1-3},
  journal  = {Journal of WSCG},
  pages    = {341--350},
  title    = {Terrain erosion model based on rewriting of matrices},
  volume   = 5,
  url      = {http://cat.inist.fr/?aModele=afficheN\&cpsidt=2723081},
  year     = 1997
}

@article{Marchand2019,
  author = {Maxime Marchand},
  title  = {Optimisation du traitement de nuage de points pour la production de plan de fa\c{c}ade au sein d'un cabinet de g\'{e}om\`{e}tre-expert},
  year   = 2019
}

@misc{Marechal2005,
  abstract = {Dans le cadre du programme de recherche KARSTEAU (PDR04EAU01) et de la convention n\textdegree{} 2003.07.23 \'{e}tablie avec la Ville de N\^{\i}mes, le BRGM a pour objectif de caract\'{e}riser la structure et le fonctionnement de l'hydrosyst\`{e}me karstique n\^{\i}mois et d'\'{e}valuer sa contribution \`{a} la gen\`{e}se et \`{a} la propagation des crues \'{e}clair, en travaillant \`{a} deux \'{e}chelles spatiales : celle de la totalit\'{e} du bassin d'alimentation et celle de sites pilotes li\'{e}s \`{a} un ou deux bassins versants ou sous-bassins versants de cadereaux. L'approche spatiale \`{a} l'\'{e}chelle de la totalit\'{e} du bassin d'alimentation est r\'{e}alis\'{e}e au sein : - du module 1 du projet, dont l'objectif est la connaissance de la structure et du fonctionnement hydrologique du bassin d'alimentation de la Fontaine de N\^{\i}mes ; - du module 2 du projet, dont l'objectif est la connaissance du fonctionnement hydrog\'{e}ologique de l'\'{e}pikarst et de la zone noy\'{e}e au moyen de l'acquisition de donn\'{e}es compl\'{e}mentaires. Dans le cadre du module 1, un premier bilan de l'\'{e}tat des connaissances a \'{e}t\'{e} effectu\'{e} au sein d'une synth\`{e}se bibliographique – rapport RP-53422-FR (Mar\'{e}chal et al., 2004). Le pr\'{e}sent rapport contient les premiers r\'{e}sultats des observations entreprises sur le syst\`{e}me karstique de la Fontaine de N\^{\i}mes dans le cadre de cette \'{e}tude (modules 1 et 2). Son principal objectif est de fournir un premier mod\`{e}le conceptuel du fonctionnement et de la structure du syst\`{e}me karstique \`{a} l'\'{e}chelle du bassin d'alimentation.},
  author   = {Jean-christophe Mar\'{e}chal and B. Ladouche and N. Courtois and N. D\"{o}rfliger and P. Le Strat and A. Bironne},
  keywords = {Innondation,Mod\'{e}lisation,N\^{\i}mes,eau souterraine,syst\`{e}me karstique},
  pages    = 187,
  title    = {Mod\`{e}le conceptuel de la structure et du fonctionnement du syst\`{e}me karstique de la Fontaine de N\^{\i}mes - Rapport final},
  url      = {http://infoterre.brgm.fr/rapports/RP-53827-FR.pdf},
  year     = 2005
}

@article{Mareschal1989,
  abstract = {Sea-floor bathymetric profiles exhibit features at many different scales of length; this suggests that they could be described as fractals. An algorithm interpolating a fractal line between points has been used to reconstruct bathymetric profiles from a few data points. In general, this fractal line has the same Fourier amplitude spectrum as real bathymetry, and, if the parameters of the interpolation are suitably chosen, it has a very similar appearance. The success of this fractal reconstruction algorithm for the sea-floor raises the possibility that it could be used to extrapolate, from data collected at one scale, the properties of the sea-floor at finer scales, and that similar techniques could be used to interpolate a surface between bathymetric profiles. The fractal character is a sign that the processes that shape the sea-floor are scale invariant and suggests that the renormalization group technique could be used to model these processes. \textcopyright{} 1989 Birkh\"{a}user-Verlag.},
  author   = {Jean Claude Mareschal},
  doi      = {10.1007/BF00874487},
  issn     = {00334553},
  issue    = {1-2},
  journal  = {Pure and Applied Geophysics PAGEOPH},
  keywords = {Fractal,bathymetry,fracture zone,interpolation,ridge,tectonics},
  pages    = {197--210},
  title    = {Fractal reconstruction of sea-floor topography},
  volume   = 131,
  year     = 1989
}

@inbook{Margin,
  author  = {Paula Keener-Chavis},
  journal = {Learning Ocean Science through Ocean Exploration},
  pages   = {41--63},
  title   = {Ocean Geologic Features},
  url     = {https://oceanexplorer.noaa.gov/edu/curriculum/section4a.pdf},
  year    = 2006
}

@inproceedings{Marhefka1996,
  abstract  = {I n this paper, a sample nonlinear contact model is presented f o r use in computer simulation. The nonlinear model is shown to maintain the computational simplicity of the linear model while addressing many of its deficiencies. One such advantage is that contact forces vary continuously over time. A new phase plane solution f o r the nonlinear model is obtained which reveals m a n y previously unnoted properties. These include proper variation of the coejjicient of restitution with impact velocity over a wide range of impact velocities , independence of model parameters, and lack of tensile (sticking) forces in simple impacts. A n example is presented which demonstrates the use of the contact model i n simulating the foot-ground interaction during the locomotion cycle of a walking machine.},
  author    = {D.W. Marhefka and D.E. Orin},
  doi       = {10.1109/ROBOT.1996.506951},
  isbn      = {0-7803-2988-0},
  booktitle = {Proceedings of IEEE International Conference on Robotics and Automation},
  pages     = {1662--1668},
  publisher = {IEEE},
  title     = {Simulation of contact using a nonlinear damping model},
  volume    = 2,
  url       = {http://ieeexplore.ieee.org/document/506951/},
  year      = 1996
}

@misc{MariaDiazBarros2015,
  abstract = {This paper presents a novel approach to estimate the human pose from a body-scanned point cloud. To do so, a predefined skeleton model is first initialized according to both the skeleton base point and its torso limb obtained by Principal Component Analysis (PCA). Then, the body parts are iteratively clustered and the skeleton limb fitting is performed, based on Expectation Maximization (EM). The human pose is given by the location of each skeletal node in the fitted skeleton model. Experimental results show the ability of the method to estimate the human pose from multiple point cloud video sequences representing the external surface of a scanned human body; being robust, precise and handling large portions of missing data due to occlusions, acquisition hindrances or registration inaccuracies.},
  author   = {Jilliam Mar\'{\i}a Diaz Barros and Frederic Garcia and D\'{e}sir\'{e} Sidib\'{e}},
  keywords = {Human pose estimation,point cloud,skeleton model},
  title    = {Real-Time Human Pose Estimation from Body-Scanned Point Clouds},
  url      = {https://hal-univ-bourgogne.archives-ouvertes.fr/hal-01145637},
  year     = 2015
}

@article{Mark2015,
  abstract = {Procedural Content Generation in Games (PCG) is a thriv-\r\ning field of research and application. Recent presented ex-\r\namples range from levels, stories and race tracks to complete\r\nrulesets for games. However, there is not much research to\r\ndate on procedural 3D modeling of caves, and similar en-\r\nclosed natural spaces. In this paper, we present a modular\r\npipeline to procedurally generate underground caves in real-\r\ntime, to be used as part of larger landscapes in game worlds.\r\nWe propose a three step approach, which can be fully im-\r\nplemented using General-Purpose Computing on Graphics\r\nProcessing (GPGPU) technology: 1) an L-System to em-\r\nulate the expanded cracks and passages which form cave\r\nstructures in nature, 2) a noise-perturbed metaball approach\r\nfor virtual 3D carving, and 3) a rendering component for\r\nisosurface extraction of the modeled voxel data, and fur-\r\nther mesh enhancement through shader programming. We\r\ndemonstrate how the interaction between these components\r\nproduce results comparable to real world caves, and show\r\nthat the solution is viable for video game environments. For\r\nthis, we present the findings of a user study we conducted\r\namong indie-game developers and players, using our results.},
  author   = {Benjamin Mark and Tudor Berechet and Tobias Mahlmann and Julian Togelius},
  isbn     = 9780991398249,
  journal  = {Foundations of Digital Games},
  keywords = {Filosofi},
  title    = {Procedural Generation of 3D Caves for Games on the GPU},
  url      = {http://lup.lub.lu.se/record/5464981/file/5464988.pdf},
  year     = 2015
}

@article{Markenzon2008,
  abstract = {In this paper two methods for automatic generation of connected chordal graphs are proposed: the first one is based on new results concerning the dynamic maintenance of chordality under edge insertions; the second is based on expansion/merging of maximal cliques. Theoretical and experimental results are presented. In both methods, chordality is preserved along the whole generation process. \textcopyright{} 2007 Springer Science+Business Media, LLC.},
  author   = {Lilian Markenzon and Oswaldo Vernet and Luiz Henrique Araujo},
  doi      = {10.1007/s10479-007-0190-4},
  issn     = {02545330},
  issue    = 1,
  journal  = {Annals of Operations Research},
  keywords = {Chordal graphs,Clique-tree,Dynamic algorithms,Graph generation},
  pages    = {47--60},
  title    = {Two methods for the generation of chordal graphs},
  volume   = 157,
  year     = 2008
}

@article{Martinet2010,
  author = {Lucie Martinet},
  pages  = {1--16},
  title  = {Drawing Planar Graphs},
  volume = 1,
  year   = 2010
}

@article{Martinez,
  abstract = {Action recognition has seen a dramatic performance improvement in the last few years. Most of the current state-of-the-art literature either aims at improving performance through changes to the backbone CNN network, or they explore different trade-offs between computational efficiency and performance, again through altering the backbone network. However, almost all of these works maintain the same last layers of the network, which simply consist of a global average pooling followed by a fully connected layer. In this work we focus on how to improve the representation capacity of the network, but rather than altering the backbone, we focus on improving the last layers of the network, where changes have low impact in terms of computational cost. In particular, we show that current architectures have poor sensitivity to finer details and we exploit recent advances in the fine-grained recognition literature to improve our model in this aspect. With the proposed approach, we obtain state-of-the-art performance on Kinetics-400 and Something-Something-V1, the two major large-scale action recognition benchmarks.},
  author   = {Brais Martinez and Davide Modolo and Yuanjun Xiong and Joseph Tighe},
  month    = 8,
  title    = {Action recognition with spatial-temporal discriminative filter banks},
  url      = {http://arxiv.org/abs/1908.07625},
  year     = 2019
}

@article{Maslin2021,
  abstract  = {Coral reefs are under increasing threat, and the loss of reef-associated fishes providing valuable ecosystem services is accelerating. The monitoring of such rapid changes has become a challenge for ecologists and ecosystems managers using traditional approaches like scuba divers performing underwater visual censuses (UVC) or diver operated video recording (DOV). However, the use of small, low-cost robots could help tackle the challenge of such monitoring, provided that they perform at least as well as diver-based methods. To address this question, tropical fish assemblages from 13 fringing reefs around Mayotte Island (Indian Ocean) were monitored along 50~m-long transects using stereo videos recorded by a semi-autonomous underwater vehicle (SAUV) and by a scuba diver (Diver Operated stereo Video system, DOV). Differences between the methods were tested for complementary fish assemblage metrics (species richness, total biomass, total density, Shannon diversity and Pielou evenness) and for the number and size of nine targeted species. SAUV recorded on average 35\% higher biomass than DOV which in turn recorded on average 12\% higher species richness. Biomass differences were found to be due to SAUV monitoring larger fishes than DOV, a potential marker of human-related fish avoidance behaviour. This study demonstrates that SAUV provides accurate metrics of coral reef fish biodiversity compared to diver-based procedures. Given their ability to conduct video transects at high frequency, 100~m depth range and at a moderate cost, SAUV is a promising tool for monitoring fish assemblages in coral reef ecosystems.},
  author    = {Mathilde Maslin and Silvain Louis and Karen Godary Dejean and Lionel Lapierre and S\'{e}bastien Vill\'{e}ger and Thomas Claverie},
  doi       = {10.1002/rse2.209},
  issn      = 20563485,
  issue     = 4,
  journal   = {Remote Sensing in Ecology and Conservation},
  keywords  = {Coral reef ecosystems,fish biometrics,marine robotics,stereovision,transect surveys},
  month     = 12,
  pages     = {567--578},
  publisher = {John Wiley and Sons Inc},
  title     = {Underwater robots provide similar fish biodiversity assessments as divers on coral reefs},
  volume    = 7,
  year      = 2021
}

@article{Masselink2020,
  abstract = {Increased flooding due to sea level rise (SLR) is expected to render reef islands, defined as sandy or gravel islands on top of coral reef platforms, uninhabitable within decades. Such projections generally assume that reef islands are geologically inert landforms unable to adjust morphologically. We present numerical modeling results that show reef islands composed of gravel material are morphodynamically resilient landforms that evolve under SLR by accreting to maintain positive freeboard while retreating lagoonward. Such island adjustment is driven by wave overtopping processes transferring sediment from the beachface to the island surface. Our results indicate that such natural adaptation of reef islands may provide an alternative future trajectory that can potentially support near-term habitability on some islands, albeit with additional management challenges. Full characterization of SLR vulnerability at a given reef island should combine morphodynamic models with assessments of climate-related impacts on freshwater supplies, carbonate sediment supply, and future wave regimes.},
  author   = {Gerd Masselink and Eddie Beetham and Paul Kench},
  doi      = {10.1126/sciadv.aay3656},
  issn     = 23752548,
  issue    = 24,
  journal  = {Science Advances},
  pmid     = 32577502,
  title    = {Coral reef islands can accrete vertically in response to sea level rise},
  volume   = 6,
  year     = 2020
}

@article{Matthews,
  abstract = {We present a system for procedurally generating a map for a story-driven game, where locations in the map are assigned algorithmically or by designer preference. In addition, we also generate terrain, together with climate to match the terrain, with smooth, coherent transitions between terrain exhibiting different weather. We summarize weather approximations using a tuple to represent conditions such as temperature and humidity. We then exploit our previous work in map construction by placing locations of interest in the story on the map and then build a terrain boundary map that determines the boundaries between ranges of tuple values that belong to specific terrain types. We complete our construction by combining the climate map with a terrain type lookup, producing a final map with cohesive terrains. We describe the implementation of our system and illustrate the construction with some procedurally generated maps, including the procedural generation of the Narshe/Figaro area from Final Fantasy VI.},
  author   = {EA Matthews and BA Malloy},
  journal  = {Meaningfulplay.Msu.Edu},
  title    = {Incorporating Coherent Terrain Types into Story-Driven Procedural Maps},
  url      = {http://meaningfulplay.msu.edu/proceedings2012/mp2012\_submission\_41.pdf}
}

@article{Maximovitch2008,
  author   = {N Maximovitch and O Shumilova},
  journal  = {3-rd International Workshop on ice Caves: Proceedings, Kungur ice Cave, Perm region},
  keywords = {cave,chemistry,easternmost,european region of russia,form the,ice,in turn,mineralogy,perm region is the,situated near,stalagmites,the ural mountains,which},
  pages    = {105--107},
  title    = {ORDINSKAYA CAVE - THE LONGEST UNDERWATER CAVE IN RUSSIA},
  year     = 2008
}

@article{Mcclanahan2022,
  abstract = {Since the launch of the 50 Reefs portfolio in 2018, the world's coral reefs have experienced continued climate change impacts that have led to mass coral bleaching and mortality. Drawing on thirty years of research, we highlight the environmental and biological factors that predict the ongoing climate impacts of coral reefs, and explore the potential for adaptation, acclimation and stress tolerance of coral reefs. We propose to expand the 50 Reefs approach into three types of climate change sanctuaries: avoidance, resistance, and recovery refugia. While previous efforts have typically focused on avoidance sanctuaries, defined as coral reef locations that have until now avoided climate-change related stresses and are predicted to experience less future acceleration of stresses (e.g., the 50 Reefs), there is a renewed urgency to safeguard locations that can also display resistance to climate exposure or show rapid recovery after bleaching events. The 50 Reefs portfolio remains a good investment for avoidance sanctuaries but becomes more robust when resistance and recovery sanctuaries are included. We recommend that future portfolios should include reefs with broader environmental, ecological, and genetic characteristics that specifically underscore resistance and recovery. However, testing the predictions of these models remains crucial in order to evaluate the expectation that reefs within proposed sanctuaries are healthier (i.e., coral cover and reef fish biomass above key thresholds, higher diversity) than reefs outside of proposed sanctuaries. Ultimately, a holistic approach integrating sanctuaries and ecosystem services can inform how investments in coral reef conservation can safeguard key reef functions of maintained carbonate production of reef corals, coral adaptation/acclimation processes, and reef fisheries production. As impacts of climate change accelerate and result in ecological surprises or adaptation/acclimation mechanisms, future modeling efforts should go beyond excess heat and temperatures to integrate globally comparable datasets of ecological surveys, hydrodynamic modeling, genetics, and remotely sensed environmental data layers. We conclude with specific recommendations for governments, funders, conservation organizations, and stakeholders on how to promote the persistence and survival of tropical coral reefs in order to minimize the loss of reef services to humanity under the increasing stress of climate change. These recommendations include: Continue with the 50 Reefs approach (i.e., climate change avoidance sanctuaries) as a priority for investment in coral reef conservation. Expand the 50 Reefs conservation portfolio for climate change to include coral resistance and recovery sanctuaries. Increase support for regional evaluations of the health of the 50 Reefs portfolio, and sustainable financing initiatives to support the implementation of regional portfolios. Catalyze large-scale, data-driven coral reef monitoring efforts to test and develop new models and predictions of climate sanctuaries. Use the latest climate coral reef science to guide investments, especially as the impacts of climate change accelerate and produce novel environmental stresses and responses among reefs. Embrace a holistic approach to the management of 50 Reefs sites, including connections to broader seascapes, fisheries and water quality management, mitigation of other pressures (e.g., industrial development), so that effective and equitable management has measurable benefits for coral reefs and coastal communities.},
  author   = {Tim Mcclanahan and Emily Darling and Remy Oddenyo and Gautam Surya and Maria Beger and Helen Fox5 and Stacy Jupiter6 and Lizzie Mcleod7 and Lisa Mcmanus8 and Robert Van Woesik9 and Hedley Grantham3 and Cheryl Logan and Joseph Maina and Vardhan Patankar and Amelia Wenger1 and Jens Zinke},
  issue    = {April},
  journal  = {Vibrant Oceans Initiative Whitepaper},
  title    = {Forecasting Climate Sanctuaries for Securing the Future of Coral Reefs},
  url      = {https://coral.org/wp-content/uploads/2022/04/50-Reefs-Science-whitepaper.pdf},
  year     = 2022
}

@article{McDonald1969,
  abstract = {Statistical method for studying the two-dimensional topography of a patch of ocean floor from radial track soundings is discussed and then illustrated for a 18. 5-km square located at the intersection of a continental rise and slope. The topographic features highlighted by the sutdy are related to a detailed bathymetric map of the area with good correspondence. It is, therefore, suggested that a very useful description of an area can be obtained from a minimum number of intersecting tracks, and since the method is quantitative, it offers the possiblility of making objective comparison between different areas.},
  author   = {Martin F. McDonald and Eli Joel Katz},
  doi      = {10.1029/jb074i010p02597},
  issue    = 10,
  journal  = {J Geophys Res},
  pages    = 25972607,
  title    = {Quantitative Method for Describing the Regional Topography of the Ocean Floor},
  volume   = 74,
  year     = 1969
}

@article{McInerney2007,
  abstract = {3D geometric modelling is a powerful tool enabling improved understanding of geology. It allows one to check and validate the consistency of separate 1D or 2D interpretations. Building a 3D model is also a way to share and communicate a geological view. Furthermore, a consistent 3D geometric model is essential for modelling computations of Earth-processes (such as groundwater studies) that need an accurate and coherent geometry of the distribution of physical properties of geological bodies. An original methodology has been developed in the BRGM to jointly interpolate geological contact locations and dips of the formations. The method uses the geological history of the area and the rock-relationships between the geological bodies. The model is calculated using an implicit 3D potential function as the interpolator for each component part of that geological history, and allows automatic computation of intersections between component parts and volume reconstruction. By using these tools, the geologist focuses on geological issues and easily tests different interpretations. This methodology has been applied to various geological contexts. The Elk gas field case-study is presented to illustrate the development of a 3D geology model, and the application of the model for computing conventional potential field model responses. For the Elk field the Gdd component of the gravity gradient tensor was computed for the 3D geology model, and those data compared to the first vertical derivative of the fully terrain-corrected Bouguer gravity airborne survey data. These comparisons of the computed vs. observed gravity data provided a basis for several iterations of interpretive adjustment of the 3D geology model. This iterative interpretive revision of the model was only practical by virtue of the ability to rapidly re-compute the 3D geology model using the potential field interpolator methodology. The outcome from this approach was an improved 3D geology model which honoured the available geology constraints from outcrop, drilling and seismic data, but which now had a modelled gravity response that was in better agreement with the observed gravity data.},
  author   = {P. McInerney and A. Goldberg and P. Calcagno and G. Courrioux and R. Guillen and R. Seikel},
  journal  = {Exploration 07: Fifth Decennial International Conference on Mineral Exploration},
  pages    = {919--922},
  title    = {Improved 3D Geology Modelling using an Implicit Function Interpolator and Forward Modelling of Potential Field Data},
  url      = {https://www.911metallurgist.com/blog/wp-content/uploads/2015/10/Improved-3D-Geology-Modelling-using-an-Implicit-Function-Interpolator-and-Forward-Modelling-of-Potential-Field-Data.pdf},
  year     = 2007
}

@misc{McLane2011,
  abstract = {Conservation planning of critical habitats for wildlife species at risk is a priority topic that requires the knowledge of how animals select and use their habitat, and how they respond to future developmental changes in their environment. This paper explores the role of a habitat-modeling methodological approach, agent-based modeling, which we advocate as a promising approach for ecological research. Agent-based models (ABMs) are capable of simultaneously distinguishing animal densities from habitat quality, can explicitly represent the environment and its dynamism, can accommodate spatial patterns of inter- and intra-species mechanisms, and can explore feedbacks and adaptations inherent in these systems. ABMs comprise autonomous, individual entities; each with dynamic, adaptive behaviors and heterogeneous characteristics that interact with each other and with their environment. These interactions result in emergent outcomes that can be used to quantitatively examine critical habitats from the individual- to population-level. ABMs can also explore how wildlife will respond to potential changes in environmental conditions, since they can readily incorporate adaptive animal-movement ecology in a changing landscape. This paper describes the necessary elements of an ABM developed specifically for understanding wildlife habitat selection, reviews the current empirical literature on ABMs in wildlife ecology and management, and evaluates the current and future roles these ABMs can play, specifically with regards to scenario planning of designated critical habitats. \textcopyright{} 2011 Elsevier B.V.},
  author   = {Adam J. McLane and Christina Semeniuk and Gregory J. McDermid and Danielle J. Marceau},
  doi      = {10.1016/j.ecolmodel.2011.01.020},
  issn     = {03043800},
  issue    = 8,
  journal  = {Ecological Modelling},
  keywords = {Agent-based model,Animal learning,Conservation planning,Environmental representation,Habitat modeling,Movement ecology},
  month    = 4,
  pages    = {1544--1556},
  title    = {The role of agent-based models in wildlife ecology and management},
  volume   = 222,
  year     = 2011
}

@article{Mcmanus2021,
  abstract = {<p>Corals are experiencing unprecedented decline from climate change-induced mass bleaching events. Dispersal not only contributes to coral reef persistence through demographic rescue but can also hinder or facilitate evolutionary adaptation. Locations of reefs that are likely to survive future warming therefore remain largely unknown, particularly within the context of both ecological and evolutionary processes across complex seascapes that differ in temperature range, strength of connectivity, network size, and other characteristics. Here, we used eco-evolutionary simulations to examine coral adaptation to warming across reef networks in the Caribbean, the Southwest Pacific, and the Coral Triangle. We assessed the factors associated with coral persistence in multiple reef systems to understand which results are general and which are sensitive to particular geographic contexts. We found that evolution can be critical in preventing extinction and facilitating the long-term recovery of coral communities in all regions. Furthermore, the strength of immigration to a reef (destination strength) and current sea surface temperature robustly predicted reef persistence across all reef networks and across temperature projections. However, we found higher initial coral cover, slower recovery, and more evolutionary lag in the Coral Triangle, which has a greater number of reefs and more larval settlement than the other regions. We also found the lowest projected future coral cover in the Caribbean. These findings suggest that coral reef persistence depends on ecology, evolution, and habitat network characteristics, and that, under an emissions stabilization scenario (RCP 4.5), recovery may be possible over multiple centuries.</p>},
  author   = {Lisa C. McManus and Daniel L. Forrest and Edward W. Tekwa and Daniel E. Schindler and Madhavi A. Colton and Michael M. Webster and Timothy E. Essington and Stephen R. Palumbi and Peter J. Mumby and Malin L. Pinsky},
  doi      = {10.1111/gcb.15725},
  issn     = {1354-1013},
  issue    = 18,
  journal  = {Global Change Biology},
  keywords = {biology,hawaiʻi institute of marine,kaneʻohe,manoa,university of hawaiʻi at},
  month    = 9,
  pages    = {4307--4321},
  title    = {Evolution and connectivity influence the persistence and recovery of coral reefs under climate change in the Caribbean, Southwest Pacific, and Coral Triangle},
  volume   = 27,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/gcb.15725},
  year     = 2021
}

@article{McNamara2004,
  abstract = {We describe a novelmethod for controlling physics-based fluid simulations through gradient-based nonlinear optimization. Using a technique known as the adjoint method, derivatives can be computed efficiently, even for large 3D simulations with millions of control parameters. In addition, we introduce the first method for the full control of free-surface liquids. We show how to compute adjoint derivatives through each step of the simulation, including the fast marching algorithm, and describe a new set of control parameters specifically designed for liquids. Copyright \textcopyright{} 2004 ACM.},
  author   = {Antoine McNamara and Adrien Treuille and Zoran Popovi\'{c} and Jos Stam},
  doi      = {10.1145/1186562.1015744},
  journal  = {ACM SIGGRAPH 2004 Papers, SIGGRAPH 2004},
  keywords = {Adjoint method,Inverse control,Optimization},
  pages    = {449--456},
  title    = {Fluid control using the adjoint method},
  year     = 2004
}

@article{Meakin1986,
  author  = {Paul Meakin},
  journal = {Journal of Theoretical Biology},
  pages   = {101--113},
  title   = {A New Model for Biological Pattern Formation},
  volume  = 118,
  year    = 1986
}

@article{Meakin1991,
  abstract = {Adaptive-network growth has been obtained by a diffusion-limited- aggregation model in which particles of the cluster that do not connect active regions (regions in which deposition is occurring) to the seed or origin of the cluster are removed from the cluster. In the computer simulation of this model, the accumulated score associated with each of the Nb particles connecting a deposited particle to the seed is increased by 1/Nb when the particle is added. At the same time, the scores of all particles in the cluster are decreased by an amount 1/Nm, which is a parameter of the model. Particles with scores less than zero are then removed from the cluster. This model leads to the formation of clusters that reach a stationary state in which the cluster size s(t) fluctuates about a constant value controlled by the parameter Nm. The number of particles N(r) within a distance r from the seed is given by N(r)r, where the exponent (fractal dimensionality) 1.25. The scaling of the cluster size with Nm is described by s\guillemotright{}(t)=Nmf(t/Nm), where t is the time (number of particles that have contacted the cluster). The exponent has a value of about 0.75. The score of each surviving particle is a measure (r) that also exhibits interesting scaling behavior. \textcopyright{} 1991 The American Physical Society.},
  author   = {Paul Meakin and Jens Feder and Torstein Jossang},
  doi      = {10.1103/PhysRevA.44.5104},
  issn     = 10502947,
  issue    = 8,
  journal  = {Physical Review A},
  pages    = {5104--5110},
  title    = {Growth of adaptive networks in a modified diffusion-limited-aggregation model},
  volume   = 44,
  url      = {https://journals.aps.org/pra/pdf/10.1103/PhysRevA.44.5104},
  year     = 1991
}

@article{Mehla2005,
  author      = {Anubhav Mehla},
  city        = {Saskatoon},
  institution = {University of Saskatchewan},
  title       = {Modeling and Animation of Orb Webs},
  url         = {https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=598c8b0a2f65c023fcc0ca0896a8d3a8c548cdc8},
  year        = 2005
}

@article{Mei2007,
  abstract = {Natural mountains and valleys are gradually eroded by rainfall and river flows. Physically-based modeling of this complex phenomenon is a major concern in producing realistic synthesized terrains. However, despite some recent improvements, existing algorithms are still computationally expensive, leading to a time-consuming process fairly impractical for terrain designers and 3D artists. In this paper, we present a new method to model the hydraulic erosion phenomenon which runs at interactive rates on today's computers. The method is based on the velocity field of the running water, which is created with an efficient shallow-water fluid model. The velocity field is used to calculate the erosion and deposition process, and the sediment transportation process. The method has been carefully designed to be implemented totally on GPU, and thus takes full advantage of the parallelism of current graphics hardware. Results from experiments demonstrate that the proposed method is effective and efficient. It can create realistic erosion effects by rainfall and river flows, and produce fast simulation results for terrains with large sizes. \textcopyright{} 2007 IEEE.},
  author   = {Xing Mei and Philippe Decaudin and Bao Gang Hu},
  doi      = {10.1109/PG.2007.27},
  isbn     = {0769530095},
  issn     = 15504085,
  journal  = {Proceedings - Pacific Conference on Computer Graphics and Applications},
  pages    = {47--56},
  title    = {Fast hydraulic erosion simulation and visualization on GPU},
  url      = {https://xing-mei.github.io/files/erosion.pdf},
  year     = 2007
}

@article{Menshutina2020,
  abstract = {We review the modern state of cellular automata (CA) applications for solving practical problems in chemistry and chemical technology. We consider the problems of material structure modeling and prediction of materials' morphology-dependent properties. We review the use of the CA approach for modeling diffusion, crystallization, dissolution, erosion, corrosion, ad-sorption, and hydration processes. We also consider examples of hybrid CA-based models, which are combinations of various CA with other computational approaches and modeling methods. Finally, we discuss the use of high-performance parallel computing to increase the efficiency of CA.},
  author   = {Natalia V Menshutina and Andrey V Kolnoochenko and Evgeniy A Lebedev},
  doi      = {10.1146/annurev-chembioeng},
  keywords = {cellular automata,chemical engineering,chemistry},
  title    = {Cellular Automata in Chemistry and Chemical Engineering},
  url      = {https://doi.org/10.1146/annurev-chembioeng-},
  year     = 2020
}

@book{Merks2003,
  author = {Roeland Mattheus Hermanus Merks},
  isbn   = 9057761033,
  pages  = 158,
  title  = {Branching Growth in Stony Corals a modelling approach},
  url    = {https://uva.computationalscience.nl/papers/archive/Merks2003b.pdf},
  year   = 2003
}

@article{Merks2004,
  abstract = {The morphogenesis of colonial stony corals is the result of the collective behaviour of many coral polyps depositing coral skeleton on top of the old skeleton on which they live. Yet, models of coral growth often consider the polyps as a single continuous surface. In the present work, the polyps are modelled individually. Each polyp takes up resources, deposits skeleton, buds off new polyps and dies. In this polyp oriented model, spontaneous branching occurs. We argue that branching is caused by a so called "polyp fanning effect" by which polyps on a convex surface have a competitive advantage relative to polyps on a flat or concave surface. The fanning effect generates a more potent branching mechanism than the Laplacian growth mechanism that we have studied previously (J. Theor. Biol. 224 (2003) 153). We discuss the application of the polyp oriented model to the study of environmentally driven morphological plasticity in stony corals. In a few examples we show how the properties of the individual polyps influence the whole colony morphology. In our model, the spacing of polyps influences the thickness of coral branches and the overall compactness of the colony. Density variations in the coral skeleton may also be important for the whole colony morphology, which we address by studying two variants of the model. Finally, we discuss the importance of small scale resource translocation in the coral colony and its effects on the morphology of the colony. \textcopyright{} 2004 Elsevier Ltd. All rights reserved.},
  author   = {Roeland M.H. Merks and Alfons G. Hoekstra and Jaap A. Kaandorp and Peter M.A. Sloot},
  doi      = {10.1016/j.jtbi.2004.02.020},
  issn     = {00225193},
  issue    = 4,
  journal  = {Journal of Theoretical Biology},
  keywords = {Branching growth,Collective behaviour,Coral growth simulation,Morphogenesis,Resource translocation,Scleractinians},
  pages    = {559--576},
  pmid     = 15178203,
  title    = {Polyp oriented modelling of coral growth},
  volume   = 228,
  year     = 2004
}

@article{Merland2014,
  abstract = {Flow simulation in a reservoir can be highly impacted by upscaling errors. These errors can be reduced by using simulation grids with cells as homogeneous as possible, hence conformable to horizons and faults. In this paper, the coordinates of 3D Voronoi seeds are optimized so that Voronoi cell facets honor the structural features. These features are modeled by piecewise linear complex (PLC). The optimization minimizes a function made of two parts: (1) a barycentric function, which ensures that the cells will be of good quality by maximizing their compactness; and (2) a conformity function, which allows to minimize the volume of cells that is isolated from the Voronoi seed w.r.t., a structural feature. To determine the isolated volume, a local approximation of the structural feature inside the Voronoi cells is used to cut the cells. It improves the algorithm efficiency and robustness compared to an exact cutting procedure. This method, used jointly with an adaptive gradient solver to minimize the function, allows dealing with complex 3D geological cases. It always produces a Voronoi simulation grid with the desired number of cells. \textcopyright{} 2014 Springer International Publishing Switzerland.},
  author   = {Romain Merland and Guillaume Caumon and Bruno L\'{e}vy and Pauline Collon-Drouaillet},
  doi      = {10.1007/s10596-014-9408-0},
  isbn     = 1059601494,
  issn     = 14200597,
  issue    = {3-4},
  journal  = {Computational Geosciences},
  keywords = {Conform,Reservoir grid,Structural features,Voronoi},
  pages    = {373--383},
  title    = {Voronoi grids conforming to 3D structural features},
  volume   = 18,
  url      = {https://www.researchgate.net/profile/Romain-Merland/publication/263558668\_Voronoi\_Grids\_Conformal\_to\_3D\_Structural\_Features/links/5acf42120f7e9b18965b1364/Voronoi-Grids-Conformal-to-3D-Structural-Features.pdf},
  year     = 2014
}

@article{Merrell2007,
  abstract = {Model synthesis is a new approach to 3D modeling which automatically generates large models that resemble a small example model provided by the user. Model synthesis extends the 2D texture synthesis problem into higher dimensions and can be used to model many different objects and environments. The user only needs to provide an appropriate example model and does not need to provide any other instructions about how to generate the model. Model synthesis can be used to create symmetric models, models that change over time, and models that fit soft constraints. There are two important differences between our method and existing texture synthesis algorithms. The first is the use of a global search to find potential conflicts before adding new material to the model. The second difference is that we divide the problem of generating a large model into smaller subproblems which are easier to solve. Copyright \textcopyright{} 2007 by the Association for Computing Machinery, Inc.},
  author   = {Paul Merrell},
  doi      = {10.1145/1230100.1230119},
  isbn     = 9781595936288,
  journal  = {Proceedings - I3D 2007, ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games},
  keywords = {Procedural modeling,Texture synthesis},
  pages    = {105--112},
  title    = {Example-based model synthesis},
  url      = {https://paulmerrell.org//model\_synthesis.pdf},
  year     = 2007
}

@article{Merrell2010,
  abstract = {We present a method for automated generation of building layouts for computer graphics applications. Our approach is motivated by the layout design process developed in architecture. Given a set of high-level requirements, an architectural program is synthesized using a Bayesian network trained on real-world data. The architectural program is realized in a set of floor plans, obtained through stochastic optimization. The floor plans are used to construct a complete three-dimensional building with internal structure. We demonstrate a variety of computer-generated buildings produced by the presented approach. \textcopyright{} 2010 ACM.},
  author   = {Paul Merrell and Eric Schkufza and Vladlen Koltun},
  doi      = {10.1145/1866158.1866203},
  isbn     = 9781450304399,
  issn     = {07300301},
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {architectural modeling,computer-aided architectural design,data-driven 3D modeling,procedural modeling,spatial allocation},
  pages    = {1--12},
  title    = {Computer-generated residential building layouts},
  volume   = 29,
  year     = 2010
}

@article{Metzer2021,
  abstract = {We introduce a novel technique for neural point cloud consolidation which learns from only the input point cloud. Unlike other point up-sampling methods which analyze shapes via local patches, in this work, we learn from global subsets. We repeatedly self-sample the input point cloud with global subsets that are used to train a deep neural network. Specifically, we define source and target subsets according to the desired consolidation criteria (e.g., generating sharp points or points in sparse regions). The network learns a mapping from source to target subsets, and implicitly learns to consolidate the point cloud. During inference, the network is fed with random subsets of points from the input, which it displaces to synthesize a consolidated point set. We leverage the inductive bias of neural networks to eliminate noise and outliers, a notoriously difficult problem in point cloud consolidation. The shared weights of the network are optimized over the entire shape, learning non-local statistics and exploiting the recurrence of local-scale geometries. Specifically, the network encodes the distribution of the underlying shape surface within a fixed set of local kernels, which results in the best explanation of the underlying shape surface. We demonstrate the ability to consolidate point sets from a variety of shapes, while eliminating outliers and noise.},
  author   = {Gal Metzer and Rana Hanocka and Raja Giryes and Daniel Cohen-Or},
  doi      = {10.1145/3470645},
  issn     = {0730-0301},
  issue    = 5,
  journal  = {ACM Transactions on Graphics},
  pages    = {1--14},
  title    = {Self-Sampling for Neural Point Cloud Consolidation},
  volume   = 40,
  year     = 2021
}

@article{Michel2015,
  abstract = {While several terrain generation methods focused on plausible watersheds, the fact that most mountains should not be isolated but rather be part of wider scale mountain ranges was seldom considered. In this work, we present the first procedural method that generates folded terrains from simple user input, in the form of some sparse peak distribution on a vector map. The key idea is to infer possible continental plates from this distribution and to use simplified plate tectonics to generate relevant terrain folds. The resulting terrain with large-scale folds, computed in real-time, can be further refined using standard erosion simulation. This leads to detailed terrains with plausible mountain ranges that match the peak distributions and main rivers specified on simple vector maps.},
  author   = {Elie Michel and Arnaud Emilien and Marie-Paule Cani},
  journal  = {Eurographics 2015},
  pages    = {2--5},
  title    = {Generation of Folded Terrains from Simple Vector Maps},
  url      = {https://hal.inria.fr/hal-01147920},
  year     = 2015
}

@article{Michel2016,
  author  = {Elie Michel and Arnaud Emilien and Marie-Paule Cani},
  doi     = {10.2312/egsh.20151019},
  journal = {Eurographics 2015 short paper proceedings},
  pages   = {4--8},
  title   = {Generation of Folded Terrains from Simple Vector Maps},
  url     = {https://hal.inria.fr/hal-01147920/file/2015\_\_Michel\_\_Generation\_of\_Folded\_Terrains\_from\_Simple\_Vector\_Maps.pdf},
  year    = 2015
}

@article{Miconi2008,
  abstract = {It is often suggested that traditional models of artificial evolution, based on explicit, human-defined fitness functions, are fundamentally more restricted and less creative than natural evolution, in which no such constraint exists. After a discussion and refinement of this statement, we suggest a classification of evolutionary systems according to their evolutionary "creativity". We describe an environment, called Evosphere, in which a population of 3D creatures interact, fight with each other, and evolve freely on the surface of a "microplanet". We demonstrate the onset of natural selection and adaptive evolution within this virtual world, both by visual inspection and statistical analysis. We show that the introduction of reproductively isolated species enriches the dynamics of the system, leading to simple evolutionary feedbacks among species. \textcopyright{} 2008 IEEE.},
  author   = {Thomas Miconi},
  doi      = {10.1109/CEC.2008.4631212},
  isbn     = 9781424418237,
  journal  = {2008 IEEE Congress on Evolutionary Computation, CEC 2008},
  pages    = {3066--3073},
  title    = {Evosphere: Evolutionary dynamics in a population of fighting virtual creatures},
  year     = 2008
}

@article{Mo2019,
  abstract = {The ability to generate novel, diverse, and realistic 3D shapes along with associated part semantics and structure is central to many applications requiring high-quality 3D assets or large volumes of realistic training data. A key challenge towards this goal is how to accommodate diverse shape variations, including both continuous deformations of parts as well as structural or discrete alterations which add to, remove from, or modify the shape constituents and compositional structure. Such object structure can typically be organized into a hierarchy of constituent object parts and relationships, represented as a hierarchy of n-ary graphs. We introduce StructureNet, a hierarchical graph network which (i) can directly encode shapes represented as such n-ary graphs, (ii) can be robustly trained on large and complex shape families, and (iii) be used to generate a great diversity of realistic structured shape geometries. Technically, we accomplish this by drawing inspiration from recent advances in graph neural networks to propose an order-invariant encoding of n-ary graphs, considering jointly both part geometry and inter-part relations during network training. We extensively evaluate the quality of the learned latent spaces for various shape families and show significant advantages over baseline and competing methods. The learned latent spaces enable several structure-aware geometry processing applications, including shape generation and interpolation, shape editing, or shape structure discovery directly from un-annotated images, point clouds, or partial scans.},
  author   = {Kaichun Mo and Paul Guerrero and Li Yi and Hao Su and Peter Wonka and Kaust Niloy J. Mitra and Leonidas J. Guibas},
  doi      = {10.1145/3355089.3356527},
  issn     = 15577368,
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {Autoencoder,Generative models,Graph neural networks,Object structure,Shape analysis and synthesis},
  title    = {StructureNet: Hierarchical graph networks for 3D shape generation},
  volume   = 38,
  url      = {https://paulguerrero.net/papers/StructureNet.pdf},
  year     = 2019
}

@misc{Moenning2003,
  abstract    = {In a recent paper [13], the Fast Marching farthest point sampling strategy (FastFPS) for planar domains and curved manifolds was introduced. The version of FastFPS for curved manifolds discussed in the paper [13] deals with surface domains in triangulated form only. Due to a restriction of the underlying Fast Marching method, the algorithm further requires the splitting of any obtuse into acute triangles to ensure the consistency of the Fast Marching approximation. In this paper, we overcome these restrictions by using M\'{e}moli and Sapiro's [11, 12] extension of the Fast Marching method to the handling of implicit surfaces and point clouds. We find that the extended FastFPS algorithm can be applied to surfaces in implicit or point cloud form without the loss of the original algorithm's computational optimality and without the need for any preprocessing.},
  author      = {Carsten Moenning and Neil A Dodgson},
  doi         = {10.48456/tr-565},
  issn        = {1476-2986},
  issue       = {December},
  institution = {University of Cambridge, Computer Laboratory},
  month       = 5,
  title       = {Fast Marching farthest point sampling for point clouds and implicit surfaces},
  url         = {http://www.cl.cam.ac.uk/http://www.cl.cam.ac.uk/TechReports/},
  year        = 2003
}

@article{Moller2005,
  abstract = {We present a clean algorithm for determining whether a ray intersects a triangle. The algorithm translates the origin of the ray and then changes the base of that vector which yields a vector (t u v)T, where t is the distance to the plane in which the triangle lies and (u, v) represents the coordinates inside the triangle. One advantage of this method is that the plane equation need not be computed on the fly nor be stored, which can amount to significant memory savings for triangle meshes. As we found our method to be comparable in speed to previous methods, we believe it is the fastest ray/triangle intersection routine for triangles which do not have precomputed plane equations.},
  author   = {Tomas M\"{o}ller and Ben Trumbore},
  doi      = {10.1145/1198555.1198746},
  issue    = 1,
  journal  = {ACM SIGGRAPH 2005 Courses, SIGGRAPH 2005},
  keywords = {Base transformation,Intersection,Ray tracing,Ray/triangle-intersection},
  pages    = {1--7},
  title    = {Fast, minimum storage ray/triangle intersection},
  url      = {https://gitea.yiem.net/QianMo/Real-Time-Rendering-4th-Bibliography-Collection/raw/branch/main/Chapter 1-24/[1231] [JGT 1997] Fast, Minimum Storage Ray-Triangle Intersection.pdf},
  year     = 2005
}

@article{Montgomery1988,
  abstract = {Darwin's effort to relate his theory of coral reefs to global tectonic concepts failed to impress geologists more immediately interested in European phenomena. Charles Lyell had initially regarded coral reefs as a way to explain the European Chalk formation. However, he encountered criticism from catastrophist authors who thought the Chalk was a result of chemical precipitation. Lyell embraced Darwin's coral reef theory in an effort to strengthen his argument; and though C. G. Ehrenberg explained the Chalk as the product of fossil Foramanifera, he reinforced the general case in favor of organic deposition as opposed to chemical precipitation. As a result geologists tended to follow Lyell in discussing coral reef formation in the larger context of carbonate deposition generally.},
  author   = {William Montgomery},
  issue    = 2,
  journal  = {Earth Sciences History},
  pages    = {111--120},
  title    = {Charles Darwin's theory of coral reefs and the problem of the chalk},
  volume   = 7,
  year     = 1988
}

@article{Morato2022,
  abstract = {It is increasingly recognised that deep-sea mining of seafloor massive sulphides (SMS) could become an important source of mineral resources. These operations will remove the targeted substrate and produce potentially toxic plumes from in situ seabed excavation and from the return water pumped back down to the seafloor. However, the spatial extent of the impact of deep-sea mining is still uncertain because few field experiments and models of plume dispersion have been conducted. In this study, we used three-dimensional hydrodynamic models of the Azores region together with a theoretical commercial mining operation of polymetallic SMS to simulate the potential dispersal of plumes originating from different phases of mining operations, and to assess the magnitude of potential impacts. Although the model simulations presented here were subject to many caveats, they did reveal some important patterns. The model projected marked differences among sites making generalisations about plume-dispersal patterns in mid-ocean ridges difficult. Nevertheless, the models predicted large horizontal and vertical plume-dispersals above the thresholds adopted. Persistent plumes (temporal frequency >50\%, i.e., 6 months out of 12 months) were projected to disperse an average linear distance of 10 to 20~km, cover an area of 17 to 150 km2, and extend more than 800~m in the water column. In fact, the model projected that plumes may disperse beyond the licensed mining areas, reach the flanks and summits of nearby topographic features, and extend into the bathypelagic, mesopelagic, and epipelagic environments. Modelled plume-dispersal overlaps with the predicted distribution of cold-water corals and with existing fishing activities. These potential impacts would be of particular concern in regions such as the Azores, where local populations are highly dependent on the sea for their livelihoods. The findings of this study are an important initial step towards understanding the nature and magnitude of deep-sea mining impacts in space and time.},
  author   = {Telmo Morato and Manuela Juliano and Christopher K. Pham and Marina Carreiro-Silva and In\^{e}s Martins and Ana Cola\c{c}o},
  doi      = {10.3389/fmars.2022.910940},
  issn     = 22967745,
  issue    = {July},
  journal  = {Frontiers in Marine Science},
  keywords = {MOHID,Mid Atlantic Ridge,deep-sea,hydrodynamic model,mining,sediment plumes,spatial extent of impacts},
  pages    = {1--18},
  title    = {Modelling the Dispersion of Seafloor Massive Sulphide Mining Plumes in the Mid Atlantic Ridge Around the Azores},
  volume   = 9,
  year     = 2022
}

@article{Mordvintsev2021,
  abstract = {Neural Cellular Automata (NCA) have shown a remarkable ability to learn the required rules to "grow" images, classify morphologies, segment images, as well as to do general computation such as path-finding. We believe the inductive prior they introduce lends itself to the generation of textures. Textures in the natural world are often generated by variants of locally interacting reaction-diffusion systems. Human-made textures are likewise often generated in a local manner (textile weaving, for instance) or using rules with local dependencies (regular grids or geometric patterns). We demonstrate learning a texture generator from a single template image, with the generation method being embarrassingly parallel, exhibiting quick convergence and high fidelity of output, and requiring only some minimal assumptions around the underlying state manifold. Furthermore, we investigate properties of the learned models that are both useful and interesting, such as non-stationary dynamics and an inherent robustness to damage. Finally, we make qualitative claims that the behaviour exhibited by the NCA model is a learned, distributed, local algorithm to generate a texture, setting our method apart from existing work on texture generation. We discuss the advantages of such a paradigm.},
  author   = {Alexander Mordvintsev and Eyvind Niklasson and Ettore Randazzo},
  month    = 5,
  title    = {Texture Generation with Neural Cellular Automata},
  url      = {http://arxiv.org/abs/2105.07299},
  year     = 2021
}

@article{Morris2009,
  abstract = {Light is critical in structuring aquatic ecosystems. Seasonal variations in the heat energy provided by sunlight are responsible for thermal stratification and mixing regimes of aquatic systems. Sunlight used in photosynthesis (both terrestrial and aquatic) forms the foundation of all but the simplest microbial communities of aquatic ecosystems. This article addresses the fate of light in aquatic ecosystems. It starts with a discussion of the nature of light and the spectral output of the sun. Reflectance, scattering, and absorption in the atmosphere are addressed, along with the role of latitude, in regulating the incident flux of light at the surface of aquatic systems. Once light penetrates the air-water interface, it can either be scattered or absorbed. The inherent optical properties of absorptance, scatterance, and volume scattering function are defined as they pertain to aquatic systems. Wavelength-specific differences in scattering and absorption are discussed in the context of optically significant components of the water column such as dissolved organic carbon and phytoplankton. The diffuse attenuation coefficient is introduced as a parameter in defining the transparency of aquatic systems. Wavelength-specific differences in this parameter are discussed and placed in the context of a system's inherent optical properties. Finally, the environmental variability of transparency is illustrated using data from five Western Hemisphere lakes.},
  author   = {D. P. Morris},
  doi      = {10.1016/B978-012370626-3.00069-7},
  isbn     = 9780123706263,
  journal  = {Encyclopedia of Inland Waters},
  keywords = {Absorption coefficient,Aquatic ecosystems,Chromophoric dissolved organic carbon,Diffuse attenuation coefficient,Reflectance,Scattering},
  pages    = {682--689},
  title    = {Optical Properties of Water},
  url      = {http://misclab.umeoce.maine.edu/boss/classes/RT\_Weizmann/Chapter3.pdf},
  year     = 2009
}

@article{Motoshilanaka,
  abstract = {The human footsteps recognition (walk-recognition) is discussed. The pitch frequency related with walking pace, and the first peak frequency of a footstep, are characterized by frequency analysis, and used as a feature vector for the recognition. A simple recognition method comparing with the Euclidean distance are used. The recognition rate is approximately 83 \%, and then the feasibility of walk-recognition is confirmed.},
  author   = {Motoshi TANAKA and Hiroshi INOUE},
  doi      = {10.1541/ieejeiss1987.119.6\_762},
  issn     = {0385-4221},
  issue    = 6,
  journal  = {IEEJ Transactions on Electronics, Information and Systems},
  keywords = {feature extraction,footsteps,frequency analysis,walk-recognition},
  pages    = {762--763},
  title    = {A Study on Walk-Recognition by Frequency Analysis of Footsteps},
  volume   = 119,
  url      = {https://www.jstage.jst.go.jp/article/ieejeiss1987/119/6/119\_6\_762/\_article},
  year     = 1999
}

@article{Moussaoui2016,
  abstract = {A geometric constraint system consists of a finite set of geometric elements, such as points, lines, and circles, along with relationships of different types such as distance, angle, incidence and parallelism. This problem is central to many applications, such as computer-aided design, molecular modelling and recently localization in wireless sensor networks. Solving a geometric constraint system consists of finding real coordinates of geometric elements in the Euclidean space. In 2-dimensional geometric constraint solving, graph-based techniques are a dominant approach, particularly in the computer-aided design context. To speed up the resolution process, these methods transform the geometric problem into a graph, which is decomposed into small subgraphs. Each one is solved, separately, and the final solution is obtained by recomposing the solved subgraphs. However, most of the previous research on graph-based approaches has only focused on the decomposition without any attention on what will be decomposed: the geometric constraint graph. Major proposed algorithms are discussed or compared theoretically, without presenting any tests on graphs instances with different structural properties, representing several cases of difficulties. Why? because as far as we know, there is no known algorithm for the creation of non-decomposable graphs or graphs with interesting structural properties that best highlight the efficiency of any algorithm. Our contribution is the design of a simple, but efficient random 2D geometric constraint graph generator. It can be used to make benchmarks for consistent tests, or to observe the behaviour of geometric constraints solving algorithms. It produces problem instances with various sizes and structural properties, covering different cases of complexity. Our design is based on the problem classification reported in the literature. We proved that our proposed generator is complete, customizable, simple and efficient. It has been validated experimentally and some of its properties have been theoretically proved.},
  author   = {Adel Moussaoui},
  issue    = 1,
  keywords = {Acari,Agricultur,Animalia,Arachnida,Arthropoda},
  pages    = {17--34},
  title    = {Geometric Constraint Solver},
  volume   = 8,
  url      = {Evolution des propri\'{e}t\'{e}s di\'{e}lectriques, ferro\'{e}lectriques et \'{e}lectrom\'{e}caniques dans le syst\`{e}me pseudo-binaire (1-x)BaTi0.8Zr0.2O3- xBa0.7Ca0.3TiO3 / Corr\'{e}lations structures et propri\'{e}t\'{e}s Feres Benabdallah\%0A},
  year     = 2016
}

@article{Mullen2009,
  abstract = {Numerical viscosity has long been a problem in fluid animation. Existing methods suffer from intrinsic artificial dissipation and often apply complicated computational mechanisms to combat such effects. Consequently, dissipative behavior cannot be controlled or modeled explicitly in a manner independent of time step size, complicating the use of coarse previews and adaptive-time stepping methods. This paper proposes simple, unconditionally stable, fully Eulerian integration schemes with no numerical viscosity that are capable of maintaining the liveliness of fluid motion without recourse to corrective devices. Pressure and fluxes are solved efficiently and simultaneously in a time-reversible manner on simplicial grids, and the energy is preserved exactly over long time scales in the case of inviscid fluids. These integrators can be viewed as an extension of the classical energy-preserving Harlow-Welch / Crank-Nicolson scheme to simplicial grids. \textcopyright{} 2009 ACM.},
  author   = {Patrick Mullen and Keenan Crane and Dmitry Pavlov and Yiying Tong and Mathieu Desbrun},
  doi      = {10.1145/1531326.1531344},
  issn     = {07300301},
  issue    = 3,
  journal  = {ACM Transactions on Graphics},
  keywords = {Energy preservation,Eulerian fluid animation,Time integration},
  title    = {Energy-preserving integrators for fluid animation},
  volume   = 28,
  url      = {https://www.cs.cmu.edu/~kmcrane/Projects/EnergyPreservingFluid/paper.pdf},
  year     = 2009
}

@article{Muller2003,
  abstract = {Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.},
  author   = {Matthias M\"{u}ller and David Charypar and Markus Gross},
  isbn     = 1581136595,
  journal  = {Proceedings of the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA 2003},
  title    = {Particle-based fluid simulation for interactive applications},
  year     = 2003
}

@article{Musgrave1989,
  abstract = {In standard fractal terrain models based on fractional Brownian motion the statistical character of the surface is, by design, the same everywhere. A new approach to the synthesis of fractal terrain height fields is presented which, in contrast to previous techniques, features locally independent control of the frequencies composing the surface, and thus local control of fractal dimension and other statistical characteristics. The new technique, termed noise synthesis, is intermediate in difficulty of implementation, between simple stochastic subdivision and Fourier filtering or generalized stochastic subdivision, and does not suffer the drawbacks of creases or periodicity. Varying the local crossover scale of fractal character or the fractal dimension with altitude or other functions yields more realistic first approximations to eroded landscapes. A simple physical erosion model is then suggested which simulates hydraulic and thermal erosion processes to create global stream/valley networks and talus slopes. Finally, an efficient ray tracing algorithm for general height fields, of which most fractal terrains are a subset, is presented.},
  author   = {Forest Kenton Musgrave and Craig E. Kolb and Robert S. Mace},
  doi      = {10.1145/74333.74337},
  isbn     = {0897913124},
  journal  = {Proceedings of the 16th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1989},
  keywords = {Crossover scale,Erosion models,Fractal,Fractal dimension,Fractional brownian motion,Height fields,Lacunarity,Ray tracing,Stochastic subdivision,Terrain models},
  pages    = {41--50},
  title    = {The synthesis and rendering of eroded fractal terrains},
  url      = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.8939\&rep=rep1\&type=pdf},
  year     = 1989
}

@misc{Nacer2006,
  abstract = {The aim of this work is to evaluate the performance of an image compression system based on wavelet-based subband decomposition. The compression method used in this paper differs from the classical procedure in the direction where the scalar quantization of the coarse scale approximation sub-image is replaced by a discrete cosine transform (DCT) based quantization. The images were decomposed using wavelet filters into a set of subbands with different resolutions corresponding to different frequency bands. The resulting high-frequency subbands were vector quantized according to the magnitude of their variances. The coarse scale approximation sub-image is quantized using scalar quantization and then using DCT-base quantization to show the benefit of this new optional method in term of CPU computationa1 cost vs restitution quality.},
  author   = {Fatma Zohra Nacer and R\'{e}da Yahiaoui},
  issue    = 4,
  journal  = {WSEAS Transactions on Signal Processing},
  pages    = {518--524},
  title    = {Image Compression Using Subband Wavelet Decomposition and DCT-based Quantization},
  volume   = 2,
  url      = {https://hal.archives-ouvertes.fr/hal-00080377},
  year     = 2006
}

@article{Nakamura2007,
  abstract = {The conspicuous growth of a reef crest and the resulting differentiation of reef topography into a moat (shallow lagoon), crest and slope have long attracted the interest of scientists studying coral reefs. A geochemical model is here proposed for reef formation, taking into account diffusion-limited and light-enhanced calcification. First, to obtain data on net photosynthesis and calcification rates in the field, a typical coral community was cultured in situ on a reef flat. Using these data, equations including parameters for calcification were then developed and applied in computer simulations to model the development over time of reef profiles and the diffusion of carbon species. The reef topography simulated by the model was in general agreement with reef topography observed in nature. The process of reef growth as shown by the modeling was as follows. Increases in the shore-to-offshore gradients of the concentrations of carbonate species result from calcification by reef biota, giving a lower rate of growth on near-shore parts of the reef than on those further offshore. As a result, original topography is diversified into moat and reef crest for the first time. Reef growth on the reef crest is more rapid than in the inshore moat area, because more light is available at the crest. Reef growth on the near-shore side of the reef is further inhibited by damming of carbon-rich seawater on the seaward side of the reef by the reef crest. Over time, the topographic expression of the reef crest and moat becomes progressively more clearly defined by these geochemical processes. \textcopyright{} 2007 Springer-Verlag.},
  author   = {T. Nakamura and T. Nakamori},
  doi      = {10.1007/s00338-007-0262-6},
  issn     = {07224028},
  issue    = 4,
  journal  = {Coral Reefs},
  keywords = {Calcification,Photosynthesis,Reef formation,Simulation},
  pages    = {741--755},
  title    = {A geochemical model for coral reef formation},
  volume   = 26,
  year     = 2007
}

@article{Narain2011,
  abstract = {Many large-scale systems such as human crowds, fluids, and granular materials exhibit complicated motion at many different scales, from a characteristic global behavior to important small-scale detail. Such multiscale systems are computationally expensive for traditional simulation techniques to capture over the full range of scales. I present novel techniques for scalable simulation of these large, complex phenomena for visual computing applications. These techniques achieve their efficiency by coupling together separate models for the large-scale and fine-scale dynamics of a complex system. In fluid simulation, it remains a challenge to efficiently simulate fine details such as foam, ripples, and turbulence without compromising the accuracy of the large-scale flow. I present two techniques for this problem that combine physically-based numerical simulation for the global flow with efficient local models for detail. For surface features, I propose the use of texture synthesis, guided by the physical characteristics of the macroscopic flow. For turbulence in the fluid motion itself, I present a technique that tracks the transfer of energy from the mean flow to the turbulent fluctuations and synthesizes these fluctuations procedurally, allowing extremely efficient visual simulation of turbulent fluids. Another large class of problems which are not easily handled by traditional approaches is the simulation of very large aggregates of discrete entities, such as dense pedestrian crowds and granular materials. I present a technique for crowd simulation that couples a discrete model of individual navigation with a novel continuum formulation for the collective motion of pedestrians, enabling simulation of extremely large crowds at nearreal-time rates on commodity hardware. I also present a technique for simulating granular materials which generalizes this model and introduces a novel computational scheme for friction, thus efficiently reproducing a wide range of granular behavior. In all these cases, the proposed techniques are typically an order of magnitude faster than comparable existing methods. Through these applications to a diverse set of challenging simulation problems, I demonstrate that the proposed approach is a powerful and versatile technique for the simulation of a broad range of large, complex systems.},
  author   = {Rahul Narain},
  title    = {Visual modeling and visualisation of multiscale phenomena},
  year     = 2011
}

@article{Nash2020,
  abstract = {Polygon meshes are an efficient representation of 3D geometry, and are of central importance in computer graphics, robotics and games development. Existing learning-based approaches for object synthesis have avoided the challenges of working with 3D meshes, instead using alternative object representations that are more compatible with neural architectures and training approaches. We present PolyGen, a generative model of 3D objects which models the mesh directly, predicting vertices and faces sequentially using a Transformer-based architecture. Our model can condition on a range of inputs, including object classes, voxels, and images, and because the model is probabilistic it can produce samples that capture uncertainty in ambiguous scenarios. We show that the model is capable of producing high-quality, usable meshes, and establish log-likelihood benchmarks for the mesh-modelling task. We also evaluate the conditional models on surface reconstruction metrics against alternative methods, and demonstrate competitive performance despite not training directly on this task.},
  author   = {Charlie Nash and Yaroslav Ganin and S. M.Ali Eslami and Peter W. Battaglia},
  isbn     = 9781713821120,
  journal  = {37th International Conference on Machine Learning, ICML 2020},
  pages    = {7177--7186},
  title    = {PolyGen: An autoregressive generative model of 3D meshes},
  volume   = {PartF16814},
  url      = {https://arxiv.org/pdf/2002.10880.pdf},
  year     = 2020
}

@article{Nasr-Azadani2014,
  abstract = {Direct numerical simulations are employed to investigate the interactions of bidisperse turbidity currents with three-dimensional seafloor topography in the form of Gaussian bumps. Results for two different bump heights are compared against currents propagating over a flat surface. The bump heights are chosen such that the current largely flows over the smaller bump, while it primarily flows around the taller bump. Furthermore, the effects of the settling velocity are investigated by comparing turbidity currents with corresponding compositional gravity currents. The influence of the bottom topography on the front velocity of turbidity currents is seen to be much weaker than the influence of the particle settling velocity. Consistent with earlier work on gravity currents propagating over flat boundaries, the influence of the Reynolds number on the front velocity of currents interacting with three-dimensional bottom topography is found to be small, as long as Re\geq{}O(1000). The lobe-and-cleft structures, on the other hand, exhibit a stronger influence of the Reynolds number. The current/bump interaction deforms the bottom boundary-layer vorticity into traditional horseshoe vortices, with a downwash region in the centre of the wake. At the same time, the vorticity originating in the mixing layer between the current and the ambient interacts with the bump in such a way as to form 'inverted horseshoe vortices', with an upwash region in the wake centre. Additional streamwise vortical structures form as a result of baroclinic vorticity generation. The dependence of the sedimentation rate and streamwise vorticity generation on the height of the bump are discussed, and detailed analyses are presented of the energy budget and bottom wall-shear stress. It is shown that for typical laboratory-scale experiments, the range of parameters explored in the present investigation will not give rise to bedload transport or sediment resuspension. Based on balance arguments for the kinetic and potential energy components, a scaling law is obtained for the maximum bump height over which gravity currents can travel. This scaling law is validated by simulation results, and it provides a criterion for distinguishing between 'short' and 'tall' topographical features. For turbidity currents, this scaling result represents an upper limit. An interesting non-monotonic influence of the bump height is observed on the long-term propagation velocity of the current. On the one hand, the lateral deflection of the current by the bump leads to an effective increase in the current height and its front velocity in the region away from the bump. At the same time, taller bumps result in a more vigorous three-dimensional evolution of the current, accompanied by increased levels of dissipation, which slows the current down. For small bumps, the former mechanism dominates, so that on average the current front propagates faster than its flat bottom counterpart. For currents interacting with larger bumps, however, the increased dissipation becomes dominant, so that they exhibit a reduced front velocity as compared to currents propagating over flat surfaces.},
  author   = {M. M. Nasr-Azadani and E. Meiburg},
  doi      = {10.1017/jfm.2014.47},
  issn     = 14697645,
  issue    = 2,
  journal  = {Journal of Fluid Mechanics},
  keywords = {gravity currents,stratified flows,topographic effect},
  pages    = {409--443},
  title    = {Turbidity currents interacting with three-dimensional seafloor topography},
  volume   = 745,
  year     = 2014
}

@article{Natali2012,
  abstract  = {We describe a sketch-based system for constructing an illustrative visualization of the subsurface. An intuitive and rapid modelling tool is defined, which takes as input user's strokes and creates a 3D layer-cake model of the earth. Our tool enables users to quickly express and communicate their ideas directly using a 3D model. For sketching, we have created geometric operators that capture the domain specific modelling requirements. We have devised sketching operators for expressing folding and faulting processes. This makes it possible to produce a large span of scenarios. Moreover, for communicating layer properties such as rock type and grain size, our system allows for associating user defined texture to each layer which can be deformed with a few sketch strokes. \textcopyright{} 2012 IEEE.},
  author    = {Mattia Natali and Ivan Viola and Daniel Patel},
  doi       = {10.1109/SIBGRAPI.2012.29},
  isbn      = 9780769548296,
  issn      = 15301834,
  journal   = {Brazilian Symposium of Computer Graphic and Image Processing},
  keywords  = {illustrative visualization,layer-cake model,sketch-based technique,stratigraphy,structural geology},
  pages     = {150--157},
  publisher = {IEEE},
  title     = {Rapid visualization of geological concepts},
  year      = 2012
}

@article{Neidhold2005,
  abstract = {Realistically eroded terrain is a base of almost every outdoor visualization for simulators or computer games. In order to achieve convincing results physically based erosion algorithms are necessary. We present a new method that combines a non-expensive fluid simulation with an erosion algorithm. Both parts are running at interactive rates so the artist is able to influence the erosion process in real-Time by changing simulation parameters or applying additional water to the scene. In this way, we support realism as well as design aspects during the terrain creation process. To simplify the three dimensional fluid simulation we use a newtonian physics approach that works on a two dimensional grid storing acceleration, velocity and mass. The method provides all features that are important for simulation of erosion e.g. moving, non-moving water (rivers, lakes) and evaporation. This allows us to support effects like dissolving, transportation and sedimentation of material in the erosion process. \textcopyright{} The Eurographics Association 2005.},
  author   = {B. Neidhold and M. Wacker and Oliver Deussen},
  isbn     = 3905673290,
  issn     = 18160867,
  journal  = {Natural Phenomena},
  pages    = {25--32},
  title    = {Interactive physically based fluid and erosion simulation},
  url      = {http://graphics.uni-konstanz.de/publikationen/Neidhold2005InteractivePhysicallyBased/Neidhold2005InteractivePhysicallyBased.pdf},
  year     = 2005
}

@article{Nelson1999,
  abstract  = {Virtual environments are an emerging technology, which make use of 3-D display devices. Currently very little research into using this new technology for statistical graphics has been done. In association with the Iowa Center for Emerging Manufacturing Technology we have been building a statistical graphics application in the highly immersive C2 environment,called VR-Gobi. This paper describes an experiment conducted to determine if the new technology provides an improved exploratory data analysis environment over traditional workstation graphics environments, such as XGobi. A good analogy comparing the difference between the two environments is that one is like a desk and the other like a room. The visualization tasks we compare between the two environments are detecting clusters, dimensionality and radial sparseness in high-dimensional data, and we also compare the ease of interaction between the computer and human user in the two environments.},
  author    = {Laura Nelson and Dianne Cook and Carolina Cruz-Neira},
  doi       = {10.1007/pl00022704},
  issn      = {09434062},
  issue     = 1,
  journal   = {Computational Statistics},
  keywords  = {Economic Theory/Quantitative Economics/Mathematica,Probability Theory and Stochastic Processes,Probability and Statistics in Computer Science,Statistics,general},
  month     = 9,
  pages     = {39--51},
  publisher = {Springer-Verlag GmbH Co. KG},
  title     = {XGobi vs the C2: Results of an experiment comparing data visualization in a 3-D immersive virtual reality environment with a 2-D workstation display},
  volume    = 14,
  url       = {https://link.springer.com/article/10.1007/PL00022704},
  year      = 1999
}

@inproceedings{Nescher2014,
  abstract  = {RedirectedWalking (RDW) is a technique that allows exploring immersive virtual environments by real walking in a small physical room. RDW employs so-called redirection techniques (RETs) to manipulate the user's real world trajectory in such a way that he remains within the boundaries of the physical room. Different RETs were suggested and evaluated in the past. In addition, steering algorithms were proposed that apply a limited set of RETs to redirect a user away from the physical room's boundaries. \textcopyright{} 2014 IEEE.},
  author    = {Thomas Nescher and Ying Yin Huang and Andreas Kunz},
  doi       = {10.1109/3DUI.2014.6798851},
  booktitle = {IEEE Symposium on 3D User Interfaces 2014, 3DUI 2014 - Proceedings},
  keywords  = {Redirected walking,Virtual reality,locomotion,model predictive control,optimal control,redirection techniques},
  pages     = {111--118},
  publisher = {IEEE Computer Society},
  title     = {Planning redirection techniques for optimal free walking experience using model predictive control},
  year      = 2014
}

@article{Neubert2007,
  abstract = {We present a method for producing 3D tree models from input photographs with only limited user intervention. An approximate voxel-based tree volume is estimated using image information. The density values of the voxels are used to produce initial positions for a set of particles. Performing a 3D flow simulation, the particles are traced downwards to the tree basis and are combined to form twigs and branches. If possible, the trunk and the first-order branches are determined in the input photographs and are used as attractors for particle simulation. The geometry of the tree skeleton is produced using botanical rules for branch thicknesses and branching angles. Finally, leaves are added. Different initial seeds for particle simulation lead to a variety, yet similar-looking branching structures for a single set of photographs. \textcopyright{} 2007 ACM.},
  author   = {Boris Neubert and Thomas Franken and Oliver Deussen},
  doi      = {10.1145/1275808.1276487},
  journal  = {Proceedings of the ACM SIGGRAPH Conference on Computer Graphics},
  keywords = {Botanics,Image-based modeling,Plant models},
  title    = {Approximate image-based tree-modeling using particle flows},
  volume   = 26,
  url      = {https://kops.uni-konstanz.de/bitstream/handle/123456789/39022/Neubert\_0-408373.pdf},
  year     = 2007
}

@article{Ng2006,
  abstract    = {This dissertation introduces a new approach to everyday photography, which solves the longstanding problems related to focusing images accurately. The root of these problems ismissing information. It turns out that conventional photographs tell us rather little about the light passing through the lens. In particular, they do not record the amount of light traveling along individual rays that contribute to the image. They tell us only the sum total of light rays striking each point in the image. To make an analogy with a music-recording studio, taking a conventional photograph is like recording all themusicians playing together, rather than recording each instrument on a separate audio track. In this dissertation, we will go after themissing information. With micron-scale changes to its optics and sensor, we can enhance a conventional camera so that it measures the light along each individual ray flowing into the image sensor. In other words, the enhanced camera samples the total geometric distribution of light passing through the lens in a single exposure. The price we will pay is collecting much more data than a regular photograph. However, I hope to convince you that the price is a very fair one for a solution to a problem as pervasive and long-lived as photographic focus. In photography, as in recordingmusic, it iswise practice to save asmuch of the source data as you can. Of course simply recording the light rays in the camera is not a complete solution to the focus problem. The other ingredient is computation.The idea is to re-sort the recorded light rays to where they should ideally have terminated, to simulate the flow of rays through the virtual optics of an idealized camera into the pixels of an idealized output photograph.},
  author      = {Ren Ng},
  institution = {Stanford University},
  title       = {Digital Light field photography},
  url         = {https://stanford.edu/class/ee367/reading/Ren Ng-thesis Lytro.pdf},
  year        = 2006
}

@article{Ni2013,
  abstract = {Population topology of particle swarm optimization (PSO) will directly affect the dissemination of optimal information during the evolutionary process and will have a significant impact on the performance of PSO. Classic static population topologies are usually used in PSO, such as fully connected topology, ring topology, star topology, and square topology. In this paper, the performance of PSO with the proposed random topologies is analyzed, and the relationship between population topology and the performance of PSO is also explored from the perspective of graph theory characteristics in population topologies. Further, in a relatively new PSO variant which named logistic dynamic particle optimization, an extensive simulation study is presented to discuss the effectiveness of the random topology and the design strategies of population topology. Finally, the experimental data are analyzed and discussed. And about the design and use of population topology on PSO, some useful conclusions are proposed which can provide a basis for further discussion and research. \textcopyright{} 2013 Qingjian Ni and Jianming Deng.},
  author   = {Qingjian Ni and Jianming Deng},
  doi      = {10.1155/2013/409167},
  issn     = {1537744X},
  journal  = {The Scientific World Journal},
  pmid     = 23818820,
  title    = {A new logistic dynamic particle swarm optimization algorithm based on random topology},
  volume   = 2013,
  year     = 2013
}

@misc{Nick2020,
  author = {Nicholas McDonald},
  title  = {Nick's blog : Transport-Oriented Growth and Procedural Trees},
  url    = {https://nickmcd.me/2020/10/19/transport-oriented-growth-and-procedural-trees/}
}

@article{Nicolas-Carlock2016,
  abstract  = {In nature, fractal structures emerge in a wide variety of systems as a local optimization of entropic and energetic distributions. The fractality of these systems determines many of their physical, chemical and/or biological properties. Thus, to comprehend the mechanisms that originate and control the fractality is highly relevant in many areas of science and technology. In studying clusters grown by aggregation phenomena, simple models have contributed to unveil some of the basic elements that give origin to fractality, however, the specific contribution from each of these elements to fractality has remained hidden in the complex dynamics. Here, we propose a simple and versatile model of particle aggregation that is, on the one hand, able to reveal the specific entropic and energetic contributions to the clusters' fractality and morphology, and, on the other, capable to generate an ample assortment of rich natural-looking aggregates with any prescribed fractal dimension.},
  author    = {J. R. Nicolas-Carlock and J. L. Carrillo-Estrada and V. Dossetti},
  doi       = {10.1038/srep19505},
  issn      = 20452322,
  issue     = {December 2015},
  journal   = {Scientific Reports},
  pages     = {1--8},
  publisher = {Nature Publishing Group},
  title     = {Fractality a la carte: A general particle aggregation model},
  volume    = 6,
  year      = 2016
}

@book{Nielsen2009,
  abstract  = {This book covers water waves, surf zone hydrodynamics, tides in oceans and estuaries, storm surges, estuarine mixing, basic sediment transport, coastal morphodynamics and coastal groundwater dynamics. It is an introductory treatment, suitable for a first course in coastal and estuarine processes for earth scientists or engineers. Yet, there are substantial amounts of new material that are included, such as the explicit, analytical treatment of transient, forced long waves. Inclusion of this material will in turn strongly enhance the introductory treatment of tsunami, storm surges and surf beat. The treatment of sine wave theory emphasizes expressions which are explicit in the water depth h (using koh instead of kh) so that they can easily be differentiated or integrated with respect to h. This is a major pedagogical advantage because of the enhanced transparency. The treatment of turbulent mixing includes finite mixing length effects which provide an explanation for differential diffusion of different sediment sizes in suspension. The effects of acceleration skewness and boundary layer streaming are also included in the basic sediment transport models. The inclusion of beach groundwater dynamics - including the mechanisms by which waves as well as tides drive groundwater motion - provides a link between the previously unconnected fields of coastal hydraulics and regional groundwater modeling. Serving as a good reference book, it is fully indexed and comprehensively cross referenced. Abundant references to more detailed texts are also provided.},
  author    = {Peter Nielsen},
  doi       = {10.1142/7114},
  isbn      = {978-981-283-711-0},
  journal   = {Coastal And Estuarine Processes},
  month     = 4,
  pages     = {1--360},
  publisher = {WORLD SCIENTIFIC},
  title     = {Coastal and Estuarine Processes},
  volume    = 29,
  url       = {https://www.worldscientific.com/worldscibooks/10.1142/7114},
  year      = 2009
}

@article{Niesner2013,
  abstract = {Online 3D reconstruction is gaining newfound interest due to the availability of real-time consumer depth cameras. The basic problem takes live overlapping depth maps as input and incrementally fuses these into a single 3D model. This is challenging particularly when real-time performance is desired without trading quality or scale. We contribute an online system for large and fine scale volumetric reconstruction based on a memory and speed efficient data structure. Our system uses a simple spatial hashing scheme that compresses space, and allows for real-time access and updates of implicit surface data, without the need for a regular or hierarchical grid data structure. Surface data is only stored densely where measurements are observed. Additionally, data can be streamed efficiently in or out of the hash table, allowing for further scalability during sensor motion. We show interactive reconstructions of a variety of scenes, reconstructing both fine-grained details and large scale environments. We illustrate how all parts of our pipeline from depth map pre-processing, camera pose estimation, depth map fusion, and surface rendering are performed at real-time rates on commodity graphics hardware. We conclude with a comparison to current state-of-the-art online systems, illustrating improved performance and reconstruction quality.},
  author   = {Matthias Niesner and Michael Zollh\"{o}fer and Shahram Izadi and Marc Stamminger},
  doi      = {10.1145/2508363.2508374},
  issn     = {07300301},
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {Data structure,GPU,Real-time reconstruction,Scalable},
  title    = {Real-time 3D reconstruction at scale using voxel hashing},
  volume   = 32,
  url      = {https://niessnerlab.org/papers/2013/4hashing/niessner2013hashing.pdf},
  year     = 2013
}

@article{Nikeghbali2018,
  abstract = {Investigation of breaking and undular tidal bores is a challenging problem in river mouths as fluid flows upstream, where significant bed erosion and scour take place under the bore. In this study, smoothed particle hydrodynamics (SPH) was used to simulate the breaking and undular tidal bores on a movable bed. To model the bores, a moving gate was used to block a steady uniform flow in a channel, and bores were consequently generated as a positive surge and propagated upstream. First, results were presented for the breaking and undular bores on a flat bed, looking carefully at velocity and surface profiles, which were compared with available experimental data. Then, the breaking and undular bores were tested in a channel with a movable bed using a previous experimental study of particle motion. The authors show the morphology changes of the bed under the breaking and undular bore. The results show that the SPH method can be successfully used to investigate the dynamics of the tidal bore and its effects on a movable bed.},
  author   = {Pooyan Nikeghbali and Pourya Omidvar},
  doi      = {10.1061/(asce)ww.1943-5460.0000424},
  isbn     = 7184645634,
  issn     = {0733-950X},
  issue    = 2,
  journal  = {Journal of Waterway, Port, Coastal, and Ocean Engineering},
  title    = {Application of the SPH Method to Breaking and Undular Tidal Bores on a Movable Bed},
  volume   = 144,
  year     = 2018
}

@article{Nikiel2011,
  author  = {S\l{}awomir Nikiel},
  isbn    = 9780956494429,
  journal = {Proceedings 25th European Conference on Modelling and Simulation (ECMS)},
  title   = {Game-logic simulation based on cellular automata and flocking techniques},
  year    = 2011
}

@article{Nikolopoulos2007,
  abstract = {In this paper we study the problems of detecting holes and antiholes in general undirected graphs, and we present algorithms for these problems. For an input graph G on n vertices and m edges, our algorithms run in O(n + m 2) time and require O(n m) space; we thus provide a solution to the open problem posed by Hayward et al. asking for an O(n 4)-time algorithm for finding holes in arbitrary graphs. The key element of the algorithms is the use of the depth-first-search traversal on appropriate auxiliary graphs in which moving between any two adjacent vertices is equivalent to walking along a P 4 (i.e., a chordless path on four vertices) of the input graph or on its complement, respectively. The approach can be generalized so that for a fixed constant k \geq{} 5 we obtain an O(n k-1)-time algorithm for the detection of a hole (antihole resp.) on at least k vertices. Additionally, we describe a different approach which allows us to detect antiholes in graphs that do not contain chordless cycles on five vertices in O(n + m 2) time requiring O(n + m) space. Again, for a fixed constant k \geq{} 6, the approach can be extended to yield O(n k-2)-time and O(n 2)-space algorithms for detecting holes (antiholes resp.) on at least k vertices in graphs which do not contain holes (antiholes resp.) on k - 1 vertices. Our algorithms are simple and can be easily used in practice. Finally, we also show how our detection algorithms can be augmented so that they return a hole or an antihole whenever such a structure is detected in the input graph; the augmentation takes O(n + m) time and space. \textcopyright{} Springer 2007.},
  author   = {Stavros D. Nikolopoulos and Leonidas Palios},
  doi      = {10.1007/s00453-006-1225-y},
  issn     = {01784617},
  issue    = 2,
  journal  = {Algorithmica (New York)},
  keywords = {Antiholes,Co-connectivity,Holes,Weakly chordal graphs},
  pages    = {119--138},
  title    = {Detecting holes and antiholes in graphs},
  volume   = 47,
  year     = 2007
}

@misc{Nikooyan2011,
  abstract = {Several mass-spring-damper models have been developed to study the response of the human body to the collision with the ground during hopping, trotting, or running. The mass, spring, and damper elements represent the masses, stiffness properties, and damping properties of hard and soft tissues. The masses that models are composed of are connected to each other via springs and dampers. The present paper reviews the various types of mass-spring-damper models including one-body and multi-body models. The models are further categorized as being either passive or active. In passive models, the mechanical properties (stiffness and damping) of soft tissues remain constant regardless of the type of footwear, ground stiffness, etc. In active models, the mechanical properties adapt to external loads. The governing equations of motion of all models as well as their parameters are presented. The specific ways that the models take account of the shoe-ground interactions are discussed as well. The methods used for determination of different modelling parameters are briefly surveyed. The advantages and disadvantages of the different types of mass-spring-damper models are also discussed. The paper concludes with a brief discussion of possible future research trends in the area of mass-spring-damper modelling. \textcopyright{} IMechE 2011.},
  author   = {A. A. Nikooyan and A. A. Zadpoor},
  doi      = {10.1177/0954411911424210},
  issn     = {09544119},
  issue    = 12,
  journal  = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
  keywords = {damping,ground reaction force,mechanical modelling,passive and active models,shoe-ground model,stiffness},
  month    = 12,
  pages    = {1121--1135},
  pmid     = 22320052,
  title    = {Mass-spring-damper modelling of the human body to study running and hopping-an overview},
  volume   = 225,
  year     = 2011
}

@article{Niyazov2021,
  abstract = {Pervasive interfaces can present relevant information anywhere in our environment, and they are thus challenged by the non rectilinearity of the display surface (e.g. circular table) and by the presence of objects that can partially occlude the interface (e.g. a book or cup on the table). To tackle this problem, we propose a novel solution based on two core contributions: the decomposition of the interface into deformable graphical units, called Dynamic Decals, and the control of their position and behaviour by a constraint-based approach. Our approach dynamically deforms the interface when needed while minimizing the impact on its visibility and layout properties. To do so, we extend previous work on implicit deformations to propose and experimentally validate functions defining different decal shapes and new deformers modeling decal deformations when they collide. Then, we interactively optimize the decal placements according to the interface geometry and their interrelations. Relations are modeled as constraints and the interface evolution results from an easy and efficient to solve minimization problem. Our approach is validated by a user study showing that, compared to two baselines, Dynamic decals is an aesthetically pleasant interface that preserves visibility, layout and aesthetic properties.},
  author   = {Aziz Niyazov and Nicolas Mellado and Lo\"{\i}c Barthe and Marcos Serrano},
  doi      = {10.1145/3488538},
  issn     = 25730142,
  issue    = {ISS},
  journal  = {Proceedings of the ACM on Human-Computer Interaction},
  keywords = {constraints,contact deformation,optimization,projected interfaces},
  title    = {Dynamic Decals: Pervasive Freeform Interfaces Using Constrained Deformable Graphical Elements},
  volume   = 5,
  year     = 2021
}

@article{Noca1997,
  abstract = {We present an exact expression for the evaluation of instantaneous forces on a body in an incompressible cross-flow which only requires the knowledge of the velocity and vorticity field in a finite and arbitrarily chosen region enclosing the body. This expression is particularly useful for experimental techniques like Digital Particle Image Velocimetry (DPIV) which provide instantaneous , 2-D velocity and vorticity fields but not pressure fields. The present formula is tested on a numerical flow simulation using a high-resolution vortex method and experimentally with DPIV on a circular cylinder flow .},
  author   = {F. Noca and D. Shiels and D. Jeon},
  doi      = {10.1006/jfls.1997.0081},
  issn     = {08899746},
  issue    = 3,
  journal  = {Journal of Fluids and Structures},
  month    = 4,
  pages    = {345--350},
  title    = {Measuring instantaneous fluid dynamic forces on bodies, using only velocity fields and their derivatives},
  volume   = 11,
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0889974697900815},
  year     = 1997
}

@article{Norato2034,
  abstract = {This work presents a method for the continuum-based topology optimization of structures whereby the structure is represented by the union of supershapes. Supershapes are an extension of superellipses that can exhibit variable symmetry as well as asymmetry and that can describe through a single equation, the so-called superformula, a wide variety of shapes, including geometric primitives. As demonstrated by the author and his collaborators and by others in previous work, the availability of a feature-based description of the geometry opens the possibility to impose geometric constraints that are otherwise difficult to impose in density-based or level set-based approaches. Moreover, such description lends itself to direct translation to computer aided design systems. This work is an extension of the author's group previous work, where it was desired for the discrete geometric elements that describe the structure to have a fixed shape (but variable dimensions) in order to design structures made of stock material, such as bars and plates. The use of supershapes provides a more general geometry description that, using a single formulation, can render a structure made exclusively of the union of geometric primitives. It is also desirable to retain hallmark advantages of existing methods, namely the ability to employ a fixed grid for the analysis to circumvent re-meshing and the availability of sensitivities to use robust and efficient gradient-based optimization methods. The conduit between the geometric representation of the supershapes and the fixed analysis discretization is, as in previous work, a differentiable geometry projection that maps the supershapes parameters onto a density field. The proposed approach is demonstrated on classical problems of 2-dimensional compliance-based topology optimization.},
  author   = {Jul\'{\i}an A. Norato},
  doi      = {10.1007/s00158-018-2034-z},
  journal  = {Structural and Multidisciplinary Optimization},
  keywords = {Geometry projection,Superformula,Supershapes,Topology optimization},
  pages    = {415--434},
  title    = {Topology optimization with supershapes},
  volume   = 58,
  url      = {https://doi.org/10.1007/s00158-018-2034-z},
  year     = 2034
}

@article{Noser1992,
  abstract = {Augmented Vision and Reality},
  author   = {Hansrudi Noser and Daniel Thalmann and Russell Turner},
  doi      = {10.1007/978-4-431-68204-2},
  isbn     = 9784431682042,
  issue    = {September},
  journal  = {Visual Computing},
  title    = {Animation based on the Interaction of L-systems with Vector Force Fields},
  year     = 1992
}

@article{OBrien1995,
  abstract = {We describe a method for modeling the dynamic behavior of splashing fluids. The model simulates the behavior of a fluid when objects impact or float on its surface. The forces generated by the objects create waves and splashes on the surface of the fluid. To demonstrate the realism and limitations of the model, images from a computer-generated animation are presented and compared with video frames of actual splashes occurring under similar initial conditions.},
  author   = {James F. O'Brien and Jessica K. Hodgins},
  doi      = {10.1109/CA.1995.393532},
  isbn     = {0818670622},
  journal  = {Proceedings Computer Animation, CA 1995},
  pages    = {198--205},
  title    = {Dynamic simulation of splashing fluids},
  url      = {https://arxiv.org/pdf/2302.06087.pdf},
  year     = 1995
}

@inproceedings{Ogniewicz1992,
  abstract  = {The paper presents a novel method of robust skele-tonization based on the Voronoi diagram (VD) of boundary points, which is characterized by correct Eu-clidean metrics and inherent preservation of connec-tivity. The regularization of the Voronoi medial axis (VMA) in the sense of Blum's prairie re analogy is done by attributing each component of the VMA with a measure of prominence and stability. The resulting Voronoi skeletons (VSK) appear largely invariant with respect to typical noise conditions in the image and geometric transformations. Hierarchical clustering of the skeleton branches, the so-called skeleton pyramid, leads to further simpliication of the skeleton. Several applications demonstrate the suitability of the Voronoi skeleton to higher order tasks such as object recognition.},
  author    = {R Ogniewicz and M Ilg},
  booktitle = {Proceeding in CVPR '92},
  pages     = {63--69},
  title     = {Voronoi Skeletons: Theory and Applications},
  year      = 1992
}

@article{Olsen2004,
  abstract = {The main goal of this paper is to provide an overview of a variety of methods for synthesis of eroded terrain for use in computer games, VR worlds and the like. Traditionally, such software uses either predefined terrains or runtime generated data based on simple fractal noise techniques. In recent years, the advances in processing power of average home computers have made it possible to simulate erosion processes near-realtime by putting emphasis on speed at the expense of physical correctness. This paper presents a fast method to synthesize natural looking fractal terrain and then proceeds to evaluate and suggest optimizations for two of the most commonly used erosion algorithms 1, 2. With some criteria for applicability in computer games in mind, a new and much faster algorithm is then proposed. Finally, a few issues regarding terrain modifications for maximum playability are discussed.},
  author   = {Jacob Olsen},
  journal  = {Department of Mathematics And Computer Science ( \ldots{}},
  pages    = 20,
  title    = {Realtime procedural terrain generation},
  url      = {https://pdfs.semanticscholar.org/5961/c577478f21707dad53905362e0ec4e6ec644.pdf\%5Cnhttp://www.tsi.enst.fr/~bloch/P6/PRREC/terrain\_generation.pdf\%5Cnhttp://web.mit.edu/cesium/Public/terrain.pdf},
  year     = 2004
}

@article{Ong2005,
  abstract = {We propose a method for applying genetic algorithms to create 3D terrain data sets. Existing procedural algorithms for generation of terrain have several shortcomings. The most popular approach, fractal-based terrain generation, is efficient, but is difficult for a user to control. Other methods tend to require too much user input. In this paper, we provide an alternative method of terrain generation that uses a two-pass genetic algorithm approach to produce a variety of terrain types using only intuitive user inputs. We allow a user to specify a rough sketch of terrain region boundaries, and we refine these boundaries using a genetic algorithm. We then couple this with a database of given terrain data to generate an artificial terrain, which we optimize using a second genetic algorithm. Copyright 2005 ACM.},
  author   = {Teong Joo Ong and Ryan Saunders and John Keyser and John J. Leggett},
  doi      = {10.1145/1068009.1068241},
  isbn     = 1595930108,
  journal  = {GECCO 2005 - Genetic and Evolutionary Computation Conference},
  keywords = {Genetic algorithms,Geographic information systems (gis),Height field,Image processing,Terrain generation},
  pages    = {1463--1470},
  title    = {Terrain generation using genetic algorithms},
  year     = 2005
}

@article{Onoue2000,
  abstract = {This paper proposes a method for modeling and rendering realistic desert scenes. A desert terrain includes sand dunes and wind ripples. We use two types of scale models to form them. We render the dunes with the wind-ripples by bump-mapping using LOD (levels of detail).},
  author   = {K. Onoue and T. Nishita},
  doi      = {10.1109/PCCGA.2000.883978},
  isbn     = {0769508685},
  issn     = 15504085,
  journal  = {Proceedings - Pacific Conference on Computer Graphics and Applications},
  keywords = {Clouds,Computational modeling,Computer graphics,Creep,Equations,Large-scale systems,Layout,Rendering (computer graphics),Terrain mapping,Vegetation mapping},
  pages    = {427--428},
  title    = {A method for modeling and rendering dunes with wind-ripples},
  volume   = {2000-Janua},
  year     = 2000
}

@article{Onrust2017,
  abstract = {Current techniques for the creation and exploration of virtual worlds are largely unable to generate sound natural environments from ecological data and to provide interactive web-based visualizations of such detailed environments. We tackle this challenge and propose a novel framework that (i) explores the advantages of landscape maps and ecological statistical data, translating them to an ecologically sound plant distribution, and (ii) creates a visually convincing 3D representation of the natural environment suitable for its interactive visualization over the web. Our vegetation model improves techniques from procedural ecosystem generation and neutral landscape modeling. It is able to generate diverse ecological sound plant distributions directly from landscape maps with statistical ecological data. Our visualization model integrates existing level of detail and illumination techniques to achieve interactive frame rates and improve realism. We validated with ecology experts the outcome of our framework using two case studies and concluded that it provides convincing interactive visualizations of large natural environments.},
  author   = {Benny Onrust and Rafael Bidarra and Robert Rooseboom and Johan Van De Koppel},
  doi      = {10.1155/2017/7057141},
  issn     = 16877055,
  journal  = {International Journal of Computer Games Technology},
  title    = {Ecologically Sound Procedural Generation of Natural Environments},
  volume   = 2017,
  url      = {https://downloads.hindawi.com/journals/ijcgt/2017/7057141.pdf},
  year     = 2017
}

@article{Oron2023,
  abstract  = {In March 2020, an unusually intense storm system struck the Gulf of Aqaba-Eilat, resulting in severe shoreline damage. This brief account examines post-storm observations of inconsistent damage patterns and structural changes along a specific coastal stretch located at the south beach of Eilat. Certain sections of the coastline experienced direct impact from extreme waves on the south-southeast-facing shallow reef, resulting in areas where rocks were completely stripped of corals due to sediment backwash. Conversely, areas characterized by ridges and deep troughs saw the loss of branching corals and some massive colonies, while many small corals survived. A neighboring area with a well-developed fringing reef suffered lesser damage. Between the severely affected shallow reef and the robust fringing reef lies an unconsolidated slope that migrated eastward by at least 2 m following the storm, incorporating numerous coral colonies dislodged by the event. We propose that this slope advances with each major storm occurrence, influencing the characteristics of nearby shores and coral reefs. This case demonstrates how storm events, in conjunction with geomorphology, have a cumulative and significant impact not only on the structure of coral communities but also on the fundamental shape of coral reefs themselves. As climate change amplifies the range, intensity, and frequency of storms, comprehending these processes becomes increasingly crucial.},
  author    = {Shai Oron and Derya Akkaynak and Beverly N. Goodman Tchernov and Yonathan Shaked},
  doi       = {10.1002/ecs2.4602},
  issn      = 21508925,
  issue     = 7,
  journal   = {Ecosphere},
  keywords  = {climate change,coral reefs,cyclone,disturbance,reef development,storm},
  month     = 7,
  publisher = {John Wiley and Sons Inc},
  title     = {How monster storms shape fringing reefs: Observations from the 2020 Middle East Cyclone},
  volume    = 14,
  year      = 2023
}

@article{Orthuber2015,
  abstract = {This paper presents a novel workflow for data-driven building reconstruction from Light Detection and Ranging (LiDAR) point clouds. The method comprises building extraction, a detailed roof segmentation using region growing with adaptive thresholds, segment boundary creation, and a structural 3D building reconstruction approach using adaptive 2.5D Dual Contouring. First, a 2D-grid is overlain on the segmented point cloud. Second, in each grid cell 3D vertices of the building model are estimated from the corresponding LiDAR points. Then, the number of 3D vertices is reduced in a quad-tree collapsing procedure, and the remaining vertices are connected according to their adjacency in the grid. Roof segments are represented by a Triangular Irregular Network (TIN) and are connected to each other by common vertices or - at height discrepancies - by vertical walls. Resulting 3D building models show a very high accuracy and level of detail, including roof superstructures such as dormers. The workflow is tested and evaluated for two data sets, using the evaluation method and test data of the "ISPRS Test Project on Urban Classification and 3D Building Reconstruction" (Rottensteiner et al., 2012). Results show that the proposed method is comparable with the state of the art approaches, and outperforms them regarding undersegmentation and completeness of the scene reconstruction.},
  author   = {E. Orthuber and J. Avbelj},
  doi      = {10.5194/isprsannals-II-3-W4-157-2015},
  issn     = 21949050,
  issue    = {3W4},
  journal  = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  keywords = {Building,City,Computer,LIDAR,Model,Photogrammetry,Reconstruction,Vision},
  pages    = {157--164},
  title    = {3D building reconstruction from lidar point clouds by adaptive dual contouring},
  volume   = 2,
  year     = 2015
}

@misc{Ortiz2020,
  abstract    = {Geostatistics deals with two different problems: estimation and uncertainty quantifica-tion. MultiGaussian and indicator kriging allow determining the local uncertainty at every location. However, these methods do not permit quantifying uncertainty over a larger volume, or characterizing the expected variability in a sequence of points that will be transferred to another process. In this paper, the concept of geostatistical simulation is introduced along with an explanation about why it is necessary and how it is different from estimation. Sequential Gaussian simulation is introduced as one of the most used algorithms for multiGaussian simulation, and as a natural extension from multiGaussian kriging.},
  author      = {Julian M. Ortiz},
  institution = {Queen's University},
  keywords    = {preprint},
  pages       = {7--19},
  title       = {Introduction to sequential Gaussian simulation},
  url         = {https://qspace.library.queensu.ca/handle/1974/28538},
  year        = 2020
}

@article{Orzan2008,
  abstract = {<p> We describe a new vector-based primitive for creating smooth-shaded images, called the <italic>diffusion curve</italic> . A diffusion curve partitions the space through which it is drawn, defining different colors on either side. These colors may vary smoothly along the curve. In addition, the sharpness of the color transition from one side of the curve to the other can be controlled. Given a set of diffusion curves, the final image is constructed by solving a Poisson equation whose constraints are specified by the set of gradients across all diffusion curves. Like all vector-based primitives, diffusion curves conveniently support a variety of operations, including geometry-based editing, keyframe animation, and ready stylization. Moreover, their representation is compact and inherently resolution-independent. We describe a GPU-based implementation for rendering images defined by a set of diffusion curves in realtime. We then demonstrate an interactive drawing system for allowing artists to create artworks using diffusion curves, either by drawing the curves in a freehand style, or by tracing existing imagery. The system is simple and intuitive: we show results created by artists after just a few minutes of instruction. Furthermore, we describe a completely automatic conversion process for taking an image and turning it into a set of diffusion curves that closely approximate the original image content. </p>},
  author   = {Alexandrina Orzan and Adrien Bousseau and Holger Winnem\"{o}ller and Pascal Barla and Jo\"{e}lle Thollot and David Salesin},
  doi      = {10.1145/1360612.1360691},
  issn     = {0730-0301},
  issue    = 3,
  journal  = {ACM Transactions on Graphics},
  keywords = {color,gradient mesh,vector graphics,vectorization},
  month    = 8,
  pages    = {1--8},
  title    = {Diffusion curves},
  volume   = 27,
  url      = {https://dl.acm.org/doi/10.1145/1360612.1360691},
  year     = 2008
}

@article{Orzan2009,
  abstract    = {This thesis proposes a novel image primitive--the diffusion curve. This primitive relies on the principle that images can be defined via their discontinuities, and concentrates image features along contours. The diffusion curve can be defined in vector graphics, as well as in raster graphics, to increase user control during the process of art creation. The vectorial diffusion curve primitive augments the expressive powers of vector images by capturing complex spatial appearance behaviors. Diffusion curves represent a simple and easy- to-manipulate support for complex content representation and edition. In raster images, diffusion curves define a higher level structural organization of the pixel image. This structure is used to create simplified or exaggerated representations ofphotographs in a way consistent with the original image content. Finally, a fully automatic vectorization method is presented, that converts raster diffusion curve to vector diffusion curve.},
  author      = {Alexandrina Orzan},
  institution = {INPG},
  keywords    = {expressive rendering,image processing,vector graphics},
  pages       = 136,
  title       = {Contour-Based Images: Representation, Creation and Manipulation},
  url         = {http://maverick.inria.fr/Publications/2009/Orz09},
  year        = 2009
}

@misc{Ostoma1999,
  abstract = {ACKNOWLEGMENTS We wish to thank R. Mongrain (P. Eng.) for his encouragement, constructive criticisms, and for the lengthy conversations on the nature of space, time, light, matter, and CA theory.},
  author   = {Tom Ostoma and Mike Trushyk},
  title    = {CELLULAR AUTOMATA THEORY AND PHYSICS A New Paradigm For The Unification of Physics},
  year     = 1999
}

@inbook{OswaldoValencia-Rosado2019,
  abstract = {Advances in computer graphics allow to simulate ever growing virtual worlds with a higher level of realism which can even be created in real time. An integral part of these worlds are the terrains which are the physical features of the land. Despite the capabilities of modern computer systems, the creation process still demands high amounts of man-hours. To automatically generate coherent, realistic-looking and useful content is still and open problem, and research focuses on how to automatize these processes while allowing users to exert a certain degree on control over the generated content. This survey goes over the different techniques used for the automatic generation of terrains, which include different land formations such as mountains, valleys, rivers, shores, etc. These terrains have different uses such as simulation or entertainment which translates on different needs over the desired realism of the terrain and the degree of control that users have. Through time, different approaches have been proposed: repeating patterns that resemble those seen in nature; using software agents that imitate geological processes; using artificial intelligence techniques for pattern recognition and imitation of landscapes; or allowing users to interact with the system to draw desired terrain features. This review presents an overview of the area and discusses how different techniques adapt to the different needs and different stages of terrain creation.},
  author   = {Luis Oswaldo Valencia-Rosado and Oleg Starostenko},
  doi      = {10.1007/978-3-030-21077-9\_6},
  keywords = {Automatic,Landscape,Simulation,Videogames,Virtual},
  pages    = {58--67},
  title    = {Methods for Procedural Terrain Generation: A Review},
  url      = {https://link.springer.com/10.1007/978-3-030-21077-9\_6},
  year     = 2019
}

@article{Othmani2017,
  abstract = {A high-resolution 2D barotropic tidal model was developed for the Gulf of Gabes and used to characterise hydrodynamic processes and tidal dynamics. The model is based on the Regional Ocean Modelling System. It is forced at the open boundaries by the semidiurnal M2 and S2 astronomical components while meteorological forcing has been neglected. The model results show good agreement with observations confirming that it reproduces the gulf's main tidal characteristics reasonably well. In fact, the simulated semidiurnal tidal components M2 and S2 generate important sea level variations and coastal currents. Tidal propagation is directed to the gulf's western sector while tidal resonance occurs in its inner sector where the M2 and S2 amplitudes are about 50 and 36~cm, respectively. Phase maxima (170\textdegree{}–185\textdegree{}) are located inside Boughrara Lagoon for both the simulated M2 and S2 tides. The strongest currents are found in shallow coastal regions and at the lagoon's western inlet. During spring tides, currents are around 10–20~cm~s-1 in the gulf center and up to 50~cm~s-1 inside the lagoon.},
  author   = {Achref Othmani and B\'{e}chir B\'{e}jaoui and Crist\`{e}le Chevalier and Dalila Elhmaidi and Jean Luc Devenon and Lotfi Aleya},
  doi      = {10.1016/j.jafrearsci.2017.01.007},
  issn     = 18791956,
  journal  = {Journal of African Earth Sciences},
  keywords = {Gulf of Gabes,High resolution,Hydrodynamics,Numerical modelling,Tide},
  pages    = {224--232},
  title    = {High-resolution numerical modelling of the barotropic tides in the Gulf of Gabes, eastern Mediterranean Sea (Tunisia)},
  volume   = 129,
  year     = 2017
}

@inbook{Ouannes2012,
  abstract = {In this chapter a virtual ecosystem environment with basic physical law and energy concept has been proposed, this ecosystem is populated with 3D virtual creatures that are living in this environment in order to forage food. Artificial behaviors are developed in order to control artificial creatures. Initially, we study the behavior of herbivore's creatures, which feed resources available in their environment. A genetic algorithm with an artificial neural network were implemented together to guarantee some of these behaviors like searching food. Foods are presented in different locations in the virtual ecosystem. The evolutionary process uses the physical properties of the virtual creatures and an external fitness function with several objectives that will conduct to the expected behaviors. The experiment evolving locomoting virtual creatures shows that these virtual creatures try to obtain at least one of the food sources presented in their trajectories. Our best-evolved creatures are able to reach multiple food sources during the simulation time.},
  author   = {Nesrine Ouannes and Noureddine Djedi and Yves Duthen and Herv\'{e} Luga},
  journal  = {Virtual Worlds},
  pages    = {99--116},
  title    = {Following Food Sources by Artificial Creatures in a Virtual Ecosystem},
  year     = 2012
}

@inbook{Owen1988,
  abstract = {Creating robust artificial intelligence is one of the greatest challenges for game developers, yet the commercial success of a game is often dependent upon the quality of the AI. In this book, Ian Millington brings extensive professional experience to the problem of improving the quality of AI in games. He describes numerous examples from real games and explores the underlying ideas through detailed case studies. He goes further to introduce many techniques little used by developers today. The book's associated web site contains a library of C++ source code and demonstration programs, and a complete commercial source code library of AI algorithms and techniques."Artificial Intelligence for Games - 2nd edition" will be highly useful to academics teaching courses on game AI, in that it includes exercises with each chapter. It will also include new and expanded coverage of the following: AI-oriented gameplay; Behavior driven AI; Casual games (puzzle games). \textasteriskcentered The first comprehensive, professional tutorial and reference to implement true AI in games written by an engineer with extensive industry experience.\textasteriskcentered Walks through the entire development process from beginning to end.\textasteriskcentered Includes examples from over 100 real games, 10 in-depth case studies, and web site with sample code.},
  author   = {Patrick Henry Winston},
  doi      = {10.1017/S0263574700004070},
  issn     = {0263-5747},
  issue    = 2,
  journal  = {Robotica},
  keywords = {0123747317 9780123747310},
  month    = 4,
  pages    = {165--165},
  title    = {Artificial Intelligence},
  volume   = 6,
  url      = {https://www.cambridge.org/core/product/identifier/S0263574700004070/type/journal\_article},
  year     = 1988
}

@article{Oyundolgor2012,
  author      = {Khorloo Oyundolgor},
  issue       = {March},
  institution = {Graduate School of Engineering Iwate University},
  title       = {A Study on Efficient Algorithms for Generating Virtual Wind Field Usable for Real-time Animation},
  year        = 2012
}

@article{Palmer2021,
  abstract  = {Marine robots have the potential to enhance WIO marine research to improve regional adaptation to the challenges presented by climate change by providing enhanced research capacity that bypasses the requirement for expensive infrastructure, such as large research vessels. This paper tests this potential and assesses the readiness of WIO communities to adopt autonomous technologies to meet its marine research priorities. We apply a range of analyses to a marine robots case study undertaken in waters around the island of Pemba, part of the Zanzibar archipelago, in Tanzania in 2019. The campaign formed part of a multinational project focused on increasing WIO capacity to meet food security and ocean sustainability challenges. A community engagement programme with six Tanzanian coastal communities resulted in positive changes in attitudes towards marine robots with reported increases in understanding and acceptance of such technologies. Suspicion of the robots was reduced and a lower risk of removing operational equipment was recorded following the provision of educational material. Cost, risk and benefit analysis shows that marine robots are perceived to provide high level benefits, but come at a high cost that is difficult to achieve using national or regional funding. An assessment of the capacity of WIO marine institutes to adopt such technologies shows that prior to this work, few skills or infrastructure related to marine robots were available to researchers and further confirmed that funding opportunities were perceived to be largely unavailable at institutional, national, regional or international levels. Responses from regional partners following completion of the case study however, revealed an uplift in perceived capacity, particularly related to access to infrastructure and expertise as well as support and opportunities for funding at each level. The presented case study is shown to have been a valuable demonstrator of the benefits of using marine robots to meet WIO coastal ocean research requirements and regional capacity was shown to be substantially increased within the broad range of marine institutes surveyed throughout the case study period. This study demonstrates that taking early steps towards adopting marine autonomous robots has increased WIO regional marine research capacity and increased the confidence and willingness of local researchers to seek alternative solutions to ongoing marine research challenges. Recommendations for future action that will continue to increase the capacity and readiness for regional adoption of marine robots include investment at local, national and regional levels to provide accessible training opportunities and to facilitate regional and international collaborations; investment in a regional hub, or centre of excellence for marine robotic technology; early adoption of newly emerging smaller, cheaper autonomous technologies; investment in local skills and support facilities to aid local buy-in and acceptance while supporting regional capacity.},
  author    = {Matthew R. Palmer and Yohana W. Shagude and Michael J. Roberts and Ekaterina Popova and Juliane U. Wihsgott and Shankar Aswani and Jack Coupland and John A. Howe and Brian J. Bett and Kennedy E. Osuka and Colin Abernethy and Sofia Alexiou and Stuart C. Painter and Joseph N. Kamau and Ntahondi Nyandwi and Baraka Sekadende},
  doi       = {10.1016/j.ocecoaman.2021.105805},
  issn      = {09645691},
  journal   = {Ocean and Coastal Management},
  keywords  = {Coastal ocean management,Marine autonomy,Marine robotics,Marine robots,Ocean gliders,Sustainable development},
  month     = 10,
  publisher = {Elsevier Ltd},
  title     = {Marine robots for coastal ocean research in the Western Indian Ocean},
  volume    = 212,
  year      = 2021
}

@article{Paper2020,
  abstract = {In this work we present the first version of Evolgl, an artificial environment for the development and study of 3D artificial lifeforms. In this first phase on the development of the project we have focused in setting up a virtual world governed by its own laws, whose state had direct influence upon the artificial beings that inhabit it. Starting from the definition of this virtual world, we have designed a basic type of creature (Evolworm), and the genetic coding of its main characteristics. Evolutionary techniques are then used to evolve the morphological features and behavioural aspects of Evolworms. They must learn to be unfolded inside the world, escape from their enemies, find couple, and obtain food. All of this in absence of an explicitly defined fitness function. In the future we are using this environment to study some classical techniques in the evolutionary computation field, like niche programming, and promotion of junk code (introns). GA-P techniques are used to code the external appearance of the individuals (the texture), to let evolution end up with individuals adapted to be invisible in some zones of the world. The artificial system of vision, and the implementation of the worms' behavioral mechanisms so that their actions are provoked exclusively by the sensory information are still under development. At this moment, we have obtained distinct forms of evolworms, as well as different bosses of behaviour that we describe in this article.},
  author   = {Santi Garcia Carbajal and Martin Bosque Moran and Fermin Gonzalez Martinez},
  doi      = {10.7551/mitpress/1429.003.0014},
  issue    = {December},
  journal  = {Artificial Life IX},
  title    = {EvolGL: Life in a Pond},
  year     = 2020
}

@article{Paquier2020,
  abstract  = {The current study tries a new approach to simulating interactions between waves and seagrass through Smoothed Particle Hydrodynamics (SPH). In this model, the plants are defined as a solid that respects Hooke's law, and are assumed to have direct interaction with the fluid. Given the characteristics of the SPH method, especially in terms of computational time, the dimensions of the simulations were limited. The first goal of the current study was to optimize the approach to avoid reaching certain limits such as the rupture of the simulated plant. Plant movements under waves and/or currents have been studied by several authors in various in-situ, physical, and numerical experiments concerning various vegetation species, thus proving that plant movements can be successfully reproduced by SPH 2D/3D. Manning's roughness coefficient, n, was calculated to confirm that the results were in accordance with what had been measured in flume studies. Even though there is still room for improvement, it is shown that this method can be used to estimate Manning's coefficient for coastal vegetation (seagrass and saltmarsh vegetation) and to greatly improve the modeling and forecasting of coastal erosion and storm surge risks by including the effects of vegetation in integrated models.},
  author    = {Anne El\'{e}onore Paquier and Thibault Oudart and Caroline Le Bouteiller and Samuel Meul\'{e} and Philippe Larroud\'{e} and Robert A. Dalrymple},
  doi       = {10.1016/j.ijsrc.2020.08.003},
  issn      = 10016279,
  journal   = {International Journal of Sediment Research},
  keywords  = {Current,Fluid structure interaction,GPUSPH,Numerical seagrass movement,Waves},
  month     = 8,
  publisher = {Elsevier B.V.},
  title     = {3D numerical simulation of seagrass movement under waves and currents with GPUSPH},
  year      = 2020
}

@article{Para2021,
  abstract = {We propose a new generative model for layout generation. We generate layouts in three steps. First, we generate the layout elements as nodes in a layout graph. Second, we compute constraints between layout elements as edges in the layout graph. Third, we solve for the final layout using constrained optimization. For the first two steps, we build on recent transformer architectures. The layout optimization implements the constraints efficiently. We show three practical contributions compared to the state of the art: our work requires no user input, produces higher quality layouts, and enables many novel capabilities for conditional layout generation.},
  author   = {Wamiq Para and Paul Guerrero and Tom Kelly and Leonidas Guibas and Peter Wonka},
  doi      = {10.1109/ICCV48922.2021.00662},
  isbn     = 9781665428125,
  issn     = 15505499,
  journal  = {Proceedings of the IEEE International Conference on Computer Vision},
  pages    = {6670--6680},
  title    = {Generative Layout Modeling using Constraint Graphs},
  url      = {https://arxiv.org/pdf/2011.13417.pdf},
  year     = 2021,
  volume   = 7
}

@article{Parberry2014,
  abstract = {The standard way to procedurally generate random terrain for video games and other applications is to post-process the output of a fast noise generator such as Perlin noise. Tuning the post-processing to achieve particular types of terrain requires game designers to be reasonably well-trained in mathematics. A well-known variant of Perlin noise called value noise is used in a process accessible to designers trained in geography to generate geotypical terrain based on elevation statistics drawn from widely available sources such as the United States Geographical Service. A step-by-step process for downloading and creating terrain from real-world USGS elevation data is described, and an implementation in C++ is given.},
  author   = {Ian Parberry},
  issn     = {2331-7418},
  issue    = 1,
  journal  = {Journal of Computer Graphics Techniques (JCGT)},
  note     = {height maps only},
  pages    = {74--85},
  title    = {Designer Worlds: Procedural Generation of Infinite Terrain from Real-World Elevation Data},
  volume   = 3,
  url      = {http://jcgt.org/published/0003/01/04/},
  year     = 2014
}

@article{Paris2019,
  abstract = {<p>While three-dimensional landforms, such as arches and overhangs, occupy a relatively small proportion of most computer-generated landscapes, they are distinctive and dramatic and have an outsize visual impact. Unfortunately, the dominant heightfield representation of terrain precludes such features, and existing in-memory volumetric structures are too memory intensive to handle larger scenes.</p>},
  author   = {Axel Paris and Eric Galin and Adrien Peytavie and Eric Gu\'{e}rin and James Gain},
  doi      = {10.1145/3342765},
  issn     = {0730-0301},
  issue    = 5,
  journal  = {ACM Transactions on Graphics},
  month    = 10,
  pages    = {1--15},
  title    = {Terrain Amplification with Implicit 3D Features},
  volume   = 38,
  url      = {https://dl.acm.org/doi/10.1145/3342765},
  year     = 2019
}

@article{Paris2020,
  abstract = {<p>We present an interactive aeolian simulation to author hot desert scenery. Wind is an important erosion agent in deserts which, despite its importance, has been neglected in computer graphics. Our framework overcomes this and allows generating a variety of sand dunes, including barchans, longitudinal and anchored dunes, and simulates abrasion which erodes bedrock and sculpts complex landforms. Given an input time varying high altitude wind field, we compute the wind field at the surface of the terrain according to the relief, and simulate the transport of sand blown by the wind. The user can interactively model complex desert landscapes, and control their evolution throughout time either by using a variety of interactive brushes or by prescribing events along a user-defined time-line.</p>},
  author   = {A. Paris and A. Peytavie and E. Gu\'{e}rin and O. Argudo and E. Galin},
  doi      = {10.1111/cgf.13815},
  issn     = {0167-7055},
  issue    = 7,
  journal  = {Computer Graphics Forum},
  keywords = {aeolian erosion,desert,procedural modeling,sand dune simulation},
  month    = 10,
  pages    = {47--55},
  title    = {Desertscape Simulation},
  volume   = 38,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13815},
  year     = 2019
}

@article{Paris2021,
  abstract = {<p>We present a geologically-based method to generate complex karstic networks. Karsts are a type of landscape formed by the dissolution of highly soluble rocks (generally limestones). In particular, they are characterized by complex underground networks made of varieties of tunnels and breakout chambers with stalagmites and stalactites. Our method computes skeletons of karstic networks by using a gridless anisotropic shortest path algorithm according to field data of the underground system (such as inlets and outlets), geomorphological features and parameters such as faults, inception horizons, fractures, and permeability contrasts. From this skeleton, we define the geometry of the conduits as a signed distance function construction tree combining primitives with blending and warping operators. Our framework provides multiple levels of control, allowing us to author both the structure of the karstic network and the geometric cross-section shapes and details of the generated conduits.</p>},
  author   = {A. Paris and E. Gu\'{e}rin and A. Peytavie and P. Collon and E. Galin},
  doi      = {10.1111/cgf.14420},
  issn     = {0167-7055},
  issue    = 7,
  journal  = {Computer Graphics Forum},
  keywords = {Computer Graphics Forum,EUROGRAPHICS,caves,implicit surfaces,karstic networks,procedural modeling},
  month    = 10,
  note     = {Des points plus ou moins faibles sont r\'{e}partis selon une distribution de Poisson Sampling dans le sol.<br/>Une ou plusieurs sources (Sink) sont d\'{e}finies, une ou plusieurs sorties sont definies (Spring).<br/>Un graphe est cr\'{e}\'{e} en utilisant tous les points de Poisson comme nodes, et le chemin principal est choisi en utilisant un pathfinder (A\textasteriskcentered ou Djikstra).<br/><br/>Les poids de chaque est d\'{e}fini en fonction des nodes d'apr\`{e}s sa position par rapport \`{a} sa distance avec un niveau d'eau (sur l'axe Z), sa distance par rapport \`{a} une \&quot;sph\`{e}re de porosit\'{e}\&quot;},
  pages    = {277--287},
  title    = {Synthesizing Geologically Coherent Cave Networks},
  volume   = 40,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.14420},
  year     = 2021
}

@article{Paris2021a,
  author = {Axel Paris and \'{E}ric Galin and Adrien Peytavie and \'{E}ric Gu\'{e}rin and James Gain},
  title  = {Amplification de Terrains avec des caract\'{e}ristiques implicites 3D},
  year   = 2021
}

@article{Paris2023,
  author      = {Axel Paris},
  institution = {Universit\'{e} Claude Bernard Lyon 1},
  title       = {Modeling and simulating virtual terrains},
  year        = 2023
}

@article{Park2010,
  abstract = {In this paper, we present a novel method for controlling massive crowds by using control particles. Our method differs from previous ones that generate attraction (or repelling) forces around the control particles. Instead of doing this, we create a steady-state, flow-like control field that guides the crowd to move along with the control particles. Our control field can be naturally incorporated into the original simulation by using density-based weighted blending. Although we focus on simulation methods that use dynamic potential functions, our method can also be used to improve the controllability of agent-based simulation methods. Since the control particles can be easily manipulated by traditional key-framing, our method provides animators with an intuitive interface for manipulating the position of crowd over time. We illustrate the effectiveness of our method on several examples. \textcopyright{} Springer-Verlag 2009.},
  author   = {Min Je Park},
  doi      = {10.1007/s00371-009-0415-4},
  isbn     = {0037100904},
  issn     = {01782789},
  issue    = 11,
  journal  = {Visual Computer},
  keywords = {Crowd simulation,Interactive control,Key-frame animation},
  pages    = {1383--1391},
  title    = {Guiding flows for controlling crowds},
  volume   = 26,
  url      = {https://link.springer.com/content/pdf/10.1007/s00371-009-0415-4.pdf},
  year     = 2010
}

@article{Park2019,
  abstract  = {Mangrove marshes are a significant global ecosystem, finely-tuned to contemporary sea level. As sea level rises the mangrove-to-freshwater ecotone reflects underlying groundwater salinity indicating the transformation of freshwater resources into saltwater unsuitable for consumption or agriculture. Hydrological numerical models can predict this dynamic given sufficient environmental detail, however, detailed data is often lacking. Alternatively, agent-based models can predict landscape vegetation changes and the associated fresh-to-saline water transformation based only on landscape surface features. We apply such a model to the southern tip of the Florida peninsula at the nexus of a metropolis and World Heritage wildlife preserve: the Florida Everglades, to predict ecotone dynamics and aquifer water resources in response to warming climate and rising sea level. The model is based on species-specific behaviors for freshwater grasses and salt-tolerant red mangroves with relevance to global mangrove ecosystems.},
  author    = {Joseph Park and Jed Redwine and Troy D. Hill and Kevin Kotun},
  doi       = {10.1016/j.ecolmodel.2019.04.015},
  issn      = {03043800},
  journal   = {Ecological Modelling},
  keywords  = {Freshwater resource,Mangrove ecotone,Sea level rise},
  month     = 8,
  pages     = {69--85},
  publisher = {Elsevier B.V.},
  title     = {Water resource and ecotone transformation in coastal ecosystems},
  volume    = 405,
  year      = 2019
}

@article{Parks2009,
  abstract = {An interactive surface editing framework that is well suited to the needs of geophysical modelers and interpreters is described. This surface editing framework allows a non-expert user to quickly create complicated surfaces by combining two simple concepts: deformation and cutting. Deformations change the geometry of a surface and allow a user to model continuous geologic horizons. Cutting changes the topology of the surface to model geologic faults.},
  author   = {Derek Parks},
  isbn     = 9781615675661,
  journal  = {79th Society of Exploration Geophysicists International Exposition and Annual Meeting 2009, SEG 2009},
  keywords = {cutting,surface modeling freeform deformation},
  pages    = {2702--2706},
  title    = {Freeform modeling of faulted surfaces in seismic images},
  url      = {https://web.archive.org/web/20170808195119id\_/http://www.cwp.mines.edu/Meetings/Project09/cwp-633.pdf},
  year     = 2009
}

@article{Parsons1977,
  author   = {Barry Parsons and John G. Sclater},
  doi      = {10.1029/JB082i005p00803},
  issn     = {01480227},
  issue    = 5,
  journal  = {Journal of Geophysical Research},
  keywords = {doi:10.1029/JB082i005p00803,http://dx.doi.org/10.1029/JB082i005p00803},
  month    = 2,
  pages    = {803--827},
  title    = {An analysis of the variation of ocean floor bathymetry and heat flow with age},
  volume   = 82,
  url      = {http://doi.wiley.com/10.1029/JB082i005p00803},
  year     = 1977
}

@article{Pascual2022,
  author    = {Romain Pascual and Hakim Belhaouari and Agn\`{e}s Arnould and Pascale Le Gall},
  doi       = {10.1016/j.gvc.2022.200049},
  issn      = 26666294,
  journal   = {Graphics and Visual Computing},
  keywords  = {topology-based geometric modeling},
  pages     = 200049,
  publisher = {Elsevier Ltd.},
  title     = {Inferring topological operations on generalized maps: Application to subdivision schemes},
  volume    = 6,
  url       = {https://doi.org/10.1016/j.gvc.2022.200049},
  year      = 2022
}

@article{Pasko1995,
  abstract = {Concepts of functionally based geometric modeling including sets of objects, operations, and relations are discussed. Transformations of a defining real function are described for set-theoretic operations, blending, offsetting, bijective mapping, projection, cartesian products, and metamorphosis. Inclusion, point membership, and intersection relations are also described. We use a high-level geometric language that can extend the interactive modeling system by input symbolic descriptions of primitives, operations, and predicates. This approach supports combinations of representational styles, including constructive geometry, sweeping, soft objects, voxel-based objects, deformable and other animated objects. Application examples of aesthetic design, collisions simulation, NC machining, range data processing, and 3D texture generation are given. \textcopyright{} 1995 Springer-Verlag.},
  author   = {A. Pasko and V. Adzhiev and A. Sourin and V. Savchenko},
  doi      = {10.1007/BF02464333},
  issn     = {01782789},
  issue    = 8,
  journal  = {The Visual Computer},
  keywords = {Geometric modeling,Implicit surfaces,R functions,Real functions,Solid modeling},
  pages    = {429--446},
  title    = {Function representation in geometric modeling: concepts, implementation and applications},
  volume   = 11,
  url      = {http://papers.cumincad.org/data/works/att/d935.content.pdf},
  year     = 1995
}

@article{Patel2005,
  abstract = {We discuss tools for calculating divergence-free fields for artistic particle simulations. We introduce a simple, fast divergence-free noise function which can be used for turbulence. We also describe how the interpolation technique used by the noise function can be used for calculating artist-controlled divergence-free fields. The artist can create realistic unbounded flow fields without the complexity or memory cost of voxel-grid methods.},
  author   = {Mayur Patel and Noah Taylor},
  doi      = {10.1080/2151237x.2005.10129206},
  issn     = {1086-7651},
  issue    = 4,
  journal  = {Journal of Graphics Tools},
  keywords = {gaseous phenomena,noise,particle systems,physically based modeling,simulation,turbulence},
  pages    = {49--60},
  title    = {Simple Divergence-Free Fields for Artistic Simulation},
  volume   = 10,
  url      = {https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=18183ace6beab86bb0d9a505bfeb6ab7bb3b840b},
  year     = 2005
}

@article{Patel2021,
  abstract = {The process of creating terrain and landscape models is important in a variety of computer graphics and visual- ization applications, from films and computer games, via flight simulators and landscape planning, to scientific visualization and subsurface modelling. Interestingly, the modelling techniques used in this large range of appli- cation areas have started to meet in the last years. In this state-of-the-art report, we present two taxonomies of different modelling methods. Firstly we present a data oriented taxonomy, where we divide modelling into three different scenarios: the data-free, the sparse-data and the dense-data scenario. Then we present a workflow ori- ented taxonomy, where we divide modelling into the separate stages necessary for creating a geological model.We start the report by showing that the new trends in geological modelling are approaching the modelling methods that have been developed in computer graphics. We then give an introduction to the process of geological mod- elling followed by our two taxonomies with descriptions and comparisons of selected methods. Finally we discuss the challenges and trends in geological modelling.},
  author   = {Daniel Patel and Mattia Natali and Endre M. Lidal and Julius Parulek and Emilio Vital Brazil and Ivan Viola},
  doi      = {10.1007/978-3-030-90716-7\_1},
  issue    = {c},
  journal  = {Interactive Data Processing and 3D Visualization of the Solid Earth},
  pages    = {1--43},
  title    = {Modeling Terrains and~Subsurface Geology},
  url      = {http://data.exppad.com/public/papers/Modeling\_Terrains\_and\_Subsurface\_Geology.pdf},
  year     = 2021
}

@article{Pedoja2019,
  author  = {Kevin Pedoja and Laurent Husson and Antoine Bezos and Anne-Morwenn Pastier and Andy Muhammad Imran and Camilo Arias-Ruiz and Anta-Clarisse Sarr and Mary Elliot and Edwige Pons-Branchu and Ma\"{e}lle Nexer and Vincent Regard and Abdul Hafidz and Xavier Robert and Laurent Benoit and Bernard Delcaillau and Christine Authemayou and Caroline Dumoulin and Ga\"{e}l Choblet},
  doi     = {10.1016/j.quascirev.2018.03.033},
  issn    = {02773791},
  journal = {Quaternary Science Reviews},
  month   = 5,
  pages   = {37--57},
  title   = {On the long-lasting sequences of coral reef terraces from SE Sulawesi (Indonesia): Distribution, formation, and global significance},
  volume  = 188,
  url     = {https://linkinghub.elsevier.com/retrieve/pii/S0277379117309824},
  year    = 2018
}

@article{Pelletier2019,
  author  = {De M A Gibert M Pelletier},
  journal = {Geocarrefour},
  pages   = {174--180},
  title   = {Probl\`{e}mes et m\'{e}thodes de l'\'{e}tude g\'{e}omorphologique des r\'{e}cifs coralliens},
  volume  = 28,
  year    = 2019
}

@inbook{Peltonen2014,
  author = {Jaakko Peltonen},
  title  = {Part 5 : Layout for general- structured graphs},
  url    = {https://coursepages2.tuni.fi/mttts17/wp-content/uploads/sites/136/2020/04/drv\_2020\_lecture13.pdf},
  year   = 2014
}

@article{Perbet2004,
  abstract    = {In computer graphics, 3D animated scenes are more and more rich and detailed. But the current techniques for managing such scenes cannot handle a wide range of observation scales. For example, creating models that allow to zoom from a galactic scale to an atomic scale is a very difficult task. Our goal is to address this problem in the scope of real-time visualization using standard computers. First, we show that multi-scale procedural modeling is particularly well suited to solve this problem. More precisely, we use complexification modeling which describes a model by its coarse representation and a set of functions which adds local details until the required precision according to perceptual criteria. We introduce a new formalism based on the C++ language which is able to describe a large set of 3D animated models over a large range of scales. We propose a tool which implements this formalism called DynamicGraph. This tool consists of a specialized graphical interface and a real-time rendering algorithm which efficently evaluates the visibility and the required precision. Finally, we illustrate the potential of this approach by several case studies.},
  author      = {Frank Perbet},
  institution = {Institut National Polytechnique de Grenoble},
  keywords    = {3D,: computer graphics,dynamic,graph,multi-resolution,multi-scale,procedural modeling,real-time,visibility},
  pages       = 150,
  title       = {Mod\'{e}lisation multi-\'{e}chelle proc\'{e}durale de sc\`{e}nes anim\'{e}es},
  url         = {https://theses.hal.science/tel-00528630/document},
  year        = 2004
}

@article{Perche2023,
  abstract  = {Various terrain modelling methods have been proposed for the past decades, providing efficient and often interactive authoring tools. However, they seldom include any notion of style, which is critical for designers in the entertainment industry. We introduce a new generative network method that bridges the gap between automatic terrain synthesis and authoring, providing a versatile set of authoring tools allowing spatialised style. We build upon the StyleGAN2 architecture and extend it with authoring tools. Given an input sketch or existing elevation map, our method generates a terrain with features that can be authored, enhanced, and augmented using interactive brushes and style manipulation tools. The strength of our approach lies in the versatility and interoperability of the different tools. We validate our method quantitatively with drainage calculation against other previous techniques and qualitatively by asking users to follow a prompt or freely create a terrain.},
  author    = {Simon Perche and Adrien Peytavie and Bedrich Benes and Eric Galin and Eric Gu\'{e}rin},
  doi       = {10.1111/cgf.14936},
  issn      = 14678659,
  issue     = 7,
  journal   = {Computer Graphics Forum},
  keywords  = {CCS Concepts,Shape modeling,\textbullet{} Computing methodologies \rightarrow{} Shape inference},
  month     = 10,
  publisher = {John Wiley and Sons Inc},
  title     = {Authoring Terrains with Spatialised Style},
  volume    = 42,
  year      = 2023,
  url       = {http://arxiv.org/abs/2304.09626}
}

@article{Petrovas2019,
  abstract  = {Creative content requires a lot of human resources. Computational creativity gets more attention as computational resources are getting fast enough to quickly create automated content with enough precision and similarity to human-created digital assets. Paper explores terrain generation methods and proposes a different solution to generate mountains. A landscape is created using voxel-based cubes and the base map is modified using generation agents. Vertical points are extended and filled using arithmetic operations between arrays for each vertical point. Height normalization is applied to remove rare mountain elevation layers.},
  author    = {Aurimas Petrovas and Romualdas Bausys},
  doi       = {10.1109/eStream.2019.8732171},
  isbn      = 9781728124995,
  journal   = {2019 Open Conference of Electrical, Electronic and Information Sciences, eStream 2019 - Proceedings},
  keywords  = {Computational creativity,game design,procedural generation,terrain},
  publisher = {IEEE},
  title     = {Automated Digital Terrain Elevation Modification by Procedural Generation Approach},
  year      = 2019
}

@article{Pettit1996,
  abstract = {Invoking its social function can explain why we find a certain functional trait or institution only if we can identify a mechanism whereby the playing of the function connects with the explanandum. That is the main claim in the missing-mechanism critique of functionalism. Is it correct? Yes, if functional explanation is meant to make sense of the actual presence of the trait or institution. No, if it is meant to make sense of why the trait or institution is resilient: why we can rely on it to survive various contingencies. The lesson? Social functionalism should be taken, and may have been taken by its founders, as a programme for explaining resilience. 1 Introduction 2 Functionalism and the missing-mechanism argument 3 Functional explanations that avoid the argument 4 A significant research programme.},
  author   = {Philip Pettit},
  doi      = {10.1093/bjps/47.2.291},
  issn     = {00070882},
  issue    = 2,
  journal  = {British Journal for the Philosophy of Science},
  pages    = {291--302},
  title    = {Functional Explanation and Virtual Selection},
  volume   = 47,
  year     = 1996
}

@article{Peytavie2009,
  abstract = {<p>In this paper, we present a framework for representing complex terrains with such features as overhangs, arches and caves and including different materials such as sand and rocks. Our hybrid model combines a volumetric discrete data structure that stores the different materials and an implicit representation for sculpting and reconstructing the surface of the terrain. Complex scenes can be edited and sculpted interactively with high level tools. We also propose an original rock generation technique that enables us to automatically generate complex rocky sceneries with piles of rocks without any computationally demanding physically-based simulation.</p>},
  author   = {A. Peytavie and E. Galin and J. Grosjean and S. Merillou},
  doi      = {10.1111/j.1467-8659.2009.01385.x},
  issn     = {0167-7055},
  issue    = 2,
  journal  = {Computer Graphics Forum},
  month    = 4,
  pages    = {457--467},
  title    = {Arches: a Framework for Modeling Complex Terrains},
  volume   = 28,
  year     = 2009
}

@article{Peytavie2010,
  author      = {Adrien Peytavie},
  institution = {Universit\'{e} de Lyon},
  title       = {G\'{e}n\'{e}ration Proc\'{e}durale de Mondes},
  url         = {https://tel.archives-ouvertes.fr/tel-00841373/document},
  year        = 2010
}

@article{Peytavie2019a,
  abstract = {<p>This paper addresses the problem of creating animated riverscapes through a novel procedural framework that generates the inscribing geometry of a river network and then synthesizes matching real-time water movement animation. Our approach takes bare-earth heightfields as input, derives hydrologically-inspired river network trajectories, carves riverbeds into the terrain, and then automatically generates a corresponding blend-flow tree for the water surface. Characteristics, such as the riverbed width, depth and shape, as well as elevation and flow of the fluid surface, are procedurally derived from the terrain and river type. The riverbed is inscribed by combining compactly supported elevation modifiers over the river course. Subsequently, the water surface is defined as a time-varying continuous function encoded as a blend-flow tree with leaves that are parameterized procedural flow primitives and internal nodes that are blend operators. While river generation is fully automated, we also incorporate intuitive interactive editing of both river trajectories and individual riverbed and flow primitives. The resulting framework enables the generation of a wide range of river forms, ranging from slow meandering rivers to rapids with churning water, including surface effects, such as foam and leaves carried downstream.</p>},
  author   = {A. Peytavie and T. Dupont and E. Gu\'{e}rin and Y. Cortial and B. Benes and J. Gain and E. Galin},
  doi      = {10.1111/cgf.13814},
  issn     = {0167-7055},
  issue    = 7,
  journal  = {Computer Graphics Forum},
  month    = 10,
  pages    = {35--46},
  title    = {Procedural Riverscapes},
  volume   = 38,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13814},
  year     = 2019
}

@article{Peytavie2020,
  abstract = {<p>In this paper, we present a tiling method for generating piles of rocks without any computationally demanding physically-based simulation. Previous techniques rely on a periodic tiling of rocks and generate unrealistic repetitive patterns. In contrast, our approach relies on a modified corner cube algorithm to generate a set of aperiodic tiles. We generalize the construction method so that the geometry of rocks should straddle corner cubes with a view to avoiding unrealistic gaps in the arrangement of rocks. Moreover, we propose an original technique to control the shape of rocks into contact by computing the Vorono\"{\i} cells using a parameterized anisotropic distance. Our method has been successfully used to generate landscapes and stone huts and walls with thousands of rocks piled together.</p>},
  author   = {A. Peytavie and E. Galin and J. Grosjean and S. Merillou},
  doi      = {10.1111/j.1467-8659.2009.01557.x},
  issn     = {0167-7055},
  issue    = 7,
  journal  = {Computer Graphics Forum},
  month    = 10,
  pages    = {1801--1809},
  title    = {Procedural Generation of Rock Piles using Aperiodic Tiling},
  volume   = 28,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2009.01557.x},
  year     = 2009
}

@misc{Pfeifer2013,
  author = {Rolf Pfeifer and Rudolf M F\"{u}chslin},
  title  = {CELLULAR AUTOMATA-DYNAMICAL SYSTEMS},
  year   = 2013
}

@article{Pi2006,
  abstract = {The navigation and rendering of very large-scale terrain are facing a difficult problem that the geometry data and texture data cannot be used directly due to the storage space, computation capacity, and I/O bandwidth. To provide more realistic detail of terrain scene, procedural detail is a good solution. Firstly, this paper introduces a method of procedural geometry based on the terrain tile quad-tree and the Patch-LOD algorithm. Then, the texture generation operator is described and the method of dynamic pre-computation of patch-texture is presented. Finally, the experimental system based on these above ideas and methods has been implemented. The experimental results show that these methods are effective and are appropriate to the development of 3D games and battlefield applications. \textcopyright{} Springer-Verlag Berlin Heidelberg 2006.},
  author   = {Xuexian Pi and Junqiang Song and Liang Zeng and Sikun Li},
  doi      = {10.1007/11736639\_111},
  isbn     = 3540334238,
  issn     = {03029743},
  issue    = 2002,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  pages    = {913--920},
  title    = {Procedural terrain detail based on Patch-LOD algorithm},
  volume   = {3942 LNCS},
  year     = 2006
}

@article{Pilat2008,
  abstract = {In this paper, we present Creature Academy, a virtual laboratory that allows for the evolution of form and function within simulated physical 3D environments. Creature Academy can be used to explore evolutionary mechanisms, design, learning and other processes studied in artificial life simulations. Our system allows to perform hierarchical evolutionary experiments and ecosystem-inspired setups to investigate bodied creatures that interact, compete, adapt, and evolve. As a first proof of concept, we use Creature Academy to evolve morphologies and motion strategies of virtual creatures that walk and jump. We then present results that compare hierarchical evolution scenarios to generate creatures that excel in both walking and jumping, demonstrating how to evolve from creature specialists to generalists. \textcopyright{} 2008 IEEE.},
  author   = {Marcin L. Pilat and Christian Jacob},
  doi      = {10.1109/CEC.2008.4631243},
  isbn     = 9781424418237,
  journal  = {2008 IEEE Congress on Evolutionary Computation, CEC 2008},
  pages    = {3289--3297},
  title    = {Creature Academy: A system for virtual creature evolution},
  year     = 2008
}

@article{Piller2003,
  abstract = {Two different coral framework structures located in a shallow subtidal area on the east coast of Bali are described in this study. One structure is a typical coral carpet with a distinct internal succession of coral taxa and growth forms. It starts with a variety of coral species exhibiting massive, tabular, branching, and platy growth forms settling on volcanic boulders and cobbles. The main body of the coral carpet is composed almost monospecifically of Acropora cf. vaughani, which has filled all accommodating spaces up to the low-water sea level. Mostof this carpet died during the bleaching event of 1998 and the resultant dead Acropora framework is now capped by a platy Montipora assemblage. Some of the Acropora branches within the dead carpet, however, are still alive and display active growth. The Montipora cover protects the dead Acropora framework against mechanical and biological destruction. The few still growing Acropora branches may also contribute to the strength of the framework. The second coral framework is made up almost monogenerically of Montipora. One species of Montipora is of a laminar growth form and produces whorl-like colonies. Within this framework, only part of the Montipora colonies are dead; however, these are intensively fragmented. The fragments have been rapidly settled by a platy Montipora species, which has stabilized the fragments. In this case, the fragment shedding of the Montipora offers the opportunity for progradation of the framework on these fragments. Concerning the Acropora carpet, similar examples from the fossil record of the Miocene era of Spain and Austria have been reported.},
  author   = {W. E. Piller and B. Riegl},
  doi      = {10.1007/s00531-003-0317-z},
  issn     = 14373254,
  issue    = 4,
  journal  = {International Journal of Earth Sciences},
  keywords = {Acropora thicket,Actuopaleontology,Bali,Coral carpet,Coral ecology,Montipora framework},
  pages    = {511--519},
  title    = {Vertical versus horizontal growth strategies of coral framework (Tulamben, Bali, Indonesia)},
  volume   = 92,
  year     = 2003
}

@article{Pintore2020,
  abstract = {Creating high-level structured 3D models of real-world indoor scenes from captured data is a fundamental task which has important applications in many fields. Given the complexity and variability of interior environments and the need to cope with noisy and partial captured data, many open research problems remain, despite the substantial progress made in the past decade. In this survey, we provide an up-to-date integrative view of the field, bridging complementary views coming from computer graphics and computer vision. After providing a characterization of input sources, we define the structure of output models and the priors exploited to bridge the gap between imperfect sources and desired output. We then identify and discuss the main components of a structured reconstruction pipeline, and review how they are combined in scalable solutions working at the building level. We finally point out relevant research issues and analyze research trends.},
  author   = {Giovanni Pintore and Claudio Mura and Fabio Ganovelli and Lizeth Fuentes-Perez and Renato Pajarola and Enrico Gobbetti},
  doi      = {10.1111/cgf.14021},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,Computer vision,Computer vision problems,Reconstruction,Shape inference,Shape modeling,\textbullet{} Applied computing \rightarrow{} Computer-aided design,\textbullet{} Computing methodologies \rightarrow{} Computer graphics},
  pages    = {667--699},
  title    = {State-of-the-art in Automatic 3D Reconstruction of Structured Indoor Environments},
  volume   = 39,
  url      = {https://diglib.eg.org/bitstream/handle/10.1111/cgf14021/v39i2pp667-699.pdf?sequence=1\&isAllowed=y},
  year     = 2020
}

@article{Plotnik2015,
  abstract  = {Background: The study of gait at self-selected speed is important. Traditional gait laboratories being relatively limited in space provide insufficient path length, while treadmill (TM) walking compromises natural gait by imposing speed variables. Self-paced (SP) walking can be realized on TM using feedback-controlled belt speed. We compared over ground walking vs. SP TM in two self-selected gait speed experiments: without visual flow, and while subjects were immersed in a virtual reality (VR) environment inducing natural visual flow. Methods: Young healthy subjects walked 96 meters at self-selected comfortable speed, first over ground and then on the SP TM without (n=15), and with VR visual flow (n=11). Gait speed was compared across conditions for four 10 m long segments (7.5 - 17.5, 30.5 - 40.5, 55.5 - 65.5 and 78.5-88.5 m). Results: During over ground walking mean (\pm{} SD) gait speed was equal for both experimental groups (1.50 \pm{} 0.13 m/s). Without visual flow, gait speed over SP TM was smaller in the first and second epochs as compared to over ground (first: 1.15 \pm{}0.18 vs. second: 1.53 \pm{} 0.13 m/s; p<0.05), and was comparable in the third and fourth (1.45 \pm{} 0.19 vs. 1.49 \pm{} 0.15 m/s; p>0.3). With visual flow, gait speed became comparable to that of over ground performance already in the first epoch (1.43 \pm{} 0.22 m/s; p>0.17). Curve fitting analyses estimated that steady state velocity in SP TM walking is reached after shorter distanced passed with visual flow (24.6 \pm{} 14.7 m) versus without (36.5 \pm{} 18.7 m, not statistically significant; p=0.097). Steady state velocity was estimated to be higher in the presence of visual flow (1.61 \pm{} 0.17 m/s) versus its absence (1.42 \pm{} 1.19 m/s; p<0.05). Conclusions: The SP TM walking is a reliable method for recording typical self-selected gait speed, provided that sufficient distance is first passed for reaching steady state. Seemingly, in the presence of VR visual flow, steady state of gait speed is reached faster. We propose that the gait research community joins forces to standardize the use of SP TMs, e.g., by unifying protocols or gathering normative data.},
  author    = {Meir Plotnik and Tamar Azrad and Moshe Bondi and Yotam Bahat and Yoav Gimmon and Gabriel Zeilig and Rivka Inzelberg and Itzhak Siev-Ner},
  doi       = {10.1186/s12984-015-0002-z},
  issn      = 17430003,
  issue     = 1,
  journal   = {Journal of NeuroEngineering and Rehabilitation},
  keywords  = {Gait speed,Over ground walking,Self- paced treadmill,Virtual reality,Visual flow},
  month     = 2,
  pages     = 20,
  pmid      = 25881130,
  publisher = {BioMed Central Ltd.},
  title     = {Self-selected gait speed - Over ground versus self-paced treadmill walking, a solution for a paradox},
  volume    = 12,
  url       = {https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-015-0002-z},
  year      = 2015
}

@article{Polana1997,
  abstract  = {The recognition of nonrigid motion, particularly that arising from human movement (and by extension from the locomotory activity of animals) has typically made use of high-level parametric models representing the various body parts (legs, arms, trunk, head etc.) and their connections to each other. Such model-based recognition has been successful in some cases; however, the methods are often difficult to apply to real-world scenes, and are severely limited in their generalizability. The first problem arises from the difficulty of acquiring and tracking the requisite model parts, usually specific joints such as knees, elbows or ankles. This generally requires some prior high-level understanding and segmentation of the scene, or initialization by a human operator. The second problem, with generalization, is due to the fact that the human model is not much good for dogs or birds, and for each new type of motion, a new model must be hand-crafted. In this paper, we show that the recognition of human or animal locomotion, and, in fact, any repetitive activity can be done using low-level, non-parametric representations. Such an approach has the advantage that the same underlying representation is used for all examples, and no individual tailoring of models or prior scene understanding is required. We show in particular, that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatio-temporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences. Results on a number of real-world sequences are described.},
  author    = {Ramprasad Polana and Randal C Nelson},
  doi       = {https://doi.org/10.1023/A:1007975200487},
  issue     = 3,
  journal   = {International Journal of Computer Vision},
  pages     = {261--282},
  publisher = {Kluwer Academic Publishers},
  title     = {Detection and Recognition of Periodic, Nonrigid Motion},
  volume    = 23,
  year      = 1997
}

@article{Potokar2022,
  abstract = {Due to the difficulty and expense of underwater field trials, a high fidelity underwater simulator is a necessity for testing and developing algorithms. To fill this need, we present HoloOcean, an open source underwater simulator, built upon Unreal Engine 4 (UE4). HoloOcean comes equipped with multi-agent support, various sensor implementations of common underwater sensors, and simulated communications support. We also implement a novel sonar sensor model that leverages an octree representation of the environment for efficient and realistic sonar imagery generation. Due to being built upon UE4, new environments are straightforward to add, enabling easy extensions to be built. Finally, HoloOcean is controlled via a simple python interface, allowing simple installation via pip, and requiring few lines of code to execute simulations.},
  author   = {Easton Potokar and Spencer Ashford and Michael Kaess and Joshua G. Mangelson},
  doi      = {10.1109/ICRA46639.2022.9812353},
  isbn     = 9781728196817,
  issn     = 10504729,
  journal  = {Proceedings - IEEE International Conference on Robotics and Automation},
  pages    = {3040--3046},
  title    = {HoloOcean: An Underwater Robotics Simulator},
  url      = {https://www.cs.cmu.edu/~kaess/pub/Potokar22icra.pdf},
  year     = 2022
}

@article{Poudret2007,
  author  = {Mathieu Poudret and A. Arnould and Yves Bertrand and Pascal Lienhardt},
  issue   = {0},
  journal = {Recherche},
  title   = {Cartes combinatoires ouvertes},
  url     = {http://xlim-sic.labo.univ-poitiers.fr/publications/files/publi2015.pdf},
  year    = 2007
}

@article{Prasad2012,
  abstract  = {Most dominant point detection methods require heuristically chosen control parameters. One of the commonly used control parameter is maximum deviation. This paper uses a theoretical bound of the maximum deviation of pixels obtained by digitization of a line segment for constructing a general framework to make most dominant point detection methods non-parametric. The derived analytical bound of the maximum deviation can be used as a natural bench mark for the line fitting algorithms and thus dominant point detection methods can be made parameter-independent and non-heuristic. Most methods can easily incorporate the bound. This is demonstrated using three categorically different dominant point detection methods. Such non-parametric approach retains the characteristics of the digital curve while providing good fitting performance and compression ratio for all the three methods using a variety of digital, non-digital, and noisy curves. \textcopyright{} 2012 Elsevier B.V.},
  author    = {Dilip K. Prasad and Maylor K.H. Leung and Chai Quek and Siu Yeung Cho},
  doi       = {10.1016/j.imavis.2012.06.010},
  issn      = {02628856},
  issue     = 11,
  journal   = {Image and Vision Computing},
  keywords  = {Digital curves,Dominant points,Line fitting,Non-parametric,Polygonal approximation},
  pages     = {843--859},
  publisher = {Elsevier B.V.},
  title     = {A novel framework for making dominant point detection methods non-parametric},
  volume    = 30,
  url       = {http://dx.doi.org/10.1016/j.imavis.2012.06.010 https://pdf.sciencedirectassets.com/271526/1-s2.0-S0262885612X00106/1-s2.0-S0262885612000984/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDUaCXVzLWVhc3QtMSJGMEQCIEvFwJ9\%2BlZhaD6vGKO22HFRdVP5iZukCZszz\%2B1\%2F},
  year      = 2012
}

@article{Prats2012,
  abstract = {This paper presents UWSim: a new software tool for visualization and simulation of underwater robotic missions. The software visualizes an underwater virtual scenario that can be configured using standard modeling software. Controllable underwater vehicles, surface vessels and robotic manipulators, as well as simulated sensors, can be added to the scene and accessed externally through network interfaces. This allows to easily integrate the simulation and visualization tool with existing control architectures, thus allowing hardware-in-the-loop simulations (HIL). UWSim has been successfully used for simulating the logics of underwater intervention missions and for reproducing real missions from the captured logs. The software is offered as open source, thus filling a gap in the underwater robotics community, where commercial simulators oriented to ROV pilot training predominate. \textcopyright{} 2012 IEEE.},
  author   = {Mario Prats and Javier Perez and J. Javier Fernandez and Pedro J. Sanz},
  doi      = {10.1109/IROS.2012.6385788},
  isbn     = 9781467317375,
  issn     = 21530858,
  journal  = {IEEE International Conference on Intelligent Robots and Systems},
  pages    = {2577--2582},
  title    = {An open source tool for simulation and supervision of underwater intervention missions},
  year     = 2012
}

@article{Prokhorov2015,
  abstract = {We formulate and study the inverse problem for the nonstationary radiative transfer equation related to an acoustic mapping of the ocean floor using side-scan sonars. In the single-scattering approximation we obtain a formula for determining the function that describes small deviations of the floor surface from a middle level.},
  author   = {I. V. Prokhorov and A. A. Sushchenko and V. A. Kan},
  doi      = {10.1134/S1990478915030126},
  issn     = 19904797,
  issue    = 3,
  journal  = {Journal of Applied and Industrial Mathematics},
  keywords = {inverse problem,radiative transfer equation,sea floor topography,single-scattering approximation},
  pages    = {412--422},
  title    = {On the problem of reconstructing the floor topography of a fluctuating ocean},
  volume   = 9,
  year     = 2015
}

@article{Prusinkiewicz1986,
  abstract = {A new method for algorithmically generating musical scores is presented and illustrated with examples. The idea is to produce a string of symbols using an L-system, and to interpret this string as a sequence of notes. The proposed musical interpretation of L-systems is closely related to their graphical interpretation, which in turn associates L-systems to fractals.},
  author   = {Przemyslaw Prusinkiewicz},
  journal  = {Proceedings of the 1986 International Computer Music Conference, ICMC 1986},
  keywords = {L-systems,fractals,generative modeling of music,turtle geometry},
  pages    = {455--457},
  title    = {Score Generation With L-Systems},
  url      = {http://algorithmicbotany.org/papers/score.icmc86.pdf},
  year     = 1986
}

@article{Prusinkiewicz1986a,
  abstract = {A new method for generating pictures is presented and illustrated with examples. The idea is to generate a string of symbols using an L-system, and to interpret this string as a sequence of commands which control a 'turtle'. Suitable generalizations of the notions of the L-system and of a turtle are introduced. The resulting mathematical model can be used to create a variety of (finite approximations of) fractal curves, ranging from Koch curves, to classic space-filling curves, to relatively realistic-looking pictures of plants and trees. All these pictures are defined in a uniform and compact way.},
  author   = {Przemyslaw Prusinkiewicz},
  issn     = {07135424},
  journal  = {Proceedings - Graphics Interface},
  pages    = {247--253},
  title    = {Graphical Applications of L-Systems.},
  url      = {http://algorithmicbotany.org/papers/graphical.gi86.pdf},
  year     = 1986
}

@article{Prusinkiewicz1989,
  abstract = {1. Introduction 3 2. Fractals 11 3. Models of plant architecture 23 4. Models of plant organs 55 5. Models of cell layers 63 6. Other applications of L-systems 69 Patterns and tilings (-> Gr\"{u}nbaum, Shephard: Tilings and Patterns) Kolam patterns Fractal music 7. A guide to the references 81 8. Program listing 101 kleine C-Programme},
  author   = {Przemyslaw Prusinkiewicz and James Hanan},
  isbn     = {0387970924 (U.S.)},
  issn     = {00361445},
  journal  = {Lecture Notes in Biomathematics},
  keywords = {Geometrie,Informatik,Mathematik},
  pages    = 120,
  pmid     = 2452354,
  title    = {Lindermayer Systems, fractals, and plants},
  url      = {http://algorithmicbotany.org/papers/lsfp.pdf},
  year     = 1989
}

@article{Prusinkiewicz1992,
  abstract = {The Algorithmic Beauty of Plants explores mathematical models of developmental processes and structures of plants, and illustrates them using state-of-the-art computer-generated images. Plant models which grow, interact with the environment, produce flowers and fruits, and finally die, have an immense intuitive appeal of "bringing life into a computer." In front of a graphics monitor it is easy to forget the underlying mathematical formulae and simply look at plants growing, self-replicating, responding to external factors, even mutating. Without compromising the mathematical rigor of presentation the authors have tried to preserve this "touch of magic" accompanying in their research. The following areas receive particular attention: methods for the modeling and rendering of plants which are suitable for realistic image synthesis; the scientific potential of computer graphics in the visualization of biological structures and processes; the relationship between control mechanisms employed by li- ing plants and the resulting complex developmental sequences and structures; and the relationship between developmental processes, self-similarity and fractals. The formalism of L-systems are adopted as the primary mathematical vehicle used to express developmental processes. The notion of L-systems was conceived in 1968 by Aristid Lindenmayer as a formal model of plant development. Its exceptional elegance was promptly recognized by mathematicians, who soon developed a comprehensive theory of L-systems. However, only recently has computer graphics revealed the full potential of L-systems applied to plant modeling. Although the focus is on the original results of joint research led by the authors, a survey of alternative methods for plant modeling is also included.},
  author   = {Przemyslaw Prusinkiewicz and Aristid Lindenmayer},
  doi      = {10.1137/1034030},
  issn     = {0036-1445},
  issue    = 1,
  journal  = {SIAM Review},
  pages    = {142--143},
  title    = {The Algorithmic Beauty of Plants},
  volume   = 34,
  url      = {http://algorithmicbotany.org/papers/abop/abop.pdf},
  year     = 1992
}

@article{Prusinkiewicz1993a,
  abstract = {This paper addresses the long-standing problem of generating fractal mountains with rivers, and presents a partial solution that incorporates a squig-curve model of a river's course into the mid-point-displacement model for mountains. The method is based on the observation that both models can be expressed by similar context-sensitive rewriting mechanisms. As a result, a mountain landscape with a river can be generated using a single integrated process.},
  author   = {Prezemyuslaw Prusinkiewicz and Mark Hammel},
  issn     = {07135424},
  issue    = {May},
  journal  = {Proceedings - Graphics Interface},
  keywords = {context-sensitive,els,geometric rewriting,midpoint displacement,modeling of natural phenomena,squig curve,terrain mod-},
  pages    = {174--180},
  title    = {Fractal model of mountains with rivers},
  url      = {http://data.exppad.com/public/papers/A Fractal Model of Mountains with Rivers.pdf},
  year     = 1993
}

@article{Prusinkiewicz1993b,
  abstract = {Rapid progress in the modeling of biological structures and simulation of their development has occurred over the last few years. It has been coupled with the visualization of simulation results, which has lead to a better understanding of morphogenesis and given rise to new procedural techniques for realistic image synthesis. This paper characterizes selected models of morphogenesis with a significant visual component.},
  author   = {Przemyslaw Prusinkiewicz},
  journal  = {Proceeding of Graphics Interface '93},
  keywords = {L-system,cellular automaton,developmental models in biology,diffusion-limited growth,morpho-genesis,reaction-diffusion,realistic image synthesis,simulation and visualization of biological phenom-ena},
  pages    = {128--137},
  title    = {Modeling and Visualization of Biological Structures},
  volume   = 1993,
  year     = 1993
}

@book{Prusinkiewicz2003,
  author  = {Przemyslaw Prusinkiewicz and Pavol Federl},
  edition = {SIGGRAPH Course},
  journal = {Course notes from \ldots{}},
  title   = {L-systems and beyond},
  url     = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:L-systems+and+Beyond\#0\%5Cnhttp://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:L-systems+and+beyond\#0},
  year    = 2003
}

@article{Prusinkiewicz2010,
  abstract = {Like all forms in nature, plants are subject to the properties of space. On the one hand, space prevents configurations that would place more than one component in the same location at the same time. A generalization of this constraint limits proximity and density of organs. On the other hand, space provides a means for a plant to create three-dimensional forms by differentially controlling their growth. This results from a connection between the metric properties of surfaces and their Gaussian curvature. Three strategies used by plants to develop within the constraints of space are presented: expansion to another dimension, egalitarian partitioning of space, and competition for space. These strategies are illustrated with examples of curved surfaces of leaves and petals, self-similar branching structures of compound leaves and inflorescences, and tree architecture. The examples highlight the fundamental role of the constraints of space in plant development, and the complementary role of genetic regulation and space-dependent emergent phenomena in shaping a plant. \textcopyright{} 2010 The Author.},
  author   = {Przemyslaw Prusinkiewicz and Pierre Barbier De Reuille},
  doi      = {10.1093/jxb/erq081},
  issn     = {00220957},
  issue    = 8,
  journal  = {Journal of Experimental Botany},
  keywords = {Competition for space,Curvature,Dimension,Fractal,Genetic regulation of form,Leaf margin,Metric,Plant modelling,Tree architecture},
  pages    = {2117--2129},
  pmid     = 20388746,
  title    = {Constraints of space in plant development},
  volume   = 61,
  url      = {http://algorithmicbotany.org/papers/constraints-of-space-in-plant-development.pdf},
  year     = 2010
}

@article{Prusinkiewicz2013,
  abstract = {We consider computational modeling of biological systems that consist of discrete components arranged into linear structures. As time advances, these components may process information, communicate and divide. We show that: (1) the topological notion of cell complexes provides a useful framework for simulating information processing and flow between components; (2) an indexfree notation exploiting topological adjacencies in the structure is needed to conveniently model structures in which the number of components changes (for example, due to cell division); and (3) Lindenmayer systems operating on cell complexes combine the above elements in the case of linear structures. These observations provide guidance for constructing L-systems and explain their modeling power. Lsystems operating on cell complexes are illustrated by revisiting models of heterocyst formation in Anabaena and by presenting a simple model of leaf development focused on the morphogenetic role of the leaf margin. \textcopyright{} Springer-Verlag Berlin Heidelberg 2013.},
  author   = {Przemyslaw Prusinkiewicz and Brendan Lane},
  doi      = {10.1007/978-3-642-20164-6\_12},
  issn     = 21905614,
  issue    = 1,
  journal  = {Springer Proceedings in Mathematics},
  pages    = {137--151},
  title    = {Modeling morphogenesis in multicellular structures with cell complexes and L-systems},
  volume   = 15,
  url      = {http://algorithmicbotany.org/papers/complexes.pfm2012.pdf},
  year     = 2013
}

@article{Przeslawski2022,
  abstract = {During feeding and burrowing, many epibenthic and infaunal animals bioturbate sediments and form a range of traces called lebensspuren (German for `life traces'), defined as any type of sedimentary structure produced by a living organism. During a 2020 survey along western Australia in the Gascoyne Marine Park, a distinct trace was observed several times, identical to the `spider trace' observed in a 2007 survey along eastern Australia, over 4000~km away. The purpose of this brief note is to document and describe the occurrence of this unique and distinctive type of lebensspuren and to discuss ways in which similar observations may be effectively shared to increase our understanding of deep-sea biology.},
  author   = {Rachel Przeslawski},
  doi      = {10.3389/fmars.2022.1086193},
  issn     = 22967745,
  issue    = {December},
  journal  = {Frontiers in Marine Science},
  keywords = {ROV,deep-sea,ichnology,trace fossils,underwater imagery},
  pages    = {1--5},
  title    = {Broad distribution of spider-shaped lebensspuren along the Australian continental margin},
  volume   = 9,
  year     = 2022
}

@article{Purkis2018,
  abstract = {Carbonate precipitation has been a common life strategy for marine organisms for 3.7 billion years, as, therefore, has their construction of reefs. As favored by modern corals, reef-forming organisms have typically adopted a niche in warm, shallow, well-lit, tropical marine waters, where they are capable of building vast carbonate edifices. Because fossil reefs form water aquifers and hydrocarbon reservoirs, considerable effort has been dedicated to understanding their anatomy and morphology. Remote sensing has a particular role to play here. Interpretation of satellite images has done much to reveal the grand spatial and temporal tapestry of tropical reefs. Comparative sedimentology, whereby modern environments are contrasted with the rock record to improve interpretation, has been particularly transformed by observations made from orbit. Satellite mapping has also become a keystone technology to quantify the coral reef crisis - it can be deployed not only directly to quantify the distribution of coral communities, but also indirectly to establish a climatology for their physical environment. This article reviews the application of remote sensing to tropical coralgal reefs in order to communicate how this fast-growing technology might be central to addressing the coral reef crisis and to look ahead at future developments in the science.},
  author   = {Sam J. Purkis},
  doi      = {10.1146/annurev-marine-121916-063249},
  issn     = 19410611,
  issue    = {August},
  journal  = {Annual Review of Marine Science},
  keywords = {carbonate reefs,climate change,remote sensing},
  pages    = {149--168},
  pmid     = 28793810,
  title    = {Remote sensing tropical coral reefs: The view from above},
  volume   = 10,
  year     = 2018
}

@article{Pyarelal2021,
  abstract = {Task environments developed in Minecraft are becoming increasingly popular for artificial intelligence (AI) research. However, most of these are currently constructed manually, thus failing to take advantage of procedural content generation (PCG), a capability unique to virtual task environments. In this paper, we present mcg, an open-source library to facilitate implementing PCG algorithms for voxel-based environments such as Minecraft. The library is designed with human-machine teaming research in mind, and thus takes a 'top-down' approach to generation, simultaneously generating low and high level machine-readable representations that are suitable for empirical research. These can be consumed by downstream AI applications that consider human spatial cognition. The benefits of this approach include rapid, scalable, and efficient development of virtual environments, the ability to control the statistics of the environment at a semantic level, and the ability to generate novel environments in response to player actions in real time.},
  author   = {Adarsh Pyarelal and Aditya Banerjee and Kobus Barnard},
  doi      = {10.1007/978-3-031-21671-8\_6},
  month    = 4,
  title    = {Modular Procedural Generation for Voxel Maps},
  url      = {http://arxiv.org/abs/2104.08890 http://dx.doi.org/10.1007/978-3-031-21671-8\_6},
  year     = 2021
}

@article{Pytel2013,
  abstract  = {A simulation of the effects of hydraulic erosion should generate realistic fractal character and exhibit certain high-level behavior, such as tributary capture. Our simulation method is able to achieve these goals in an emergent way by using a variant of avalanching, which is a principle followed by many physical self-organized systems. We also use the same approach to generate initial conditions for the erosion, so that the combined algorithm is a complete terrain modeling method based only on self-organization.},
  author    = {Alexei Pytel and Stephen Mann},
  doi       = {10.1016/j.cag.2013.01.006},
  issn      = {00978493},
  issue     = 4,
  journal   = {Computers and Graphics (Pergamon)},
  keywords  = {Hydraulic erosion,Procedural modeling,Terrain modeling},
  pages     = {280--292},
  publisher = {Elsevier},
  title     = {Self-organized approach to modeling hydraulic erosion features},
  volume    = 37,
  url       = {http://dx.doi.org/10.1016/j.cag.2013.01.006},
  year      = 2013
}

@article{Qili2020,
  abstract  = {In order to study the flow and erosion behavior of gas-solid exhaust in the polysilicon reduction furnace, the flow characteristics of exhaust gas and silicon particles were analyzed. The flow model and erosion model of exhaust gas and silicon particles were established based on the gas-solid flow theory and the erosion theory. The erosion and wear behavior of the gas-solid mixture in the flow passage pipeline were studied by numerical simulation. The results show that the wear and erosion from Nos. 1 to 8 regions at the bottom of the ring were caused by silicon particles colliding with high angle. The wear and erosion of 2 regions from Nos. 9 to 10 at the outside of the up azimuth on both sides of loop pipe outlets, 4 regions from Nos. 11 to 14 on the upper and lower wall of single furnace main channel were severely affected wear regions, which is caused by silicon particles with low angle and high velocity. Through comparative analysis, the erosion of upper wall of single furnace main channel is most serious. Increased gas velocity, particle concentration and particle size will exacerbate the erosion and wear rate of the pipeline in polysilicon reduction furnace, but the distribution and development of severe wear zone would not be affected significantly.},
  author    = {Wang Qili and Jia Binbin and Yu Mingquan and He Min and Li Xiaochuan and Sridhar Komarneni},
  doi       = {10.1038/s41598-020-58529-y},
  issn      = 20452322,
  issue     = 1,
  journal   = {Scientific Reports},
  pages     = {1--12},
  pmid      = 32024886,
  publisher = {Springer US},
  title     = {Numerical simulation of the flow and erosion behavior of exhaust gas and particles in polysilicon reduction furnace},
  volume    = 10,
  url       = {http://dx.doi.org/10.1038/s41598-020-58529-y https://www.nature.com/articles/s41598-020-58529-y.pdf},
  year      = 2020
}

@article{Qiu2008,
  abstract = {Spatial simulation models of seed dispersal have been constructed at the landscape level under the assumption of ubiquitous or uniform dispersibility. The anisotropic nature of vegetation distribution caused by different dispersal agents such as wind, gravity, water and animals were ignored. We propose a prototype of a GIS-based spatially explicit model of dispersal agent behavior (SEMODAR) to simulate the seed dispersal process by considering the unique behavioral characteristics of each seed dispersal agent. As a result, the influence of dispersal agent behavior on the species coexistence in competitive communities with and without habitat destruction could be explored. The model consists of four module components: dispersal rules, species competition, species colonization, and habitat destruction. An experimental simulation was conducted using three hypothetical species with differing competitive and migration abilities in both intact and disturbed conditions for 250 years. The findings of this study support the theoretical expectation that inferior competitors can coexist with superior competitors given that the inferior competitors have efficient colonization ability. The simulation also reveals the important role of agent behavior in the seed dispersal process and the biased impact of environment fragmentation on superior competitors that are not superior dispersers. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  author   = {Fang Qiu and Bin Li and Bryan Chastain and Mohammed Alfarhan},
  doi      = {10.1016/j.foreco.2007.06.038},
  issn     = {03781127},
  issue    = 3,
  journal  = {Forest Ecology and Management},
  keywords = {CA model,Dispersal agent behavior,Forest landscape modeling,GIS,Habitat destruction,Seed dispersal simulation,Species competition},
  month    = 2,
  pages    = {524--537},
  title    = {A GIS based spatially explicit model of dispersal agent behavior},
  volume   = 254,
  year     = 2008
}

@article{Rabbani2020,
  author   = {A H Rabbani and S. Khiat},
  journal  = {ACM SIGGRAPH / Eurographics Symposium on Computer Animation},
  keywords = {Computer Graphics Forum,EUROGRAPHICS},
  pages    = {1--3},
  title    = {Fast Eulerian Fluid Simulation In Games Using Poisson Filters},
  volume   = 2,
  url      = {https://www.youtube.com/watch?v=\_3eyPUyqluc\&t=0s},
  year     = 2020
}

@article{Raffe2012a,
  abstract = {This paper provides a review of existing approaches to using evolutionary algorithms (EA) during procedural terrain generation (PTG) processes in video games. A reliable PTG algorithm would allow game maps to be created partially or completely autonomously, reducing the development cost of a game and providing players with more content. Specifically, the use of EA raises possibilities of more control over the terrain generation process, as well as the ability to tailor maps for individual users. In this paper we outline the prominent algorithms that use EA in terrain generation, describing their individual advantages and disadvantages. This is followed by a comparison of the core features of these approaches and an analysis of their appropriateness for generating game terrain. This survey concludes with open challenges for future research. \textcopyright{} 2012 IEEE.},
  author   = {William L. Raffe and Fabio Zambetta and Xiaodong Li},
  doi      = {10.1109/CEC.2012.6256610},
  isbn     = 9781467315098,
  issue    = {Cec},
  journal  = {2012 IEEE Congress on Evolutionary Computation, CEC 2012},
  pages    = {2090--2097},
  title    = {A survey of procedural terrain generation techniques using evolutionary algorithms},
  url      = {https://ap-st01.ext.exlibrisgroup.com/61RMIT\_INST/upload/1654105000990\_n2006034557.pdf?Expires=1654105121\&Signature=FrlTT4vBpkq~nbL9nxnPRu4SV6tegL~9cBpjuIslucfR2pzwyy8oZ4su--Qd13yzcWwQMhP2nJAtJpb5gRqsYXTbnLDwjRd69O5V1WyWcrX6riggwjkBZ2fKrTNYVH3KDlCY~fDBCp8},
  year     = 2012
}

@article{Rajasekaran2022,
  abstract = {Terrains are visually prominent and commonly needed objects in many computer graphics applications. While there are many algorithms for synthetic terrain generation, it is rather difficult to assess the realism of a generated output. This article presents a first step toward the direction of perceptual evaluation for terrain models. We gathered and categorized several classes of real terrains, and we generated synthetic terrain models using computer graphics methods. The terrain geometries were rendered by using the same texturing, lighting, and camera position. Two studies on these image sets were conducted, ranking the terrains perceptually, and showing that the synthetic terrains are perceived as lacking realism compared to the real ones. We provide insight into the features that affect the perceived realism by a quantitative evaluation based on localized geomorphology-based landform features (geomorphons) that categorize terrain structures such as valleys, ridges, hollows, and so forth. We show that the presence or absence of certain features has a significant perceptual effect. The importance and presence of the terrain features were confirmed by using a generative deep neural network that transferred the features between the geometric models of the real terrains and the synthetic ones. The feature transfer was followed by another perceptual experiment that further showed their importance and effect on perceived realism. We then introduce Perceived Terrain Realism Metrics (PTRM), which estimates human-perceived realism of a terrain represented as a digital elevation map by relating the distribution of terrain features with their perceived realism. This metric can be used on a synthetic terrain, and it will output an estimated level of perceived realism. We validated the proposed metrics on real and synthetic data and compared them to the perceptual studies.},
  author   = {Suren Deepak Rajasekaran and Hao Kang and Martin \c{C}ad\'{\i}k and Eric Galin and Eric Gu\'{e}rin and Adrien Peytavie and Pavel Slav\'{\i}k and Bedrich Benes},
  doi      = {10.1145/3514244},
  issn     = 15443965,
  issue    = 2,
  journal  = {ACM Transactions on Applied Perception},
  keywords = {Procedural modeling,feature transfer,neural networks,terrains,visual perception},
  pages    = {1--22},
  title    = {PTRM: Perceived Terrain Realism Metric},
  volume   = 19,
  year     = 2022
}

@article{Ranz1960,
  abstract = {Irregular particles bounce with randomly distributed angles of reflection. There is a certain probability that a particle striking at low angle will bounce at a high angle and be carried far out into the main fluid flow. Bounce phenomena were investigated with respect to bounce of a model particle, limitations on dust collection (back mixing), and energy loss during the flow of suspensions.},
  author   = {W. E. Ranz and G. R. Talandis and Bernard Gutterman},
  doi      = {10.1002/aic.690060123},
  issn     = {0001-1541},
  issue    = 1,
  journal  = {AIChE Journal},
  month    = 3,
  pages    = {124--127},
  title    = {Mechanics of particle bounce},
  volume   = 6,
  url      = {https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.690060123},
  year     = 1960
}

@article{Reynolds2006,
  abstract = {This paper presents solutions for one requirement of autonomous characters in animation and games: the ability to navigate around their world in a lifelike and improvisational manner. These "steering behaviors" are largely independent of the particulars of the character's means of locomotion. Combinations of steering behaviors can be used to achieve higher level goals (For example: get from here to there while avoiding obstacles, follow this corridor, join that group of characters...) This paper divides motion behavior into three levels. It will focus on the middle level of steering behaviors, briefly describe the lower level of locomotion, and touch lightly on the higher level of goal setting and strategy.},
  author   = {Craig W Reynolds},
  keywords = {animation techniques,artificial life,autonomous agent,behavioral animation,collision avoidance,embodied,evasion,flocking,games,group behavior,interactive environments,navigation,obstacle avoidance,path following,path planning,pursuit,reactive,simulation,situated,steering,vehicle,virtual},
  pages    = {1--14},
  title    = {Steering Behaviors For Autonomous Characters Steering Behaviors For Autonomous Characters},
  url      = {http://www.red3d.com/cwr/steer/gdc99/},
  year     = 2006
}

@article{Richardson1954,
  author  = {J. F. Richardson and W. N. Zaki},
  journal = {Chemical Engineering Science},
  title   = {The sedimentation of a suspension of uniform spheres under conditions of viscous flow},
  volume  = 3,
  year    = 1954
}

@misc{RicherdeForges1988,
  author = {Bertrand Richer de Forges and Christophe Chevillon and Pierre Laboute and Georges Bargibant and Jean-Louis Menou and Philippe Tirard},
  title  = {La campagne CORAIL 2 sur le plateau des \^{\i}les Chesterfield},
  url    = {http://dsiphoto.mnhn.fr/expeditions/Documents/CORAIL2/CRCorail2.pdf},
  year   = 1988
}

@article{Ridao2001,
  abstract = {This report takes an in-depth look at the physical laws governing the behavior of an underwater robotic vehicle. A complete 3D kinematics and dynamics matrix-based model is also presented. This model uses the dynamics equations which describe the movement of a rigid body and the main hydrodynamic equations affecting this movement through a fluid environment. This model depends on a set of physical parameters which are obtained from experimentation. This report goes on to describe an identification methodology for slow Underwater Vehicles. As an example, it presents the identified model of an underwater robotic vehicle called GARBI. Real experiments are provided demonstrating the feasibility of the presented model as well as the identification methodology.},
  author   = {Pere Ridao and Joan Batlle and Marc Carrera},
  issue    = {April 2016},
  journal  = {Research report IIiA},
  pages    = {1--50},
  title    = {Dynamics model of an underwater robotic vehicle},
  url      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.4430\&amp;rep=rep1\&amp;type=pdf},
  year     = 2001
}

@article{Rieux2015,
  author = {Fr\'{e}d\'{e}ric Rieux},
  title  = {Processus de Diffusion Discret Op\'{e}rateur Laplacien appliqu\'{e} \`{a} l'\'{e}tude de surfaces},
  url    = {https://tel.archives-ouvertes.fr/tel-01174715/file/these.pdf},
  year   = 2015
}

@article{Rigaudiere2000,
  author   = {Dominique Rigaudi\`{e}re and Gilles Gesqui\`{e}re and Dominique Faudot},
  journal  = {Methods},
  keywords = {Skeleton, Implicit Primitives,d,implicit primitives,m,min,modelling,sk i,skeleton},
  title    = {Shape Modelling with Skeleton based Implicit Primitives},
  url      = {https://www.graphicon.ru/html/2000/2D GRAPHICS/Rigaudiere.pdf},
  year     = 2000
}

@article{Risandi2020,
  abstract = {Pocket beaches bound by headlands or other geologic features are common worldwide and experience constrained alongshore transport that influences their morphological changes. Pocket beaches fringed by shallow reefs have not been well-studied, yet can be commonly found throughout temperate and tropical regions. The presence of a reef is expected to drive distinct hydrodynamic processes and shoreline responses to offshore waves and water levels, which is investigated in this study. To examine the drivers of shoreline variability, a 20-month field study was conducted on a reef-fringed pocket beach in southwestern Australia (Gnarabup Beach), using a series of in situ wave and water level observations, topographic surveys, as well as video shoreline monitoring. The results indicate that the beach as a whole (alongshore averaged) was in a mostly stable state. However, we observed substantial spatial variability of the local shorelines in response to offshore wave and water levels across a range of time-scales (from individual storms to the seasonal cycle). We observed local regions of beach rotation within cells that were partitioned by the headlands and offshore reefs. The shoreline response was also dictated by the combination of offshore waves and water level which varied seasonally, with the shoreline generally eroding with lower water levels for the same wave height. Despite the contrasting responses in different alongshore locations of the beach, the overall beach volume of the pocket beach was largely conserved.},
  author   = {Johan Risandi and Jeff E. Hansen and Ryan J. Lowe and Dirk P. Rijnsdorp},
  doi      = {10.3389/fmars.2020.00445},
  issn     = 22967745,
  issue    = {June},
  journal  = {Frontiers in Marine Science},
  keywords = {Western Australia,beach rotation,coastal erosion,pocket beach,rocky reef},
  pages    = {1--16},
  title    = {Shoreline Variability at a Reef-Fringed Pocket Beach},
  volume   = 7,
  year     = 2020
}

@inproceedings{Rivest2010,
  abstract  = {A new level-set based active contour method for the segmentation of small blood vessels and other elongated structures is presented. Its main particularity is the presence of a length increasing force in the contour driving equation. The effect of this force is to push the active contour in the direction of thin elongated shapes. Although the proposed force is not stable in general, our experiments show that with few precautions it can successfully be integrated in a practical segmentation scheme and that it helps to segment a longer part of the structures of interest. For the segmentation of blood vessels, this may reduce the amount of user interactivity needed: only a small region inside the structure of interest need to be specified. \textcopyright{} 2010 IEEE.},
  author    = {D. Rivest-H\'{e}nault and M. Cheriet and S. Desch\^{e}nes and C. Lapierre},
  doi       = {10.1109/ICPR.2010.685},
  isbn      = 9780769541099,
  issn      = 10514651,
  booktitle = {Proceedings - International Conference on Pattern Recognition},
  pages     = {2796--2799},
  title     = {Length increasing active contour for the segmentation of small blood vessels},
  year      = 2010
}

@article{Roa2004,
  abstract = {An algorithm for simulating wind-ripples and moving sand is extended by the detection of fixed objects. This permits us simulation and animation of sand interacting with objects like houses, highways, cactuses, etc. Sand is accumulated on the windward side of an obstacle and the sand relocation and wind-ripples formation is diminished on the leeward side. The wind shadow depends on the object's geometry and the wind speed and direction. Sand tongues are formed as the result of the sand motion.},
  author   = {Toney Roa and Bedrich Benes},
  journal  = {Winter School of Computer Graphics SHORT communication Papers Proceedings},
  keywords = {desert scenery,erosion,procedural modeling,regular height fields,visual simulation},
  pages    = {17--22},
  title    = {Simulating desert scenery},
  url      = {https://dspace5.zcu.cz/bitstream/11025/6180/1/C79.pdf},
  year     = 2004
}

@inbook{Roberts2001,
  author  = {Jonathan C. Roberts},
  isbn    = {0954032101},
  journal = {Eurographics UK 2001 Conference Proceedings},
  pages   = {149--155},
  title   = {Sticky Pixels: Evolutionary Growth by Random Drop Ballistic Aggregation},
  url     = {https://kar.kent.ac.uk/13627/1/sticky\_pixels\_evolutionary\_roberts.pdf},
  year    = 2001
}

@article{Robinson1995,
  abstract = {Scientific Diving techniques were employed during a 54 day oceanographic research cruise to the Bellings-hausen Sea, Southern Ocean (65\textdegree{}S-72\textdegree{}S, 80 0 W-87\textdegree{}W), in order to position sampling and data collecting instrumentation beneath sea ice. Eight Scientific Divers and a Field Diving Officer safely completed 112 individual dives (range 2-80 minutes, 2-28 m); 94 of these were roped dives through holes cut in 1 m thick sea ice. Seawater temperature was-1.8\textdegree{}C, horizontal visibility 30 m + and water depth 600 m or more. No problems were encountered with the diving equipment used. Diving techniques enabled the collection of an important data set describing the dynamics of phytoplankton and zooplankton growth beneath sea ice. Recommendations for future under-ice oceanic scientific diving inc1ude the use of dive tables with ascent rates of less than 15 m/min, the provision for therapeutic oxygen at the dive site, and adequate shelter for surface tenders.},
  author   = {C. Robinson and H. J. Hill and S. Archer and R. J. G Leakey and P. W. Boyd and S. J. Bury},
  doi      = {10.3723/175605495783328845},
  issn     = 17560543,
  issue    = 1,
  journal  = {Underwater Technology},
  pages    = {21--27},
  title    = {Scientific Diving Under Sea Ice in the Southern Ocean},
  volume   = 21,
  url      = {https://www.ingentaconnect.com/content/sut/unwt/1995/00000021/00000001/art00005?crawler=true},
  year     = 1995
}

@article{Rocca2012,
  abstract = {We present a radically new method for the management, multi-resolution representation and rendering of large terrain databases. Our method has two main benefits: it provides a C \ensuremath{\kappa} representation of terrain, with \ensuremath{\kappa} depending on the type of base patches; and it supports efficient updates of the database as new data come in. We assume terrain data to come as a collection of regularly sampled overlapping grids, with arbitrary spacing and orientation. A multi-resolution model is built and updated dynamically off-line from such grids, which can be queried on-line to obtain a suitable collection of patches to cover a given domain with a given, possibly view-dependent, level of detail. Patches are combined to obtain a C \ensuremath{\kappa} surface. The whole framework can is designed to take advantage of the parallel computing power of modern GPUs.},
  author   = {Luigi Rocca and Daniele Panozzo and Enrico Puppo},
  doi      = {10.5220/0003848500670076},
  isbn     = 9789898565020,
  journal  = {GRAPP 2012 IVAPP 2012 - Proceedings of the International Conference on Computer Graphics Theory and Applications and International Conference on Information Visualization Theory and Applications},
  keywords = {Multiresolution modeling,Terrain modeling,Terrain rendering},
  pages    = {67--76},
  title    = {Patchwork terrains},
  url      = {https://cims.nyu.edu/gcl/papers/GRAPP12-RocPanPup.pdf},
  year     = 2012
}

@article{Rockwood1989,
  abstract = {To date, methods that blend solids, that is, B-rep or CSG models, with implicit functions require successive composition of the blending functions to handle an arbitrary solid model. The shape of the resulting surfaces depends upon the algebraic distances defined by these functions. To achieve meaningful shapes, previous methods have relied on blending functions that have a pseudo-Euclidean distance measure. These methods are abstracted, resulting in some general observations. Unfortunately, the functions used can exhibit unwanted discontinuities. A new method, the displacement form of blending, embeds the zero surface of the blending functions in a form for which algebraic distance is C1 continuous in the entire domain of definition. Characteristics of the displacement form are demonstrated using the superelliptic blending functions. Intuitive and mathematical underpinnings are provided. \textcopyright{} 1989, ACM. All rights reserved.},
  author   = {Alyn P. Rockwood},
  doi      = {10.1145/77269.77271},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics (TOG)},
  keywords = {Algebraic distance,blending,geometric modeling,implicit surfaces,sculptured surfaces,solid modeling},
  pages    = {279--297},
  title    = {The Displacement Method for Implicit Blending Surfaces in Solid Models},
  volume   = 8,
  url      = {https://dl.acm.org/doi/pdf/10.1145/77269.77271},
  year     = 1989
}

@article{Roden2004,
  abstract = {Procedural techniques will soon automate many aspects of content creation for computer games. We describe an efficient, deterministic, methodology for procedurally generating 3D game content of arbitrary size and complexity. The technique progressively amplifies simple dynamically generated data structures into complex geometry. We use a procedural pipeline with a minimum set of controls at each stage to facilitate authoring. We show two examples from our research. Our terrain generator can synthesize massive 3D terrains in real-time while our level generator can be used to create indoor environments offline or in real-time. \textcopyright{} IFIP International Federation for Information Processing 2004.},
  author   = {Timothy Roden and Ian Parberry},
  doi      = {10.1007/978-3-540-28643-1\_19},
  isbn     = 9783540286431,
  issn     = 16113349,
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  pages    = {151--156},
  title    = {From artistry to automation: A structured methodology for procedural content creation},
  volume   = 3166,
  year     = 2004
}

@article{Roger2014,
  abstract = {The recent catastrophic tsunamis show that it is now more than ever necessary to assess tsunami hazard for all coastal communities. In fact, facing the dangerous increase of population in low-lying coastal areas during the last decades directly linked to the reduction of the natural defences against sea assaults, including tsunamis, and considering the economy of most of the concerned countries, solutions should be found quickly to protect those populations and/or mitigate the hazard. In that way, recent studies and post-event field observations have highlighted the protective role played by coral reefs and the consequences of their destructions on the tsunami amplitudes. In this study previous results about the effect of fringing coral reef geometry on the tsunami amplitude are discussed using numerical modeling of nonlinear shallow water equations (NAMI-DANCE code). For this purpose, a set of different artificial Digital Elevation Models has been prepared in agreement with real bathymetric profiles and results of simulations are compared and discussed together with the conclusions obtained by the other authors.},
  author   = {Jean Roger and Bernard Dudon and Yann Krien and Narcisse Zahibo},
  doi      = {10.1007/978-94-007-7269-4\_8},
  isbn     = 9789400772694,
  issn     = 22136959,
  issue    = {September},
  journal  = {Advances in Natural and Technological Hazards Research},
  keywords = {Coral fringing reef,Numerical modeling,Tsunami},
  pages    = {161--176},
  title    = {Discussion about tsunami interaction with fringing coral reef},
  volume   = 35,
  year     = 2014
}

@article{Rogers2004,
  abstract = {Deep-sea coral reefs live in the cold, dark waters of the oceans but like shallow water tropical coral reefs they have a distinct, diverse and sometimes highly endemic associated animal community. These reefs are under direct threat from deep-sea trawling and in some areas have already been seriously impacted by fishing. At present there is no protection for these habitats on the high seas.},
  author   = {Alex Rogers},
  journal  = {International Union for Conservation of Nature \& Natural Resources},
  pages    = 13,
  title    = {The Biology , Ecology and Vulnerability of Deep-Water Coral Reefs},
  url      = {https://www.iucn.org/sites/default/files/import/downloads/alexrogers\_cbdcop7\_deepwatercorals\_complete.pdf},
  year     = 2004
}

@article{Rogers2013,
  abstract = {Spur and groove (SAG) formations are found on the fore reefs of many coral reefs worldwide. Although these formations are primarily present in wave-dominated environments, their effect on wave-driven hydrodynamics is not well understood. A two-dimensional, depth-averaged, phase-resolving nonlinear Boussinesq model ( funwaveC) was used to model hydrodynamics on a simplified SAG system. The modeling results show that the SAG formations together with shoaling waves induce a nearshore Lagrangian circulation pattern of counter-rotating circulation cells. The mechanism driving the modeled flow is an alongshore imbalance between the pressure gradient (PG) and nonlinear wave (NLW) terms in the momentum balance. Variations in model parameters suggest the strongest factors affecting circulation include spur-normal waves, increased wave height, weak alongshore currents, increased spur height, and decreased bottom drag. The modeled circulation is consistent with a simple scaling analysis based on the dynamical balance of NLW, PG, and bottom stress terms. Model results indicate that the SAG formations efficiently drive circulation cells when the alongshore SAG wavelength allows for the effects of diffraction to create alongshore differences in wave height without changing the mean wave angle.},
  author   = {Justin S. Rogers and Stephen G. Monismith and Falk Feddersen and Curt D. Storlazzi},
  doi      = {10.1002/jgrc.20225},
  issn     = {2169-9275},
  issue    = 6,
  journal  = {Journal of Geophysical Research: Oceans},
  month    = 6,
  pages    = {3059--3073},
  title    = {Hydrodynamics of spur and groove formations on a coral reef},
  volume   = 118,
  url      = {https://agupubs.onlinelibrary.wiley.com/doi/10.1002/jgrc.20225},
  year     = 2013
}

@article{Rongier2014,
  abstract = {Karst conduit shapes have a high influence on fluid flows. As these underground hidden systems are partially inaccessible, their stochastic simulation is an essential tool to assess the uncertainties related to these highly exploited water resources. The object-distance simulation method (ODSIM) is a hybrid dual-scale approach that has been recently proposed to model geological underground structures due to late processes such as dolomitized rocks, mineralized veins or karsts. Using a perturbed Euclidean distance field around a curve representing roughly the conduit centre and called a skeleton, the resulting shapes are globally cylindrical-like 3D envelopes. But at a drain scale, karstic conduits are elongated along weakness planes such as lithostratigraphic horizons, bedding planes, fractures or faults. In addition to those planes the influence of the water table is added. This work presents different improvements of ODSIM methodology for simulating more realistic shapes in the particular case of karst. Firstly, we propose using a custom distance field computed with a fast marching method. Considering the "velocity" field to be proportional to the permeability allows the resulting features to be elongated along the weakness planes. Secondly, to handle specific shapes due to the proximity of the water table, such as trenches or notches, we impose areas of higher velocity between the skeleton and the water table. Finally, we generate a custom random threshold with several variograms and/or distributions depending on the different features integrated in the "velocity" field. Applied on different models, it is shown that the resulting karst conduits have more realistic shapes than those obtained with the previous workflow, while the variability of structures which can be modelled with ODSIM is preserved. \textcopyright{} 2014 Elsevier B.V.},
  author   = {Guillaume Rongier and Pauline Collon-Drouaillet and Marco Filipponi},
  doi      = {10.1016/j.geomorph.2014.04.024},
  issn     = {0169555X},
  journal  = {Geomorphology},
  keywords = {Inception feature,Karst conduit,Shape,Skeleton,Stochastic simulation},
  pages    = {152--164},
  title    = {Simulation of 3D karst conduits with an object-distance based method integrating geological knowledge},
  volume   = 217,
  url      = {https://hal.archives-ouvertes.fr/hal-01304938/document},
  year     = 2014
}

@article{Rongier2017,
  abstract = {Simulating realistic sedimentary bodies while conditioning all the available data is a major topic of research. We present a new method to simulate the channel morphologies resulting from the deposition processes. It relies on a formal grammar system, the Lindenmayer system, or L-system. The L-system puts together channel segments based on user-defined rules and parameters. The succession of segments is then interpreted to generate non-rational uniform B-splines representing straight to meandering channels. Constraints attract or repulse the channel from the data during the channel development. They enable to condition various data types, from well data to probability cubes or a confinement. The application to a synthetic case highlights the method's ability to manage various data while preserving at best the channel morphology.},
  author   = {Guillaume Rongier and Pauline Collon and Philippe Renard},
  doi      = {10.1016/j.cageo.2017.05.006},
  issn     = {00983004},
  journal  = {Computers and Geosciences},
  keywords = {Channel,Constraints,Data conditioning,Lindenmayer system,Sedimentary system,Stochastic simulation},
  pages    = {158--168},
  title    = {Stochastic simulation of channelized sedimentary bodies using a constrained L-system},
  volume   = 105,
  url      = {https://hal.archives-ouvertes.fr/hal-01527896/file/Article\_ChannelLSystem\_Rongier.pdf},
  year     = 2017
}

@misc{Roose2011,
  abstract = {In this paper, we present a refinement algorithm for the SPH method. A particle is refined by replacing it with smaller daughter particles. The position of the new particles is calculated by using a square pattern centered at the position of the refined particle. We study the possibility of scaling and rotating this pattern according to the local distribution of the particles to reduce the overlap with the newly created daughter particles. The results of the simulations using the fully refined domain and the simulations using the dynamic refinement starting from the unrefined domain are compared and are in a good agreement. Kinetic energy as well as linear and angular momentum are conserved by the refinement procedure. The algorithm is presented in 2D, but its extension to 3D is straightforward.},
  author   = {Dirk Roose and K U Leuven and Yaidel Reyes L\'{o}pez},
  journal  = {Computer Methods in Mechanics},
  keywords = {Smoothed Particle Hydrodynamics,adaptivity,meshless methods,particle refinement},
  title    = {Dynamic refinement for fluid flow simulations with SPH Particle refinement for fluid flow simulations with SPH},
  url      = {https://www.researchgate.net/publication/228531954},
  year     = 2011
}

@misc{Rothman1988,
  abstract = {We introduce a new deterministic collision rule for lattice-gas (cellular-automaton) hydrodynamics that yields immiscible two-phase flow. The rule is based on a minimization principle and the conservation of mass, momentum, and particle type. A numerical example demonstrates the spontaneous separation of two phases in two dimensions. Numerical studies show that the surface tension coefficient obeys Laplace's formula. Recently, Frisch et aL (1) (FHP) introduced a discrete lattice-gas model for the numerical solution of the 2D incompressible Navier-Stokes equations. In their model, space, time, and the velocities of particles are discrete. Identical particles of equal mass populate a triangular lattice, obey simple collision rules, and travel to neighboring sites at each time step. Because the model is entirely discrete, and because the evolution of a site is determined by the state of the ;ite and its nearest neighbors, the lattice gas is a cellular automaton. (2) Despite its simplicity, the macroscopic behavior of the lattice-gas automaton asymptotically approaches continuum flow. Since its introduction, this new model of fluid dynamics has not only been the subject of extensive theoretical and numerical studies, ~ 7) but has also been extended to 3D (8) and applied to a wide range of problems (e.g., refs. \%11). Here we introduce a simple yet fundamental extension of the lattice gas that leads to immiscible two-phase flow with interracial tension between fluid phases. In regions occupied by only a single phase, our 2D model is (barring irrelevant details) identical to the FHP gas. When two phases occupy the same region, however, we apply a new collision rule that},
  author   = {Daniel H Rothman and Jeffrey M Keller},
  issue    = 3,
  journal  = {Journal of Statistical Physics},
  keywords = {Cellular automata,lattice gases,phase separation,surface tension,two-phase flow},
  title    = {Immiscible Cellular-Automaton Fluids},
  volume   = 52,
  year     = 1988
}

@article{Roudier1993,
  author = {Pascale Roudier},
  title  = {Synth\`{e}se de paysages r\'{e}alistes par simulation de processus d'\'{e}rosion},
  year   = 1993
}

@article{Roudier1993a,
  abstract = {This paper describes an original approach to terrain evolution in landscapes synthesis. In order to create some realistic landforms, we simulate geologically contrasted terrains and apply to them deterministic erosion processes. This allows us to relate the erosion on any point of the landsurface to local geological parameters. Any height field may be chosen as an initial topographic surface. Small perturbations may be introduced to avoid unpleasant regularities. A 3D model defines the geological parameters of each point according to its elevation. Our method is iterative: at each step, rock removal and possible alluvial deposition are computed at each point of the landsurface. The available erosion laws simulate mechanical erosion, chemical dissolution and alluvial deposition. At the end of each iteration, a new landsurface and the corresponding river network are created. Landsurfaces can be visualized at the final stage by two rendering algorithms including natural textures mapping. The stream network and the ridges may also be visualized. \textcopyright{} 1993 Eurographics Association},
  author   = {P. Roudier and B. Peroche and M. Perrin},
  doi      = {10.1111/1467-8659.1230375},
  issn     = 14678659,
  issue    = 3,
  journal  = {Computer Graphics Forum},
  keywords = {artificial landscapes modelling,geological phenomena simulation,landscapes rendering,natural textures},
  note     = {No mass conservation},
  pages    = {375--383},
  title    = {Landscapes Synthesis Achieved through Erosion and Deposition Process Simulation},
  volume   = 12,
  year     = 1993
}

@misc{Roy2007,
  author = {S\'{e}bastien Roy and Jean-Philippe Tardif},
  title  = {Vision par ordinateur: Calibration de Cam\'{e}ra et g\'{e}om\'{e}tri\'{e} epipolaire},
  year   = 2007
}

@article{Rungjiratananon2008,
  abstract = {Recent advances in physically-based simulations have made it possible to generate realistic animations. However, in the case of solid-fluid coupling, wetting effects have rarely been noticed despite their visual importance especially in interactions between fluids and granular materials.},
  author   = {Witawat Rungjiratananon and Zoltan Szego and Yoshihiro Kanamori and Tomoyuki Nishita},
  doi      = {10.1111/j.1467-8659.2008.01336.x},
  issn     = {0167-7055},
  issue    = 7,
  journal  = {Computer Graphics Forum},
  month    = 10,
  pages    = {1887--1893},
  title    = {Real-time Animation of Sand-Water Interaction},
  volume   = 27,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2008.01336.x},
  year     = 2008
}

@article{Runions2007,
  abstract = {We extend the open leaf venation model by Runions et al. [RFL05] to three dimensions and show that it generates surprisingly realistic tree structures. Model parameters correspond to visually relevant tree characteristics identified in landscaping, offering convenient control of tree shape and structure. \textcopyright{} The Eurographics Association 2007.},
  author   = {Adam Runions and Brendan Lane and Przemyslaw Prusinkiewicz},
  isbn     = 9783905673494,
  issn     = 18160867,
  journal  = {Natural Phenomena},
  keywords = {Generative tree modeling,Model control,Procedural modeling,Visual realism},
  pages    = {63--70},
  title    = {Modeling trees with a space colonization algorithm},
  url      = {http://algorithmicbotany.org/papers/colonization.egwnp2007.pdf},
  year     = 2007
}

@article{Runions2008,
  author  = {Adam Runions},
  issn    = {0147-958X},
  journal = {A Thesis submitted to the faculty of graduate studies for degree of master of science},
  pages   = 74,
  title   = {Modeling biological patterns using the space colonization algorithm},
  url     = {http://algorithmicbotany.org/papers/runionsa.th2008.pdf},
  year    = 2008
}

@article{Rusconi2023,
  abstract  = {The paper describes a general modelling procedure to build a simulation tool to investigate contact motion of a CubeSat on an asteroid surface. We investigate landing performance and landing success for the case of elastic rocky terrain and flat surfaces. As a case study, we focus on the disposal of ESA's Hera Milani CubeSat by landing on the moon of Didymos binary asteroid system. The simulation environment includes the modelling of real shape and 6-DOF motion of the lander, the shape-based gravity models of Didymos and Dimorphos and rocks on surface, that are generated as physical obstacles. Trends and estimates on the performance of the landing phase and the most relevant effects on the outcome of the soil interaction process, are inferred. The statistical results on settling time, dispersion area and motion characteristics, such as number of bounces, show and quantify the effect of rocks on a successful passive and permanent landing.},
  author    = {Martina Rusconi and Fabio Ferrari and Francesco Topputo},
  doi       = {10.1016/j.asr.2022.10.056},
  issn      = 18791948,
  issue     = 1,
  journal   = {Advances in Space Research},
  keywords  = {AIDA,Asteroid,Ballistic landing,Contact dynamics,Rocky terrain,Simulation},
  month     = 1,
  pages     = {829--844},
  publisher = {Elsevier Ltd},
  title     = {The effect of a rocky terrain for CubeSat landing on asteroid surfaces},
  volume    = 71,
  year      = 2023
}

@article{Rusnell2009,
  author  = {Brennan Rusnell},
  issue   = {May},
  journal = {Information Visualization},
  title   = {Feature-Rich Distance-Based Terrain Synthesis},
  year    = 2009
}

@article{Sabella1988,
  abstract = {This paper presents a ray tracing algorithm for rendering 3D scalar fields. An illumination model is developed in which the field is characterized as a varying density emittter with a single level of scattering. This model is equivalent to a particle system in which the particles are sufficiently small. Along each ray cast from the eye, the field is expressed as a function of the ray parameter. The algorithm computes properties of the field along the ray such as the attenuated intensity, the peak density, and the center of gravity, etc.. These are mapped into HSV color space to produce an image for visualization. Images produced in this manner are perceived as a varying density 'cloud' where color highlights the computed attributes. The application of this technique is demonstrated for visualizing a three dimensional seismic data set.},
  author   = {Paolo Sabella},
  doi      = {10.1145/54852.378476},
  isbn     = {0897912756},
  issue    = 4,
  journal  = {Proceedings of the 15th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1988},
  keywords = {3D image,Light scattering,Ray tracing,Thresholding},
  pages    = {51--58},
  title    = {A rendering algorithm for visualizing 3D scalar fields},
  volume   = 22,
  year     = 1988
}

@article{Salgado2007,
  author  = {Alex Salgado and Aura Conci},
  issue   = 1,
  journal = {\ldots{} Symposium on Computer Graphics and Image \ldots{}},
  pages   = {6--7},
  title   = {On the Simulation of Ocean Waves in Real-Time Using the GPU},
  url     = {http://www.lbd.dcc.ufmg.br/bdbcomp/servlet/Trabalho?id=15912},
  year    = 2007
}

@misc{Sanchez-Caballero2020,
  abstract = {Human actions recognition is a fundamental task in artificial vision, that has earned a great importance in recent years due to its multiple applications in different areas. In this context, this paper describes an approach for real-time human action recognition from raw depth image-sequences, provided by an RGB-D camera. The proposal is based on a 3D fully convolutional neural network, named 3DFCNN, which automatically encodes spatio-temporal patterns from depth sequences without pre-processing. Furthermore, the described 3D-CNN allows actions classification from the spatial and temporal encoded information of depth sequences. The use of depth data ensures that action recognition is carried out protecting people's privacy, since their identities can not be recognized from these data. 3DFCNN has been evaluated and its results compared to those from other state-of-the-art methods within three widely used datasets, with different characteristics (resolution, sensor type, number of views, camera location, etc.). The obtained results allows validating the proposal, concluding that it outperforms several state-of-the-art approaches based on classical computer vision techniques. Furthermore , it achieves action recognition accuracy comparable to deep learning based state-of-the-art methods with a lower computational cost, which allows its use in real-time applications.},
  author   = {Adrian Sanchez-Caballero and Sergio De L\'{o}pez-Diz and David Fuentes-Jimenez and Cristina Losada-Guti\'{e}rrez and Marta Marr\'{o}n-Romera and David Casillas-Perez and Mohammad Ibrahim Sarker},
  title    = {3DFCNN: Real-Time Action Recognition using 3D Deep Neural Networks with Raw Depth Information},
  year     = 2020
}

@article{Sane2020,
  abstract = {Streamlines are an extensively utilized flow visualization technique for understanding, verifying, and exploring computational fluid dynamics simulations. One of the major challenges associated with the technique is selecting which streamlines to display. Using a large number of streamlines results in dense, cluttered visualizations, often containing redundant information and occluding important regions, whereas using a small number of streamlines could result in missing key features of the flow. Many solutions to select a representative set of streamlines have been proposed by researchers over the past two decades. In this state-of-the-art report, we analyze and classify seed placement and streamline selection (SPSS) techniques used by the scientific flow visualization community. At a high-level, we classify techniques into automatic and manual techniques, and further divide automatic techniques into three strategies: density-based, feature-based, and similarity-based. Our analysis evaluates the identified strategy groups with respect to focus on regions of interest, minimization of redundancy, and overall computational performance. Finally, we consider the application contexts and tasks for which SPSS techniques are currently applied and have potential applications in the future.},
  author   = {Sudhanshu Sane and Roxana Bujack and Christoph Garth and Hank Childs},
  doi      = {10.1111/cgf.14036},
  issn     = 14678659,
  issue    = 3,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,\textbullet{} Human-centered computing \rightarrow{} Scientific visualizat},
  pages    = {785--809},
  title    = {A Survey of Seed Placement and Streamline Selection Techniques},
  volume   = 39,
  url      = {https://diglib.eg.org/bitstream/handle/10.1111/cgf14036/v39i3pp785-809.pdf?sequence=1\&isAllowed=y},
  year     = 2020
}

@article{Sansano-Sansano2020,
  abstract = {<p>To estimate the user gait speed can be crucial in many topics, such as health care systems, since the presence of difficulties in walking is a core indicator of health and function in aging and disease. Methods for non-invasive and continuous assessment of the gait speed may be key to enable early detection of cognitive diseases such as dementia or Alzheimer's disease. Wearable technologies can provide innovative solutions for healthcare problems. Bluetooth Low Energy (BLE) technology is excellent for wearables because it is very energy efficient, secure, and inexpensive. In this paper, the BLE-GSpeed database is presented. The dataset is composed of several BLE RSSI measurements obtained while users were walking at a constant speed along a corridor. Moreover, a set of experiments using a baseline algorithm to estimate the gait speed are also presented to provide baseline results to the research community.</p>},
  author   = {Emilio Sansano-Sansano and Fernando J. Aranda and Ra\'{u}l Montoliu and Fernando J. \'{A}lvarez},
  doi      = {10.3390/data5040115},
  issn     = {2306-5729},
  issue    = 4,
  journal  = {Data},
  keywords = {BLE-based technology,Gait speed,Public database},
  month    = 12,
  pages    = 115,
  title    = {BLE-GSpeed: A New BLE-Based Dataset to Estimate User Gait Speed},
  volume   = 5,
  url      = {https://www.mdpi.com/2306-5729/5/4/115},
  year     = 2020
}

@article{Santelices2007,
  author  = {Bernab\'{e} Santelices},
  doi     = {10.1073/pnas.0708963104},
  issn    = {00278424},
  issue   = 49,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  pages   = {19163--19164},
  pmid    = 18042707,
  title   = {The discovery of kelp forests in deep-water habitats of tropical regions},
  volume  = 104,
  year    = 2007
}

@article{Sarkar2021,
  abstract = {Behavior trees (BTs) are a popular method for modeling NPC and enemy AI behavior and have been widely used in commercial games. In this work, rather than use BTs to model game playing agents, we use them for modeling game design agents, defining behaviors as content generation tasks rather than in-game actions. Similar to how traditional BTs enable modeling behaviors in a modular and dynamic manner, BTs for PCG enable simple subtrees for generating parts of levels to be combined modularly to form complex trees for generating whole levels as well as generators that can dynamically vary the generated content. We refer to this approach as Procedural Content Generation using Behavior Trees, or PCGBT, and demonstrate it by using BTs to model generators for Super Mario Bros., Mega Man and Metroid levels as well as dungeon layouts and discuss several ways in which this paradigm could be applied and extended in the future.},
  author   = {Anurag Sarkar and Seth Cooper},
  month    = 6,
  title    = {Procedural Content Generation using Behavior Trees (PCGBT)},
  url      = {http://arxiv.org/abs/2107.06638},
  year     = 2021
}

@inproceedings{Sauer2021,
  author    = {Christian Sauer and Eike Lyczkowski and Marco Schmidt and Andreas N\"{u}chter and Tobias Ho\ss{}feld},
  city      = {New York, NY, USA},
  doi       = {10.1145/3479239.3485724},
  isbn      = 9781450390774,
  issue     = 1,
  booktitle = {Proceedings of the 24th International ACM Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
  keywords  = {Coverage Optimization,Industrial Application,Mobile Ad-hoc Network,Mobile Robotics,Procedural Generation,all or part of,coverage optimization,industrial application,mobile ad-hoc network,mobile robotics,or,or hard copies of,permission to make digital,procedural generation,this work for personal},
  month     = 11,
  pages     = {13--22},
  publisher = {ACM},
  title     = {Testing AGV Mobility Control Method for MANET Coverage Optimization using Procedural Generation},
  volume    = 1,
  url       = {https://dl.acm.org/doi/10.1145/3479239.3485724},
  year      = 2021
}

@book{SBGames2008,
  author = {Belo Horizonte -Mg -Brazil},
  title  = {VII Brazilian Symposium on Computer Games and Digital Entertainment},
  year   = 2008
}

@article{Scalise2016,
  abstract  = {Chemical reactions and diffusion can produce a wide variety of static or transient spatial patterns in the concentrations of chemical species. Little is known, however, about what dynamical patterns of concentrations can be reliably programmed into such reaction–diffusion systems. Here we show that given simple, periodic inputs, chemical reactions and diffusion can reliably emulate the dynamics of a deterministic cellular automaton, and can therefore be programmed to produce a wide range of complex, discrete dynamics. We describe a modular reaction–diffusion program that orchestrates each of the fundamental operations of a cellular automaton: storage of cell state, communication between neighboring cells, and calculation of cells' subsequent states. Starting from a pattern that encodes an automaton's initial state, the concentration of a ``state'' species evolves in space and time according to the automaton's specified rules. To show that the reaction–diffusion program we describe produces the target dynamics, we simulate the reaction–diffusion network for two simple one-dimensional cellular automata using coupled partial differential equations. Reaction–diffusion based cellular automata could potentially be built in vitro using networks of DNA molecules that interact via branch migration processes and could in principle perform universal computation, storing their state as a pattern of molecular concentrations, or deliver spatiotemporal instructions encoded in concentrations to direct the behavior of intelligent materials.},
  author    = {Dominic Scalise and Rebecca Schulman},
  doi       = {10.1007/s11047-015-9503-8},
  issn      = 15729796,
  issue     = 2,
  journal   = {Natural Computing},
  keywords  = {Cellular automata,Chemical reaction network,DNA strand displacement,Distributed computation,Intelligent materials,Molecular programming,Programmable matter,Reaction–diffusion},
  month     = 6,
  pages     = {197--214},
  publisher = {Springer Netherlands},
  title     = {Emulating cellular automata in chemical reaction–diffusion networks},
  volume    = 15,
  year      = 2016
}

@book{Scheidegger1970,
  author  = {Adrian E. Scheidegger},
  doi     = {10.1007/978-3-662-01025-9},
  isbn    = 9783662010273,
  journal = {Theoretical Geomorphology},
  title   = {Theoretical Geomorphology},
  year    = 1970
}

@article{Schettino1999,
  abstract = {This paper describes a set of algorithms for performing overlay operations on polygonal regions in spherical topology. A solution to the intersection problem for a polygonal region on the unit sphere with respect to a base set of polygons is proposed. The method is based upon a variant of the point-in-polygon procedure and has been successfully used to reconstruct ancient ocean-floor age maps and plate boundaries.},
  author   = {Antonio Schettino},
  doi      = {10.1016/S0098-3004(98)00081-8},
  issn     = {00983004},
  issue    = 1,
  journal  = {Computers and Geosciences},
  keywords = {Computational geometry,Ocean-floor age grid,Plate tectonics,Point-in-polygon,Polygons},
  pages    = {61--69},
  title    = {Polygon intersections in spherical topology: Application to plate tectonics},
  volume   = 25,
  year     = 1999
}

@article{Schmidt2005,
  abstract = {A technique is presented for generating implicit sweep objects that support direct specification and manipulation of the surface with no topological limitations on the 2D sweep template. The novelty of this method is that the under-lying scalar field is bounded and C 1 continuous, apart from surface creases. Bounded scalar fields guarantee local in-fluence when modeling with implicit surfaces, an important usbility requirement for interactive modeling. A discrete ap-proximation is also described that supports fast evaluation for bounded scalar fields. The new sweep objects are imple-mented in an interactive BlobTree modeling tool, provid-ing an intuitive and expressive free-form implicit modeling component. This sweep representation permits conversion of parametric sweep surfaces to implicit volumes. An ap-plication to volume reconstruction from parallel contours is also explored.},
  author   = {Ryan Schmidt and Brian Wyvill},
  journal  = {Department of Computer Science. University of Calgary},
  title    = {Implicit sweep surfaces},
  url      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.1738\&amp;rep=rep1\&amp;type=pdf},
  year     = 2005
}

@article{Schmidt2005a,
  abstract = {A technique is presented for generating implicit sweep objects that support direct specification and manipulation of the surface with no topological limitations on the 2D sweep template. The novelty of this method is that the under-lying scalar field is bounded and C 1 continuous, apart from surface creases. Bounded scalar fields guarantee local in-fluence when modeling with implicit surfaces, an important usbility requirement for interactive modeling. A discrete ap-proximation is also described that supports fast evaluation for bounded scalar fields. The new sweep objects are imple-mented in an interactive BlobTree modeling tool, provid-ing an intuitive and expressive free-form implicit modeling component. This sweep representation permits conversion of parametric sweep surfaces to implicit volumes. An ap-plication to volume reconstruction from parallel contours is also explored.},
  author   = {Ryan Schmidt and Brian Wyvill},
  journal  = {Department of Computer Science. University of Calgary},
  title    = {Implicit sweep surfaces},
  url      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.1738\&amp;rep=rep1\&amp;type=pdf},
  year     = 2005
}

@article{Schmidt2006,
  abstract = {Various systems have explored the idea of inferring 3D models from sketched 2D outlines. In all of these systems the underlying modeling methodology limits the complexity of models that can be created interactively. The ShapeShop sketch-based modeling system utilizes Hierarchical Implicit Volume Models (BlobTrees) as an underlying shape representation. The BlobTree framework supports interactive creation of complex, detailed solid models with arbitrary topology. A new technique is described for inflating 2D contours into rounded three-dimensional implicit volumes. Sketch-based modeling operations are defined that combine these basic shapes using standard blending and CSG operators. Since the underlying volume hierarchy is by definition a construction history, individual sketched components can be non-linearly edited and removed. For example, holes can be interactively dragged through a shape. ShapeShop also provides 2D drawing assistance using a new curve-sketching system based on variational contours. A wide range of models can be sketched with ShapeShop, from cartoon-like characters to detailed mechanical parts. Examples are shown which demonstrate significantly higher model complexity than existing systems.},
  author   = {R. Schmidt and Brian Wyvill and M. C. Sousa and J. A. Jorge},
  doi      = {10.1145/1185657.1185775},
  isbn     = 1595933646,
  journal  = {SIGGRAPH 2006 - ACM SIGGRAPH 2006 Courses},
  pages    = {1--10},
  title    = {ShapeShop: Sketch-based solid modeling with BlobTrees},
  url      = {https://www.inesc-id.pt/ficheiros/publicacoes/2607.pdf},
  year     = 2006
}

@article{Schneider2006,
  abstract = {Recent advances in algorithms and graphics hardware have opened the possibility to render large terrain fields at interactive rates on commodity PCs. Due to these advances it is possible today to interactively synthesize artificial terrains using procedural descriptions. Our paper extends on this work by presenting a new GPU method for real-time editing, synthesis, and rendering of infinite landscapes exhibiting a wide range of geological structures. Our method builds upon the concept of projected grids to achieve near-optimal sampling of the landscape. We describe the integration of procedural shaders for multifractals into this approach, and we propose intuitive options to edit the shape of the resulting terrain. The method is multi-scale and adaptive in nature, and it has been extended towards infinite and spherical domains. In combination with geo-typical textures that automatically adapt to the shape being synthesized, a powerful method for the creation and rendering of realistic landscapes is presented.},
  author   = {Jens Schneider and T. Boldte and R\"{u}diger Westermann},
  isbn     = 3898380815,
  journal  = {Vision, modeling, and visualization 2006: proceedings},
  pages    = 145,
  title    = {Real-time editing, synthesis, and rendering of infinite landscapes on GPUs},
  url      = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=zndnSzkfkXwC\&amp;oi=fnd\&amp;pg=PA145\&amp;dq=real+time+editing+synthesis+and+rendering+of+infinite+landscapes+on+gpus\&amp;ots=0Wd0aCUIo6\&amp;sig=5tgTvz3EQ\_seL0S9\_g6soYekjds},
  year     = 2006
}

@article{Schott2023,
  abstract  = {<p>Large-scale terrains are essential in the definition of virtual worlds. Given the diversity of landforms and the geomorphological complexity, there is a need for authoring techniques offering hydrological consistency without sacrificing user control. In this article, we bridge the gap between large-scale erosion simulation and authoring into an efficient framework. We set aside modeling in the elevation domain in favour of the uplift domain and compute emerging reliefs by simulating the stream power erosion. Our simulation relies on a fast yet accurate approximation of drainage area and flow routing to compute the erosion interactively, which allows for incremental authoring. Our model provides landscape artists with tools for shaping mountain ranges and valleys, such as copy-and-paste operations; warping for imitating folds and faults; and point and curve elevation constraints to precisely sculpt ridges or carve river networks. It also lends itself to inverse procedural modeling by reconstructing the uplift from an input digital elevation model and allows hydrologically consistent blending between terrain patches.</p>},
  author    = {Hugo Schott and Axel Paris and Lucie Fournier and Eric Gu\'{e}rin and Eric Galin},
  doi       = {10.1145/3592787},
  issn      = {0730-0301},
  issue     = 5,
  journal   = {ACM Transactions on Graphics},
  keywords  = {Erosion Simulation,Landscapes},
  month     = 10,
  pages     = {1--15},
  publisher = {inPress},
  title     = {Large-scale Terrain Authoring through Interactive Erosion Simulation},
  volume    = 42,
  url       = {https://dl.acm.org/doi/10.1145/3592787},
  year      = 2023
}

@article{Schott2024,
  abstract = {<p>Modeling high-resolution terrains is a perennial challenge in the creation of virtual worlds. In this paper, we focus on the amplification of a low-resolution input terrain into a high-resolution, hydrologically consistent terrain featuring complex patterns by a multi-scale approach. Our framework combines the best of both worlds, relying on physics-inspired erosion models producing consistent erosion landmarks and introducing control at different scales, thus bridging the gap between physics-based erosion simulations and multi-scale procedural modeling. The method uses a fast and accurate approximation of different simulations, including thermal, stream power erosion and deposition performed at different scales to obtain a range of effects. Our approach provides landscape designers with tools for amplifying mountain ranges and valleys with consistent details.</p>},
  author   = {Hugo Schott and Eric Galin and Eric Gu\'{e}rin and Axel Paris and Adrien Peytavie},
  doi      = {10.1145/3658200},
  issn     = {0730-0301},
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Erosion Simulation,Landscapes},
  month    = 7,
  pages    = {1--12},
  title    = {Terrain Amplification using Multi Scale Erosion},
  volume   = 43,
  url      = {https://dl.acm.org/doi/10.1145/3658200},
  year     = 2024
}

@article{Schroeder1994,
  abstract = {Swept surfaces and volumes are generated by moving a geometric model through space. Swept surfaces and volumes are important in many computer-aided design applications including geometric modeling, numerical cutter path generation, and spatial path planning. In this paper we describe a numerical algorithm to generate swept surfaces and volumes using implicit modeling techniques. The algorithm is applicable to any geometric representation for which a distance function can be computed. The algorithm also treats degenerate trajectories such as self-intersection and surface singularity. We show applications of this algorithm to maintainability design and robot path planning.},
  author   = {William J. Schroeder and William E. Lorensen and Steve Linthicum},
  doi      = {10.1109/visual.1994.346339},
  issn     = 10702385,
  issue    = {May 2014},
  journal  = {Proceedings Visualization},
  pages    = {40--45},
  title    = {Implicit modeling of swept surfaces and volumes},
  year     = 1994
}

@article{SCOFFIN1983,
  abstract = {Plate tectonic theory accounts for the steady subsidence of mid-plate oceanic islands by cooling of the lithosphere and so provides a sound basis for Darwin's theory of atoll formation. Now it is evident that because the lithosphere behaves elastically in response to loads such as islands, more localized subsidence and uplift patterns can also be explained. Tectonically active areas, where one plate is subducted beneath another, are also likely to contain regions of marked uplift, but are less amenable to modelling. These processes together provide a background motion framework for most reef settings with rates of vertical movement of the order of a few millimetres per year. Reef forms are greatly influenced by the configuration of their foundations. Holocene reef foundations were essentially moulded by processes of deposition and erosion during the Pleistocene when global sea level changes were often greater than 1 cm year-1. We are now developing a sufficient understanding of the rates and nature of reef processes of growth and destruction to be able to see the manner in which the structural development of reefs responds to the complex interplay of tectonic uplift and subsidence plus changes of sea level and climate. Copyright \textcopyright{} 1983, Wiley Blackwell. All rights reserved},
  author   = {T. P. SCOFFIN and J. E. DIXON},
  doi      = {10.1111/j.1095-8312.1983.tb01587.x},
  issn     = 10958312,
  issue    = 1,
  journal  = {Biological Journal of the Linnean Society},
  keywords = {Corals reefs,atolls,oceanic islands,plate tectonics,reef geomorphology,reef sedimentation,sea level changes,subsidence,tectonic theory,uplift},
  pages    = {11--38},
  title    = {The distribution and structure of coral reefs: one hundred years since Darwin},
  volume   = 20,
  year     = 1983
}

@article{Scott2007,
  abstract = {The modelling of fault populations and quantification of fault risk is a challenge for earth science and engineering applications, including minerals and coal mining, tunnel construction, forecasting of petroleum production, and selection of subterranean repositories for the disposal of toxic waste. This paper discusses a new advance in the use of stochastic fault simulation methods for the quantification of fault risk. The fractal properties of a fully known fault population are used as an analogue of the properties of an undiscovered fault population. The approach is elucidated through the quantification of fault risk in a prospective coalfield at Wyong, New South Wales, Australia, and incorporates spatial patterns of available 'hard' and 'soft' geological data. The method does not find faults unequivocally; rather the output is a map of fault probability. Simulations are found to be consistent with the available information and are statistically and spatially reasonable in geological terms. Significantly, the analogue approach provides a robust, quantified assessment of fault risk using limited exploration information.},
  author   = {J. Scott and R. Dimitrakopoulos and S. Li and K. Bartlett},
  isbn     = 9781920806774,
  journal  = {Australasian Institute of Mining and Metallurgy Publication Series},
  pages    = {87--93},
  title    = {Fractal-based fault simulations using a geological analogue - quantification of fault risk at Wyong, NSW, Australia},
  volume   = 14,
  year     = 2007
}

@article{Scott2020,
  author   = {Fred Scott and Jose A. A. Antolinez and Robert McCall and Curt Storlazzi and Ad Reniers and Stuart Pearson},
  doi      = {10.3389/fmars.2020.00361},
  issn     = {2296-7745},
  issue    = {May},
  journal  = {Frontiers in Marine Science},
  keywords = {cluster analysis,coral reefs,data mining,data mining, cluster analysis, K-means, coral reef,k-means,wave runup,xbeach},
  month    = 5,
  pages    = {1--20},
  title    = {Hydro-Morphological Characterization of Coral Reefs for Wave Runup Prediction},
  volume   = 7,
  url      = {https://www.frontiersin.org/article/10.3389/fmars.2020.00361/full},
  year     = 2020
}

@inproceedings{SeanSchumer,
  author    = {Sean Schumer},
  doi       = {10.1109/ICASSP.2011.5946499},
  isbn      = {978-1-4577-0538-0},
  booktitle = {2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  month     = 5,
  pages     = {697--700},
  publisher = {IEEE},
  title     = {Analysis of human footsteps utilizing multi-axial seismic fusion},
  url       = {http://ieeexplore.ieee.org/document/5946499/},
  year      = 2011
}

@article{Sederberg1992,
  abstract = {This paper presents a new algorithm for smoothly blending be- tween two 2-D polygonal shapes. The algorithm is based on a physical model wherein one of the shapes is considered to be con- structed of wire, and a solution is found whereby the first shape can be bent and/or stretched into the second shape with a min- imum amount of work. The resulting solution tends to associate regions on the two shapes which look alike. If the two polY- gons have m and n vertices respectively, the afgorithm is O(mn). The algorithm avoids local shape inversions in whkh intermediate polygons self-intersect, if such a solution exists.},
  author   = {Thomas W. Sederberg and Eugene Greenwood},
  issue    = 2,
  journal  = {ACM Computer Graphics},
  month    = 12,
  title    = {A Physically Based Approach to 2-D Shape Blending},
  volume   = 26,
  url      = {https://www.cs.drexel.edu/~david/Classes/Papers/p25-sederberg.pdf},
  year     = 1992
}

@inproceedings{Sederberg1993,
  abstract  = {This paper presentsan algorithmfor determiningthe paths alongwhich corresponding vertices travel in a 2–D shape blending. Rather than considering the vertex paths explicitly, the algorithmdefines the inter- mediate shapes by interpolating the intrinsic definitions of the initial and final shapes. The algorithm produces shape blends which gener- ally are more satisfactory than those produced using linear or cubic curve paths. Particularly, the algorithm can avoid the shrinkage that normally occurs when rotating rigid bodies are linearly blended, and avoids kinks in the blend when there were none in the key polygons.},
  author    = {Thomas W. Sederberg and Peisheng Gao and Guojin Wang and Hong Mu},
  city      = {New York, NY, USA},
  doi       = {10.1145/166117.166118},
  isbn      = {0897916018},
  booktitle = {Proceedings of the 20th annual conference on Computer graphics and interactive techniques},
  month     = 9,
  pages     = {15--18},
  publisher = {ACM},
  title     = {2-D shape blending},
  url       = {https://dl.acm.org/doi/10.1145/166117.166118},
  year      = 1993
}

@article{Seidel2018,
  abstract = {Ubisoft's game designers successfully used autonomous tools to develop an innovative virtual world. The authors discuss the reflective practices underlying this success and how autonomous tools enable more complex system design.},
  author   = {Stefan Seidel and Nicholas Berente and Beno\^{\i}t Martinez and Aron Lindberg and Kalle Lyytinen and Jeffrey V. Nickerson},
  doi      = {10.1109/MC.2018.3971341},
  issn     = 15580814,
  issue    = 10,
  journal  = {Computer},
  keywords = {AI,Ghost Recon Wildlands,Ubisoft,Winning and Losing in IT,artificial intelligence,autonomous tools,design,design processes,game design,machine learning,procedural generation,reflective practice},
  pages    = {16--23},
  title    = {Autonomous tools in system design: Reflective practice in ubisofts ghost recon wildlands project},
  volume   = 51,
  year     = 2018
}

@article{Seidel2019,
  author  = {Stefan Seidel and Nicholas Berente and John Gibbs and Stefan Seidel and John Gibbs},
  journal = {ICIS Proceedings},
  title   = {Designing with Autonomous Tools: Video Games, Procedural Generation, and Creativity},
  year    = 2019
}

@article{Seidel2020,
  abstract = {Autonomous, intelligent tools are reshaping all sorts of work practices, including innovative design work. These tools generate outcomes with little or no user intervention and produce designs of unprecedented complexity and originality, ushering profound changes to how organizations will design and innovate in future. In this paper, we formulate conceptual foundations to analyze the impact of autonomous design tools on design work. We proceed in two steps. First, we conceptualize autonomous design tools as `rational' agents which will participate in the design process. We show that such agency can be realized through two separate approaches of information processing: symbolic and connectionist. Second, we adopt control theory to unpack the relationships between the autonomous design tools, human actors involved in the design, and the environment in which the tools operate. The proposed conceptual framework lays a foundation for studying the new kind of material agency of autonomous design tools in organizational contexts. We illustrate the analytical value of the proposed framework by drawing on two examples from the development of Ubisoft's Ghost Recon Wildlands video game, which relied on such tools. We conclude this essay by constructing a tentative research agenda for the research into autonomous design tools and design work. Keywords:},
  author   = {Stefan Seidel and Nicholas Berente and Aron Lindberg and Kalle Lyytinen and Beno\^{\i}t Martinez and Jeffrey V. Nickerson},
  issue    = 3,
  journal  = {Journal of Digital Social Research},
  keywords = {artificial intelligence,autonomous design tools,control,design,digital innovation,indiana,innovation,liechtenstein,organizing,university of liechtenstein,university of notre dame,usa,work},
  pages    = {126--157},
  title    = {Artificial Intelligence and Video Game Creation: a Framework for the New Logic of Autonomous Design},
  volume   = 2,
  url      = {https://jdsr.se/ojs/index.php/jdsr/article/download/46/30},
  year     = 2020
}

@article{Sellan2021,
  abstract = {Given a solid 3D shape and a trajectory of it over time, we compute its swept volume - the union of all points contained within the shape at some moment in time. We consider the representation of the input and output as implicit functions, and lift the problem to 4D spacetime, where we show the problem gains a continuous structure which avoids expensive global searches. We exploit this structure via a continuation method which marches and reconstructs the zero level set of the swept volume, using the temporal dimension to avoid erroneous solutions. We show that, compared to other methods, our approach is not restricted to a limited class of shapes or trajectories, is extremely robust, and its asymptotic complexity is an order lower than standards used in the industry, enabling its use in applications such as modeling, constructive solid geometry, and path planning.},
  author   = {Silvia Sell\'{a}n and Noam Aigerman and Alec Jacobson},
  doi      = {10.1145/3450626.3459780},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {continuation algorithm,swept volume},
  title    = {Swept volumes via spacetime numerical continuation},
  volume   = 40,
  url      = {https://www.silviasellan.com/pdf/papers/swept-volumes.pdf},
  year     = 2021
}

@misc{Shaker2016,
  author = {Noor Shaker and Julian Togelius and Mark J Nelson},
  title  = {Computational Synthesis and Creative Systems Procedural Content Generation in Games},
  url    = {http://www.springer.com/series/15219}
}

@inproceedings{Shamos2008,
  abstract  = {We develop optimal algorithms for forming the intersection of geometric objects in the plane and apply them to such diverse problems as linear programming, hidden-line elimination, and wire layout. Given N line segments in the plane, finding all intersecting pairs requires O(N2) time. We give an O(N log N) algorithm to determine whether any two intersect and use it to detect whether two simple plane polygons intersect. We employ an O(N log N) algorithm for finding the common intersection of N half-planes to show that the Simplex method is not optimal. The emphasis throughout is on obtaining upper and lower bounds and relating these results to other problems in computational geometry.},
  author    = {Michael Ian Shamos and Dan Hoey},
  doi       = {10.1109/SFCS.1976.16},
  booktitle = {17th Annual Symposium on Foundations of Computer Science (sfcs 1976)},
  month     = 10,
  pages     = {208--215},
  publisher = {IEEE},
  title     = {Geometric intersection problems},
  url       = {http://ieeexplore.ieee.org/document/4567905/},
  year      = 1976
}

@misc{Shand2017,
  author = {Tom Shand and James T. Carley},
  doi    = {10.13140/RG.2.2.18657.66403},
  issue  = {February},
  title  = {Affordable coastal protection in the Pacific Islands - Desktop Review},
  year   = 2017
}

@article{Shao2012c,
  abstract  = {In this paper, we present an automated video analysis system which addresses segmentation and detection of human actions in an indoor environment, such as a gym. The system aims at segmenting different movements from the input video and recognizing the action types simultaneously. Two action segmentation techniques, namely color intensity based and motion based, are proposed. Both methods can efficiently segment periodic human movements into temporal cycles. We also apply a novel approach for human action recognition by describing human actions using motion and shape features. The descriptor contains both the local shape and its spatial layout information, therefore is more effective for action modeling and is suitable for detecting and recognizing a variety of actions. Experimental results show that the proposed action segmentation and detection algorithms are highly effective. \textcopyright{} 2011 Published by Elsevier B.V. All rights reserved.},
  author    = {Ling Shao and Ling Ji and Yan Liu and Jianguo Zhang},
  doi       = {10.1016/j.patrec.2011.05.015},
  issn      = {01678655},
  issue     = 4,
  journal   = {Pattern Recognition Letters},
  keywords  = {Human action recognition,Human action segmentation,Motion analysis,Motion history image,PCOG},
  month     = 3,
  pages     = {438--445},
  publisher = {North-Holland},
  title     = {Human action segmentation and recognition via motion and shape analysis},
  volume    = 33,
  year      = 2012
}

@article{Sharma2019,
  abstract = {Cellular-automata-based modelling for simulating snow bedforms and snow deposition is introduced in this study. The well-known ReSCAL model, previously used for sand bedforms, is adapted for this purpose by implementing a simple sintering mechanism. The effect of sintering is first explored for solitary barchan dunes of different sizes and flow conditions. Three types of behaviour are observed: small barchans continue their motion without any perceptible difference while large barchans sinter immediately. Barchans of intermediate size split, leaving behind a sintered core and a smaller barchan is formed. It is found that sintering introduces an upper limit to the size of bedforms that can remain mobile. The concept of "maximum streamwise length" (MSL) is introduced and MSL is identified for different wind speeds using the solitary dune scenario. Simulations of the full evolution from an initially flat snow layer to a complex dune field are performed next. It is found that the largest bedforms lie below the MSL threshold. Additionally, it is found that shallow snow layers are most susceptible to mechanical destabilization by the wind.},
  author   = {Varun Sharma and Louise Braud and Michael Lehning},
  doi      = {10.5194/tc-13-3239-2019},
  issn     = 19940424,
  issue    = 12,
  journal  = {Cryosphere},
  pages    = {3239--3260},
  title    = {Understanding snow bedform formation by adding sintering to a cellular automata model},
  volume   = 13,
  url      = {https://tc.copernicus.org/articles/13/3239/2019/tc-13-3239-2019.pdf},
  year     = 2019
}

@article{Sharp2020,
  abstract = {This paper introduces a new approach to computing geodesics on polyhedral surfaces - -the basic idea is to iteratively perform edge flips, in the same spirit as the classic Delaunay flip algorithm. This process also produces a triangulation conforming to the output geodesics, which is immediately useful for tasks in geometry processing and numerical simulation. More precisely, our FlipOut algorithm transforms a given sequence of edges into a locally shortest geodesic while avoiding self-crossings (formally: it finds a geodesic in the same isotopy class). The algorithm is guaranteed to terminate in a finite number of operations; practical runtimes are on the order of a few milliseconds, even for meshes with millions of triangles. The same approach is easily applied to curves beyond simple paths, including closed loops, curve networks, and multiply-covered curves. We explore how the method facilitates tasks such as straightening cuts and segmentation boundaries, computing geodesic B\'{e}zier curves, extending the notion of constrained Delaunay triangulations (CDT) to curved surfaces, and providing accurate boundary conditions for partial differential equations (PDEs). Evaluation on challenging datasets such as Thingi10k indicates that the method is both robust and efficient, even for low-quality triangulations.},
  author   = {Nicholas Sharp and Keenan Crane},
  doi      = {10.1145/3414685.3417839},
  issn     = 15577368,
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {edge flip,geodesic,triangulation},
  title    = {You can find geodesic paths in triangle meshes by just flipping edges},
  volume   = 39,
  url      = {https://www.cs.cmu.edu/~kmcrane/Projects/FlipOut/FlipOut.pdf},
  year     = 2020
}

@article{Shaw2018,
  abstract = {Island formation and distributary channel branching are important processes in prograding river deltas. We develop and test a new theory predicting the distance to islands and channel bifurcations based on fluid mass conservation and radially symmetric transport conditions. We analyze channelization and island formation using nine new and five existing delta experiments as well as four field deltas. The new experiments were designed to produce islands from initial deposition of a mouth bar. Before island formation, each bar evolved into a radially symmetric deposit with unchannelized flow over its top previously described as a topographic flow expansion. This morphology was stable to topographic perturbations, and its distal limit prograded basinward while maintaining a characteristic flow depth. Island formation and channel branching occurred on top of this deposit. We hypothesize that this distance (\ensuremath{\Psi}) is set by the location where boundary shear stress applied by expanding, radially averaged flow falls below the threshold of sediment motion. The model predicts that the distance to the first island scales with water discharge, scales inversely with flow depth, and scales with the inverse square root of median grain diameter. From experiment to field scales, distances to island locations are predicted within a factor of two.},
  author   = {John B. Shaw and Kimberly Miller and Brandon McElroy},
  doi      = {10.1002/2017JF004464},
  issn     = 21699011,
  issue    = 2,
  journal  = {Journal of Geophysical Research: Earth Surface},
  keywords = {coast,delta,flow expansion,island,jet,mouth bar},
  pages    = {363--383},
  title    = {Island Formation Resulting From Radially Symmetric Flow Expansion},
  volume   = 123,
  year     = 2018
}

@inproceedings{Shen2008,
  abstract  = {This paper describes the Medical Visualizer, a real-time visualization system for analyzing medical volumetric data in various virtual environments, such as autostereoscopic displays, dual-projector screens and immersive environments such as the CAVE. Direct volume rendering is used for visualizing the details of medical volumetric data sets without intermediate geometric representations. By interactively manipulating the color and transparency functions through the friendly user interface, radiologists can either inspect the data set as a whole or focus on a specific region. In our system, 3D texture hardware is employed to accelerate the rendering process. The system is designed to be platform independent, as all virtual reality functions are separated from kernel functions. Due to its modular design, our system can be easily extended to other virtual environments, and new functions can be incorporated rapidly. \textcopyright{} 2008 IEEE.},
  author    = {Rui Shen and Pierre Boulanger and Michelle Noga},
  doi       = {10.1109/MediVis.2008.10},
  isbn      = 9780769532844,
  booktitle = {Proceedings - 5th International Conference BioMedical Visualization, Information Visualization in Medical and Biomedical Informatics, MediVis 2008},
  pages     = {63--70},
  title     = {Med vis: A real-time immersive visualization environment for the exploration of medical volumetric data},
  year      = 2008
}

@article{Shen2019,
  abstract = {Tutte embedding is one of the most common building blocks in geometry processing algorithms due to its simplicity and provable guarantees. Although provably correct in infinite precision arithmetic, it fails in challenging cases when implemented using floating point arithmetic, largely due to the induced exponential area changes. We propose Progressive Embedding, with similar theoretical guarantees to Tutte embedding, but more resilient to the rounding error of floating point arithmetic. Inspired by progressive meshes, we collapse edges on an invalid embedding to a valid, simplified mesh, then insert points back while maintaining validity. We demonstrate the robustness of our method by computing embeddings for a large collection of disk topology meshes. By combining our robust embedding with a variant of the matchmaker algorithm, we propose a general algorithm for the problem of mapping multiply connected domains with arbitrary hard constraints to the plane, with applications in texture mapping and remeshing.},
  author   = {Hanxiao Shen and Zhongshi Jiang and Denis Zorin and Daniele Panozzo},
  doi      = {10.1145/3306346.3323012},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  title    = {Progressive embedding},
  volume   = 38,
  url      = {https://cims.nyu.edu/gcl/papers/2019-Progressive.pdf},
  year     = 2019
}

@inproceedings{Shi2005,
  abstract  = {In this paper, a general blind image steganalysis system is proposed, in which the statistical moments of characteristic functions of the prediction-error image, the test image, and their wavelet subbands are selected as features. Artificial neural network is utilized as the classifier. The performance of the proposed steganalysis system is significantly superior to the prior arts. \textcopyright{} 2005 IEEE.},
  author    = {Yun Q. Shi and Guorong Xuan and Dekun Zou and Jianjiong Gao and Chengyun Yang and Zhenping Zhang and Peiqi Chai and Wen Chen and Chunhua Chen},
  doi       = {10.1109/ICME.2005.1521412},
  isbn      = {0780393325},
  booktitle = {IEEE International Conference on Multimedia and Expo, ICME 2005},
  pages     = {269--272},
  title     = {Image steganalysis based on moments of characteristic functions using wavelet decomposition, prediction-error image, and neural network},
  volume    = 2005,
  year      = 2005
}

@article{Shields1936,
  author  = {A. Shields},
  journal = {Mitteilungen der Preu\ss{}ischen Versuchsanstalt f\"{u}r Wasserbau},
  title   = {Anwendung der Aehnlichkeitsmechanik und der Turbulenzforschung auf die Geschiebebewegung},
  year    = 1936
}

@article{Shifley2017,
  abstract  = {Context: Quantitative models of forest dynamics have followed a progression toward methods with increased detail, complexity, and spatial extent. Objectives: We highlight milestones in the development of forest dynamics models and identify future research and application opportunities. Methods: We reviewed milestones in the evolution of forest dynamics models from the 1930s to the present with emphasis on forest growth and yield models and forest landscape models We combined past trends with emerging issues to identify future needs. Results: Historically, capacity to model forest dynamics at tree, stand, and landscape scales was constrained by available data for model calibration and validation; computing capacity; model applicability to real-world problems; and ability to integrate biological, social, and economic drivers of change. As computing and data resources improved, a new class of spatially explicit forest landscape models emerged. Conclusions: We are at a point of great opportunity in development and application of forest dynamics models. Past limitations in computing capacity and in data suitable for model calibration or evaluation are becoming less restrictive. Forest landscape models, in particular, are ready to transition to a central role supporting forest management, planning, and policy decisions. Recommendations: Transitioning forest landscape models to a central role in applied decision making will require greater attention to evaluating performance; building application support staffs; expanding the included drivers of change, and incorporating metrics for social and economic inputs and outputs.},
  author    = {Stephen R. Shifley and Hong S. He and Heike Lischke and Wen J. Wang and Wenchi Jin and Eric J. Gustafson and Jonathan R. Thompson and Frank R. Thompson and William D. Dijak and Jian Yang},
  doi       = {10.1007/s10980-017-0540-9},
  issn      = 15729761,
  issue     = 7,
  journal   = {Landscape Ecology},
  keywords  = {Ecosystem services,Forest Vegetation Simulator,Gap model,Individual-tree model,LANDIS,Model validation,Process model,TreeMig},
  pages     = {1307--1325},
  publisher = {Springer Netherlands},
  title     = {The past and future of modeling forest dynamics: from growth and yield curves to forest landscape models},
  volume    = 32,
  year      = 2017
}

@article{Shneiderman1997,
  abstract = {Direct manipulation user interfaces have proven their worth over two decades, but they are still in their youth. Dramatic opportunities exist to develop direct manipulation programming to create end-user programming tools, dynamic queries to perform information search in large databases, and information visualization to support network database browsing. Direct manipulation depends on visual representation of the objects and actions of interest, physical actions or pointing instead of complex syntax, and rapid incremental reversible operations whose effect on the object of interest is immediately visible. This strategy can lead to user interfaces that are comprehensible, predictable and controllable. Direct manipulation interfaces are seen as more likely candidates to influence advanced user interfaces than adaptive, autonomous, intelligent agents. User control and responsibility are highly desirable.},
  author   = {Ben Shneiderman},
  doi      = {10.1145/238218.238281},
  journal  = {International Conference on Intelligent User Interfaces, Proceedings IUI},
  pages    = {33--39},
  title    = {Direct manipulation for comprehensible, predictable and controllable user interfaces},
  year     = 1997
}

@article{Short2007,
  abstract = {Seagrasses, marine flowering plants, are widely distributed along temperate and tropical coastlines of the world. Seagrasses have key ecological roles in coastal ecosystems and can form extensive meadows supporting high biodiversity. The global species diversity of seagrasses is low (< 60 species), but species can have ranges that extend for thousands of kilometers of coastline. Seagrass bioregions are defined here, based on species assemblages, species distributional ranges, and tropical and temperate influences. Six global bioregions are presented: four temperate and two tropical. The temperate bioregions include the Temperate North Atlantic, the Temperate North Pacific, the Mediterranean, and the Temperate Southern Oceans. The Temperate North Atlantic has low seagrass diversity, the major species being Zostera marina, typically occurring in estuaries and lagoons. The Temperate North Pacific has high seagrass diversity with Zostera spp. in estuaries and lagoons as well as Phyllospadix spp. in the surf zone. The Mediterranean region has clear water with vast meadows of moderate diversity of both temperate and tropical seagrasses, dominated by deep-growing Posidonia oceanica. The Temperate Southern Oceans bioregion includes the temperate southern coastlines of Australia, Africa and South America. Extensive meadows of low-to-high diversity temperate seagrasses are found in this bioregion, dominated by various species of Posidonia and Zostera. The tropical bioregions are the Tropical Atlantic and the Tropical Indo-Pacific, both supporting mega-herbivore grazers, including sea turtles and sirenia. The Tropical Atlantic bioregion has clear water with a high diversity of seagrasses on reefs and shallow banks, dominated by Thalassia testudinum. The vast Tropical Indo-Pacific has the highest seagrass diversity in the world, with as many as 14 species growing together on reef flats although seagrasses also occur in very deep waters. The global distribution of seagrass genera is remarkably consistent north and south of the equator; the northern and southern hemispheres share ten seagrass genera and only have one unique genus each. Some genera are much more speciose than others, with the genus Halophila having the most seagrass species. There are roughly the same number of temperate and tropical seagrass genera as well as species. The most widely distributed seagrass is Ruppia maritima, which occurs in tropical and temperate zones in a wide variety of habitats. Seagrass bioregions at the scale of ocean basins are identified based on species distributions which are supported by genetic patterns of diversity. Seagrass bioregions provide a useful framework for interpreting ecological, physiological and genetic results collected in specific locations or from particular species. \textcopyright{} 2007 Elsevier B.V. All rights reserved.},
  author   = {F. Short and T. Carruthers and W. Dennison and M. Waycott},
  doi      = {10.1016/j.jembe.2007.06.012},
  issn     = {00220981},
  issue    = {1-2},
  journal  = {Journal of Experimental Marine Biology and Ecology},
  keywords = {Bioregional models,Diversity,Global distribution,Seagrass,Species,Temperate,Tropical},
  pages    = {3--20},
  title    = {Global seagrass distribution and diversity: A bioregional model},
  volume   = 350,
  year     = 2007
}

@misc{Short2017,
  author = {Tania Short and Tarn Adams},
  title  = {Procedural Generation in Game Design - Google Livres},
  url    = {https://books.google.fr/books?hl=fr\&lr=\&id=Rj4PEAAAQBAJ\&oi=fnd\&pg=PP1\&dq=procedural+generation\&ots=HDpV2D6fYE\&sig=00uNJnqhoid3QRa0z1fznNW-1ao\&redir\_esc=y\#v=onepage\&q=procedural generation\&f=false},
  year   = 2017
}

@article{Sims1994,
  abstract = {This article describes a system for the evolution and coevolution of virtual creatures that compete in physically simulated three-dimensional worlds. Pairs of individuals enter one-on-one contests in which they contend to gain control of a common resource. The winners receive higher relative fitness scores allowing them to survive and reproduce. Realistic dynamics simulation including gravity, collisions, and friction, restricts the actions to physically plausible behaviors.The morphology of these creatures and the neural systems for controlling their muscle forces are both genetically determined, and the morphology and behavior can adapt to each other as they evolve simultaneously. The genotypes are structured as directed graphs of nodes and connections, and they can efficiently but flexibly describe instructions for the development of creatures' bodies and control systems with repeating or recursive components. When simulated evolutions are performed with populations of competing creatures, interesting and diverse strategies and counterstrategies emerge.},
  author   = {Karl Sims},
  doi      = {10.1162/artl.1994.1.4.353},
  issn     = {1064-5462},
  issue    = 4,
  journal  = {Artificial Life},
  pages    = {353--372},
  title    = {Evolving 3D Morphology and Behavior by Competition},
  volume   = 1,
  url      = {https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=625cf770e697cc01b9201fd3b67456ac56a7a27b},
  year     = 1994
}

@article{Sims1994a,
  abstract = {This paper describes a novel system for creating virtual creatures that move and behave in simulated three-dimensional physical worlds. The morphologies of creatures and the neural systems for controlling their muscle forces are both generated automatically using genetic algorithms. Different fitness evaluation functions are used to direct simulated evolutions towards specific behaviors such as swimming, walking, jumping, and following. A genetic language is presented that uses nodes and connections as its primitive elements to represent directed graphs, which are used to describe both the morphology and the neural circuitry of these creatures. This genetic language defines a hyperspace containing an indefinite number of possible creatures with behaviors, and when it is searched using optimization techniques, a variety of successful and interesting locomotion strategies emerge, some of which would be difficult to invent or build by design.},
  author   = {Karl Sims},
  doi      = {10.1145/192161.192167},
  isbn     = {0897916670},
  journal  = {Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1994},
  pages    = {15--22},
  title    = {Evolving virtual creatures},
  url      = {https://dl.acm.org/doi/pdf/10.1145/192161.192167},
  year     = 1994
}

@unpublished{Singh2018,
  author = {Jasmeet Singh and Dave Pagurek},
  pages  = {1--7},
  title  = {Automatic Secondary Motion with Dynamic Kelvinlets},
  volume = {c},
  year   = 2018
}

@article{Skorkovska2015,
  abstract = {Although hydraulic erosion modeling on a GIS terrain models has been addressed by a body of previous work, it still remains an open problem. In GIS, raster representation and triangular irregular networks (TIN) are the most commonly used surface models, because they are simple and offer implicit topological information. However, these data structures do not allow the simulation of erosion on concave terrain features, such as caves or overhangs. Other methods, more commonly used in the computational fluid dynamics, use volumetric data representation. They are able to model the 3D features, but they usually have high memory requirements and are computationally demanding. We propose a novel solution to the hydraulic erosion modeling problem that uses a triangular mesh data structure. Our framework allows for adaptive changes of the mesh resolution according to the local complexity of the terrain, which leads to lower memory requirements when compared to the volumetric approaches. Our data structure also supports the visualization of the concave 3D features, allowing the simulation and visualization of erosion on terrain elements such as tunnels or caves.},
  author   = {V\v{e}ra Skorkovsk\'{a} and Ivana Kolingerov\'{a} and Bedrich Benes},
  doi      = {10.1007/978-3-319-18407-4\_20},
  isbn     = 9783319184067,
  issn     = 18632351,
  journal  = {Lecture Notes in Geoinformation and Cartography},
  keywords = {Erosion,Hydraulic erosion,Smoothed particle hydrodynamics,Terrain modeling,Triangular mesh},
  pages    = {237--247},
  title    = {Hydraulic erosion modeling on a triangular mesh},
  volume   = 211,
  year     = 2015
}

@article{Sloot2014,
  abstract  = {Instrumented treadmills are increasingly used in gait research, although the imposed walking speed is suggested to affect gait performance. A feedback-controlled treadmill that allows subjects to walk at their preferred speed, i.e. functioning in a self-paced (SP) mode, might be an attractive alternative, but could disturb gait through accelerations of the belt. We compared SP with fixed speed (FS) treadmill walking, and also considered various feedback modes. Nineteen healthy subjects walked on a dual-belt instrumented treadmill. Spatio-temporal, kinematic and kinetic gait parameters were derived from both the average stride patterns and stride-to-stride variability. For 15 out of 70 parameters significant differences were found between SP and FS. These differences were smaller than 1. cm, 1\textdegree{}, 0.2. N. m and 0.2. W/kg for respectively stride length and width, joint kinematics, moments and powers. Since this is well within the normal stride variability, these differences were not considered to be clinically relevant, indicating that SP walking is not notably affected by belt accelerations. The long-term components of walking speed variability increased during SP walking (43\%, p< 0.01), suggesting that SP allows for more natural stride variability. Differences between SP feedback modes were predominantly found in the timescales of walking speed variability, while the gait pattern was similar between modes. Overall, the lack of clinically significant differences in gait pattern suggests that SP walking is a suitable alternative to fixed speed treadmill walking in gait analysis. \textcopyright{} 2013 Elsevier B.V.},
  author    = {L. H. Sloot and M. M. van der Krogt and J. Harlaar},
  doi       = {10.1016/j.gaitpost.2013.08.022},
  issn      = {09666362},
  issue     = 1,
  journal   = {Gait and Posture},
  keywords  = {Biomechanics,Feedback-controlled treadmill,Fixed speed,Self-paced walking},
  month     = 1,
  pages     = {478--484},
  pmid      = 24055003,
  publisher = {Elsevier},
  title     = {Self-paced versus fixed speed treadmill walking},
  volume    = 39,
  year      = 2014
}

@article{Smelik2009,
  abstract = {Procedural methods are a promising but underused alternative to manual content creation. Commonly heard drawbacks are the randomness of and the lack of control over the output and the absence of integrated solutions, although more recent publications increasingly address these issues. This paper surveys procedural methods applied to terrain modelling, evaluating realism of their output, performance and control users can exert over the procedure},
  author   = {Ruben M. Smelik and Klaas Jan De Kraker and Saskia A Groenewegen and Tim Tutenel and Rafael Bidarra},
  journal  = {Proceedings of the CASA workshop on 3D advanced media in gaming and simulation (3AMIGAS)},
  title    = {A survey of procedural methods for terrain modelling},
  year     = 2009
}

@article{Smelik2010b,
  abstract = {Because of the increasing detail and size of virtual worlds, designers are more and more urged to consider employing procedural methods to alleviate part of their modeling work. However, such methods are often unintuitive to use, difficult to integrate, and provide little user control, making their application far from straightforward. In our declarative modeling approach, designers are provided with a more productive and simplified virtual world modeling workow that matches better with their iterative way of working. Using interactive procedural sketching, they can quickly layout a virtual world, while having proper user control at the level of large terrain features. However, in practice, designers require a finer level of control. Integrating procedural techniques with manual editing in an iterative modeling workow is an important topic that has remained relatively unaddressed until now. This paper identifies challenges of this integration and discusses approaches to combine these methods in such a way that designers can freely mix them, while the virtual world model is kept consistent during all modifications. We conclude that overcoming the challenges mentioned, for example in a declarative modeling context, is instrumental to achieve the much desired adoption of procedural modeling in mainstream virtual world modeling. Copyright 2010 ACM.},
  author   = {Ruben M. Smelik and Tim Tutenel and Klaas Jan De Kraker and Rafael Bidarra},
  doi      = {10.1145/1814256.1814258},
  isbn     = 9781450300230,
  journal  = {Workshop on Procedural Content Generation in Games, PC Games 2010, Co-located with the 5th International Conference on the Foundations of Digital Games},
  keywords = {Declarative modeling,Manual modelling,Procedural methods,Virtual worlds},
  title    = {Integrating procedural generation and manual editing of virtual worlds},
  url      = {https://d1wqtxts1xzle7.cloudfront.net/36779011/FDGWorkshopPaper\_final\_rc1-with-cover-page-v2.pdf?Expires=1642695458\&Signature=LvUwj6x8fYomPWljJ9TjFWohVXPTtSTw3PlARTq1uwqGdQu3ilMDZYngI-qAvc5492XGjWe0FpAyVZWKV0HRi0hHIkZ5IX8~adYOE0R2RwVEMR8q5NW~xXg6knDS5BQwt},
  year     = 2010
}

@article{Smelik2014,
  abstract = {Procedural modelling deals with (semi-)automatic content generation by means of a program or procedure. Among other advantages, its data compression and the potential to generate a large variety of detailed content with reduced human intervention, have made procedural modelling attractive for creating virtual environments increasingly used in movies, games and simulations. We survey procedural methods that are useful to generate features of virtual worlds, including terrains, vegetation, rivers, roads, buildings and entire cities. In this survey, we focus particularly on the degree of intuitive control and of interactivity offered by each procedural method, because these properties are instrumental for their typical users: designers and artists. We identify the most promising research results that have been recently achieved, but we also realize that there is far from widespread acceptance of procedural methods among non-technical, creative professionals. We conclude by discussing some of the most important challenges of procedural modelling. Procedural modeling deals with (semi-)automatic content generation by means of a procedure. This article surveys procedural methods that generate features of virtual worlds, including terrain, vegetation and cities. Promising results are identified, and the most salient challenges are discussed. A special focus is put on their degree of control and interactivity, essential for a more widespread use by creative professionals.},
  author   = {Ruben M. Smelik and Tim Tutenel and Rafael Bidarra and Bedrich Benes},
  doi      = {10.1111/cgf.12276},
  issn     = 14678659,
  issue    = 6,
  journal  = {Computer Graphics Forum},
  keywords = {procedural content generation,procedural modeling methods,virtual worlds},
  pages    = {31--50},
  title    = {A survey on procedural modelling for virtual worlds},
  volume   = 33,
  year     = 2014
}

@article{Smith1997,
  abstract = {A digital bathymetric map of the oceans with a horizontal resolution of 1 to 12 kilometers was derived by combining available depth soundings with high-resolution marine gravity information from the Geosat and ERS-1 spacecraft. Previous global bathymetric maps lacked features such as the 1600-kilometer-long Foundation Seamounts chain in the South Pacific. This map shows relations among the distributions of depth, sea floor area, and sea floor age that do not fit the predictions of deterministic models of subsidence due to lithosphere cooling but may be explained by a stochastic model in which randomly distributed reheating events warm the lithosphere and raise the ocean floor.},
  author   = {Walter H.F. Smith and David T. Sandwell},
  doi      = {10.1126/science.277.5334.1956},
  issn     = {00368075},
  issue    = 5334,
  journal  = {Science},
  pages    = {1956--1962},
  title    = {Global sea floor topography from satellite altimetry and ship depth soundings},
  volume   = 277,
  year     = 1997
}

@article{Smith2009,
  abstract = {We present a rhythm-based method for the automatic generation of levels for 2D platformers, where the rhythm is that which the player feels with his hands while playing. Levels are created using a grammar-based method: first generating rhythms, then generating geometry based on those rhythms. Generation is constrained by a set of style parameters tweakable by a human designer. The approach also minimizes the amount of content that must be manually authored, instead relying on geometry components that are included in the level designer's tileset and a set of jump types. Our results show that this method produces an impressive variety of levels, all of which are fully playable. Copyright 2009 ACM.},
  author   = {Gillian Smith and Mike Treanor and Jim Whitehead and Michael Mateas},
  doi      = {10.1145/1536513.1536548},
  isbn     = 9781605584379,
  journal  = {FDG 2009 - 4th International Conference on the Foundations of Digital Games, Proceedings},
  keywords = {2D platformers,Games,Levels,Procedural generation},
  pages    = {175--182},
  title    = {Rhythm-based level generation for 2D platformers},
  year     = 2009
}

@article{Smith2010,
  abstract = {Tanagra is a prototype mixed-initiative design tool for 2D plat-former level design, in which a human and computer can work together to produce a level. The human designer can place constraints on a continuously running level generator, in the form of exact geometry placement and manipulation of the level's pacing. The computer then flls in the rest of the level with geometry that guarantees playability, or informs the designer that there is no level that meets their requirements. This paper presents the design of Tanagra, a discussion of the editing operations it provides to the designer, and an evaluation of the expressivity of its generator. \textcopyright{} 2010 ACM.},
  author   = {Gillian Smith and Jim Whitehead and Michael Mateas},
  doi      = {10.1145/1822348.1822376},
  isbn     = 9781605589374,
  journal  = {FDG 2010 - Proceedings of the 5th International Conference on the Foundations of Digital Games},
  keywords = {AI-assisted design,Games,Level design,Procedural content generation},
  pages    = {209--216},
  title    = {Tanagra: A mixed-initiative level design tool},
  url      = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.190.1116\&rep=rep1\&type=pdf},
  year     = 2010
}

@article{Smith2018,
  abstract = {We consider the problem of scaling deep generative shape models to high-resolution. Drawing motivation from the canonical view representation of objects, we introduce a novel method for the fast up-sampling of 3D objects in voxel space through networks that perform super-resolution on the six orthographic depth projections. This allows us to generate high-resolution objects with more efficient scaling than methods which work directly in 3D. We decompose the problem of 2D depth super-resolution into silhouette and depth prediction to capture both structure and fine detail. This allows our method to generate sharp edges more easily than an individual network. We evaluate our work on multiple experiments concerning high-resolution 3D objects, and show our system is capable of accurately predicting novel objects at resolutions as large as 512\texttimes{}512\texttimes{}512 - the highest resolution reported for this task. We achieve state-of-the-art performance on 3D object reconstruction from RGB images on the ShapeNet dataset, and further demonstrate the first effective 3D super-resolution method.},
  author   = {Edward Smith and Scott Fujimoto and David Meger},
  issn     = 10495258,
  issue    = {Nips},
  journal  = {Advances in Neural Information Processing Systems},
  pages    = {6478--6488},
  title    = {Multi-view silhouette and depth decomposition for high resolution 3D object representation},
  volume   = {2018-Decem},
  year     = 2018
}

@article{Snodgrass2014,
  abstract = {In this paper we describe a hierarchical method for procedurally generating maps using Markov chains. Our method takes as input a collection of human-authored two-dimensional maps, and splits them into high-level tiles which capture large structures. Markov chains are then learned from those maps to capture the structure of both the high-level tiles, as well as the low-level tiles. Then, the learned Markov chains are used to generate new maps by first generating the high-level structure of the map using high-level tiles, and then generating the low-level layout of the map. We validate our approach using the game Super Mario Bros., by evaluating the quality of maps produced using different configurations for training and generation.},
  author   = {Sam Snodgrass and Santiago Onta\~{n}\'{o}n},
  isbn     = 9781577356813,
  issue    = {Aiide},
  journal  = {Proceedings of the 10th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, AIIDE 2014},
  pages    = {59--65},
  title    = {A hierarchical approach to generating maps using Markov chains},
  year     = 2014
}

@article{Snodgrass2016,
  abstract = {Statistical models, such as Markov chains, have recently started to be studied for the purpose of Procedural Content Generation (PCG). A major problem with this approach is controlling the sampling process in order to obtain output satisfying some desired constraints. In this paper we present three approaches to constraining the content generated using multi-dimensional Markov chains: (1) a generate and test approach that simply resamples the content until the desired constraints are satisfied, (2) an approach that finds and resamples parts of the generated content that violate the constraints, and (3) an incremental method that checks for constraint violations during sampling. We test our approaches by generating maps for two classic video games, Super Mario Bros. and Kid Icarus.},
  author   = {Sam Snodgrass and Santiago Onta\~{n}\'{o}n},
  issn     = 10450823,
  issue    = {MdMC},
  journal  = {IJCAI International Joint Conference on Artificial Intelligence},
  pages    = {780--786},
  title    = {Controllable procedural content generation via constrained multi-dimensional markov chain sampling},
  volume   = {2016-Janua},
  url      = {https://www.ijcai.org/Proceedings/16/Papers/116.pdf},
  year     = 2016
}

@article{Solomon2014,
  abstract = {We present a generalization of the bilateral filter that can be applied to feature-preserving smoothing of signals on images, meshes, and other domains within a single unified framework. Our discretization is competitive with state-of-the-art smoothing techniques in terms of both accuracy and speed, is easy to implement, and has parameters that are straightforward to understand. Unlike previous bilateral filters developed for meshes and other irregular domains, our construction reduces exactly to the image bilateral on rectangular domains and comes with a rigorous foundation in both the smooth and discrete settings. These guarantees allow us to construct unconditionally convergent mean-shift schemes that handle a variety of extremely noisy signals. We also apply our framework to geometric edge-preserving effects like feature enhancement and show how it is related to local histogram techniques.},
  author   = {Justin Solomon and Keenan Crane and Adrian Butscher and Chris Wojtan},
  doi      = {https://doi.org/10.48550/arXiv.1405.4734},
  pages    = {1--11},
  title    = {A General Framework for Bilateral and Mean Shift Filtering},
  url      = {http://arxiv.org/abs/1405.4734},
  year     = 2014
}

@article{Solow1956,
  author   = {R. M. Solow},
  issue    = 70,
  journal  = {The quarterly journal of economics},
  keywords = {asymptotic analysis,conservation biology,population dynamics,size-structured continuous model},
  pages    = {65--94},
  title    = {Growth model},
  volume   = 18,
  year     = 1956
}

@article{Song2008,
  abstract = {The goal of this study was to compare treadmill walking with overground walking in healthy subjects with no known gait disorders. Nineteen subjects were tested, where each subject walked on a split-belt instrumented treadmill as well as over a smooth, flat surface. Comparisons between walking conditions were made for temporal gait parameters such as step length and cadence, leg kinematics, joint moments and powers, and muscle activity. Overall, very few differences were found in temporal gait parameters or leg kinematics between treadmill and overground walking. Conversely, sagittal plane joint moments were found to be quite different, where during treadmill walking trials, subjects demonstrated less dorsiflexor moments, less knee extensor moments, and greater hip extensor moments. Joint powers in the sagittal plane were found to be similar at the ankle but quite different at the knee and hip joints. Differences in muscle activity were observed between the two walking modalities, particularly in the tibialis anterior throughout stance, and in the hamstrings, vastus medialis and adductor longus during swing. While differences were observed in muscle activation patterns, joint moments and joint powers between the two walking modalities, the overall patterns in these behaviors were quite similar. From a therapeutic perspective, this suggests that training individuals with neurological injuries on a treadmill appears to be justified. Copyright \textcopyright{} 2008 the American Physiological Society.},
  author   = {Joo Lee Song and Joseph Hidler},
  doi      = {10.1152/japplphysiol.01380.2006},
  issn     = 87507587,
  issue    = 3,
  journal  = {Journal of Applied Physiology},
  keywords = {Electromyogram,Gait,Motion analysis},
  month    = 3,
  pages    = {747--755},
  pmid     = 18048582,
  title    = {Biomechanics of overground vs. treadmill walking in healthy individuals},
  volume   = 104,
  year     = 2008
}

@article{Sorgente2023,
  abstract = {We analyze the joint efforts made by the geometry processing and the numerical analysis communities in the last decades to define and measure the concept of ``mesh quality''. Researchers have been striving to determine how, and how much, the accuracy of a numerical simulation or a scientific computation (e.g., rendering, printing, modeling operations) depends on the particular mesh adopted to model the problem, and which geometrical features of the mesh most influence the result. The goal was to produce a mesh with good geometrical properties and the lowest possible number of elements, able to produce results in a target range of accuracy. We overview the most common quality indicators, measures, or metrics that are currently used to evaluate the goodness of a discretization and drive mesh generation or mesh coarsening/refinement processes. We analyze a number of local and global indicators, defined over two- and three-dimensional meshes with any type of elements, distinguishing between simplicial, quadrangular/hexahedral, and generic polytopal elements. We also discuss mesh optimization algorithms based on the above indicators and report common libraries for mesh analysis and quality-driven mesh optimization.},
  author   = {T. Sorgente and S. Biasotti and G. Manzini and M. Spagnuolo},
  doi      = {10.1111/cgf.14779},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,Numerical analysis,\textbullet{} Computing methodologies \rightarrow{} Modeling and simulatio,\textbullet{} Mathematics of computing \rightarrow{} Mesh generation},
  pages    = {461--483},
  title    = {A Survey of Indicators for Mesh Quality Assessment},
  volume   = 42,
  year     = 2023
}

@article{Sorkine2007,
  author  = {Olga Sorkine and Marc Alexa},
  journal = {Symposium on Geometry processing},
  title   = {As-Rigid-As-Possible Surface Modeling},
  url     = {https://diglib.eg.org/bitstream/handle/10.2312/SGP.SGP07.109-116/109-116.pdf?sequence=1\&isAllowed=n},
  year    = 2007
}

@article{Sous2017,
  author  = {Damien Sous and Cristele Chevalier and Jean-Luc Devenon and Jean Blanchot and Marc Pagano},
  doi     = {10.1016/j.ecss.2017.07.015},
  issn    = {02727714},
  journal = {Estuarine, Coastal and Shelf Science},
  month   = 9,
  pages   = {315--330},
  title   = {Circulation patterns in a channel reef-lagoon system, Ouano lagoon, New Caledonia},
  volume  = 196,
  url     = {https://linkinghub.elsevier.com/retrieve/pii/S0272771416304474},
  year    = 2017
}

@article{Sous2019,
  author  = {Damien Sous and Marion Tissier and Vincent Rey and Julien Touboul and Fr\'{e}d\'{e}ric Bouchette and Jean-Luc Devenon and Cristele Chevalier and Jer\^{o}me Aucan},
  doi     = {10.1016/j.csr.2019.07.010},
  issn    = {02784343},
  journal = {Continental Shelf Research},
  month   = 8,
  pages   = {66--80},
  title   = {Wave transformation over a barrier reef},
  volume  = 184,
  url     = {https://linkinghub.elsevier.com/retrieve/pii/S0278434318304904},
  year    = 2019
}

@article{Sous2020,
  abstract = {The topographical complexity of coral reefs is of primary importance for a number of hydrodynamical and ecological processes. The present study is based on a series of high-resolution seabottom elevation measurements along the Maupiti Barrier Reef, French Polynesia. Several statistical metrics and spectral analysis are used to characterize the spatial evolution of the coral geometrical structure from the reef crest to the backreef. A consistent fractal-like power law exists in the spectral density of bottom elevation for length scales between 0.1 and 7 m, while at larger scale, the reef structure shows a different pattern. Such a fine characterization of the reef geometrical structure provides key elements to reconstruct the reef history, to improve the representation of reef roughness in hydrodynamical models and to monitor the evolution of coral reef systems in the context of global change. \textcopyright{} 2020 John Wiley \& Sons, Ltd.},
  author   = {Damien Sous and Fr\'{e}d\'{e}ric Bouchette and Erik Doerflinger and Samuel Meul\'{e} and Raphael Certain and Gwladys Toulemonde and Benjamin Dubarbier and Bernard Salvat},
  doi      = {10.1002/esp.4950},
  issn     = 10969837,
  issue    = 12,
  journal  = {Earth Surface Processes and Landforms},
  keywords = {coral reef,fractal law,high-resolution bathymetry,roughness,volcanic island},
  pages    = {3042--3054},
  title    = {On the small-scale fractal geometrical structure of a living coral reef barrier},
  volume   = 45,
  year     = 2020
}

@article{Spalding2007,
  abstract = {The conservation and sustainable use of marine resources is a highlighted goal on a growing number of national and international policy agendas. Unfortunately, efforts to assess progress, as well as to strategically plan and prioritize new marine conservation measures, have been hampered by the lack of a detailed, comprehensive biogeographic system to classify the oceans. Here we report on a new global system for coastal and shelf areas: the Marine Ecoregions of the World, or MEOW, a nested system of 12 realms, 62 provinces, and 232 ecoregions. This system provides considerably better spatial resolution than earlier global systems, yet it preserves many common elements and can be cross-referenced to many regional biogeographic classifications. The designation of terrestrial ecoregions has revolutionized priority setting and planning for terrestrial conservation; we anticipate similar benefits from the use of a coherent and credible marine system. \textcopyright{} 2007 American Institute of Biological Sciences.},
  author   = {Mark D. Spalding and Helen E. Fox and Gerald R. Allen and Nick Davidson and Zach A. Ferda\~{n}a and Max Finlayson and Benjamin S. Halpern and Miguel A. Jorge and Al Lombana and Sara A. Lourie and Kirsten D. Martin and Edmund McManus and Jennifer Molnar and Cheri A. Recchia and James Robertson},
  doi      = {10.1641/B570707},
  issn     = {00063568},
  issue    = 7,
  journal  = {BioScience},
  keywords = {Ecoregions,Mapping,Marine biogeography,Marine protected areas,Representative conservation},
  pages    = {573--583},
  title    = {Marine ecoregions of the world: A bioregionalization of coastal and shelf areas},
  volume   = 57,
  year     = 2007
}

@article{Spencer2004,
  abstract = {Summary: SelSim is a program for Monte Carlo simulation of DNA polymorphism data for a recombining region within which a single bi-allelic site has experienced natural selection. SelSim allows simulation from either a fully stochastic model of, or deterministic approximations to, natural selection within a coalescent framework. A number of different mutation models are available for simulating surrounding neutral variation. The package enables a detailed exploration of the effects of different models and strengths of selection on patterns of diversity. This provides a tool for the statistical analysis of both empirical data and methods designed to detect natural selection. \textcopyright{} Oxford University Press 2004; all rights reserved.},
  author   = {Chris C.A. Spencer and Graham Coop},
  doi      = {10.1093/bioinformatics/bth417},
  issn     = 13674803,
  issue    = 18,
  journal  = {Bioinformatics},
  pages    = {3673--3675},
  pmid     = 15271777,
  title    = {SelSim: A program to simulate population genetic data with natural selection and recombination},
  volume   = 20,
  year     = 2004
}

@article{Sprague2005,
  abstract = {We present software tools and methods applicable to the geological modelling of sparse spatial and structural data within a 3-D digital environment. Free-form surfaces derived from section-style control frames and constrained by field-based structural measurements are employed as partially automated design aids intended to speed up and streamline the 3-D geological model building process. Some design degrees of freedom such as NURBS tension (or weights), knot sequencing and tying surface features are also discussed with examples drawn from spatial and structural data collected in Baffin Island by the Geological Survey of Canada and near-mine exploration data from Canadian mines. Interpolation of field-based structural measurements along the boundary of an unknown surface is also demonstrated. This work is potentially relevant to regional mappers and others dealing with sparse spatial and structural data, and/or conceptual surface modelling. \textcopyright{} 2005 Springer Science + Business Media, Inc.},
  author   = {Kevin B. Sprague and Eric A. de Kemp},
  doi      = {10.1007/s10707-004-5620-8},
  isbn     = 1070700456208,
  issn     = 13846175,
  issue    = 1,
  journal  = {GeoInformatica},
  keywords = {B\'{e}zier,Geology,Map trace,Mining,NURBS,Orientation,Sparse,Structure,Surface},
  pages    = {5--32},
  title    = {Interpretive tools for 3-D structural geological modelling part II: Surface design from sparse spatial data},
  volume   = 9,
  year     = 2005
}

@article{Stachniak2005,
  abstract = {Fractal terrains provide an easy way to generate realistic landscapes. There are several methods to generate fractal terrains, but none of those algorithms allow the user much flexibility in controlling the shape or properties of the final outcome. A few methods to modify fractal terrains have been previously proposed, both algorithm-based as well as by hand editing, but none of these provide a general solution. In this work, we present a new algorithm for fractal terrain deformation. We present a general solution that can be applied to a wide variety of deformations. Our approach employs stochastic local search to identify a sequence of local modifications, which deform the fractal terrain to conform to a set of specified constraints. The presented results show that the new method can incorporate multiple constraints simultaneously, while still preserving the natural look of the fractal terrain.},
  author   = {S Stachniak and W Stuerzlinger},
  issue    = {January 2009},
  journal  = {In Proceedings of Computer Graphics and Artificial Intelligence},
  keywords = {2,3,7,8,according to acm ccs,and search,computer graphics,control methods,fractals,graph and tree search,graphics and realism,i,problem solving,strategies,three-dimensional},
  pages    = {64--76},
  title    = {An Algorithm for Automated Fractal Terrain Deformation},
  url      = {www.cs.yorku.ca/~wolfgang/\%5Cnhttp://alter-unilim.teiath.gr/3ia\_previous\_conferences\_cds/2005/Papers/Papers/Paper03.pdf},
  year     = 2005
}

@article{Stachniak2005a,
  abstract = {Fractal terrains provide an easy way to generate realistic landscapes. There are several methods to generate fractal terrains, but none of those algorithms allow the user much flexibility in controlling the shape or properties of the final outcome. A few methods to modify fractal terrains have been previously proposed, both algorithm-based as well as by hand editing, but none of these provide a general solution. In this work, we present a new algorithm for fractal terrain deformation. We present a general solution that can be applied to a wide variety of deformations. Our approach employs stochastic local search to identify a sequence of local modifications, which deform the fractal terrain to conform to a set of specified constraints. The presented results show that the new method can incorporate multiple constraints simultaneously, while still preserving the natural look of the fractal terrain.},
  author   = {S Stachniak and W Stuerzlinger},
  issue    = {January 2015},
  journal  = {In Proceedings of Computer Graphics and Artificial Intelligence},
  keywords = {2,3,7,8,according to acm ccs,and search,computer graphics,control methods,fractals,graph and tree search,graphics and realism,i,problem solving,strategies,three-dimensional},
  pages    = {64--76},
  title    = {An Algorithm for Automated Fractal Terrain Deformation},
  url      = {www.cs.yorku.ca/~wolfgang/\%5Cnhttp://alter-unilim.teiath.gr/3ia\_previous\_conferences\_cds/2005/Papers/Papers/Paper03.pdf},
  year     = 2005
}

@article{Stam1999,
  abstract = {Building animation tools for fluid-like motions is an important and challenging problem with many applications in computer graphics. The use of physics-based models for fluid flow can greatly assist in creating such tools. Physical models, unlike key frame or procedural based techniques, permit an animator to almost effortlessly create interesting, swirling fluid-like behaviors. Also, the interaction of flows with objects and virtual forces is handled elegantly. Until recently, it was believed that physical fluid models were too expensive to allow real-time interaction. This was largely due to the fact that previous models used unstable schemes to solve the physical equations governing a fluid. In this paper, for the first time, we propose an unconditionally stable model which still produces complex fluid-like flows. As well, our method is very easy to implement. The stability of our model allows us to take larger time steps and therefore achieve faster simulations. We have used our model in conjuction with advecting solid textures to create many fluid-like animations interactively in two- and three-dimensions. Copyright ACM 1999.},
  author   = {Jos Stam},
  doi      = {10.1145/311535.311548},
  isbn     = {0201485605},
  journal  = {Proceedings of the 26th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1999},
  keywords = {Advected textures,Animation of fluids,Gaseous phenomena,Implicit elliptic PDE solvers,Interactive modeling,Navier-Stokes,Stable solvers},
  pages    = {121--128},
  title    = {Stable fluids},
  year     = 1999
}

@article{Stam2003,
  abstract = {In this paper we introduce a method to simulate fluid flows on smooth surfaces of arbitrary topology: an effect never seen before. We achieve this by combining a two-dimensional stable fluid solver with an atlas of parametrizations of a Catmull-Clark surface. The contributions of this paper are: (i) an extension of the Stable Fluids solver to arbitrary curvilinear coordinates, (ii) an elegant method to handle cross-patch boundary conditions and (iii) a set of new external forces custom tailored for surface flows. Our techniques can also be generalized to handle other types of processes on surfaces modeled by partial differential equations, such as reaction-diffusion. Some of our simulations allow a user to interactively place densities and apply forces to the surface, then watch their effects in real-time. We have also computed higher resolution animations of surface flows off-line. \textcopyright{} 2003 ACM.},
  author   = {Jos Stam},
  doi      = {10.1145/882262.882338},
  issn     = {07300301},
  issue    = 3,
  journal  = {ACM Transactions on Graphics},
  keywords = {Computational fluid dynamics,Subdivision Surfaces},
  pages    = {724--731},
  title    = {Flows on surfaces of arbitrary topology},
  volume   = 22,
  year     = 2003
}

@article{Stam2003a,
  abstract = {In this paper we present a simple and rapid implementation of a fluid dynamics solver for game engines. Our tools can greatly enhance games by providing realistic fluid-like effects such as swirling smoke past a moving character. The potential applications are endless. Our algorithms are based on the physical equations of fluid flow, namely the Navier-Stokes equations. These equations are notoriously hard to solve when strict physical accuracy is of prime importance. Our solvers on the other hand are geared towards visual quality. Our emphasis is on stability and speed, which means that our simulations can be advanced with arbitrary time steps. We also demonstrate that our solvers are easy to code by providing a complete C code implementation in this paper. Our algorithms run in real-time for reasonable grid sizes in both two and three dimensions on standard PC hardware, as demonstrated during the presentation of this paper at the conference.},
  author   = {Jos Stam},
  issn     = {09574174},
  issue    = 11,
  journal  = {Proceedings of the Game Developer Conference},
  pages    = 17,
  title    = {Real-Time Fluid Dynamics for Games},
  volume   = 18,
  url      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.12.6736\&amp;rep=rep1\&amp;type=pdf},
  year     = 2003
}

@article{Stava2008,
  abstract = {We present a step toward interactive physics-based modeling of terrains. A terrain, composed of layers of materials, is edited with interactive modeling tools built upon different physics-based erosion and deposition algorithms. First, two hydraulic erosion algorithms for running water are coupled. Areas where the motion is slow become more eroded by the dissolution erosion, whereas in the areas with faster motion, the force-based erosion prevails. Second, when the water under-erodes certain areas, slippage takes effect and the river banks fall into the water. A variety of local and global editing operation is provided. The user has a great level of control over the process and receives immediate feedback since the GPU-based erosion simulation runs at least at 20 fps on off-the-shelf computers for scenes with grid resolution of 2048\texttimes{}1024 and four layers of material. We also present a divide and conquer approach to handle large terrain erosion, where the terrain is tiled, and each tile calculated independently on the GPU. We show a wide variety of erosion-based modeling features such as forming rivers, drying flooded areas, rain, interactive manipulation with rivers, spring, adding obstacles into the water, etc.},
  author   = {Ond\v{r}ej \v{S}t'ava and Bed\v{r}ich Bene\v{s} and Matthew Brisbin and Jaroslav Kriv\'{a}nek},
  isbn     = 9783905674101,
  journal  = {Computer Animation 2008 - ACM SIGGRAPH / Eurographics Symposium, SCA 2008 - Proceedings},
  pages    = {200--210},
  title    = {Interactive terrain modeling using hydraulic erosion},
  url      = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.173.5239\&rep=rep1\&type=pdf},
  year     = 2008
}

@article{Stava2010,
  abstract = {We present an important step towards the solution of the problem of inverse procedural modeling by generating parametric context-free L-systems that represent an input 2D model. The L-system rules efficiently code the regular structures and the parameters represent the properties of the structure transformations. The algorithm takes as input a 2D vector image that is composed of atomic elements, such as curves and poly-lines. Similar elements are recognized and assigned terminal symbols of an L-system alphabet. The terminal symbols' position and orientation are pair-wise compared and the transformations are stored as points in multiple 4D transformation spaces. By careful analysis of the clusters in the transformation spaces, we detect sequences of elements and code them as L-system rules. The coded elements are then removed from the clusters, the clusters are updated, and then the analysis attempts to code groups of elements in (hierarchies) the same way. The analysis ends with a single group of elements that is coded as an L-system axiom. We recognize and code branching sequences of linearly translated, scaled, and rotated elements and their hierarchies. The L-system not only represents the input image, but it can also be used for various editing operations. By changing the L-system parameters, the image can be randomized, symmetrized, and groups of elements and regular structures can be edited. By changing the terminal and non-terminal symbols, elements or groups of elements can be replaced. \textcopyright{} 2010 The Eurographics Association and Blackwell Publishing Ltd.},
  author   = {Ond\v{r}ej \v{S}t'ava and Bed\v{r}ich Bene\v{s} and Radomir M\v{e}ch and Daniel G. Aliaga and Peter Kri\v{s}tof},
  doi      = {10.1111/j.1467-8659.2009.01636.x},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {Computer Graphics [I.3.5]: Computational Geometry,Mathematical Logic and Formal Languages [F.4.2]: G},
  pages    = {665--674},
  title    = {Inverse procedural modeling by automatic generation of L-systems},
  volume   = 29,
  url      = {https://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Stava10.pdf},
  year     = 2010
}

@article{Stava2014,
  abstract = {Procedural tree models have been popular in computer graphics for their ability to generate a variety of output trees from a set of input parameters and to simulate plant interaction with the environment for a realistic placement of trees in virtual scenes. However, defining such models and their parameters is a difficult task. We propose an inverse modelling approach for stochastic trees that takes polygonal tree models as input and estimates the parameters of a procedural model so that it produces trees similar to the input. Our framework is based on a novel parametric model for tree generation and uses Monte Carlo Markov Chains to find the optimal set of parameters. We demonstrate our approach on a variety of input models obtained from different sources, such as interactive modelling systems, reconstructed scans of real trees and developmental models. Procedural tree models have been popular in computer graphics for their ability to generate a variety of output trees from a set of input parameters and to simulate plant interaction with the environment for a realistic placement of trees in virtual scenes. However, defining such models and their parameters is a difficult task. We propose an inverse modeling approach for stochastic trees that takes polygonal tree models as input and estimates the parameters of a procedural model so that it produces trees similar to the input.},
  author   = {Ond\v{r}ej \v{S}t'ava and Julian Kratt and Baoquan Chen and Radomir M\v{e}ch and Oliver Deussen and Bed\v{r}ich Bene\v{s}},
  doi      = {10.1111/cgf.12282},
  issn     = 14678659,
  issue    = 6,
  journal  = {Computer Graphics Forum},
  keywords = {biological modeling,mesh generation,natural phenomena},
  pages    = {118--131},
  title    = {Inverse procedural modelling of trees},
  volume   = 33,
  url      = {https://cfcs.pku.edu.cn/baoquan/docs/20180621170343624947.pdf},
  year     = 2014
}

@article{Stearns1954,
  author  = {F. Stearns MacNeil},
  issue   = {July},
  journal = {American Journal of Science},
  pages   = {402--427},
  title   = {The shape of atolls: An inheritance from subaerial erosion forms},
  volume  = 252,
  year    = 1954
}

@article{Stoddart1988,
  author  = {D. R. Stoddart},
  issue   = 2,
  journal = {Earth Sciences History},
  pages   = {99--110},
  title   = {Joseph Beete Jukes, the 'Cambridge connection', and the theory of reef development in Australia in the nineteenth century},
  volume  = 7,
  year    = 1988
}

@inbook{Stokes1850,
  abstract  = {Not Available},
  author    = {George Gabriel Stokes},
  doi       = {10.1017/CBO9780511702266.002},
  journal   = {Mathematical and Physical Papers},
  month     = 7,
  pages     = {1--10},
  publisher = {Cambridge University Press},
  title     = {On the Effect of the Internal Friction of Fluids on the Motion of Pendulums},
  url       = {https://www.cambridge.org/core/product/identifier/CBO9780511702266A006/type/book\_part},
  year      = 2009
}

@article{Stolte2001,
  abstract = {Voxelization is the transformation of geometric surfaces into voxels. Up to date this process has been done essentially using incremental algorithms. Incremental algorithms have the reputation of being efficient but they lack an important property: robustness. The voxelized representation should envelop its continuous model. However, without robust methods this cannot be guaranteed. This article describes novel techniques of robust voxelization and visualization of implicit surfaces. First of all our recursive subdivision voxelization algorithm is reviewed. This algorithm was initially inspired by Duff's image space subdivision method. Then, we explain the algorithm to voxelize implicit surfaces defined in spherical or cylindrical coordinates. Next, we show a new technique to produce infinite replications of implicit objects and their voxelization method. Afterward, we comment on the parallelization of our voxelization procedure. Finally we present our voxel visualization algorithm based on point display. Our voxelization algorithms can be used with any data structure, thanks to the fact that a voxel is only stored once the last subdivision level is reached. We emphasize the use of the octree, though, because it is a convenient way to store the discrete model hierarchically. In a hierarchy the discrete model refinement is simple and possible from any previous voxelized scene thanks to the fact that the voxelization algorithms are robust. \textcopyright{} 2001 Elsevier Science (USA).},
  author   = {Nilo Stolte and Arie Kaufman},
  doi      = {10.1006/gmod.2001.0559},
  issn     = 15240703,
  issue    = 6,
  journal  = {Graphical Models},
  keywords = {3D visualization,Implicit surfaces,Interval arithmetic,Parallel processing,Voxel,Voxelization},
  pages    = {387--412},
  title    = {Novel techniques for robust voxelization and visualization of implicit surfaces},
  volume   = 63,
  url      = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.5836\&rep=rep1\&type=pdf},
  year     = 2001
}

@article{Stomakhin2014,
  abstract = {In this paper, we introduce a novel material point method for heat transport, melting and solidifying materials. This brings a wider range of material behaviors into reach of the already versatile material point method. This is in contrast to best-of-breed fluid, solid or rigid body solvers that are difficult to adapt to a wide range of materials. Extending the material point method requires several contributions. We introduce a dilational/deviatoric splitting of the constitutive model and show that an implicit treatment of the Eulerian evolution of the dilational part can be used to simulate arbitrarily incompressible materials. Furthermore, we show that this treatment reduces to a parabolic equation for moderate compressibility and an elliptic, Chorin-style projection at the incompressible limit. Since projections are naturally done on marker and cell (MAC) grids, we devise a staggered grid MPM method. Lastly, to generate varying material parameters, we adapt a heat-equation solver to a material point framework. Copyright \textcopyright{} ACM.},
  author   = {Alexey Stomakhin and Craig Schroeder and Chenfanfu Jiang and Lawrence Chai and Joseph Teran and Andrew Selle},
  doi      = {10.1145/2601097.2601176},
  issn     = 15577333,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Freezing,Lava,Material point,Melting,Physically-based modeling},
  title    = {Augmented MPM for phase-change and varied materials},
  volume   = 33,
  year     = 2014
}

@article{Stone2013,
  abstract = {A system for capturing habitual, in-home gait measurements using an environmentally mounted depth camera, the Microsoft Kinect, is presented. Previous work evaluating the use of the Kinect sensor for in-home gait measurement in a lab setting has shown the potential of this approach. In this paper, a single Kinect sensor and computer were deployed in the apartments of older adults in an independent living facility for the purpose of continuous, in-home gait measurement. In addition, a monthly fall risk assessment protocol was conducted for each resident by a clinician, which included traditional tools such as the timed up a go and habitual gait speed tests. A probabilistic methodology for generating automated gait estimates over time for the residents of the apartments from the Kinect data is described, along with results from the apartments as compared to two of the traditionally measured fall risk assessment tools. Potential applications and future work are discussed. \textcopyright{} 1964-2012 IEEE.},
  author   = {Erik E. Stone and Marjorie Skubic},
  doi      = {10.1109/TBME.2013.2266341},
  issn     = {00189294},
  issue    = 10,
  journal  = {IEEE Transactions on Biomedical Engineering},
  keywords = {Depth camera,Kinect,fall risk,gait},
  pages    = {2925--2932},
  pmid     = 23744661,
  title    = {Unobtrusive, continuous, in-home gait measurement using the microsoft kinect},
  volume   = 60,
  year     = 2013
}

@misc{Stork2012,
  author = {Joris Stork},
  title  = {Camera pose estimation with circular markers},
  year   = 2012
}

@article{Storlazzi2017,
  abstract = {Connectivity among individual marine protected areas (MPAs) is one of the most important considerations in the design of integrated MPA networks. To provide such information for managers in Hawaii, USA, a numerical circulation model was developed to determine the role of ocean currents in transporting coral larvae from natal reefs throughout the high volcanic islands of the Maui Nui island complex in the southeastern Hawaiian Archipelago. Spatially- and temporally-varying wind, wave, and circulation model outputs were used to drive a km-scale, 3-dimensional, physics-based circulation model for Maui Nui. The model was calibrated and validated using satellite-tracked ocean surface current drifters deployed during coral-spawning conditions, then used to simulate the movement of the larvae of the dominant reef-building coral, Porites compressa, from 17 reefs during eight spawning events in 2010-2013. These simulations make it possible to investigate not only the general dispersal patterns from individual coral reefs, but also how anomalous conditions during individual spawning events can result in large deviations from those general patterns. These data also help identify those reefs that are dominated by self-seeding and those where self-seeding is limited to determine their relative susceptibility to stressors and potential roadblocks to recovery. Overall, the numerical model results indicate that many of the coral reefs in Maui Nui seed reefs on adjacent islands, demonstrating the interconnected nature of the coral reefs in Maui Nui and providing a key component of the scientific underpinning essential for the design of a mutually supportive network of MPAs to enhance conservation of coral reefs.},
  author   = {Curt D. Storlazzi and Maarten van Ormondt and Yi Leng Chen and Edwin P.L. Elias},
  doi      = {10.3389/fmars.2017.00381},
  issn     = 22967745,
  issue    = {DEC},
  journal  = {Frontiers in Marine Science},
  keywords = {Coral,Design,Larvae,Marine protected area,Model,Porites compressa,Reef},
  pages    = {1--14},
  title    = {Modeling fine-scale coral larval dispersal and interisland connectivity to help designate mutually-supporting coral reef marine protected areas: Insights from Maui Nui, Hawaii},
  volume   = 4,
  year     = 2017
}

@article{Studivan2022,
  abstract = {Stony coral tissue loss disease (SCTLD) was first observed in 2014 near Virginia Key in Miami-Dade County, Florida. Field sampling, lab experiments, and modeling approaches have suggested that reef sediments may play a role in SCTLD transmission, though a positive link has not been tested experimentally. We conducted an ex situ transmission assay using a statistically-independent disease apparatus to test whether reef sediments can transmit SCTLD in the absence of direct contact between diseased and healthy coral tissue. We evaluated two methods of sediment inoculation: batch inoculation of sediments collected from southeast Florida using whole colonies of diseased Montastraea cavernosa, and individual inoculations of sediments following independent, secondary infections of \sim{}5 cm2 coral fragments. Healthy fragments of the coral species Orbicella faveolata and M. cavernosa were exposed to these diseased sediment treatments, as well as direct disease contact and healthy sediment controls. SCTLD transmission was observed for both batch and individual diseased sediment inoculation treatments, albeit with lower proportions of infected individuals as compared to disease contact controls. The time to onset of lesions was significantly different between species and among disease treatments, with the most striking infections occurring in the individual diseased sediment treatment in under 24 h. Following infection, tissue samples were confirmed for the presence of SCTLD signs via histological examination, and sediment subsamples were analyzed for microbial community variation between treatments, identifying 16 SCTLD indicator taxa in sediments associated with corals experiencing tissue loss. This study demonstrated that reef sediments can indeed transmit SCTLD through indirect exposure between diseased and healthy corals, and adds credence to the assertion that SCTLD transmission occurs via an infectious agent or agents. This study emphasizes the critical need to understand the roles that sediment microbial communities and coastal development activities may have on the persistence of SCTLD throughout the endemic zone, especially in the context of management and conservation strategies in Florida and the wider Caribbean.},
  author   = {Michael S. Studivan and Ashley M. Rossin and Ewelina Rubin and Nash Soderberg and Daniel M. Holstein and Ian C. Enochs},
  doi      = {10.3389/fmars.2021.815698},
  issn     = 22967745,
  issue    = {January},
  journal  = {Frontiers in Marine Science},
  keywords = {16S,ballast water,disease reservoir,disease transmission,disease vector,histology,microbial communities,sedimentation},
  pages    = {1--15},
  title    = {Reef Sediments Can Act As a Stony Coral Tissue Loss Disease Vector},
  volume   = 8,
  year     = 2022
}

@article{Sugihara2008,
  author  = {Masamichi Sugihara and Erwin De Groot and Brian Wyvill and Ryan Schmidt},
  journal = {Computational Geometry},
  title   = {A Sketch-Based Method to Control Deformation in a Skeletal Implicit Surface Modeler},
  url     = {http://diglib.eg.org/bitstream/handle/10.2312/SBM.SBM08.065-072/065-072.pdf?sequence=1\&isAllowed=y},
  year    = 2008
}

@article{Sumner1999,
  abstract = {Computer animations often lack the subtle environmental changes that should occur due to the actions of the characters. Squealing car tires usually leave no skid marks, airplanes rarely leave jet trails in the sky, and most runners leave no footprints. In this paper, we describe a simulation model of ground surfaces that can be deformed by the impact of rigid body models of animated characters. To demonstrate the algorithms, we show footprints made by a runner in sand, mud, and snow as well as bicycle tire tracks, a bicycle crash, and a falling runner. The shapes of the footprints in the three surfaces are quite different, but the effects were controlled through only five essentially independent parameters. To assess the realism of the resulting motion, we compare the simulated footprints to human footprints in sand.},
  author   = {Robert W. Sumner and James F. O'Brien and Jessica K. Hodgins},
  doi      = {10.1111/1467-8659.00299},
  issn     = {01677055},
  issue    = 1,
  journal  = {Computer Graphics Forum},
  keywords = {animation,ground interaction,mud,physical simulation,sand,snow,terrain},
  pages    = {17--26},
  title    = {Animating sand, mud, and snow},
  volume   = 18,
  year     = 1999
}

@misc{Sun,
  abstract = {In this paper, we address the problem of estimating and removing non-uniform motion blur from a single blurry image. We propose a deep learning approach to predicting the probabilistic distribution of motion blur at the patch level using a convolutional neural network (CNN). We further extend the candidate set of motion kernels predicted by the CNN using carefully designed image rotations. A Markov random field model is then used to infer a dense non-uniform motion blur field enforcing motion smoothness. Finally, motion blur is removed by a non-uniform de-blurring model using patch-level image prior. Experimental evaluations show that our approach can effectively estimate and remove complex non-uniform motion blur that is not handled well by previous approaches.},
  author   = {Jian Sun and Wenfei Cao and Zongben Xu and Jean Ponce},
  title    = {Learning a Convolutional Neural Network for Non-uniform Motion Blur Removal},
  url      = {http://caffe.berkeleyvision.org}
}

@article{Suzuki2005,
  abstract = {This paper presents a newly developed numerical procedure to predict three-dimensional sand-erosion phenomena. It is well known that sand erosion is a typical multi-physics problem, i.e. turbulent flow field, particle motions and wall deformations, among others, interact. In the present code, in order to simulate this phenomenon, turbulent flow field, particle trajectories and amount of erosion on an eroded wall are calculated repeatedly. The gas-particle two-phase turbulent flow around a turbine blade is computed to clarify sand-erosion phenomena on the turbine blade. The numerical results indicate that sand erosion occurs severely around the leading edge and on the pressure surface, the rebounding particles cause the mechanical damage on the suction surface, and the aerodynamic performance deteriorates with proceeding sand erosion. \textcopyright{} 2005 Elsevier Ltd.},
  author   = {Masaya Suzuki and Kazuyuki Toda and Makoto Yamamoto},
  isbn     = {0080444814},
  journal  = {3rd M.I.T. Conference on Computational Fluid and Solid Mechanics},
  keywords = {Computational fluid dynamics,Multi-physics simulation,Sand erosion,Three-dimensional computation,Turbine blade},
  pages    = {1006--1008},
  title    = {Multi-physics simulation of sand-erosion phenomena on turbine blade},
  url      = {https://www.flair.monash.edu.au/intranet/proceedings/3mit/data/content/1006/paper.pdf},
  year     = 2005
}

@misc{Svensson,
  author = {Samuel Svensson},
  title  = {Procedural creation of corals using Lindenmayer systems and OSL shaders in Blender Cycles},
  url    = {https://samuelllsvensson.github.io/files/Procedurella\_projekt.pdf}
}

@article{Swope1982,
  abstract = {We present a molecular dynamics computer simulation method for calculating equilibrium constants for the formation of physical clusters of molecules. The method is based on Hill's formal theory of physical clusters. In the method, a molecular dynamics calculation is used to calculate the average potential energy of a cluster of molecules as a function of temperature, and the equilibrium constants are calculated from the integral of the energy with respect to reciprocal temperature. The method is illustrated by calculations of the equilibrium constants for the formation of clusters of two to five water molecules that interact with each other by an intermolecular potential devised by Watts. The method is compared with other procedures for calculating the thermodynamic properties of clusters. \textcopyright{} 1982 American Institute of Physics.},
  author   = {William C. Swope and Hans C. Andersen and Peter H. Berens and Kent R. Wilson},
  doi      = {10.1063/1.442716},
  issn     = {00219606},
  issue    = 1,
  journal  = {The Journal of Chemical Physics},
  pages    = {637--649},
  title    = {A computer simulation method for the calculation of equilibrium constants for the formation of physical clusters of molecules: Application to small water clusters},
  volume   = 76,
  year     = 1982
}

@article{Takayama2010,
  abstract = {The modeling of volumetric objects is still a difficult problem. Solid texture synthesis methods enable the design of volumes with homogeneous textures, but global features such as smoothly varying colors seen in vegetables and fruits are difficult to model. In this paper, we propose a representation called diffusion surfaces (DSs) to enable modeling such objects. DSs consist of 3D surfaces with colors defined on both sides, such that the interior colors in the volume are obtained by diffusing colors from nearby surfaces. A straightforward way to compute color diffusion is to solve a volumetric Poisson equation with the colors of the DSs as boundary conditions, but it requires expensive volumetric meshing which is not appropriate for interactive modeling. We therefore propose to interpolate colors only locally at user-defined cross-sections using a modified version of the positive mean value coordinates algorithm to avoid volumetric meshing. DSs are generally applicable to model many different kinds of objects with internal structures. As a case study, we present a simple sketch-based interface for modeling objects with rotational symmetries that can also generate random variations of models. We demonstrate the effectiveness of our approach through various DSs models with simple non-photorealistic rendering techniques enabled by DSs. \textcopyright{} 2010 ACM.},
  author   = {Kenshi Takayama and Olga Sorkine and Andrew Nealen and Takeo Igarashi},
  doi      = {10.1145/1866158.1866202},
  isbn     = 9781450304399,
  issn     = {07300301},
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {color diffusion,sketching interface,volumetric modeling},
  title    = {Volumetric modeling with diffusion surfaces},
  volume   = 29,
  year     = 2010
}

@article{Talgorn2018,
  abstract = {We tackle the problem of real-time constrained terrain generation by proposing a new fractal-based GPU model. Our approach allows to control the terrain's topology and aspect both on a global and local scope in a homogeneous manner. Relying on a sequential model of constrained midpoint displacement, we implement its GPU parallelization, improve the quality of results by erasing its artifacts and propose to extend parameterization with the objective of a finer-grained local control over the generated topologies. In order to test this approach, we propose a minimalistic sketch-based terrain editor that highlights the benefits of such a model in terms of instantaneous responsiveness, realism and expressiveness offering new perspectives both in terrain authoring tools and in real-time procedural generation of pseudo-infinite universe.},
  author   = {Fran\c{c}ois Xavier Talgorn and Far\`{e}s Belhadj},
  doi      = {10.1145/3208159.3208184},
  isbn     = 1595930361,
  issue    = {March 2021},
  journal  = {ACM International Conference Proceeding Series},
  keywords = {GPU-based algorithm,Real-time terrain generation,Sketch-based interface},
  pages    = {13--18},
  title    = {Real-time sketch-based terrain generation},
  url      = {https://www.researchgate.net/profile/Fares-Belhadj/publication/325327322\_Real-Time\_Sketch-Based\_Terrain\_Generation/links/6054c4b4a6fdccbfeaf0a8b2/Real-Time-Sketch-Based-Terrain-Generation.pdf},
  year     = 2018
}

@article{Tamborrino2022,
  abstract = {Cold-water corals mounds develop over millennial timescales as a result of sustained coral growth and concurrent with sediment deposition within their coral frameworks. So far, coral mounds have been primarily investigated as deep-sea biodiversity hotspots and geo-biological paleo-archives, whereas their morphological appearance and spatial arrangement have received much less attention. Here, we analysed the spatial distribution and the morphometry of coral mounds that developed on the Namibian shelf during a single short period dating back to the Early. The spatial distribution of these ``early-stage'' mounds and their morphological characteristics revealed a hierarchy of three different patterns. These comprise an alongslope mound distribution at a regional scale (first-order pattern), a topography-steered downslope alignment of mounds at a local scale (second-order pattern), and a hydrodynamic-controlled downslope orientation of the individual mounds at a mound scale (third-order pattern). In addition, because the Namibian mounds rarely exceed 20 m in height, key steps in the development of early-stage coral mounds (e.g. elongation, merging, limited gain in height compared to lateral extension) have been identified. With increasing size, coral mounds are more elongated, parallel to the prevailing tidal system, which is interpreted to reflect the transition from an ``inherited'' to a ``developed'' mound morphology. Besides supporting this earlier hypothesis on mound development, we could show that this transition takes place when the Namibian coral mounds reach ~150 m in length and ~8 m in height. This study reveals that the spatial-morphological appearance of coral mounds, often treated as a descriptive information, can provide valid information to understand their formation.},
  author   = {Leonardo Tamborrino and J\"{u}rgen Titschack and Claudia Wienberg and Sam Purkis and Gregor P. Eberli and Dierk Hebbeln},
  doi      = {10.3389/fmars.2022.877616},
  issn     = 22967745,
  issue    = {October},
  journal  = {Frontiers in Marine Science},
  keywords = {cold-water corals,coral mound formation,internal tides/waves,morphometry,spatial analysis,underlying topography},
  pages    = {1--20},
  title    = {Spatial distribution and morphometry of the Namibian coral mounds controlled by the hydrodynamic regime and outer-shelf topography},
  volume   = 9,
  year     = 2022
}

@inbook{Tasse2014,
  author   = {Flora Ponjou Tasse and Arnaud Emilien and Marie-Paule Cani and Stefanie Hahmann and Adrien Bernhardt},
  journal  = {Graphics Interface},
  keywords = {first person editing,sketch-based modelling,terrain},
  title    = {First Person Sketch-based Terrain Editing},
  url      = {https://hal.inria.fr/hal-00976689/file/FirstPersonSketchBasedTerrainEditing\_GI2014.pdf},
  year     = 2014
}

@article{Tasse2015,
  author   = {Flora Ponjou Tasse and Arnaud Emilien and Marie-Paule Cani and Stefanie Hahmann and Neil Dodgson},
  doi      = {10.1016/j.cag.2014.09.001},
  issn     = {00978493},
  journal  = {Computers \& Graphics},
  keywords = {first person editing,silhouettes,sketch-based modelling,terrain},
  month    = 12,
  pages    = {101--115},
  title    = {Feature-based terrain editing from complex sketches},
  volume   = 45,
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0097849314000818},
  year     = 2014
}

@article{Taylor2001,
  abstract = {Karl Sims' work [25, 26] on evolving body shapes and controllers for three-dimensional, physically simulated creatures generated wide interest on its publication in 1994. The purpose of this article is threefold: (a) to highlight a spate of recent work by a number of researchers in replicating, and in some cases extending, Sims' results using standard PCs (Sims' original work was done on a Connection Machine CM-5 parallel computer). In particular, a re-implementation of Sims' work by the authors will be described and discussed; (b) to illustrate how off-the-shelf physics engines can be used in this sort of work, and also to highlight some deficiencies of these engines and pitfalls when using them; and (c) to indicate how these recent studies stand in respect to Sims' original work. \textcopyright{} 2001 Massachusetts Institute of Technology.},
  author   = {Tim Taylor and Colm Massey},
  doi      = {10.1162/106454601300328034},
  isbn     = 1064546013,
  issn     = 10645462,
  issue    = 1,
  journal  = {Artificial Life},
  keywords = {Brain-body evolution,Morphological evolution,Physics engine,Virtual creature evolution},
  pages    = {77--87},
  pmid     = 11461690,
  title    = {Recent developments in the evolution of morphologies and controllers for physically simulated creatures},
  volume   = 7,
  year     = 2001
}

@article{Teh2013,
  abstract = {Overfishing threatens coral reefs worldwide, yet there is no reliable estimate on the number of reef fishers globally. We address this data gap by quantifying the number of reef fishers on a global scale, using two approaches - the first estimates reef fishers as a proportion of the total number of marine fishers in a country, based on the ratio of reef-related to total marine fish landed values. The second estimates reef fishers as a function of coral reef area, rural coastal population, and fishing pressure. In total, we find that there are 6 million reef fishers in 99 reef countries and territories worldwide, of which at least 25\% are reef gleaners. Our estimates are an improvement over most existing fisher population statistics, which tend to omit accounting for gleaners and reef fishers. Our results suggest that slightly over a quarter of the world's small-scale fishers fish on coral reefs, and half of all coral reef fishers are in Southeast Asia. Coral reefs evidently support the socio-economic well-being of numerous coastal communities. By quantifying the number of people who are employed as reef fishers, we provide decision-makers with an important input into planning for sustainable coral reef fisheries at the appropriate scale. \textcopyright{} 2013 Teh et al.},
  author   = {Louise S.L. Teh and Lydia C.L. Teh and U. Rashid Sumaila},
  doi      = {10.1371/journal.pone.0065397},
  issn     = 19326203,
  issue    = 6,
  journal  = {PLoS ONE},
  pmid     = 23840327,
  title    = {A Global Estimate of the Number of Coral Reef Fishers},
  volume   = 8,
  year     = 2013
}

@article{Temucin2020,
  abstract  = {Procedural content generation (PCG) methods are commonly employed in computer games, simulations, and other related industries. While these methods are used for levels, terrains, stories and missions, their usage for procedural city generation is relatively rare because cities are heterogeneous structures with different components such as roads, layouts and buildings that depend on and affect each other. Additionally, ancient cities grew organically to areas that are safe and to those that provide food and water. This resulted in cities that do not have apparent regular patterns, such as rectangular building blocks. We propose an approach that uses cellular automata (CA) that generates clusters of areas. The CA is repeated for each cluster to hierarchically create different levels of the city. This procedure creates an organic city layout with fractal properties. The layout specifies the building blocks, main roads, and foliage. We also present a set of methods that can transform this layout into a three-dimensional model of the city. The results are promising; cities can be created in under a minute with minimal required input, and the resulting virtual city looks organic, rather than an algorithmic layout that has repeating patterns. ~},
  author    = {Melek B. Temu\c{c}in and \.{I}lker Kocaba\c{s} and Kaya O\u{g}uz},
  doi       = {10.24018/ejers.2020.5.12.2293},
  issue     = 12,
  journal   = {European Journal of Engineering Research and Science},
  month     = 12,
  pages     = {116--120},
  publisher = {European Open Access Publishing (Europa Publishing)},
  title     = {Using Cellular Automata as a Basis for Procedural Generation of Organic Cities},
  volume    = 5,
  year      = 2020
}

@article{Terry2013,
  abstract = {<p>April 2012 marked the 130th anniversary of the death of Charles Darwin. One of many significant contributions he made to science was the subsidence theory of atoll formation, which he penned on 12 April 1836 during the voyage of the Beagle through the Pacific. Darwin's elegant theory, founded on the premise of a subsiding volcano and the corresponding upward growth of coral reef, was astonishing for the time considering the absence of an underpinning awareness of plate tectonics. His theory has endured until modern times in spite of a number of opposing ideas and permutations and has an enviable longevity amongst paradigms in geomorphology. Darwin frequently alluded to the generally circular morphology of the atoll shape, yet the reality is that many atolls are neither circular nor elliptical, instead possessing irregular morphologies. In particular, many exhibit major arcuate `bight-like' structures (ABLS) in their plan form. These departures from the circular form are indicative of geomorphological processes that cannot be ignored. ABLS are the morphological expression of large submarine failures that are common on the slopes of volcanic edifices. Such failures can occur during any stage of atoll formation and are a valuable addition to Darwin's theory because they indicate the instability of the volcanic foundations. Moreover, ABLS have fundamental implications for hazard research in the context of oceanic islands. Not only does our extension to the theory explain the diversity of atoll shape, but it also provides a mechanism for identifying a vast number of potential local tsunamigenic sources, which is critical for advancing modern understanding of tsunami hazards in oceanic environments.</p>},
  author   = {James P Terry and James Goff},
  doi      = {10.1177/0959683612463101},
  issn     = {0959-6836},
  issue    = 4,
  journal  = {The Holocene},
  month    = 4,
  pages    = {615--619},
  title    = {One hundred and thirty years since Darwin: `Reshaping' the theory of atoll formation},
  volume   = 23,
  url      = {http://journals.sagepub.com/doi/10.1177/0959683612463101},
  year     = 2013
}

@article{Teske2011,
  abstract = {The southern African marine realm is located at the transition zone between the Atlantic and Indo-Pacific biomes. Its biodiversity is particularly rich and comprises faunal and floral elements from the two major oceanic regions, as well as a large number of endemics. Within this realm, strikingly different biota occur in close geographic proximity to each other, and many of the species with distributions spanning two or more of the region's marine biogeographic provinces are divided into evolutionary units that can often only be distinguished on the basis of genetic data. In this review, we describe the state of marine phylogeography in southern Africa, that is, the study of evolutionary relationships at the species level, or amongst closely related species, in relation to the region's marine environment. We focus particularly on coastal phylogeography, where much progress has recently been made in identifying phylogeographic breaks and explaining how they originated and are maintained. We also highlight numerous shortcomings that should be addressed in the near future. These include: the limited data available for commercially important organisms, particularly offshore species; the paucity of oceanographic data for nearshore areas; a dearth of studies based on multilocus data; and the fact that studying the role of diversifying selection in speciation has been limited to physiological approaches to the exclusion of genetics. It is becoming apparent that the southern African marine realm is one of the world's most interesting environments in which to study the evolutionary processes that shape not only regional, but also global patterns of marine biodiversity.},
  author   = {Peter R. Teske and Sophie Von Der Heyden and Christopher D. McQuaid and Nigel P. Barker},
  doi      = {10.4102/sajs.v107i5/6.514},
  issn     = 19967489,
  issue    = {5-6},
  journal  = {South African Journal of Science},
  pages    = {43--53},
  title    = {A review of marine phylogeography in southern Africa},
  volume   = 107,
  year     = 2011
}

@article{Theisel2003,
  abstract = {In this paper we introduce a new compression technique for 2D vector fields which preserves the complete topology, i.e., the critical points and the connectivity of the separatrices. As the theoretical foundation of the algorithm, we show in a theorem that for local modifications of a vector field, it is possible to decide entirely by a local analysis whether or not the global topology is preserved. This result is applied in a compression algorithm which is based on a repeated local modification of the vector field - namely a repeated edge collapse of the underlying piecewise linear domain. We apply the compression technique to a number of data sets with a complex topology and obtain significantly improved compression ratios in comparison to pre-existing topology-preserving techniques.},
  author   = {H. Theisel and Ch R\"{o}ssl and H. P. Seidel},
  doi      = {10.1111/1467-8659.00680},
  issn     = {01677055},
  issue    = 3,
  journal  = {Computer Graphics Forum},
  keywords = {Data visualization,Flow visualization,Vector field compression,Vector field topology},
  pages    = {333--342},
  title    = {Compression of 2D Vector Fields Under Guaranteed Topology Preservation},
  volume   = 22,
  url      = {https://domino.mpi-inf.mpg.de/intranet/ag4/ag4publ.nsf/93832a04987390a3c12567530068622d/21fe90c7c981a5e3c1256d050047db4b/\$file/theiselroesslseidel03a.pdf},
  year     = 2003
}

@article{Thorseth2001,
  abstract = {Electron microscopy and biomolecular methods have been used to describe and identify microbial communities inhabiting the glassy margins of ocean floor basalts. The investigated samples were collected from a neovolcanic ridge and from older, sediment-covered lava flows in the rift valley of the Knipovich Ridge at a water depth around 3500 m and an ambient seawater temperature of -0.7\textdegree{}C. Successive stages from incipient microbial colonisation, to well-developed biofilms occur on fracture surfaces in the glassy margins. Observed microbial morphologies are various filamentous, coccoidal, oval, rod-shaped and stalked forms. Etch marks in the fresh glass, with form and size resembling the attached microbes, are common. Precipitation of alteration products around microbes has developed hollow subspherical and filamentous structures. These precipitates are often enriched in Fe and Mn. The presence of branching and twisted stalks that resemble those of the iron-oxidising Gallionella, indicate that reduced iron may be utilised in an energy metabolic process. Analysis of 16S-rRNA gene sequences from microbes present in the rock samples, show that the bacterial population inhabiting these samples cluster within the \ensuremath{\gamma}-and \ensuremath{\epsilon}-Proteobacteria and the Cytophaga/Flexibacter/Bacteroides subdivision of the Bacteria, while the Archaea all belong to the Crenarchaeota kingdom. This microbial population appears to be characteristic for the rock and their closest relatives have previously been reported from cold marine waters in the Arctic and Antarctic, deep-sea sediments and hydrothermal environments. \textcopyright{} 2001 Elsevier Science B.V. All rights reserved.},
  author   = {I. H. Thorseth and T. Torsvik and V. Torsvik and F. L. Daae and R. B. Pedersen},
  doi      = {10.1016/S0012-821X(01)00537-4},
  issn     = {0012821X},
  issue    = {1-2},
  journal  = {Earth and Planetary Science Letters},
  keywords = {Alteration,Basalts,Biosphere,Glasses,Microorganisms,Oceanic crust},
  pages    = {31--37},
  title    = {Diversity of life in ocean floor basalt},
  volume   = 194,
  year     = 2001
}

@misc{TianzhongSong,
  author = {TianzhongSong},
  title  = {TianzhongSong/Real-Time-Action-Recognition: Real-time pose estimation and action recognition},
  url    = {https://github.com/TianzhongSong/Real-Time-Action-Recognition}
}

@article{Togelius2010,
  abstract = {A search-based procedural content generation (SBPCG) algorithm for strategy game maps is proposed. Two representations for strategy game maps are devised, along with a number of objectives relating to predicted player experience. A multiobjective evolutionary algorithm is used for searching the space of maps for candidates that satisfy pairs of these objectives. As the objectives are inherently partially conicting, the algorithm generates Pareto fronts showing how these objectives can be balanced. Such fronts are argued to be a valuable tool for designers looking to balance various design needs. Choosing appropriate points (manually or automatically) on the Pareto fronts, maps can be found that exhibit good map design according to specified criteria, and could either be used directly in e.g. an RTS game or form the basis for further human design. Copyright 2010 ACM.},
  author   = {Julian Togelius and Mike Preuss and Georgios N. Yannakakis},
  doi      = {10.1145/1814256.1814259},
  isbn     = 9781450300230,
  journal  = {Workshop on Procedural Content Generation in Games, PC Games 2010, Co-located with the 5th International Conference on the Foundations of Digital Games},
  title    = {Towards multiobjective procedural map generation},
  year     = 2010
}

@article{Togelius2012,
  abstract = {We consider the strengths and drawbacks of various procedural content generation methods, and how they could be combined to hybrid methods that retain the advantages and avoid the disadvantages of their constituent methods. One answer is composition, where one method is nestled inside another. As an example, we present a hybrid evolutionary-ASP dungeon generator.},
  author   = {Julian Togelius and Tr\'{o}ndur Justinussen and Anders Hartzen},
  doi      = {10.1145/2538528.2538541},
  journal  = {3rd Workshop on Procedural Content Generation in Games, PCG 2012, Organized in Conjunction with the Foundations of Digital Games Conference, FDG 2012},
  note     = {Can be useful for specific tests of the robot (start with many waterflows, have sharp edges, start inside a gallery, etc...)},
  pages    = {66--69},
  title    = {Compositional procedural content generation},
  year     = 2012
}

@article{Tomlinson2019,
  abstract  = {Learning the endless intricacies of operative neurosurgical anatomy requires that surgeons complement their intraoperative experiences with a variety of educational resources. In the past 2 decades, rapid improvements in digital graphics and computing power have enabled a new generation of 3-dimensional (3D) virtual resources that overcome limitations of more traditional 2-dimensional materials. Today, dozens of immersive 3D visualization platforms exist for applications such as learning neuroanatomy, simulating operative techniques, and planning surgical interventions with patient-specific models. The purpose of this article is to identify current applications of 3D digital modeling and virtual reality in neurosurgery. In addition, we showcase a new series of freely available 3D virtual-reality models created to assist in learning complex cranial anatomy. We anticipate these models to have a wide range of educational, clinical, and research applications. Three-dimensional visualization is poised to modernize the ways we learn and teach neurosurgical anatomy outside of the operating room. Future generations of neurosurgeons are expected to benefit from these technologies from the earliest stages of training.},
  author    = {Samuel B. Tomlinson and Benjamin K. Hendricks and Aaron Cohen-Gadol},
  doi       = {10.1016/j.wneu.2019.06.081},
  issn      = 18788769,
  journal   = {World Neurosurgery},
  keywords  = {3D,Operative anatomy,Resident education,The Neurosurgical Atlas,Virtual reality},
  month     = 11,
  pages     = {313--320},
  pmid      = 31658575,
  publisher = {Elsevier Inc.},
  title     = {Immersive Three-Dimensional Modeling and Virtual Reality for Enhanced Visualization of Operative Neurosurgical Anatomy},
  volume    = 131,
  year      = 2019
}

@article{Tompson2017,
  abstract = {Efficient simulation of the Navicr-Stokes equations for fluid flow is a long standing problem in applied mathematics, for which state-of-the-art methods require large compute resources. In this work, we propose a data-driven approach that leverages the approximation power of deep-learning with the precision of standard solvers to obtain fast and highly realistic simulations. Our method solves the incompressible Euler equations using the standard operator splitting method, in which a large sparse linear system with many free parameters must be solved. We use a Convolutional Network with a highly tailored architecture, trained using a novel unsupervised learning framework to solve the linear system. We present real-time 2D and 3D simulations that outperform recently proposed data-driven methods; the obtained results are realistic and show good generalization properties.},
  author   = {Jonathan Tompson and Kristofer Schlachter and Pablo Sprechmann and Ken Perlin},
  isbn     = 9781510855144,
  journal  = {34th International Conference on Machine Learning, ICML 2017},
  pages    = {5258--5267},
  title    = {Accelerating eulerian fluid simulation with convolutional networks},
  volume   = 7,
  year     = 2017
}

@article{Toyokawa2011,
  abstract = {We surveyed the distribution of colonies of polyps of Aureliaaurita sensu lato (s.l.) in Mikawa Bay, Japan. First, we surveyed the distribution of ephyrae of A. aurita s.l. at 75 stations encompassing the whole of Mikawa Bay in early 2008. A total of 37 ephyrae were sampled mostly from fishing ports. Ephyrae were most abundant around the islands located near the mouth of the bay, and decreased from the western part to the eastern part of Mikawa Bay. Next, we selected five fishing ports in Mikawa Bay where ephyrae occurred and surveyed the underside of floating piers and underwater overhangs of wharfs. We found dense colonies of polyps of A. aurita s. l. under nearly all of the floating piers at the two islands located near the mouth of the bay. Fitting a logistic regression model to the dataset showed that the percentage coverage of Aurelia polyps was significantly greater at the two islands compared with the other locations. In addition, the coverage of Aurelia polyps was greater when the coverage of other fouling organisms was in the range of 65-90\%, and the coverage of Aurelia polyps was lower on floating piers with a vinyl surface and on concrete wharfs. The combined distribution of polyp colonies of A. aurita s.l. in Ise Bay and Mikawa Bay suggested that A. aurita s.l. in the two bays probably forms a single population and shoals of medusae mainly originate from protected harbors along the mouth-part of the bays. \textcopyright{} 2011 The Oceanographic Society of Japan and Springer.},
  author   = {Masaya Toyokawa and Kaoru Aoki and Satoshi Yamada and Akira Yasuda and Yusuke Murata and Tomohiko Kikuchi},
  doi      = {10.1007/s10872-011-0021-8},
  issn     = {09168370},
  issue    = 2,
  journal  = {Journal of Oceanography},
  keywords = {Benthos,Cnidaria,Coastal,Fishing port,Fouling,Model selection,Plankton,Polyp,Population,Semaeostomeae},
  pages    = {209--218},
  title    = {Distribution of ephyrae and polyps of jellyfish Aurelia aurita (Linnaeus 1758) sensu lato in Mikawa Bay, Japan},
  volume   = 67,
  year     = 2011
}

@article{Tricard2019,
  author  = {Thibault Tricard and Semyon Efremov and C\'{e}dric Zanni and Fabrice Neyret and Jon\`{a}s Mart\'{\i}nez and Sylvain Lefebvre},
  issue   = 4,
  journal = {ACM Transactions on Graphics},
  title   = {Procedural Phasor Noise},
  volume  = 38,
  url     = {https://hal.archives-ouvertes.fr/hal-02118508/file/ProceduralPhasorNoise.pdf},
  year    = 2019
}

@article{Tsubota2006,
  abstract = {A new computer simulation using a particle method was proposed to analyze the microscopic behavior of blood flow. A simulation region, including plasma, red blood cells (RBCs) and platelets, was modeled by an assembly of discrete particles. The proposed method was applied to the motions and deformations of a single RBC and multiple RBCs, and the thrombogenesis caused by platelet aggregation. It is expected that, combined with a sophisticated large-scale computational technique, the simulation method will be useful for understanding the overall properties of blood flow from blood cellular level (microscopic) to the resulting rheological properties of blood as a mass (macroscopic).},
  author   = {Ken-Ichi Tsubota and Shigeo Wada and Hiroki Kamada and Yoshitaka Kitagawa and Rui Lima and Takami Yamaguchi},
  doi      = {http://hdl.handle.net/10198/1622},
  journal  = {Journal of the Earth Simulator},
  keywords = {Blood Flow,Computational Biomechanics,Platelet,Red Blood Cell,Rheology},
  pages    = {2--7},
  title    = {A particle method for blood flow simulation: application to flowing red blood cells and platelets},
  volume   = 5,
  url      = {http://hdl.handle.net/10198/1622},
  year     = 2006
}

@article{Turk2010,
  abstract = {We demonstrate artificial evolution in a system that combines physical simulation with competition between creatures. The simulated creatures are constructed using point masses that are connected by oscillating springs. The creatures pull themselves across their 2D environment by varying the amount of friction at different point masses, giving them sticky feet. Creatures combat one another, and the victor of such an encounter earns the right to reproduce, possibly with mutation. Rather than testing one individual against another in pairs, as many as 100 creatures move and interact with each other in the same 2D environment. Over time, the initial creatures are replaced by new creatures that are more agile and better at combating others. The evolved creatures from such simulations exhibit a wide array of body plans, locomotion styles, and interaction behaviors.},
  author   = {Greg Turk},
  isbn     = 9780262290753,
  journal  = {Artificial Life XII: Proceedings of the 12th International Conference on the Synthesis and Simulation of Living Systems, ALIFE 2010},
  pages    = {496--503},
  title    = {Sticky feet: Evolution in a multi-creature physical simulation},
  url      = {https://www.cc.gatech.edu/home/turk/my\_papers/sticky\_feet.pdf},
  year     = 2010
}

@article{Turnewitsch2013,
  abstract = {Deep-sea sediments play a central role in a wide range of subject areas. A number of important controls on the formation of sedimentary deposits have been studied. However, to date, the impact of submarine landscape geometry as a possible control has received comparatively little attention. This seems to be particularly true for intermediate-scale topographic features such as abyssal hills, knolls and seamounts that can be found in many regions of the global seafloor: recent estimates suggest that in the deep open oceans, away from continental margins, there might be as many as ~25\texttimes{}106 abyssal hills, knolls and seamounts. Despite this large number very little is known about how they influence environmental complexity and patchiness, biogeochemical fluxes and the formation of sedimentary records. This paper reviews the currently known types of fluid-flow interactions with abyssal hills, knolls and seamounts that could potentially influence the way sediments are formed. The main types of relevant flow components are: quasi-steady to eddying background flow; internal lee and near-inertial waves; barotropic and baroclinic tides; and seamount-trapped waves. Previous studies looking into systematic links between fluid dynamics and sediments at hills, knolls and seamounts are reviewed. Finally, a case study is presented which aims to combine our current knowledge and investigate whether a given combination of recent fluid-flow components leaves a detectable imprint in the recent sediments on and around a short seamount. The main conclusions and implications are as follows. (1) Topographically generated flow-field geometries that are composed of a number of different prevailing fluid-flow components can be reflected and detected in properties of the underlying sediments. (2) Tidal and other higher-frequency (lee-wave, near-inertial) components of deep-ocean currents can be essential for locally driving total current velocities across threshold values for non-deposition/erosion/resuspension of freshly deposited deep-sea sediments. Moreover, there is evidence suggesting that not only maximum current speeds but also intensities of higher-frequency (tidal and/or (near-)inertial) current-direction variability might control sediment dynamics and sediment formation. This relativises the view that current speed is the main, or even only, controlling factor for sediment dynamics and sediment formation. (3) When it comes to the reconstruction of paleo-flows, these findings imply that certain sedimentary records may well reveal more about variability in the higher-frequency flow components than about variability in the basin-scale net flow component that often is the focus of paleoceanographic studies. (4) Single-core paleo-records from hill-, seamount- or similarly controlled sediment deposits may be biased due to the asymmetry of flow fields around these topographic features. To arrive at unbiased paleo-records for non-fluid-dynamic parameters, the influence of the flow-field geometry would have to be removed from the record first. (5) It seems the mechanistic understanding of hill- and seamount-related flow/topography interactions and their links to sediment dynamics is approaching a level that may (a) facilitate improved interpretation of topographically controlled sedimentary paleo-records, (b) help fill in the knowledge gap that exists for functional deep-sea biodiversity at intermediate space scales, and (c) improve predictive capabilities for exploration of economically relevant iron-manganese (Fe-Mn) crusts on seamounts. \textcopyright{} 2013 Elsevier B.V.},
  author   = {Robert Turnewitsch and Saeed Falahat and Jonas Nycander and Andrew Dale and Robert B. Scott and Darran Furnival},
  doi      = {10.1016/j.earscirev.2013.10.005},
  issn     = {00128252},
  journal  = {Earth-Science Reviews},
  keywords = {Abyssal hill,Erosion,Non-deposition,Seamount,Sediment,Tides},
  pages    = {203--241},
  title    = {Deep-sea fluid and sediment dynamics-Influence of hill- to seamount-scale seafloor topography},
  volume   = 127,
  year     = 2013
}

@article{Tychonievich2010,
  abstract = {Computer-generated erosion and weathering are important to convey setting and mood in computer generated images. Heightmap based landforms are good for distant scenes, but inadequate for scenes containing concave rock formations. Voxel based terrain editing algorithms do admit concave surfaces but do not scale. We introduce weathering on triangulated surface meshes, using a memory efficient modification of the Delaunay deformable model. This structure allows the freedom of an unorganized point cloud, the geometric information and visualization of a surface mesh, and the topological freedom of volumetric approaches-all while scaling linearly with surface complexity. We implement both spheroidal weathering and hydraulic erosion algorithms on this structure and demonstrate that the resulting terrain is visually plausible at modest computational cost. \textcopyright{} 2010 Springer-Verlag.},
  author   = {L. A. Tychonievich and M. D. Jones},
  doi      = {10.1007/s00371-010-0506-2},
  isbn     = {0037101005},
  issn     = {01782789},
  issue    = 12,
  journal  = {Visual Computer},
  keywords = {Geometry,Terrain,Weathering},
  pages    = {1485--1495},
  title    = {Delaunay deformable mesh for the weathering and erosion of 3D terrain},
  volume   = 26,
  year     = 2010
}

@article{Tzathas2024,
  abstract  = {Terrain generation methods have long been divided between procedural and physically-based. Procedural methods build upon the fast evaluation of a mathematical function but suffer from a lack of geological consistency, while physically-based simulation enforces this consistency at the cost of thousands of iterations unraveling the history of the landscape. In particular, the simulation of the competition between tectonic uplift and fluvial erosion expressed by the stream power law raised recent interest in computer graphics as this allows the generation and control of consistent large-scale mountain ranges, albeit at the cost of a lengthy simulation. In this paper, we explore the analytical solutions of the stream power law and propose a method that is both physically-based and procedural, allowing fast and consistent large-scale terrain generation. In our approach, time is no longer the stopping criterion of an iterative process but acts as the parameter of a mathematical function, a slider that controls the aging of the input terrain from a subtle erosion to the complete replacement by a fully formed mountain range. While analytical solutions have been proposed by the geomorphology community for the 1D case, extending them to a 2D heightmap proves challenging. We propose an efficient implementation of the analytical solutions with a multigrid accelerated iterative process and solutions to incorporate landslides and hillslope processes – two erosion factors that complement the stream power law.},
  author    = {Petros Tzathas and Boris Gailleton and Philippe Steer and Guillaume Cordonnier},
  doi       = {10.1111/cgf.15033},
  issn      = 14678659,
  journal   = {Computer Graphics Forum},
  keywords  = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Shape modeling},
  publisher = {John Wiley and Sons Inc},
  title     = {Physically-based analytical erosion for fast terrain generation},
  year      = 2024
}

@article{Ugail2003,
  abstract = {This paper presents a methodology for efficient shape parametrisation for automatic design optimisation using a partial differential equation (PDE) formulation. It is shown how the choice of an elliptic PDE enables one to define and parametrise geometries corresponding to complex shapes. By using the PDE formulation it is shown how the shape definition and parametrisation can be based on a boundary value approach by which complex shapes can be created and parametrised based on the shape information at the boundaries or the character lines defining the shape. Furthermore, this approach to shape definition allows complex shapes to be parametrised intuitively using a very small set of design parameters. Thus, it is shown that the PDE based approach to shape parametrisation when combined with a standard method for numerical optimisation is capable of setting up automatic design optimisation problems allowing practical design optimisation to be more feasible. \textcopyright{} 2003 Elsevier Ltd. All rights reserved.},
  author   = {H. Ugail and M. J. Wilson},
  doi      = {10.1016/S0045-7949(03)00321-3},
  issn     = {00457949},
  issue    = {28-29},
  journal  = {Computers and Structures},
  keywords = {Automatic optimisation,PDEs,Parametric design,Shape parametrisation},
  pages    = {2601--2609},
  title    = {Efficient shape parametrisation for automatic design optimisation using a partial differential equation formulation},
  volume   = 81,
  url      = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.488.6400\&rep=rep1\&type=pdf},
  year     = 2003
}

@article{Vaillant2013,
  abstract = {Geometric skinning techniques, such as smooth blending or dualquaternions, are very popular in the industry for their high performances, but fail to mimic realistic deformations. Other methods make use of physical simulation or control volume to better capture the skin behavior, yet they cannot deliver real-time feedback. In this paper, we present the first purely geometric method handling skin contact effects and muscular bulges in real-time. The insight is to exploit the advanced composition mechanism of volumetric, implicit representations for correcting the results of geometric skinning techniques. The mesh is first approximated by a set of implicit surfaces. At each animation step, these surfaces are combined in real-time and used to adjust the position of mesh vertices, starting from their smooth skinning position. This deformation step is done without any loss of detail and seamlessly handles contacts between skin parts. As it acts as a post-process, our method fits well into the standard animation pipeline. Moreover, it requires no intensive computation step such as collision detection, and therefore provides real-time performances. Copyright \textcopyright{} ACM. Copyright \textcopyright{} ACM 2013.},
  author   = {Rodolphe Vaillant and Lo\"{\i}c Barthe and Ga\"{e}l Guennebaud and Marie Paule Cani and Damien Rohmer and Brian Wyvill and Olivier Gourmel and Mathias Paulin},
  doi      = {10.1145/2461912.2461960},
  issn     = {07300301},
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Mesh deformation with contact,Skinning},
  title    = {Implicit skinning: Real-time skin deformation with contact modeling},
  volume   = 32,
  url      = {http://rodolphe-vaillant.fr/pivotx/templates/projects/implicit\_skinning/implicit\_skinning.pdf},
  year     = 2013
}

@article{Valette2005,
  abstract = {Soil surface structure and morphology deeply influence a lot of processes of high agronomic and environmental relevance, such as mass and heat transfer through the soil-Atmosphere interface, runoff and erosion, seed germination and seedling emergence. The soil surface structure of agricultural field is in continuous evolution: it is strongly affected by tillage, and in between tillage operations, erosion by rainfall and runoff causes a progressive degradation of the structure whose intensity and speed partly depend on the initial state associated to tillage modalities. A soil surface degradation model could allow to predict this evolution of the soil surface structure, and even to help choosing adequate tillage practices and sowing dates. Erosion modelling has been addressed by soil scientists but also by computer graphic scientists in order to add realism to virtual landscapes. Mixing both of these points of view would be interesting to simulate and visualize the evolution of the soil surface of a cultivated soil. In this paper, we present our project of a simulator of soil surface degradation by rainfall at a small spatial scale (1 m2 or less), including visualization, and which is mainly based on a 3D cellular automata approach with a specific type of cell. The choices made for the implementation of our model are discussed in the light of the results found in the literature with different modelling approaches. \textcopyright{} The Eurographics Association 2005.},
  author   = {Gilles Valette and Michel Herbin and Laurent Lucas and Jo\"{e}l L\'{e}onard},
  isbn     = 3905673290,
  issn     = 18160867,
  journal  = {Natural Phenomena},
  pages    = {41--50},
  title    = {A preliminary approach of 3D simulation of soil surface degradation by rainfall},
  url      = {https://diglib.eg.org/bitstream/handle/10.2312/NPH.NPH05.041-049/041-049.pdf?sequence=1},
  year     = 2005
}

@article{Valle2014,
  author  = {Mireia Valle},
  doi     = {10.13140/2.1.2235.3606},
  issue   = {November},
  journal = {Department of Plant Biology and Ecology},
  pages   = 220,
  title   = {Seagrass meadows under a changing climate: habitat modelling, restoration and monitoring},
  year    = 2014
}

@article{Valtchanov2012a,
  abstract = {Procedural Content Generation (PCG) is the process of automating the construction of media types for use in game development, the movie industry, and other creative fields. By approaching the process of media creation as a search for content which is evaluated to express desirable features in a well-defined manner, we are able to apply evolutionary techniques such as genetic programming. This can greatly decrease the effort required to bring a project to completion by allowing artists and developers to focus on guiding the creation process. The specific generation process addressed is that of map creation for dungeon crawler video games. The search method proposed allows artists and developers to guide the generation process by specifying a set of tiles that define the composition of each map, and a fitness function that defines its structure. \textcopyright{} 2012 ACM.},
  author   = {Valtchan Valtchanov and Joseph Alexander Brown},
  doi      = {10.1145/2347583.2347587},
  isbn     = 9781450310840,
  journal  = {ACM International Conference Proceeding Series},
  keywords = {evolutionary computation,level generation,procedural content generation},
  pages    = {27--35},
  title    = {Evolving dungeon crawler levels with relative placement},
  year     = 2012
}

@misc{VanderLinden,
  abstract = {--The use of procedural content generation (PCG) techniques in game development has been mostly restricted to very specific types of game elements. PCG has seldom been deployed for generating entire game levels, a notable exception to this being dungeons: a specific type of game level often encountered in adventure and role playing games. Due to their peculiar combination of pace, gameplay, and game spaces, dungeon levels are among the most suited to showcase the benefits of PCG. This paper surveys research on procedural methods to generate dungeon game levels. We summarize common practices, discuss pros and cons of different approaches, and identify a few promising challenges ahead. In general, what current procedural dungeon generation methods are missing is not performance, but more powerful, accurate, and richer control over the generation process. Recent research results seem to indicate that gameplay-related criteria can provide this high-level control. However, this area is still in its infancy, and many research challenges still lie ahead, e.g., improving the intuitiveness and accessibility of such methods for designers. We also observe that more research is needed into generic mechanisms for automating the generation of the actual dungeon-geometric models. We conclude that the foundations for enabling gameplay-based control of dungeon-level generation are worth being researched, and that its promising results may be instrumental in bringing PCG into mainstream game development.},
  author   = {Roland van der Linden and Ricardo Lopes and Rafael Bidarra},
  keywords = {Gameplay semantics,procedural content generation,procedural level generation,role playing games},
  title    = {Procedural Generation of Dungeons},
  url      = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=666850\&casa\_token=4-Rzyr\_kUm4AAAAA:y2VoZC1B2DmFwUm4r8G4jp2gVsKpjdjuJvTEWdP1hesQb\_zbsb7u7fe3UM49I6NBXrjx0BLzzxU\&tag=1}
}

@article{VanderLinden2014,
  author    = {Roland van der Linden and Ricardo Lopes and Rafael Bidarra},
  issue     = 1,
  journal   = {IEEE Transactions on Computational Intelligence and AI in Games},
  title     = {Procedural Generation of Dungeons},
  volume    = 6,
  url       = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782107},
  year      = 2014,
  abstract  = {The use of procedural content generation (PCG) techniques in game development has been mostly restricted to very specific types of game elements. PCG has seldom been deployed for generating entire game levels, a notable exception to this being dungeons: a specific type of game level often encountered in adventure and role playing games. Due to their peculiar combination of pace, gameplay, and game spaces, dungeon levels are among the most suited to showcase the benefits of PCG. This paper surveys research on procedural methods to generate dungeon game levels. We summarize common practices, discuss pros and cons of different approaches, and identify a few promising challenges ahead. In general, what current procedural dungeon generation methods are missing is not performance, but more powerful, accurate, and richer control over the generation process. Recent research results seem to indicate that gameplay-related criteria can provide this high-level control. However, this area is still in its infancy, and many research challenges still lie ahead, e.g., improving the intuitiveness and accessibility of such methods for designers. We also observe that more research is needed into generic mechanisms for automating the generation of the actual dungeon-geometric models. We conclude that the foundations for enabling gameplay-based control of dungeon-level generation are worth being researched, and that its promising results may be instrumental in bringing PCG into mainstream game development. \textcopyright{} 2014 IEEE.},
  doi       = {10.1109/TCIAIG.2013.2290371},
  issn      = {1943068X},
  keywords  = {Gameplay semantics,procedural content generation,procedural level generation,role playing games},
  note      = {Beaucoup d'exemples d'algos},
  pages     = {78--89},
  publisher = {IEEE}
}

@article{VanDerMaaten2008,
  abstract = {We present a new technique called "t-SNE" that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza-tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
  author   = {Laurens Van Der Maaten and Geoffrey Hinton},
  journal  = {Journal of Machine Learning Research},
  keywords = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization},
  pages    = {2579--2605},
  title    = {Visualizing Data using t-SNE},
  volume   = 9,
  year     = 2008
}

@article{vanDijk2017,
  abstract = {This thesis is about cellular automata and whether or not they are able to solve different kinds of puzzles. In the first part it is explained what a cellular autamaton is and how it works. Furthermore is the connection between puzzles and cellular automata explained and some related work is given.},
  author   = {Stef van Dijk},
  keywords = {Thesis Bachelor Informatica - 2016-2017},
  title    = {Solving Puzzles using Cellular Automata},
  url      = {www.liacs.leidenuniv.nl},
  year     = 2017
}

@article{VanLawickvanPabst1996,
  abstract = {The work, described in this paper, covers three topics: real-world terrain analysis, synthetic terrain generation based upon the results of the analysis stage, and dynamic terrain generation. Each topic involves the theory of multifractals. First, a summary of four known fractal-based techniques for terrain generation is presented including fractional Brownian motion, Mid-point displacement, Iterated Function Systems and the multifractal formalism. The multifractal formalism was chosen for both the analysis of realworld terrain data, as well as the generation of synthetic terrain surfaces. The authors implemented a multifractal terrain analysis algorithm that captures terrain characteristics of real-world data, into five parameters. These parameters were put into a multifractal terrain generation algorithm that produced synthetic terrain with features similar to those in the terrain that was analysed. Also, an algorithm for zooming in on synthetic terrain was developed. Finally, an application was developed that generates terrain dynamically. 1},
  author   = {Joost van Lawick van Pabst and Hans Jense},
  doi      = {10.1007/978-1-4471-1011-8\_13},
  journal  = {High Performance Computing for Computer Graphics and Visualisation},
  pages    = {186--203},
  title    = {Dynamic Terrain Generation Based on Multifractal Techniques},
  year     = 1996
}

@article{VanLinden2013,
  abstract = {There is an increasing demand to improve the procedural generation of game levels. Our approach empowers game designers to author and control level generators, by expressing gameplay-related design constraints. Graph grammars, resulting from these designer-expressed constraints, can generate sequences of desired player actions as well as their associated target content. These action graphs are used to determine layouts and content for game levels. We showcase this approach with a case study on a dungeon crawler game. Results allow us to conclude that our control mechanisms are both expressive and powerful, effectively supporting designers to procedurally generate levels. Copyright \textcopyright{} 2013, Association for the Advancement of Artificial Intelligence. All rights reserved.},
  author   = {Roland van der Linden and Ricardo Lopes and Rafael Bidarra},
  isbn     = 9781577356356,
  issue    = 2010,
  journal  = {AAAI Workshop - Technical Report},
  keywords = {AAAI Technical Report WS-13-20},
  note     = {Not interesting...},
  pages    = {41--47},
  title    = {Designing procedurally generated levels},
  volume   = {WS-13-20},
  year     = 2013
}

@inproceedings{Varpa2011,
  abstract  = {We studied how the splitting of a multi-class classification problem into multiple binary classification tasks, like One-vs-One (OVO) and One-vs-All (OVA), affects the predictive accuracy of disease classes. Classifiers were tested with an otoneurological data using 10-fold cross-validation 10 times with k-Nearest Neighbour (k-NN) method and Support Vector Machines (SVM). The results showed that the use of multiple binary classifiers improves the classification accuracies of disease classes compared to one multi-class classifier. In general, OVO classifiers worked out better with this data than OVA classifiers. Especially, the OVO with k-NN yielded the highest total classification accuracies. \textcopyright{} 2011 European Federation for Medical Informatics. All rights reserved.},
  author    = {Kirsi Varpa and Henry Joutsijoki and Kati Iltanen and Martti Juhola},
  doi       = {10.3233/978-1-60750-806-9-579},
  isbn      = 9781607508052,
  issn      = 18798365,
  booktitle = {Studies in Health Technology and Informatics},
  keywords  = {Binary classifiers,K-nearest neighbour method,Multi-class classification,Otoneurology,Support vector machines},
  pages     = {579--583},
  publisher = {IOS Press},
  title     = {Applying one-vs-one and one-vs-all classifiers in k-nearest neighbour method and support vector machines to an otoneurological multi-class problem},
  volume    = 169,
  url       = {https://ebooks.iospress.nl/doi/10.3233/978-1-60750-806-9-579},
  year      = 2011
}

@article{Vasa2011,
  abstract = {There are multiple areas of computer graphics where triangular meshes are being altered in order to reduce their size or complexity, while attempting to preserve the original shape of the mesh as closely as possible. Recently, this area of research has been extended to cover even a dynamic case, i.e., surface animations which are compressed and simplified. However, to date very little effort has been made to develop methods for evaluating the results, namely the amount of distortion introduced by the processing. Even the most sophisticated compression methods use distortion evaluation by some kind of mean squared error while the actual relevance of such measure has not been verified so far. In this paper, we point out some serious drawbacks of the existing error measures. We present results of the subjective testing that we have performed, and we derive a new measure called Spatiotemporal edge difference (STED) which is shown to provide much better correlation with subjective opinions on mesh distortion.},
  author   = {Libor V\'{a}\v{s}a and V\'{a}clav Skala},
  doi      = {10.1109/TVCG.2010.38},
  issue    = 2,
  journal  = {IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS},
  keywords = {Animation,discrepancy,distortion,dynamic mesh.,error,evaluation,measure},
  title    = {A Perception Correlated Comparison Method for Dynamic Meshes},
  volume   = 17,
  year     = 2011
}

@article{Velho1994,
  abstract    = {This thesis presents a complete framework for the description of implicit surfaces and solids We propose piecewise representations that are based on decomposition models and constructed using methods adapted to the geometry of ob jects These models are general in the sense that they can represent arbitrary shapes and support variable precision permitting approximations at any desirable resolution The contribution of our work consists of i an original characterization of the implicit description of shapes ii a new method for generating a smooth implicit function corresponding to a solid ob ject and iii two new piecewise representation schemes based on a multiscale decomposition of the implicit function and on an adapted simplicial decomposition of the domain of the implicit function We characterize the implicit model through an analysis of the implicit function We show that the skeleton of a shape and the tubular neighborhood of its boundary are dual structures that relate an ob ject with the space in which it is embedded We develop a method that allows the generation of smooth implicit functions from the characteristic function of an ob ject It employs multiresolution edge detection and reconstruction using dyadic wavelets We introduce a functional decomposition model based on B spline scaling func tions that generate nested multiscale approximating spaces The Laplacian transform is employed to compute a pyramid in terms of these B spline bases We introduce a spatial decomposition model based on adapted simplicial subdivi sion Physics based deformation adapts to the boundary of the ob ject a mesh derived from this simplicial complex Some of the applications of these methods include approximate conversion be tween volumetric implicit and parametric representations surface rendering volume visualization and animation of implicit objects In summary the relevance of this thesis is twofold it provides a conceptual as well as a practical scheme for piecewise shape description The piecewise implicit representations that we have developed are e ective and e cient They capture the spatial features of ob jects using composite structures that are constructed from simple elements},
  author      = {Luiz Velho},
  institution = {University of Toronto},
  title       = {Piecewise Descriptions of Implicit Surfaces and Solids},
  url         = {http://web.cs.ucla.edu/~dt/theses/velho-thesis.pdf},
  year        = 1994
}

@article{Veltkamp2001,
  abstract = {Shape matching is an important ingredient in shape retrieval, recognition and classification, alignment and registration, and approximation and simplification. This paper treats various aspects that are needed to solve shape matching problems: choosing the precise problem, selecting the properties of the similarity measure that are needed for the problem, choosing the specific similarity measure, and constructing the algorithm to compute the similarity. The focus is on methods that lie close to the field of computational geometry. \textcopyright{} 2001 IEEE.},
  author   = {Remco C. Veltkamp},
  doi      = {10.1109/SMA.2001.923389},
  isbn     = {0769508537},
  journal  = {Proceedings - International Conference on Shape Modeling and Applications, SMI 2001},
  pages    = {188--197},
  title    = {Shape matching: Similarity measures and algorithms},
  url      = {https://webspace.science.uu.nl/~veltk101/publications/art/smi2001.pdf},
  year     = 2001
}

@article{Verlet1967,
  abstract = {The equation of motion of a system of 864 particles interacting through a Lennard-Jones potential has been integrated for various values of the temperature and density, relative, generally, to a Quid state. The equilibrium properties have been calculated and are shoran to agree very vreH vrith the corresponding properties of argon. It is concluded that, to a good approximation, the equilibrium state of argon can be described thlough a t\&o-twdy potential.},
  author   = {Loup Verlet},
  doi      = {10.1103/PhysRev.159.98},
  issn     = {0031-899X},
  issue    = 1,
  journal  = {Physical Review},
  month    = 7,
  pages    = {98--103},
  title    = {Computer "Experiments" on Classical Fluids. I. Thermodynamical Properties of Lennard-Jones Molecules},
  volume   = 159,
  url      = {https://link.aps.org/doi/10.1103/PhysRev.159.98},
  year     = 1967
}

@inbook{VilaConcejo2016,
  abstract  = {This chapter examines the effects of storm events on coral reefs and reef-associated landforms. It begins with a brief examination of the geomorphic units of reef systems, places the physical dynamics of reefs within an eco-morphodynamic framework and highlights the unique aspects of the interaction of waves and storm waves with reef systems that force ecological and geomorphic change. The focus of the chapter is on the event-scale effects of storm events. Storm effects are considered with respect to both the structure of coral reefs, which is further considered on the different morphological components, and sedimentary landforms. Storm driven effects are placed within the eco-morphodynamic framework that reflects the interaction of biological and physical processes. The chapter also highlights contemporary research questions in understanding the influence of storms on the current dynamics and future trajectories of coral reef structure and associated sedimentary landforms.},
  author    = {Ana Vila-Concejo and Paul Kench},
  doi       = {10.1002/9781118937099.ch7},
  isbn      = 9781118937099,
  journal   = {Coastal Storms: Processes and Impacts},
  keywords  = {Coral reefs,Eco-morphodynamic framework,Morphological components,Reef-associated landforms,Sedimentary landforms,Storm events},
  month     = 8,
  pages     = {127--149},
  publisher = {Wiley Blackwell},
  title     = {Storms in Coral Reefs},
  year      = 2016
}

@article{Villanueva2017,
  abstract = {Voxelized representations of complex 3D scenes are widely used to accelerate visibility queries in many GPU rendering techniques. Since GPU memory is limited, it is important that these data structures can be kept within a strict memory budget. Recently, directed acyclic graphs (DAGs) have been successfully introduced to compress sparse voxel octrees (SVOs), but they are limited to sharing identical regions of space. In this paper, we show that a more efficient lossless compression of geometry can be achieved while keeping the same visibility-query performance. This is accomplished by merging subtrees that are identical through a similarity transform and by exploiting the skewed distribution of references to shared nodes to store child pointers using a variabile bit-rate encoding. We also describe how, by selecting plane reflections along the main grid directions as symmetry transforms, we can construct highly compressed GPU-friendly structures using a fully out-of-core method. Our results demonstrate that state-of-the-art compression and real-time tracing performance can be achieved on high- resolution voxelized representations of real-world scenes of very different characteristics, including large CAD models, 3D scans, and typical gaming models, leading, for instance, to real-time GPU in-core visualization with shading and shadows of the full Boeing 777 at sub-millimeter precision. This article is based on an earlier work: SSVDAGs: Symmetry-aware Sparse Voxel DAGs, in Proceedings of the 20th ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games c ?ACM, 2016. http://dx.doi.org/10.1145/2856400.2856420. We include here a more thorough exposition, a description of alternative construction and tracing methods, as well as additional results. In order to facilitate understanding, evaluation and extensions, the full source code of the method is provided in the supplementary material.},
  author   = {Alberto Jaspe Villanueva and Fabio Marton and Enrico Gobbetti},
  issue    = 2,
  journal  = {Journal of Computer Graphics Techniques},
  keywords = {Journal of Computer Graphics Techniques},
  pages    = {1--30},
  title    = {Symmetry-aware Sparse Voxel DAGs ( SSVDAGs ) for compression-domain tracing of high-resolution geometric scenes},
  volume   = 6,
  year     = 2017
}

@article{Vinyals2015,
  abstract = {We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. Such problems cannot be trivially addressed by existent approaches such as sequence-to-sequence and Neural Turing Machines, because the number of target classes in each step of the output depends on the length of the input, which is variable. Problems such as sorting variable sized sequences, and various combinatorial optimization problems belong to this class. Our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention. It differs from the previous attention attempts in that, instead of using attention to blend hidden units of an encoder to a context vector at each decoder step, it uses attention as a pointer to select a member of the input sequence as the output. We call this architecture a Pointer Net (Ptr-Net). We show Ptr-Nets can be used to learn approximate solutions to three challenging geometric problems -- finding planar convex hulls, computing Delaunay triangulations, and the planar Travelling Salesman Problem -- using training examples alone. Ptr-Nets not only improve over sequence-to-sequence with input attention, but also allow us to generalize to variable size output dictionaries. We show that the learnt models generalize beyond the maximum lengths they were trained on. We hope our results on these tasks will encourage a broader exploration of neural learning for discrete problems.},
  author   = {Oriol Vinyals and Meire Fortunato and Navdeep Jaitly},
  journal  = {Nips 2015},
  pages    = {1--9},
  title    = {Pointer Networks},
  url      = {http://arxiv.org/abs/1506.03134},
  year     = 2015
}

@article{VitalBrazil2010,
  abstract = {We present techniques for modeling Variational Hermite Radial Basis Function (VHRBF) Implicits using a set of sketch-based interface and modeling (SBIM) operators. VHRBF Implicits is a simple and compact representation well suited for SBIM. It provides quality reconstructions, preserving the intended shape from a coarse and non-uniform number of point-normal samples extracted directly from the input strokes. In addition, it has a number of desirable properties such as parameter-free modeling, invariance under geometric similarities on the input strokes, suitable estimation of differential quantities, good behavior near close sheets, and both linear fitting and reproduction. Our approach uses these properties of VHRBF Implicits to quickly and robustly generate the overall shape of 3D models. We present examples of implicit models obtained from a set of SBIM language operators for contouring, cross-editing, kneading, oversketching and merging.},
  author   = {Emilio Vital Brazil and Ives Macedo and Mario Costa Sousa and Luiz Henrique de Figueiredo and L Velho},
  doi      = {10.2312/SBM/SBM10/001-008},
  journal  = {Proceedings of the Seventh Sketch-Based Interfaces and Modeling Symposium},
  pages    = {1--8},
  title    = {Sketching Variational Hermite-RBF Implicits},
  url      = {https://diglib.eg.org/bitstream/handle/10.2312/SBM.SBM10.001-008/001-008.pdf?sequence=1\&isAllowed=n},
  year     = 2010
}

@article{VonRadziewsky2016,
  abstract = {We propose a novel construction of subspaces for real-time deformation-based modeling and shape interpolation. The scheme constructs a subspace that optimally approximates the manifold of deformations relevant for a specific modeling or interpolation problem. The idea is to automatically sample the deformation manifold and construct the subspace that best-approximates these snapshots. This is realized by writing the shape modeling and interpolation problems as parametrized optimization problems with few parameters. The snapshots are generated by sampling the parameter domain and computing the corresponding minimizers. Finally, the optimized subspaces are constructed using a mass-dependent principle component analysis. The optimality provided by this scheme contrasts it from alternative approaches, which aim at constructing spaces containing low-frequency deformations. The benefit of this construction is that compared to alternative approaches a similar approximation quality is achieved with subspaces of significantly smaller dimension. This is crucial because the run-times and memory requirements of the real-time shape modeling and interpolation schemes mainly depend on the dimensions of the subspaces.},
  author   = {Philipp Von Radziewsky and Elmar Eisemann and Hans Peter Seidel and Klaus Hildebrandt},
  doi      = {10.1016/j.cag.2016.05.016},
  issn     = {00978493},
  journal  = {Computers and Graphics (Pergamon)},
  keywords = {Shape deformation,Shape interpolation,Shape modeling},
  pages    = {128--138},
  title    = {Optimized subspaces for deformation-based modeling and shape interpolation},
  volume   = 58,
  url      = {https://graphics.tudelft.nl/Publications-new/2016/VESH16/optimizedSubspaces.pdf},
  year     = 2016
}

@article{Vortsepneva2008,
  author  = {Elena Vortsepneva},
  issue   = {November},
  journal = {Geomorfology, oceanology, biology},
  pages   = 44,
  title   = {Saya de Malha Bank – an invisible island in the Indian Ocean},
  url     = {https://lighthouse-foundation.org/Binaries/Binary1070/Saya-de-Malha-report-final.pdf},
  year    = 2008
}

@article{Wakwella2022,
  abstract = {\ldots{} by the Fijian government as the three plagues: leptospirosis, typhoid, and dengue (hereafter \ldots{} for ecosystem services: practice learns from theory and theory can learn from practice.'' Oryx \ldots{}},
  author   = {A Wakwella and A Wegner and S Jupiter and J Lamb and ...},
  issue    = {March},
  journal  = {Wildlife Conservative \ldots{}},
  pages    = {1--22},
  title    = {Managing Watersheds for Coral Reefs and Public Health: A Vibrant Oceans Initiative Whitepaper},
  url      = {https://repository.fnu.ac.fj/id/eprint/42/},
  year     = 2022
}

@article{Walsh2010,
  abstract  = {This paper introduces the Auto Terrain Generation System (ATGS), which is based on an Interactive Genetic Algorithm (IGA) that enables non-specialist users to rapidly generate terrains. The motivation for using an IGA is discussed, existing terrain generation techniques are described and a new approach, based on a fractal terrain engine, is outlined. Graphics engines allow terrains to be specified with over 800 floating point parameters, which can overwhelm non-specialist users. These parameters also create a vast search space for auto-terrain generation systems that can complicate procedural techniques. ATGS addresses these issues via interaction with the user, which is implemented in ATGS by a web based user interface that allows users to rapidly indicate terrain preferences. These user preferences are used by a genetic algorithm to explore a multi-dimensional parameter space that satisfies the user's intuition and aesthetics. Proof of concept experiments are outlined, results are presented and future research work is projected. \textcopyright{} 2010 IEEE.},
  author    = {Paul Walsh and Prasad Gade},
  doi       = {10.1109/CEC.2010.5585913},
  isbn      = 9781424469109,
  journal   = {2010 IEEE World Congress on Computational Intelligence, WCCI 2010 - 2010 IEEE Congress on Evolutionary Computation, CEC 2010},
  publisher = {IEEE},
  title     = {Terrain generation using an interactive genetic algorithm},
  year      = 2010
}

@article{Walton1993,
  abstract = {Molecular-dynamics-like simulations are utilized to map regions of flow parameter space where steady flows occur for monodisperse assemblies of inelastic, frictional spheres, flowing down frictional, inclined planar surfaces. The trajectory-following technique utilizes nearly-rigid particles interacting via contact forces and gravity. Energy losses in the simulations occur only via displacement-dependent hysteretic loading/unloading paths and sliding friction. Initial scoping calculations are examining flows on an incline tilted 17 \textdegree{} from the horizontal, determining the boundaries of various flow regimes. Assemblies of inelastic spheres with interparticle friction coefficients less than the tangent of the inclination angle accelerate unboundedly. Those with friction coefficients somewhat greater than the tangent of the inclination angle develop steady velocity and density profiles for a variety of flow depths but result in arrested flow for coefficients of friction greatly exceeding the inclination angle tangent (e.g., by more than a factor of 2). Conversely, a significant range of inclination angles that will result in steady flows for a given set of assembly properties, is expected to exist.},
  author   = {Otis R. Walton},
  doi      = {10.1016/0167-6636(93)90048-V},
  issn     = {01676636},
  issue    = {1-2},
  journal  = {Mechanics of Materials},
  month    = 8,
  pages    = {239--247},
  title    = {Numerical simulation of inclined chute flows of monodisperse, inelastic, frictional spheres},
  volume   = 16,
  url      = {https://linkinghub.elsevier.com/retrieve/pii/016766369390048V},
  year     = 1993
}

@article{Wampler2009,
  abstract = {We present a fully automatic method for generating gaits and morphologies for legged animal locomotion. Given a specific animal's shape we can determine an efficient gait with which it can move. Similarly, we can also adapt the animal's morphology to be optimal for a specific locomotion task. We show that determining such gaits is possible without the need to specify a good initial motion, and without manually restricting the allowed gaits of each animal. Our approach is based on a hybrid optimization method which combines an efficient derivative-aware spacetime constraints optimization with a derivative-free approach able to find non-local solutions in high-dimensional discontinuous spaces. We demonstrate the effectiveness of this approach by synthesizing dynamic locomotions of bipeds, a quadruped, and an imaginary five-legged creature. \textcopyright{} 2009 ACM.},
  author   = {Kevin Wampler and Zoran Popovi},
  doi      = {10.1145/1531326.1531366},
  issn     = {07300301},
  issue    = 3,
  journal  = {ACM Transactions on Graphics},
  keywords = {Animation,Character dynamics,Gait,Spacetime optimization},
  title    = {Optimal gait and form for animal locomotion},
  volume   = 28,
  year     = 2009
}

@misc{Wang,
  abstract = {Accurate modeling and simulation of underwater vehicles is essential for autonomous control. In this paper, we present a dynamic model of the VideoRay Pro III microROV, in which the hydrodynamic derivatives are determined both theoretically and experimentally, based on the assumption that the motions in different directions are decoupled. The experi\- ments show that this assumption is reasonable within operating conditions of the VideoRay Pro fuw. A computer simulation with 3D graphics is also developed to help user to visualize the vehicle's motion.},
  author   = {Wei Wang and Christopher M Clark},
  isbn     = 1424401380,
  title    = {Modeling and Simulation of the VideoRay Pro III Underwater Vehicle}
}

@article{Wang_a_2019,
  author  = {Xiyao Wang and Lonni Besan\c{c}on and Florimond Gu\'{e}niat and Mickael Sereno and Mehdi Ammi and Tobias Isenberg},
  journal = {The ACM CHI Conference on Human Factors in Computing Systems - Workshop on Interaction Design \& Prototyping for Immersive Analytics},
  title   = {A Vision of Bringing Immersive Visualization to Scientific Workflows},
  url     = {https://hal.archives-ouvertes.fr/hal-02053969},
  year    = 2019
}

@article{Wang2011,
  abstract = {We introduce multiscale vector volumes, a compact vector repre- sentation for volumetric objects with complex internal structures spanning a wide range of scales. With our representation, an object is decomposed into components and each component is modeled as an SDF tree, a novel data structure that uses multiple signed dis- tance functions (SDFs) to further decompose the volumetric com- ponent into regions. Multiple signed distance functions collectively can represent non-manifold surfaces and deliver a powerful vector representation for complex volumetric features. We use multiscale embedding to combine object components at different scales into one complex volumetric object. As a result, regions with dramat- ically different scales and complexities can co-exist in an object. To facilitate volumetric object authoring and editing, we have also developed a scripting language and a GUI prototype. With the help of a recursively defined spatial indexing structure, our vector repre- sentation supports fast random access, and arbitrary cross sections of complex volumetric objects can be visualized in real time.},
  author   = {L Wang and Y Yu and K Zhou and B Guo},
  doi      = {doi.acm.org/10.1145/2024156.2024201},
  issue    = 6,
  journal  = {ACM SIGGRAPH Asia},
  keywords = {multiscale representations,volumetric modeling},
  pages    = {12--15},
  title    = {Multiscale vector volumes},
  volume   = 30,
  url      = {https://core.ac.uk/download/pdf/37973373.pdf},
  year     = 2011
}

@article{Wang2013,
  abstract  = {Many computational models of visual attention performing well in predicting salient areas of 2D images have been proposed in the literature. The emerging applications of stereoscopic 3D display bring additional depth information affecting the human viewing behavior, and require extensions of the efforts made in 2D visual modeling. In this paper, we propose a new computational model of visual attention for stereoscopic 3D still image. Apart from detecting salient areas based on 2D visual features, the proposed model takes depth as an additional visual dimension. The measure of depth saliency is derived from the eye movement data obtained from an eye-tracking experiment using synthetic stimuli. Two different ways of integrating depth information in the modeling of 3D visual attention are then proposed and examined. For the performance evaluation of 3D visual attention models, we have created an eye-tracking database which contains stereoscopic images of natural content and is publicly available along with this paper. The proposed model gives a good performance, compared to that of state-of-the-art 2D models on 2D images. The results also suggest that a better performance is obtained when depth information is taken into account through the creation of a depth saliency map rather than when it is integrated by a weighting method.},
  author    = {Junle Wang and Matthieu Perreira da Silva and Patrick Le Callet and Vincent Ricordel and Matthieu Perreira Da Silva},
  doi       = {10.1109/TIP.2013.2246176\"{\i}},
  issn      = {2151-2165},
  issue     = 6,
  journal   = {IEEE Transactions on Image Processing},
  keywords  = {3DTV,Index Terms-Visual attention,depth saliency,eye-tracking,saliency map,stereoscopy},
  publisher = {Institute of Electrical and Electronics Engineers},
  title     = {A computational model of stereoscopic 3D visual saliency A computational model of stereoscopic 3D visual saliency A computational model of stereoscopic 3D visual saliency},
  volume    = 22,
  url       = {https://hal.archives-ouvertes.fr/hal-00788847},
  year      = 2013
}

@article{Wang2019,
  abstract = {We present a new framework for interior scene synthesis that combines a high-level relation graph representation with spatial prior neural networks. We observe that prior work on scene synthesis is divided into two camps: object-oriented approaches (which reason about the set of objects in a scene and their configurations) and space-oriented approaches (which reason about what objects occupy what regions of space). Our insight is that the object-oriented paradigm excels at high-level planning of how a room should be laid out, while the space-oriented paradigm performs well at instantiating a layout by placing objects in precise spatial configurations. With this in mind, we present PlanIT, a layout-generation framework that divides the problem into two distinct planning and instantiation phases. PlanIT represents the ``plan'' for a scene via a relation graph, encoding objects as nodes and spatial/semantic relationships between objects as edges. In the planning phase, it uses a deep graph convolutional generative model to synthesize relation graphs. In the instantiation phase, it uses image-based convolutional network modules to guide a search procedure that places objects into the scene in a manner consistent with the graph. By decomposing the problem in this way, PlanIT generates scenes of comparable quality to those generated by prior approaches (as judged by both people and learned classifiers), while also providing the modeling flexibility of the intermediate relationship graph representation. These graphs allow the system to support applications such as scene synthesis from a partial graph provided by a user.},
  author   = {Kai Wang and Yu An Lin and Ben Weissmann and Manolis Savva and Angel X. Chang and Daniel Ritchie},
  doi      = {10.1145/3306346.3322941},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Convolutional networks,Deep learning,Graph generation,Indoor scene synthesis,Neural networks,Object layout,Relationship graphs},
  title    = {Planit: Planning and instantiating indoor scenes with relation graph and spatial prior networks},
  volume   = 38,
  url      = {https://dl.acm.org/doi/pdf/10.1145/3306346.3322941},
  year     = 2019
}

@article{Wang2020,
  abstract = {Virtual reality (VR) offers an artificial, computer generated simulation of a real life environment. It originated in the 1960s and has evolved to provide increasing immersion, interactivity, imagination, and intelligence. Because deep learning systems are able to represent and compose information at various levels in a deep hierarchical fashion, they can build very powerful models which leverage large quantities of visual media data. Intelligence of VR methods and applications has been significantly boosted by the recent developments in deep learning techniques. VR content creation and exploration relates to image and video analysis, synthesis and editing, so deep learning methods such as fully convolutional networks and general adversarial networks are widely employed, designed specifically to handle panoramic images and video and virtual 3D scenes. This article surveys recent research that uses such deep learning methods for VR content creation and exploration. It considers the problems involved, and discusses possible future directions in this active and emerging research area.},
  author   = {Miao Wang and Xu Quan Lyu and Yi Jun Li and Fang Lue Zhang},
  doi      = {10.1007/s41095-020-0162-z},
  issn     = 20960662,
  issue    = 1,
  journal  = {Computational Visual Media},
  keywords = {360\textdegree{} image and video virtual content,deep learning,neural networks,virtual reality},
  pages    = {3--28},
  title    = {VR content creation and exploration with deep learning: A survey},
  volume   = 6,
  year     = 2020
}

@article{Wang2021a,
  abstract  = {The prediction of the bulk drag coefficient (CD) for aquatic vegetation is of great significance for evaluating the influence of vegetation on the hydrodynamic processes in wave environments. Different CD empirical formulas have been mostly proposed as functions of either Reynolds (Re) number or Keulegan–Carpenter (KC) number in the literature, and the influences of other wave and vegetation parameters on CD were often ignored. The difference in formulas is largely attributable to inconsistent uses of characteristic velocity and length scales in the definitions of Re and KC. By considering the vegetation and hydrodynamic characteristics in this study, new Re and KC numbers were redefined using the mean pore velocity and vegetation-related hydraulic radius. Besides, a genetic programming algorithm was adopted to develop a robust relationship between CD and possible dimensionless variables based on extensive experimental data. Ultimately, a new CD predictor that has a similar form to that of the classical expression was obtained without any prespecified forms before searching. It turns out that the new predictor depends on not only the new KC number but also the submergence ratio and Ursell number. Compared with the existing predictors, the proposed CD predictor exhibits a considerable improvement in predictive ability for a wider parameter space.},
  author    = {Yanxu Wang and Zegao Yin and Yong Liu},
  doi       = {10.1016/j.oceaneng.2021.108694},
  issn      = {00298018},
  journal   = {Ocean Engineering},
  keywords  = {Aquatic vegetation,Bulk drag coefficient,Genetic programming,Predictor,Wave flows},
  month     = 3,
  pages     = 108694,
  publisher = {Elsevier Ltd},
  title     = {Predicting the bulk drag coefficient of flexible vegetation in wave flows based on a genetic programming algorithm},
  volume    = 223,
  year      = 2021
}

@article{Wang2022,
  abstract = {Bidirectional Scattering Distribution Functions (BSDFs) encode how a material reflects or transmits the incoming light. The most commonly used model is the microfacet BSDF. It computes the material response from the microgeometry of the surface assuming a single bounce on specular microfacets. The original model ignores multiple bounces on the microgeometry, resulting in an energy loss, especially for rough materials. In this paper, we present a new method to compute the multiple bounces inside the microgeometry, eliminating this energy loss. Our method relies on a position-free formulation of multiple bounces inside the microgeometry. We use an explicit mathematical definition of the path space that describes single and multiple bounces in a uniform way. We then study the behavior of light on the different vertices and segments in the path space, leading to a reciprocal multiple-bounce description of BSDFs. Furthermore, we present practical, unbiased Monte Carlo estimators to compute multiple scattering. Our method is less noisy than existing algorithms for computing multiple scattering. It is almost noise-free with a very-low sampling rate, from 2 to 4 samples per pixel (spp).},
  author   = {Beibei Wang and Wenhua Jin and Jiahui Fan and Jian Yang and Nicolas Holzschuch and Ling Qi Yan},
  doi      = {10.1145/3528223.3530112},
  issn     = 15577368,
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {full-spherical,microfacet,multiple-bounce,position-free},
  pages    = {1--14},
  title    = {Position-free multiple-bounce computations for smith microfacet BSDFs},
  volume   = 41,
  url      = {https://wangningbei.github.io/2022/MBBRDF\_files/paper\_MBBRDF.pdf},
  year     = 2022,
  isbn     = 9783031200618
}

@article{Warszawski2019,
  abstract = {Natural terrains created by long-term erosion processes can sometimes have spectacular forms and shapes. The visible form depends often upon internal geological structure and materials. One of the unique terrain artefacts occur in the form of table mountains and can be observed in the Monument Valley (Colorado Plateau, USA). In the following article a procedural method is considered for terrain modelling of structures, geometrically similar to the mesas and buttes hills. This method is not intended to simulate physically inspired erosion processes, but targets directly the generation of eroded forms. The results can be used as assets by artists and designers. The proposed terrain model is based on a height-field representation extended by materials and its hardness information. The starting point of the technique is the Poisson Faulting algorithm that was originally used to obtain fractional Brownian surfaces. In the modification, the step function as the fault line generator was replaced with a circular one. The obtained geometry was used for materials' classification and the hardness part of the modelled terrain. The final model was achieved by the erosive modification of geometry according to the materials and its hardness data. The results are similar to the structures observed in nature and are achieved within an acceptable time for real-time interactions.},
  author   = {Korneliusz K. Warszawski and S\l{}awomir S. Nikiel and Marcin Mrugalski},
  doi      = {10.3390/app9112352},
  issn     = 20763417,
  issue    = 11,
  journal  = {Applied Sciences (Switzerland)},
  keywords = {Computer graphics,Erosion simulation,Poisson faulting,Terrain modelling,Virtual environment},
  title    = {Procedural method for fast table mountains modelling in virtual environments},
  volume   = 9,
  year     = 2019
}

@article{Watanabe2004,
  author  = {Nayuko Watanabe and Takeo Igarashi},
  doi     = {10.1145/1186415.1186500},
  isbn    = 1581138962,
  journal = {ACM SIGGRAPH 2004 Posters, SIGGRAPH 2004},
  pages   = 73,
  title   = {A sketching interface for terrain modeling},
  year    = 2004
}

@article{Watling2013,
  abstract  = {While there are many generalized schemes representing the biogeographic distribution of life in the deep sea, reviewed here, a comprehensive analysis has not been undertaken since Vinogradova (1979, 1997) for the abyssal and Belyaev (1989) for the hadal. The purpose of this paper is to propose global biogeographic provinces for the lower bathyal and abyssal benthos (>800. m depths) in order to aid high seas management efforts. Biological samples from these depths are sparse so delineation of biogeographic provinces was initially hypothesized using oceanographic proxies, and examined with documented locations of select benthic marine species. These biogeographic provinces were first developed in 2009 via an expert consultation workshop to delineate biogeographic provinces in offshore regions - the Global Open Ocean and Deep Sea (GOODS) classification. We have refined the GOODS deep-sea classification by incorporating additional high-resolution hydrographic and organic-matter flux data for the seafloor. Water mass characteristics (temperature and salinity) and particulate organic flux to the seafloor were the strongest determinants in the final delineation of provincial boundaries. This process resulted in the delineation of 14 lower bathyal and 14 abyssal provinces. The bathyal and abyssal classifications presented here should be used with other management tools and analyses (e.g., predictive habitat modeling, seamount classifications, etc.) to help determine where marine protected areas should be placed and to minimize the negative impacts of commercial activities in the high seas. \textcopyright{} 2012 Elsevier Ltd.},
  author    = {Les Watling and John Guinotte and Malcolm R. Clark and Craig R. Smith},
  doi       = {10.1016/j.pocean.2012.11.003},
  issn      = {00796611},
  journal   = {Progress in Oceanography},
  note      = {Can be useful for later (faune/flore)},
  pages     = {91--112},
  publisher = {Elsevier Ltd},
  title     = {A proposed biogeography of the deep ocean floor},
  volume    = 111,
  url       = {http://dx.doi.org/10.1016/j.pocean.2012.11.003},
  year      = 2013
}

@article{Watson2005,
  abstract = {Three underwater stereo-video techniques were used to sample the relative densities and species richness of temperate reef fish assemblages at three reef locations and two habitats (high- and low-relief reef) within Hamelin Bay, south-western Australia. The three techniques compared were diver-operated stereo-video strip transects, baited remote stereo-video and unbaited remote stereo-video. While unbaited remote stereo-video and diver-operated stereo-video transects recorded greater species richness at high compared to low-relief reefs, baited remote stereo-video recorded similar species richness at the two habitat types. The diver-operated stereo-video system was manoeuvred through caves and under overhangs recording small, cryptic, cave-dwelling species that were not recorded by either remote video techniques (Trachinops noarlungae, Trachinops brauni, Chromis klunzingeri, Trachichthys australis). Both remote video techniques recorded greater species richness and relative density of the most common species of Labridae, Ophthalmolepsis lineolatus. Baited remote video recorded the rarer, large predatory fish species (e.g. Seriola hippos, Glaucosoma hebraicum, Heterodontus portusjacksoni). None of the techniques sampled small cryptic fish families such as Gobiidae or Blenniidae. A combination of survey techniques is recommended for comprehensive fishery-independent studies that aim to sample broad components of fish assemblages. \textcopyright{} Springer-Verlag 2005.},
  author   = {Dianne L. Watson and Euan S. Harvey and Marti J. Anderson and Gary A. Kendrick},
  doi      = {10.1007/s00227-005-0090-6},
  issn     = {00253162},
  issue    = 2,
  journal  = {Marine Biology},
  pages    = {415--425},
  title    = {A comparison of temperate reef fish assemblages recorded by three underwater stereo-video techniques},
  volume   = 148,
  year     = 2005
}

@article{Webster2009,
  author    = {Jody M Webster and Juan Carlos and David A Clague and Christina Gallup and James R Hein and Donald C Potts and Willem Renema and Robert Riding and Kristin Riker-coleman and Eli Silver and Laura M Wallace},
  doi       = {10.1016/j.gloplacha.2008.07.010},
  issn      = {0921-8181},
  issue     = {1-2},
  journal   = {Global and Planetary Change},
  pages     = {129--148},
  publisher = {Elsevier B.V.},
  title     = {Coral reef evolution on rapidly subsiding margins},
  volume    = 66,
  url       = {http://dx.doi.org/10.1016/j.gloplacha.2008.07.010},
  year      = 2009
}

@article{Wei2001,
  author      = {Xiaoming Wei},
  institution = {Center for Visual Computing and State University of New York},
  title       = {Modeling and Manipulation of Amorphous Objects},
  url         = {https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=014d52cb7ce5122e1bfdb78c40a87525158bc83e},
  year        = 2001
}

@article{Wei2003,
  author  = {X Wei and Y Zhao and Z Fan and W Li and Yoakum-Stover Suzanne and Arie Kaufman},
  doi     = {10.1001/jama.1974.03230380038024},
  issn    = 15383598,
  issue   = {July},
  journal = {Symposium on Computer Animation},
  pages   = {75--85},
  pmid    = 4406673,
  title   = {Blowing In the Wind},
  url     = {https://citeseerx.ist.psu.edu/document?repid=rep1\&type=pdf\&doi=de7c0de4040df7725de7d11f25f2d96258fee5b8},
  year    = 2003
}

@article{Wei2023,
  abstract = {Denoising is a common, yet critical operation in geometry processing aiming at recovering high-fidelity models of piecewise-smooth objects from noise-corrupted pointsets. Despite a sizable literature on the topic, there is a dearth of approaches capable of processing very noisy and outlier-ridden input pointsets for which no normal estimates and no assumptions on the underlying geometric features or noise type are provided. In this paper, we propose a new robust-statistics approach to denoising pointsets based on line processes to offer robustness to noise and outliers while preserving sharp features possibly present in the data. While the use of robust statistics in denoising is hardly new, most approaches rely on prescribed filtering using data-independent blending expressions based on the spatial and normal closeness of samples. Instead, our approach deduces a geometric denoising strategy through robust and regularized tangent plane fitting of the initial pointset, obtained numerically via alternating minimizations for efficiency and reliability. Key to our variational approach is the use of line processes to identify inliers vs. outliers, as well as the presence of sharp features. We demonstrate that our method can denoise sampled piecewise-smooth surfaces for levels of noise and outliers at which previous works fall short.},
  author   = {Jiayi Wei and Jiong Chen and Damien Rohmer and Pooran Memari and Mathieu Desbrun},
  doi      = {10.1111/cgf.14752},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {CCS Concepts,\textbullet{} Computing methodologies \rightarrow{} Point-based models},
  pages    = {175--189},
  title    = {Robust Pointset Denoising of Piecewise-Smooth Surfaces through Line Processes},
  volume   = 42,
  year     = 2023
}

@article{Weidner2017,
  abstract  = {This paper presents a systematic approach for the 3-D mapping of underwater caves. Exploration of underwater caves is very important for furthering our understanding of hydrogeology, managing efficiently water resources, and advancing our knowledge in marine archaeology. Underwater cave exploration by human divers however, is a tedious, labor intensive, extremely dangerous operation, and requires highly skilled people. As such, it is an excellent fit for robotic technology, which has never before been addressed. In addition to the underwater vision constraints, cave mapping presents extra challenges in the form of lack of natural illumination and harsh contrasts, resulting in failure for most of the state-of-the-art visual based state estimation packages. A new approach employing a stereo camera and a video-light is presented. Our approach utilizes the intersection of the cone of the video-light with the cave boundaries: walls, floor, and ceiling, resulting in the construction of a wire frame outline of the cave. Successive frames are combined using a state of the art visual odometry algorithm while simultaneously inferring scale through the stereo reconstruction. Results from experiments at a cave, part of the Sistema Camilo, Quintana Roo, Mexico, validate our approach. The cave wall reconstruction presented provides an immersive experience in 3-D.},
  author    = {Nick Weidner and Sharmin Rahman and Alberto Quattrini Li and Ioannis Rekleitis},
  doi       = {10.1109/ICRA.2017.7989672},
  isbn      = 9781509046331,
  issn      = 10504729,
  journal   = {Proceedings - IEEE International Conference on Robotics and Automation},
  pages     = {5709--5715},
  publisher = {IEEE},
  title     = {Underwater cave mapping using stereo vision},
  year      = 2017
}

@article{Weiss2005,
  abstract    = {Simulating realistic looking hydraulic erosion can greatly increase the realism of terrains in computer graphics. Other areas of application include the fast evaluation of possible erosion scenarios which is needed in extreme weather conditions. The methods presented in this thesis are based on the SPH-method for simulating fluids using particles in 3D. The proposed extensions include the precise collision with a complex terrain represented as a sparsely stored level set. Furthermore, each particle carries its own amount of sediment which is exchanged with the terrain to simulate dissolving and deposition and with other particles to simulate sediment diffusion. By using particles and a level set instead of heightmaps, caves, overhangs and other complicated structures can be generated. The presented methods are fast enough to simulate and render up to 100,000 particles on a terrain with a resolution of 1024\textasteriskcentered1024\textasteriskcentered512.},
  author      = {Sebastian Weiss},
  institution = {Technische Universitat Munchen},
  title       = {Fast Voxel-Based Hydraulic Erosion},
  url         = {https://mediatum.ub.tum.de/doc/1310288/1310288.pdf},
  year        = 2005
}

@article{Weiss2020,
  abstract = {Heightmap-based terrain representations are common in computer games and simulations. However, adding geometric details to such a representation during rendering on the GPU is difficult to achieve. In this paper, we propose a combination of triplanar mapping, displacement mapping, and tessellation on the GPU, to create extruded geometry along steep faces of heightmap-based terrain fields on-the-fky during rendering. The method allows rendering geometric details such as overhangs and boulders, without explicit triangulation. We further demonstrate how to handle collisions and shadows for the enriched geometry.},
  author   = {Sebastian Weiss and Rudiger Westermann and Florian Bayer},
  doi      = {10.2312/egs.20201016},
  issn     = {1017-4656},
  journal  = {Eurographics 2020 - Short Papers},
  keywords = {Computer Graphics Forum,EUROGRAPHICS},
  pages    = {4 pages},
  title    = {Triplanar Displacement Mapping for Terrain Rendering},
  url      = {https://diglib.eg.org/handle/10.2312/egs20201016},
  year     = 2020
}

@article{Weiss2021a,
  abstract = {Rendering an accurate image of an isosurface in a volumetric field typically requires large numbers of data samples. Reducing this number lies at the core of research in volume rendering. With the advent of deep learning networks, a number of architectures have been proposed recently to infer missing samples in multidimensional fields, for applications such as image super-resolution. In this article, we investigate the use of such architectures for learning the upscaling of a low resolution sampling of an isosurface to a higher resolution, with reconstruction of spatial detail and shading. We introduce a fully convolutional neural network, to learn a latent representation generating smooth, edge-aware depth and normal fields as well as ambient occlusions from a low resolution depth and normal field. By adding a frame-to-frame motion loss into the learning stage, upscaling can consider temporal variations and achieves improved frame-to-frame coherence. We assess the quality of inferred results and compare it to bi-linear and cubic upscaling. We do this for isosurfaces which were never seen during training, and investigate the improvements when the network can train on the same or similar isosurfaces. We discuss remote visualization and foveated rendering as potential applications.},
  author   = {Sebastian Weiss and Mengyu Chu and Nils Thuerey and Rudiger Westermann},
  doi      = {10.1109/TVCG.2019.2956697},
  issn     = 19410506,
  issue    = 6,
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {Machine learning,extraction of surfaces (isosurfaces, material boun,volume rendering},
  pages    = {3064--3078},
  pmid     = 31796410,
  title    = {Volumetric Isosurface Rendering with Deep Learning-Based Super-Resolution},
  volume   = 27,
  year     = 2021
}

@article{Wejchert1991,
  abstract = {Methods based on aerodynamics are developed to simulate and control the motion of objects in fluid flows. To simplify the physics for animation, the problem is broken down into two parts: a fluid flow regime and an objcct boundary regime. With tin's simplification one can approximate the realistic behaviour of objects moving in liquids or air. It also enables a simple way of designing and controlling animation sequences: from a set of flow primitives, an animator can design the spatial arrangement of flows, create Hows around obstacles and direct flow liming. Hie approach is fast, simple, and is easily fitted into simulators Thai model objects governed by classical mechanics. The methods arc applied to an animation that involves hundreds of flexible leaves be-ing blown by wind currents.},
  author   = {Jakub Wejchert and David Haumann},
  doi      = {10.1145/122718.122719},
  isbn     = {0897914368},
  issue    = 4,
  journal  = {Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1991},
  keywords = {Aerodynamics,Animation,Control,Flow primitives,Fluid mechanics,Motion design,Simulation,Wind},
  pages    = {19--22},
  title    = {Animation aerodynamics},
  volume   = 25,
  url      = {https://dl.acm.org/doi/pdf/10.1145/122718.122719},
  year     = 1991
}

@article{Werner1987,
  author = {Bradley T. Werner},
  title  = {A PHYSICAL MODEL OF WIND-BLOWN SAND TRANSPORT},
  year   = 1987
}

@article{Wijns2003,
  abstract = {Inverse modelling of geological processes, in the absence of established numerical criteria to act as inversion targets, requires an approach that uses human interaction to assess forward model results. The method of interactive evolutionary computation provides for the inclusion of qualitative geological expertise within a rigorous mathematical inversion scheme, by simply asking an expert user to evaluate a sequence of forward geological models. The traditional numerical misfit is replaced by a human appraisal of misfit. We use this interactive technique to successfully invert a geodynamic model for a conceptual pattern of fault spacing during crustal extension. \textcopyright{} 2003 Elsevier Science Ltd. All rights reserved.},
  author   = {Chris Wijns and Fabio Boschetti and Louis Moresi},
  doi      = {10.1016/S0191-8141(03)00010-5},
  issn     = {01918141},
  issue    = 10,
  journal  = {Journal of Structural Geology},
  keywords = {Faulting,Genetic algorithm,Interactive evolutionary computation,Inverse modelling},
  pages    = {1615--1621},
  title    = {Inverse modelling in geology by interactive evolutionary computation},
  volume   = 25,
  url      = {https://repository.geologyscience.ru/bitstream/handle/123456789/34582/Wijn\_03.pdf?sequence=1\&isAllowed=y},
  year     = 2003
}

@misc{Wilczkowiak,
  abstract = {Dans cet article, nous nous int\'{e}ressonsint\'{e}ressons`int\'{e}ressons\`{a} l'utilisation des parall\'{e}l\'{e}pip\`{e}des pour le calibrage de cam\'{e}ras et la reconstruction de sc\`{e}nes tridimensionnelles. Les parall\'{e}l\'{e}pip\`{e}des permettent d'exploiter, deman\`{\i} ere naturelle, les contraintes g\'{e}om\'{e}triques fr\'{e}quemment pr\'{e}sentes dans une sc\`{e}ne : le parall\'{e}lisme et l'ortho-gonalit\'{e} par exemple. Un sous ensemble des parall\'{e}l\'{e}pip\`{e}des-les cubo\textasciidieresis{}\i{}descubo\textasciidieresis{}\i{}des 1-ont d\'{e}j\`{a}d\'{e}j\`{a}\textasciiacute{}d\'{e}j\`{a}\'{e}t\'{e} utilis\'{e}s par le pass\'{e} pour le calibrage partiel de cam\'{e}ras, mais le potentiel qu'offrent les parall\'{e}l\'{e}pip\`{e}des en perception tridimensionnelle n'a jamais\'{e}t\'{e}jamais\textasciiacute{}jamais\'{e}t\'{e} clairement\'{e}tabliclairement\textasciiacute{}clairement\'{e}tabli. Dans ce document, nous mettons en\'{e}videnceen\textasciiacute{}en\'{e}vidence ce poten-tiel au travers d'un\'{e} etude approfondie des contraintes fournies par les parall\'{e}l\'{e}pip\`{e}des. Nous montrons en particulier la dualit\'{e} qui existe entre les caract\'{e}ristiques intrins\`{e}ques d'une cam\'{e}ra et celles d'un paral-l\'{e}l\'{e}pip\`{e}de. Pour illustrer cett\'{e} etude, nous pr\'{e}sentons par ailleurs une application interactive permettant la reconstruction d'une sc\`{e}n\`{e} a partir d'une seule image. Dans cette application, seul un faible nombre de connaissances sur la sc\`{e}ne sont n\'{e}cessaires, et un mod\`{e}le tridimensionnel peut rapidement\^{e}trerapidementˆrapidement\^{e}tre obten\`{u} a partir d'une seule image non calibr\'{e}e.},
  author   = {Marta Wilczkowiak and Edmond Boyer and Peter Sturm},
  keywords = {Mots-cl\'{e}s : calibrage,mono-image,parall\'{e}l\'{e}pip\`{e}de,reconstruction},
  title    = {Calibrage de cam\'{e}ra et reconstruction 3D \`{a} l'aide de parall\'{e}l\'{e}pip\`{e}des},
  url      = {https://hal.inria.fr/inria-00525656}
}

@article{Williams1992,
  author  = {Donna J. Williams and Mubarak Shah},
  issue   = 1,
  journal = {CVGIP},
  pages   = {14--26},
  title   = {A Fast Algorithm for Active Contours and Curve Estimation},
  volume  = 55,
  year    = 1992
}

@article{Williams2016,
  abstract  = {This paper describes insights gained from a decade of autonomous marine systems development at the University of Sydney's Australian Centre for Marine Robotics. Over the course of this time, we have deployed numerous vehicles and imaging platforms in support of applications in engineering science, marine ecology, archaeology and geoscience. We have operated an Australia-wide benthic observing program designed to deliver precisely navigated, repeat imagery of the seafloor. This initiative makes extensive use of Autonomous Underwater Vehicles (AUVs) to collect high-resolution stereo imagery, multibeam sonar and water column measurements on an annual or semi-annual basis at sites around Australia, spanning the full latitudinal range of the continent from tropical reefs in the north to temperate regions in the south. We have also contributed to expeditions to document coral bleaching, cyclone recovery, submerged neolithic settlement sites, ancient shipwrecks, methane seeps and deepwater hydrothermal vents. We briefly consider how automated tools for working with this imagery have facilitated the resulting science outcomes.},
  author    = {Stefan B. Williams and Oscar Pizarro and Daniel M. Steinberg and Ariell Friedman and Mitch Bryson},
  doi       = {10.1016/j.arcontrol.2016.09.010},
  issn      = 13675788,
  journal   = {Annual Reviews in Control},
  keywords  = {Autonomous vehicles,Marine systems},
  pages     = {158--165},
  publisher = {Elsevier Ltd},
  title     = {Reflections on a decade of autonomous underwater vehicles operations for marine survey at the Australian Centre for Field Robotics},
  volume    = 42,
  year      = 2016
}

@book{Williamson2019,
  author = {Lecturer David P Williamson},
  pages  = {1--7},
  title  = {Lecture 09 Normalized Adjacency and Laplacian Matrices},
  year   = 2019
}

@article{Wilson1993,
  abstract = {Constraint logic programming (CLP) is a general scheme for extending logic programming to include constraints. It is parametrized by D, the domain of the constraints. However, CLP(D) languages, as well as most other constraint systems, only allow the programmer to specify constraints that must hold. In many applications, such as interactive graphics, planning document formatting, and decision support, one needs to express preferences as well as strict requirements. If we wish to make full use of the constraint paradigm, we need ways to represent these defaults and preferences declaratively, as constraints, rather than encoding them in the procedural parts of the language. We describe a scheme for extending CLP(D) to include both required and preferential constraints. An arbitrary number of strengths of preference are allowed. We present a theory of such constraint hierarchies, and an extension, hierarchical constraint logic programming (HCLP), of the CLP scheme to include constraint hierarchies. We give an operational, model theoretic, and fixed-point semantics for the HCLP scheme. Finally, we describe two interpreters we have written for instances of the HCLP scheme, give example programs, and discuss related work. \textcopyright{} 1993.},
  author   = {Molly Wilson and Alan Borning},
  doi      = {10.1016/0743-1066(93)90046-J},
  issn     = {07431066},
  issue    = {3-4},
  journal  = {The Journal of Logic Programming},
  pages    = {277--318},
  title    = {Hierarchical constraint logic programming},
  volume   = 16,
  year     = 1993
}

@article{Winberg2011,
  author   = {Olov Winberg},
  issue    = {April},
  journal  = {Masterthesis},
  keywords = {()},
  title    = {Examining Automatic Texture Mapping of Arbitrary Terrains},
  url      = {https://www.diva-portal.org/smash/get/diva2:422722/FULLTEXT01.pdf\#page=51\&zoom=100,166,605},
  year     = 2011
}

@article{Wither2009,
  abstract = {Modeling natural elements such as trees in a plausible way, while offering simple and rapid user control, is a challenge. This paper presents a method based on a new structure from silhouettes paradigm. We claim that sketching the silhouettes of foliage at multiple scales is quicker and more intuitive for a user than having to sketch each branch of a tree. This choice allows us to incorporate botanical knowledge, enabling us to infer branches that connect in a plausible way to their parent branch and have a correct distribution in 3D. We illustrate these ideas by presenting a seamless sketch-based interface, used for sketching foliage silhouettes from the scale of an entire tree to the scale of a leaf. Each sketch serves for inferring both the branches at that level and construction lines to serve as support for sub-silhouette refinement. When the user finally zooms out, the style inferred for the branching systems he has refined (in terms of branch density, angle, length distribution and shape) is duplicated to the unspecified branching systems at the same level. Meanwhile, knowledge from botany is again used for extending the branch distribution to 3D, resulting in a full, plausible 3D tree that fits the user-sketched contours. As our results show, this system can be of interest to both experts and novice users. While experts can fully specify all parts of a tree and over-sketch specific branches if required, any user can design a basic 3D tree in one or two minutes, as easily as sketching it with paper and pen. \textcopyright{} 2008 The Eurographics Association and Blackwell Publishing Ltd.},
  author   = {Jamie Wither and Fr\'{e}d\'{e}ric Boudon and Marie-Paule Cani and Christophe Godin},
  doi      = {10.1111/j.1467-8659.2009.01394.x},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  pages    = {541--550},
  title    = {Structure from silhouettes: A new paradigm for fast sketch-based design of trees},
  volume   = 28,
  url      = {https://hal.archives-ouvertes.fr/hal-00366289/document},
  year     = 2009
}

@article{Witten1981,
  abstract = {A model for random aggregates is studied by computer simulation. The model is applicable to a metal-particle aggregation process whose correlations have been measured previously. Density correlations within the model aggregates fall off with distance with a fractional power law, like those of the metal aggregates. The radius of gyration of the model aggregates has power-law behavior. The model is a limit of a model of dendritic growth. \textcopyright{} 1981 The American Physical Society.},
  author   = {T. A. Witten and L. M. Sander},
  doi      = {10.1103/PhysRevLett.47.1400},
  issn     = {00319007},
  issue    = 19,
  journal  = {Physical Review Letters},
  pages    = {1400--1403},
  title    = {Diffusion-limited aggregation, a kinetic critical phenomenon},
  volume   = 47,
  url      = {https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.47.1400},
  year     = 1981
}

@article{Wojtan2007,
  abstract = {In this paper, we present a simple method for animating natural phenomena such as erosion, sedimentation, and acidic corrosion. We discretize the appropriate physical or chemical equations using finite differences, and we use the results to modify the shape of a solid body. We remove mass from an object by treating its surface as a level set and advecting it inward, and we deposit the chemical and physical byproducts into simulated fluid. Similarly, our technique deposits sediment onto a surface by advecting the level set outward. Our idea can be used for off-line high quality animations as well as interactive applications such as games, and we demonstrate both in this paper. \textcopyright{} The Eurographics Association 2007.},
  author   = {Chris Wojtan and Mark Carlson and Peter J. Mucha and Greg Turk},
  isbn     = 9783905673494,
  issn     = 18160867,
  journal  = {Natural Phenomena},
  pages    = {15--22},
  title    = {Animating corrosion and erosion},
  url      = {https://pub.ist.ac.at/group\_wojtan/projects/acid/acid\_FINAL\_nocolorplate.pdf},
  year     = 2007
}

@misc{Wronski,
  author = {Bart\l{}omiej Wro\'{n}ski},
  title  = {Nice list of posts about debluring},
  url    = {https://bartwronski.com/}
}

@article{Wu2003,
  abstract = {Computer modeling and visualization of geological faults in 3D is currently a topical research area because of its important theoretical and application value. The usual method demands enough fault data to be able to construct geological models in 3D. However, in reality, the quantity of the input data is sparse and undersampled. In this paper, we propose a novel approach to modeling faults in 3D. Following the basic properties of geological faults and by using a simple plane to simulate the fault or multiple combined planes to approximate the fault, we can deduce unknown points on a fault and implement mathematical description for the geometry of the fault. We also introduce a new technique called lag insertion and local reconstruction, and an object-oriented framework, which can carry out computer modeling and visualization of complex faults in 3D involving obverse/reverse faults and faults that terminate within geologic models. \textcopyright{} 2003 Elsevier Science Ltd. All rights reserved.},
  author   = {Qiang Wu and Hua Xu},
  doi      = {10.1016/S0098-3004(03)00018-9},
  issn     = {00983004},
  issue    = 4,
  journal  = {Computers and Geosciences},
  keywords = {Framework modeling,Lag insertion and local reconstruction,Modeling faults in 3D,Visualization},
  pages    = {503--509},
  title    = {An approach to computer modeling and visualization of geological faults in 3D},
  volume   = 29,
  year     = 2003
}

@article{Wynn2000,
  abstract = {The Northwest African slope apron is an interesting modern analogue for deep-water systems with complex seafloor topography. A sediment process map of the Northwest African continental margin illustrates the relative roles of different sedimentary processes acting across the entire margin. Fine-grained pelagic and hemipelagic sedimentation is dominant across a large area of the margin, and is considered to result from 'background' sedimentary processes. Alongslope bottom currents smooth and mould the seafloor sediments, and produce bedforms such as erosional furrows, sediment waves and contourite drifts. Downslope gravity flows (debris avalanches, debris flows and turbidity currents) are infrequent but important events on the margin, and are the dominant processes shaping the morphology of the slope and rise. The overall distribution of sedimentary facies and morphological elements on the Northwest African margin is characteristic of a fine-grained clastic slope apron. However, the presence of numerous volcanic islands and seamounts along the margin leads to a more complex distribution of sedimentary facies than is accounted for by slope apron models. In particular, the distribution and thickness of turbidite sands are controlled by the location of the break-of-slope, which is itself controlled by the pre-existing submarine topography. (C) 2000 Elsevier Science Ltd. All rights reserved.},
  author   = {Russell B. Wynn and Douglas G. Masson and Dorrik A.V. Stow and Phillip P.E. Weaver},
  doi      = {10.1016/S0264-8172(99)00014-8},
  issn     = {02648172},
  issue    = 2,
  journal  = {Marine and Petroleum Geology},
  keywords = {Northwest Africa,Slope apron,Turbidity currents},
  pages    = {253--265},
  title    = {The Northwest African slope apron: A modern analogue for deep-water systems with complex seafloor topography},
  volume   = 17,
  year     = 2000
}

@article{Wyvill1999,
  abstract = {<p> Automatic blending has characterized the major advantage of implicit surface modeling systems. Recently, the introduction of deformations based on space warping and Boolean operations between primitives has increased the usefulness of such systems. We propose a further enhancement which will extend the range of models that can be easily and intuitively defined with a skeletal implicit surface system. We describe a hierarchical method which allows arbitrary compositions of models that make use of blending, warping and Boolean operations. We call this structure the <italic>BlobTree</italic> . Blending and space warping are treated in the same way as union, difference and intersection, i.e. as nodes in the <italic>BlobTree</italic> . The traversal of the <italic>BlobTree</italic> is described along with two rendering algorithms; a polygonizer and a ray tracer. We present some examples of interesting models which can be made easily using our approach that would be very difficult to represent with conventional systems. </p>},
  author   = {Brian Wyvill and Andrew Guy and Eric Galin},
  doi      = {10.1111/1467-8659.00365},
  issn     = {0167-7055},
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {blending,implicit surfaces,polygonizing,raytracing,warping},
  month    = 6,
  pages    = {149--158},
  title    = {Extending the CSG Tree. Warping, Blending and Boolean Operations in an Implicit Surface Modeling System},
  volume   = 18,
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/1467-8659.00365},
  year     = 1999
}

@article{Xing2016,
  abstract = {Dynamic effects such as waves, splashes, fire, smoke, and explosions are an integral part of stylized animations. However, such dynamics are challenging to produce, as manually sketching key-frames requires significant effort and artistic expertise while physical simulation tools lack sufficient expressiveness and user control. We present an interactive interface for designing these elemental dynamics for animated illustrations. Users draw with coarse-scale energy brushes which serve as control gestures to drive detailed flow particles which represent local velocity fields. These fields can convey both realistic and artistic effects based on user specification. This painting metaphor for creating elemental dynamics simplifies the process, providing artistic control, and preserves the fluidity of sketching. Our system is fast, stable, and intuitive. An initial user evaluation shows that even novice users with no prior animation experience can create intriguing dynamics using our system.},
  author   = {Jun Xing and Rubaiat Habib Kazi and Tovi Grossman and Li Yi Wei and Jos Stam and George Fitzmaurice},
  doi      = {10.1145/2984511.2984585},
  isbn     = 9781450345316,
  journal  = {UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
  keywords = {Casual animation,Dynamics,Interactive illustrations,Sketching},
  pages    = {755--766},
  title    = {Energy-brushes: Interactive tools for illustrating stylized elemental dynamics},
  year     = 2016
}

@article{Xu2009,
  abstract = {This paper describes a novel hand gesture recognition system that utilizes both multi-channel surface electromyogram (EMG) sensors and 3D accelerometer (ACC) to realize user-friendly interaction between human and computers. Signal segments of meaningful gestures are determined from the continuous EMG signal inputs. Multi-stream Hidden Markov Models consisting of EMG and ACC streams are utilized as decision fusion method to recognize hand gestures. This paper also presents a virtual Rubik's Cube game that is controlled by the hand gestures and is used for evaluating the performance of our hand gesture recognition system. For a set of 18 kinds of gestures, each trained with 10 repetitions, the average recognition accuracy was about 91.7\% in real application. The proposed method facilitates intelligent and natural control based on gesture interaction. Copyright 2009 ACM.},
  author   = {Zhang Xu and Chen Xiang and Wen Hui Wang and Ji Hai Yang and Vuokko Lantz and Kong Qiao Wang},
  doi      = {10.1145/1502650.1502708},
  isbn     = 9781605581682,
  issue    = {January},
  journal  = {International Conference on Intelligent User Interfaces, Proceedings IUI},
  keywords = {Accelero-meter,Electromyogram.,Gesture recognition,Human computer interaction},
  pages    = {401--405},
  title    = {Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors},
  year     = 2009
}

@article{Yan2017,
  abstract = {Fig. 1. Top row shows example shapes made from the control points below. In all cases, local maxima of curvature only appear at the control points, and the curves are G 2 almost everywhere. We present a method for constructing almost-everywhere curvature-continuous, piecewise-quadratic curves that interpolate a list of control points and have local maxima of curvature only at the control points. Our premise is that salient features of the curve should occur only at control points to avoid the creation of features unintended by the artist. While many artists prefer to use interpolated control points, the creation of artifacts, such as loops and cusps, away from control points has limited the use of these types of curves. By enforcing the maximum curvature property, loops and cusps cannot be created unless the artist intends for them to be. To create such curves, we focus on piecewise quadratic curves, which can have only one maximum curvature point. We provide a simple, iterative optimization that creates quadratic curves, one per interior control point, that meet with G 2 continuity everywhere except at innection points of the curve where the curves are G 1. Despite the nonlinear nature of curvature, our curves only obtain local maxima of the absolute value of curvature only at interpolated control points.},
  author   = {Zhipei Yan and Stephen Schiller and Gregg Wilensky and Scott Schaefer},
  doi      = {10.1145/3072959.3073692},
  journal  = {ACM Trans. Graph},
  keywords = {CCS Concepts: \textbullet{}Computing methodologies \rightarrow{} Parametri,curvature continuity,monotonic curva-ture},
  title    = {\ensuremath{\kappa}-Curves: Interpolation at Local Maximum Curvature},
  volume   = 36,
  year     = 2017
}

@article{Yan2020,
  abstract  = {This paper proposes a 3D model for analyzing the rockfall trajectory within the framework of contact mechanics and rigid body dynamics, focusing on arbitrary shapes of the falling rock and terrain. Firstly, the sphericity and the concavity and convexity are defined to quantitatively describe the overall shape and local appearance of often-observed falling rocks, respectively. A generation algorithm is then proposed to generate falling rock and terrain with arbitrary shapes. The surfaces of the generated falling rock and terrain model are both meshed by triangular elements. A contact searching algorithm as well as a bilinear model for contact collision are presented to solve the interaction between the falling rock and terrain. Validated by available field test data, it is demonstrated that the proposed approach could simulate the four motion modes of rockfall such as falling, bouncing, rolling and sliding, as well as the transition between them.},
  author    = {Peng Yan and Jinhua Zhang and Xiangzhen Kong and Qin Fang},
  doi       = {10.1016/j.compgeo.2020.103511},
  issn      = 18737633,
  journal   = {Computers and Geotechnics},
  keywords  = {3D modeling,Arbitrary shape,Contact collision,Rigid body dynamics,Rockfall trajectory},
  month     = 6,
  publisher = {Elsevier Ltd},
  title     = {Numerical simulation of rockfall trajectory with consideration of arbitrary shapes of falling rocks and terrain},
  volume    = 122,
  year      = 2020
}

@article{Yang2018,
  abstract = {The past few years have witnessed great success in applying deep learning to enhance the quality of compressed image/video. The existing approaches mainly focus on enhancing the quality of a single frame, ignoring the similarity between consecutive frames. In this paper, we investigate that heavy quality fluctuation exists across compressed video frames, and thus low quality frames can be enhanced using the neighboring high quality frames, seen as Multi-Frame Quality Enhancement (MFQE). Accordingly, this paper proposes an MFQE approach for compressed video, as a first attempt in this direction. In our approach, we firstly develop a Support Vector Machine (SVM) based detector to locate Peak Quality Frames (PQFs) in compressed video. Then, a novel Multi-Frame Convolutional Neural Network (MF-CNN) is designed to enhance the quality of compressed video, in which the non-PQF and its nearest two PQFs are as the input. The MF-CNN compensates motion between the non-PQF and PQFs through the Motion Compensation subnet (MC-subnet). Subsequently, the Quality Enhancement subnet (QE-subnet) reduces compression artifacts of the non-PQF with the help of its nearest PQFs. Finally, the experiments validate the effectiveness and generality of our MFQE approach in advancing the state-of-the-art quality enhancement of compressed video. The code of our MFQE approach is available at https://github.com/ryangBUAA/MFQE.git.},
  author   = {Ren Yang and Mai Xu and Zulin Wang and Tianyi Li},
  doi      = {10.1109/CVPR.2018.00697},
  isbn     = 9781538664209,
  issn     = 10636919,
  journal  = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages    = {6664--6673},
  title    = {Multi-frame Quality Enhancement for Compressed Video},
  year     = 2018
}

@article{Yang2019,
  abstract  = {The latest High Efficiency Video Coding (HEVC) standard has been increasingly applied to generate video streams over the Internet. However, HEVC compressed videos may incur severe quality degradation, particularly at low bit rates. Thus, it is necessary to enhance the visual quality of HEVC videos at the decoder side. To this end, this paper proposes a quality enhancement convolutional neural network (QE-CNN) method that does not require any modification of the encoder to achieve quality enhancement for HEVC. In particular, our QE-CNN method learns QE-CNN-I and QE-CNN-P models to reduce the distortion of HEVC I and P/B frames, respectively. The proposed method differs from the existing CNN-based quality enhancement approaches, which only handle intra-coding distortion and are thus not suitable for P/B frames. Our experimental results validate that our QE-CNN method is effective in enhancing quality for both I and P/B frames of HEVC videos. To apply our QE-CNN method in time-constrained scenarios, we further propose a time-constrained quality enhancement optimization (TQEO) scheme. Our TQEO scheme controls the computational time of QE-CNN to meet a target, meanwhile maximizing the quality enhancement. Next, the experimental results demonstrate the effectiveness of our TQEO scheme from the aspects of time control accuracy and quality enhancement under different time constraints. Finally, we design a prototype to implement our TQEO scheme in a real-time scenario.},
  author    = {Ren Yang and Mai Xu and Tie Liu and Zulin Wang and Zhenyu Guan},
  doi       = {10.1109/TCSVT.2018.2867568},
  issn      = 10518215,
  issue     = 7,
  journal   = {IEEE Transactions on Circuits and Systems for Video Technology},
  keywords  = {HEVC,convolutional neural network,quality enhancement},
  pages     = {2039--2054},
  publisher = {IEEE},
  title     = {Enhancing Quality for HEVC Compressed Videos},
  volume    = 29,
  year      = 2019
}

@misc{Yang2019a,
  author      = {Chen Yang},
  institution = {LIRMM},
  title       = {Rapport de Stage Simulateur temps r\'{e}el 3D de fonds marins pour la robotique},
  year        = 2019
}

@article{Yang2020,
  abstract  = {In imaging systems, image blurs are a major source of degradation. This paper proposes a parameter estimation technique for linear motion blur, defocus blur, and atmospheric turbulence blur, and a nonlinear deconvolution algorithm based on sparse representation. Most blur removal techniques use image priors to estimate the point spread function (PSF); however, many common forms of image priors are unable to exploit local image information fully. In this paper, the proposed method does not require models of image priors. Further, it is capable of estimating the PSF accurately from a single input image. First, a blur feature in the image gradient domain is introduced, which has a positive correlation with the degree of blur. Next, the parameters for each blur type are estimated by a learning-based method using a general regression neural network. Finally, image restoration is performed using a half-quadratic optimization algorithm. Evaluation tests confirmed that the proposed method outperforms other similar methods and is suitable for dealing with motion blur in real-life applications.},
  author    = {Haoyuan Yang and Xiuqin Su and Songmao Chen and Wenhua Zhu and Chunwu Ju},
  doi       = {10.1371/journal.pone.0230619},
  issn      = 19326203,
  issue     = 3,
  journal   = {PLoS ONE},
  pmid      = 32218591,
  publisher = {Public Library of Science},
  title     = {Efficient learning-based blur removal method based on sparse optimization for image restoration},
  volume    = 15,
  year      = 2020
}

@article{Yannakakis2011a,
  abstract  = {Procedural content generation (PCG) is an increasingly important area of technology within modern human-computer interaction (HCI) design. Personalization of user experience via affective and cognitive modeling, coupled with real-time adjustment of the content according to user needs and preferences are important steps toward effective and meaningful PCG. Games, Web 2.0, interface, and software design are among the most popular applications of automated content generation. The paper provides a taxonomy of PCG algorithms and introduces a framework for PCG driven by computational models of user experience. This approach, which we call Experience-Driven Procedural Content Generation (EDPCG), is generic and applicable to various subareas of HCI. We employ games as an example indicative of rich HCI and complex affect elicitation, and demonstrate the approach's effectiveness via dissimilar successful studies. \textcopyright{} 2011 IEEE.},
  author    = {Georgios N. Yannakakis and Julian Togelius},
  doi       = {10.1109/T-AFFC.2011.6},
  issn      = 19493045,
  issue     = 3,
  journal   = {IEEE Transactions on Affective Computing},
  keywords  = {Procedural content generation,adaptation,computer games.,personalization,user affect,user experience},
  pages     = {147--161},
  publisher = {IEEE},
  title     = {Experience-driven procedural content generation},
  volume    = 2,
  year      = 2011
}

@article{Ye1996,
  abstract    = {This dissertation describes ESCAPE (Expert Systems in Computer Animation Production Environments), a multi-agent animation system for building domain-oriented, rulebased visual programming environments. Much recent work in computer graphics has been concerned with producing behavioural animations of artificial life-forms mainly based on algorithmic approaches. This research indicates how, by adding an inference engine and rules that describe such behaviour, traditional computer animation environments can be enhanced. The comparison between using algorithmic approaches and using a rule-based approach for representing multi-agent worlds is not based upon their respective claims to completeness, but rather on the ease with which end users may express their knowledge and control their animations with a minimum of technical knowledge. An environment for the design of computer animations incorporating an expert system approach is described. In addition to direct manipulation of objects on the screen, the environment allows users to describe behavioural rules based upon both the physical and non-physical attributes of objects. These rules can be interpreted to suggest the transition from stage to stage or to automatically produce a longer animation. The output from the system can be integrated into a commercially available 3D modelling and rendering package. Experience indicates that a hybrid environment, mixing algorithmic and rulebased approaches, would be very promising and offer benefits in application areas such as creating realistic background scenes and modelling human beings or animals either singly or in groups. A prototype evaluation system and three different domains are described and illustrated with preliminary animated images.},
  author      = {Victor Ye},
  doi         = {http://dx.doi.org/10.24382/4939},
  institution = {University of Plymouth},
  title       = {A rule-based approach to animating multi-agent environments},
  url         = {https://pearl.plymouth.ac.uk/bitstream/handle/10026.1/2812/VICTOR YE.PDF?sequence=1},
  year        = 1996
}

@article{Yeh2012,
  abstract = {We present a novel Markov chain Monte Carlo (MCMC) algorithm that generates samples from transdimensional distributions encoding complex constraints. We use factor graphs, a type of graphical model, to encode constraints as factors. Our proposed MCMC method, called locally annealed reversible jump MCMC, exploits knowledge of how dimension changes affect the structure of the factor graph. We employ a sequence of annealed distributions during the sampling process, allowing us to explore the state space across different dimensionalities more freely. This approach is motivated by the application of layout synthesis where relationships between objects are characterized as constraints. In particular, our method addresses the challenge of synthesizing open world layouts where the number of objects are not fixed and optimal configurations for different numbers of objects may be drastically different. We demonstrate the applicability of our approach on two open world layout synthesis problems: coffee shops and golf courses. \textcopyright{} 2012 ACM 0730-0301/2012/08-ART56.},
  author   = {Yi Ting Yeh and Lingfeng Yang and Matthew Watson and Noah D. Goodman and Pat Hanrahan},
  doi      = {10.1145/2185520.2185552},
  issn     = {07300301},
  issue    = 4,
  journal  = {ACM Transactions on Graphics},
  keywords = {Constrained synthesis,Factor graphs,Open worlds},
  title    = {Synthesizing open worlds with constraints using locally annealed reversible jump MCMC},
  volume   = 31,
  url      = {https://graphics.stanford.edu/~lfyg/owl.pdf},
  year     = 2012
}

@article{Yentes2017,
  abstract  = {Rationale: Compared with control subjects, patients with chronic obstructive pulmonary disease (COPD) have an increased incidence of falls and demonstrate balance deficits and alterations in mediolateral trunk acceleration while walking. Measures of gait variability have been implicated as indicators of fall risk, fear of falling, and future falls. Objectives: To investigate whether alterations in gait variability are found in patientswithCOPDas comparedwith healthy control subjects. Methods: Twenty patients withCOPD(16 males; mean age, 63.6\pm{} 9.7 yr; FEV1/FVC, 0.52\pm{}0.12) and 20 control subjects (9 males; mean age, 62.568.2 yr) walked for 3minutes on a treadmill while their gait was recorded. The amount (SD and coefficient of variation) and structure of variability (sample entropy, a measure of regularity) were quantified for step length, time, and width at three walking speeds (selfselected and 620\% of self-selected speed). Generalized linear mixed models were used to compare dependent variables. Results: Patients withCOPDdemonstrated increased mean and SD step time across all speed conditions as compared with control subjects. They also walked with a narrower step width that increased with increasing speed, whereas the healthy control subjects walked with a wider step width that decreased as speed increased. Further, patients with COPD demonstrated less variability in step width, with decreased SD, compared with control subjects at all three speed conditions. No differences in regularity of gait patterns were found between groups. Conclusions: Patients with COPD walk with increased duration of time between steps, and this timing is more variable than that of control subjects.They also walk with a narrower stepwidth inwhich the variability of the step widths from step to step is decreased. Changes in these parameters have been related to increased risk of falling in aging research. This provides a mechanism that could explain the increased prevalence of falls in patients with COPD.},
  author    = {Jennifer M. Yentes and Stephen I. Rennard and Kendra K. Schmid and Daniel Blanke and Nicholas Stergiou},
  doi       = {10.1513/AnnalsATS.201607-547OC},
  issn      = 23256621,
  issue     = 6,
  journal   = {Annals of the American Thoracic Society},
  keywords  = {Biomechanics,Entropy,Gait,Locomotion,Lung disease},
  month     = 6,
  pages     = {858--866},
  pmid      = 28267374,
  publisher = {American Thoracic Society},
  title     = {Patients with chronic obstructive pulmonary disease walk with altered step time and step width variability as compared with healthy control subjects},
  volume    = 14,
  url       = {www.atsjournals.org},
  year      = 2017
}

@inproceedings{Yersin2011,
  author    = {Barbara Yersin and Jonathan Ma\"{\i}m and Julien Pettr\'{e} and Daniel Thalmann},
  city      = {New York, NY, USA},
  doi       = {10.1145/1507149.1507184},
  isbn      = 9781605584294,
  booktitle = {Proceedings of the 2009 symposium on Interactive 3D graphics and games},
  keywords  = {a typical approach is,able,densely inhabited worlds,efficient crowd rendering engines,have been de-,interactive crowd,of in-,to display thousands of,to store pre-computed images,veloped,virtual environment population,virtual humans in real-time},
  month     = 2,
  pages     = {207--214},
  publisher = {ACM},
  title     = {Crowd patches},
  url       = {https://dl.acm.org/doi/10.1145/1507149.1507184},
  year      = 2009
}

@article{Yin2013,
  abstract = {A procedural terrain generation method is presented in this paper. It uses a user-drawn sketch map, which is a raster image with lines and polygons painted by different colors to represent sketches of different terrain features, as input to control the placement of terrain features. Some simple parameters which can be easily understood and adjusted by users are used to control the generation process. To further automatically generate terrains, a mechanism that automatically generates sketches is also put forward. The method is implemented in a PC, and experiments show that terrains are generated efficiently. This method provides users a controllable way to generate terrains. Copyright \textcopyright{} 2013 The Institute of Electronics, Information and Communication Engineers.},
  author   = {Hua Fei Yin and Chang Wen Zheng},
  doi      = {10.1587/transinf.E96.D.1836},
  issn     = 17451361,
  issue    = 8,
  journal  = {IEICE Transactions on Information and Systems},
  keywords = {Automatic generation,Procedural methods,Terrain generation,Terrain sketch},
  pages    = {1836--1844},
  title    = {A practical terrain generation method using sketch map and simple parameters},
  volume   = {E96-D},
  url      = {https://www.jstage.jst.go.jp/article/transinf/E96.D/8/E96.D\_1836/\_pdf/-char/en},
  year     = 2013
}

@article{Ylmaz2010,
  abstract  = {In this work, we introduce a new version of Bishop frame using a common vector field as binormal vector field of a regular curve and call this frame as "Type-2 Bishop Frame". Thereafter, by translating type-2 Bishop frame vectors to the center of unit sphere of three-dimensional Euclidean space, we introduce new spherical images and call them as type-2 Bishop spherical images. Frenet-Serret apparatus of these new spherical images are obtained in terms of base curve's type-2 Bishop invariants. Additionally, we express some interesting relations and illustrate two examples of our main results. \textcopyright{} 2010 Elsevier Inc.},
  author    = {S\"{u}ha Ylmaz and Melih Turgut},
  doi       = {10.1016/j.jmaa.2010.06.012},
  issn      = {0022247X},
  issue     = 2,
  journal   = {Journal of Mathematical Analysis and Applications},
  keywords  = {Bishop frame,Classical differential geometry,Euclidean space,General helix,Slant helix,Spherical images},
  pages     = {764--776},
  publisher = {Elsevier Inc.},
  title     = {A new version of Bishop frame and an application to spherical images},
  volume    = 371,
  url       = {http://dx.doi.org/10.1016/j.jmaa.2010.06.012 https://core.ac.uk/download/pdf/82572186.pdf},
  year      = 2010
}

@inproceedings{Yoo2008,
  abstract  = {Animating 3D organic models to achieve compelling re- alism is a challenging task in the entertainment industry. Skin deformation based on an underlying skeleton is a com- mon method to animate believable organic models. The most widely used skeletal animation algorithm is linear blend skinning (LBS). We present a linear blend skinning technique using quaternion for deforming the skin geometry of the body of a digital creature around its skeleton. A case where blend shape is driven by Euler angle, we may even encounter gimbal lock. Our basic idea is to use quaternion representation as driven parameter for skin blend shape.},
  author    = {Tae-Kyung Yoo and Won-Hyung Lee},
  doi       = {10.1109/ICCIT.2007.188},
  isbn      = {0-7695-3038-9},
  booktitle = {2007 International Conference on Convergence Information Technology (ICCIT 2007)},
  month     = 11,
  pages     = {776--780},
  publisher = {IEEE},
  title     = {Blend Shape with Quaternions},
  url       = {http://ieeexplore.ieee.org/document/4420354/},
  year      = 2007
}

@article{Young1989,
  abstract = {Ocean wave attenuation on coral reefs is discussed using data obtained from a preliminary field experiment and from the Seasat altimeter. Marked attenuation of the waves is observed, the rate being consistent with existing theories of bottom friction and wave breaking decay. In addition, there is a significant broadening of the spectrum during propagation across reefs. Three-dimensional effects, such as refraction and defraction, can also lead to substantial wave height reduction for significant distances adjacent to coral reefs. As a result, a matrix of such reefs provides significantly more wave attenuation than may initially be expected.},
  author   = {Ian R. Young},
  doi      = {10.1029/JC094iC07p09779},
  issn     = {0148-0227},
  issue    = {C7},
  journal  = {Journal of Geophysical Research: Oceans},
  month    = 7,
  pages    = {9779--9789},
  title    = {Wave transformation over coral reefs},
  volume   = 94,
  year     = 1989
}

@article{Yu2021,
  abstract = {Functionals that penalize bending or stretching of a surface play a key role in geometric and scientific computing, but to date have ignored a very basic requirement: in many situations, surfaces must not pass through themselves or each other. This paper develops a numerical framework for optimization of surface geometry while avoiding (self-)collision. The starting point is the tangent-point energy , which effectively pushes apart pairs of points that are close in space but distant along the surface. We develop a discretization of this energy for triangle meshes, and introduce a novel acceleration scheme based on a fractional Sobolev inner product. In contrast to similar schemes developed for curves, we avoid the complexity of building a multiresolution mesh hierarchy by decomposing our preconditioner into two ordinary Poisson equations, plus forward application of a fractional differential operator. We further accelerate this scheme via hierarchical approximation, and describe how to incorporate a variety of constraints (on area, volume, etc. ). Finally, we explore how this machinery might be applied to problems in mathematical visualization, geometric modeling, and geometry processing.},
  author   = {Chris Yu and Caleb Brakensiek and Henrik Schumacher and Keenan Crane},
  doi      = {10.1145/3478513.3480521},
  issn     = {0730-0301},
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {Computational design, shape optimization, surfaces},
  pages    = {1--19},
  title    = {Repulsive surfaces},
  volume   = 40,
  url      = {https://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveSurfaces/RepulsiveSurfaces.pdf},
  year     = 2021
}

@article{Yu2021a,
  abstract = {Curves play a fundamental role across computer graphics, physical simulation, and mathematical visualization, yet most tools for curve design do nothing to prevent crossings or self-intersections. This article develops efficient algorithms for (self-)repulsion of plane and space curves that are well-suited to problems in computational design. Our starting point is the so-called tangent-point energy, which provides an infinite barrier to self-intersection. In contrast to local collision detection strategies used in, e.g., physical simulation, this energy considers interactions between all pairs of points, and is hence useful for global shape optimization: local minima tend to be aesthetically pleasing, physically valid, and nicely distributed in space. A reformulation of gradient descent based on a Sobolev-Slobodeckij inner product enables us to make rapid progress toward local minima-independent of curve resolution. We also develop a hierarchical multigrid scheme that significantly reduces the per-step cost of optimization. The energy is easily integrated with a variety of constraints and penalties (e.g., inextensibility, or obstacle avoidance), which we use for applications including curve packing, knot untangling, graph embedding, non-crossing spline interpolation, flow visualization, and robotic path planning.},
  author   = {Chris Yu and Henrik Schumacher and Keenan Crane},
  doi      = {10.1145/3439429},
  issn     = 15577368,
  issue    = 2,
  journal  = {ACM Transactions on Graphics},
  keywords = {Computational design,curves,knots,shape optimization},
  title    = {Repulsive Curves},
  volume   = 40,
  url      = {https://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveCurves/RepulsiveCurves.pdf},
  year     = 2021
}

@article{Zanni2012,
  author  = {C\'{e}dric Zanni and Paul Bares and Ares Lagae and Maxime Quiblier and Marie-paule Cani and C\'{e}dric Zanni and Paul Bares and Ares Lagae and Maxime Quiblier and Marie-paule Cani Geometric},
  journal = {Eurographics 2012-33rd Annual Conference of the European Association for Computer Graphics},
  pages   = {49--52},
  title   = {Geometric Details on Skeleton-based Implicit Surfaces},
  year    = 2012
}

@article{Zanni2012a,
  author  = {C\'{e}dric Zanni and Paul Bares and Ares Lagae and Maxime Quiblier and Marie-Paule Cani},
  journal = {Eurographics 2012-33rd Annual Conference of the European Association for Computer Graphics},
  pages   = {49--52},
  title   = {Geometric Details on Skeleton-based Implicit Surfaces},
  url     = {https://hal.inria.fr/hal-00694504/document},
  year    = 2012
}

@article{Zanni2013,
  abstract = {Modeling with skeleton is an attractive alternative to "control points" usually placed outside a shape in order to model it : this paradigm, similar to a wire inside the modeled shape, enables model of arbitrary geometry and topology. In order to do so, shapes defined by skeletons should be able to smoothly blend together. Introduced in computer graphics in the 70's, implicit surfaces are one of the main solution to this problem. They are powerful both for the modeling of 3D models and their animations : their construction from a skeleton and their blending capacity by simply summing their scalar field provide an easy way to incrementally create shapes and store them in a compact way, it also facilitates animation containing changes in topology. Implicit surfaces, and more specifically Convolution surfaces, are therefore particularly well adapted to skeleton-based modeling. However, they present a number of drawback that make them difficult to use in practice. This thesis propose new skeleton-based implicit models, inspired not only by convolution but also from space deformations. They enable : - an easier generation of shape along curve skeletons (arcs of helix), - a better control of generated shape both in term of thickness and blending, in particular our model are scale-invariant that make them more intuitive, - the generation of shape which topology better reflects the topology of its skeleton, - the generation of small details from a procedural texture, the details behave in a coherent way with the underlying surface (and its skeleton).},
  author   = {C\'{e}dric Zanni},
  pages    = 168,
  title    = {Skeleton-based Implicit Modeling \& Applications},
  year     = 2013
}

@article{Zhang2000,
  abstract = {We propose a flexible new technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use. The corresponding software is available from the author's Web page. \textcopyright{} 2000 IEEE.},
  author   = {Zhengyou Zhang},
  doi      = {10.1109/34.888718},
  issn     = {01628828},
  issue    = 11,
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {2d pattern,Absolute conic,Calibration from planes,Camera calibration,Closed-form solution,Flexible plane-based calibration,Flexible setup,Lens distortion,Maximum likelihood estimation,Projective mapping},
  month    = 11,
  pages    = {1330--1334},
  title    = {A flexible new technique for camera calibration},
  volume   = 22,
  year     = 2000
}

@article{Zhang2016,
  abstract  = {The deep two-stream architecture exhibited excellent performance on video based action recognition. The most computationally expensive step in this approach comes from the calculation of optical flow which prevents it to be real-time. This paper accelerates this architecture by replacing optical flow with motion vector which can be obtained directly from compressed videos without extra calculation. However, motion vector lacks fine structures, and contains noisy and inaccurate motion patterns, leading to the evident degradation of recognition performance. Our key insight for relieving this problem is that optical flow and motion vector are inherent correlated. Transferring the knowledge learned with optical flow CNN to motion vector CNN can significantly boost the performance of the latter. Specifically, we introduce three strategies for this, initialization transfer, supervision transfer and their combination. Experimental results show that our method achieves comparable recognition performance to the state-of-the-art, while our method can process 390.7 frames per second, which is 27 times faster than the original two-stream method.},
  author    = {Bowen Zhang and Limin Wang and Zhe Wang and Yu Qiao and Hanli Wang},
  journal   = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  month     = 4,
  pages     = {2718--2726},
  publisher = {IEEE Computer Society},
  title     = {Real-time Action Recognition with Enhanced Motion Vector CNNs},
  volume    = {2016-Decem},
  url       = {http://arxiv.org/abs/1604.07669},
  year      = 2016
}

@misc{Zhang2016Code,
  title = {Real-time Action Recognition with Enhanced Motion Vector CNNs \vert{} Papers With Code},
  url   = {https://paperswithcode.com/paper/real-time-action-recognition-with-enhanced}
}

@article{Zhang2019,
  abstract = {As an art form between drawing and sculpture, relief has been widely used in a variety of media for signs, narratives, decorations and other purposes. Traditional relief creation relies on both professional skills and artistic expertise, which is extremely time-consuming. Recently, automatic or semi-automatic relief modelling from a 3D object or a 2D image has been a subject of interest in computer graphics. Various methods have been proposed to generate reliefs with few user interactions or minor human efforts, while preserving or enhancing the appearance of the input. This survey provides a comprehensive review of the advances in computer-assisted relief modelling during the past decade. First, we provide an overview of relief types and their art characteristics. Then, we introduce the key techniques of object-space methods and image-space methods respectively. Advantages and limitations of each category are discussed in details. We conclude the report by discussing directions for possible future research.},
  author   = {Yu Wei Zhang and Jing Wu and Zhongping Ji and Mingqiang Wei and Caiming Zhang},
  doi      = {10.1111/cgf.13655},
  issn     = 14678659,
  issue    = 2,
  journal  = {Computer Graphics Forum},
  keywords = {bas-relief,high relief,image-space modelling,object-space modelling,relief modelling},
  pages    = {521--534},
  title    = {Computer-assisted Relief Modelling: A Comprehensive Survey},
  volume   = 38,
  year     = 2019
}

@misc{Zhang2020,
  abstract  = {Agent-based modelling (ABM) has become an established methodology in many areas of biology, ranging from the cellular to the ecological population and community levels. In plant science, two different scales have predominated in their use of ABM. One is the scale of populations and communities, through the modelling of collections of agents representing individual plants, interacting with each other and with the environment. The other is the scale of the individual plant, through the modelling, by functional-structural plant models (FSPMs), of agents representing plant building blocks, or metamers, to describe the development of plant architecture and functions within individual plants. The purpose of this review is to show key results and parallels in ABM for growth, mortality, carbon allocation, competition and reproduction across the scales from the plant organ to populations and communities on a range of spatial scales to the whole landscape. Several areas of application of ABMs are reviewed, showing that some issues are addressed by both population-level ABMs and FSPMs. Continued increase in the relevance of ABM to environmental science and management will be helped by greater integration of ABMs across these two scales.},
  author    = {Bo Zhang and Donald L. Deangelis},
  doi       = {10.1093/aob/mcaa043},
  issn      = 10958290,
  issue     = 4,
  journal   = {Annals of Botany},
  keywords  = {Population-level models,environmental gradients,forest succession,functional-structural plant models,gap phase models,global change,invasive plants,plant carbon allocation,spatial patterns,spatial scaling},
  month     = 9,
  pages     = {539--557},
  pmid      = 32173742,
  publisher = {Oxford University Press},
  title     = {An overview of agent-based models in plant biology and ecology},
  volume    = 126,
  year      = 2020
}

@article{Zhang2022,
  abstract  = {Natural Gas Hydrate (NGH) and Hydrate-bearing Sediments (HBS) are emerging as an important potential energy resource. Radial Jet Drilling (RJD) technology, turning sharply in the casing and drilling laterals by using water jet, is a valid approach to solve problems of high cost, low efficiency during the exploitation of NGHs. The performance of water jet drilling remains unclear, and traditional finite element methods cannot accurately depict the water jet drilling ability due to mesh distortion. This paper analyzes the water jet erosion process of NGH and HBS. Experiments on the erosion of reconstituted gas hydrates are conducted and visualized in both submerged and submerged confining pressure conditions. Subsequently, two coupled nozzle–target models are solved by Arbitrary Lagrangian Eulerian (ALE) and Smooth Particle Hydrodynamics (SPH) methods. The flow field, the deformation and erosion of the hydrates induced by water jet are simulated. The experimental results show that there are specific shapes of cylindrical erosion pits for NGH and HBS. The numerical results are consistent with the experiments, which proves the effectiveness of water jet exploring hydrate resources. The submerged condition and the confining pressure condition will hinder the erosion efficiency, and the critical erosion velocities for both HBS and NGH are obtained. ALE method has superior accuracy in modeling the damaged area and erosion pit characteristics; while SPH method, has advantages in showing the motion state of the single particles and unstable and discontinuous flow field. This paper provides a good guidance for understanding the water jet drilling performance and selecting the appropriate simulation method in NGH reservoirs development.},
  author    = {Yiqun Zhang and Xiaoya Wu and Xiao Hu and Bo Zhang and Jingsheng Lu and Panpan Zhang and Gensheng Li and Shouceng Tian and Xinming Li},
  doi       = {10.1016/j.egyr.2021.11.235},
  issn      = 23524847,
  journal   = {Energy Reports},
  keywords  = {Hydrate-bearing sediment,Multilateral well,Natural gas hydrate,Radial jet drilling,Water jet},
  pages     = {202--216},
  publisher = {Elsevier Ltd},
  title     = {Visualization and investigation of the erosion process for natural gas hydrate using water jet through experiments and simulation},
  volume    = 8,
  url       = {https://doi.org/10.1016/j.egyr.2021.11.235},
  year      = 2022
}

@inproceedings{Zhao,
  abstract  = {This paper introduces RF-Pose3D, the first system that infers 3D human skeletons from RF signals. It requires no sensors on the body, and works with multiple people and across walls and occlusions. Further, it generates dynamic skeletons that follow the people as they move, walk or sit. As such, RF-Pose3D provides a significant leap in RF-based sensing and enables new applications in gaming, healthcare, and smart homes. RF-Pose3D is based on a novel convolutional neural network (CNN) architecture that performs high-dimensional convolutions by decomposing them into low-dimensional operations. This property allows the network to efficiently condense the spatio-temporal information in RF signals. The network first zooms in on the individuals in the scene, and crops the RF signals reflected off each person. For each individual , it localizes and tracks their body parts-head, shoulders , arms, wrists, hip, knees, and feet. Our evaluation results show that RF-Pose3D tracks each keypoint on the human body with an average error of 4.2 cm, 4.0 cm, and 4.9 cm along the X, Y, and Z axes respectively. It maintains this accuracy even in the presence of multiple people, and in new environments that it has not seen in the training set. Demo videos are available at our website: http://rfpose3d.csail.mit.edu.},
  author    = {Mingmin Zhao and Yonglong Tian and Hang Zhao and Mohammad Abu Alsheikh and Tianhong Li and Rumen Hristov and Zachary Kabelac and Dina Katabi and Antonio Torralba},
  city      = {New York, NY, USA},
  doi       = {10.1145/3230543.3230579},
  isbn      = 9781450355674,
  booktitle = {Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication},
  keywords  = {CCS CONCEPTS \textbullet{} Networks \rightarrow{} Cyber-physical networks,KEYWORDS RF Sensing, 3D Human Pose Estimation, Mac,Sensor networks,\textbullet{} Computing methodologies \rightarrow{} Machine learning},
  month     = 8,
  pages     = {267--281},
  publisher = {ACM},
  title     = {RF-based 3D skeletons},
  url       = {https://dl.acm.org/doi/10.1145/3230543.3230579},
  year      = 2018
}

@article{Zhao2016,
  abstract = {We propose a novel example-based approach to synthesize scenes with complex relations, e.g., when one object is 'hooked', 'surrounded', 'contained' or 'tucked into' another object. Existing relationship descriptors used in automatic scene synthesis methods are based on contacts or relative vectors connecting the object centers. Such descriptors do not fully capture the geometry of spatial interactions, and therefore cannot describe complex relationships. Our idea is to enrich the description of spatial relations between object surfaces by encoding the geometry of the open space around objects, and use this as a template for fitting novel objects. To this end, we introduce relationship templates as descriptors of complex relationships; they are computed from an example scene and combine the interaction bisector surface (IBS) with a novel feature called the space coverage feature (SCF), which encodes the open space in the frequency domain. New variations of a scene can be synthesized efficiently by fitting novel objects to the template. Our method greatly enhances existing automatic scene synthesis approaches by allowing them to handle complex relationships, as validated by our user studies. The proposed method generalizes well, as it can form complex relationships with objects that have a topology and geometry very different from the example scene.},
  author   = {Xi Zhao and Ruizhen Hu and Paul Guerrero and Niloy Mitra and Taku Komura},
  doi      = {10.1145/2980179.2982410},
  isbn     = 9781450345149,
  issn     = 15577368,
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  keywords = {Relationship Templates,Scene Synthesis,Spatial Relationships},
  title    = {Relationship templates for creating scene variations},
  volume   = 35,
  url      = {https://paulguerrero.net/papers/Reltemplates.pdf},
  year     = 2016
}

@article{Zhao2019,
  abstract = {Achieving highly detailed terrain models spanning vast areas is crucial to modern computer graphics. The pipeline for obtaining such terrains is via amplification of a low-resolution terrain to refine the details given a desired theme, which is a time-consuming and labor-intensive process. Recently, data-driven methods, such as the sparse construction tree, have provided a promising direction to equip the artist with better control over the theme. These methods learn to amplify terrain details by using an exemplar of highresolution detailed terrains to transfer the theme. In this paper, we propose Generative Adversarial Terrain Amplification (GATA) that achieves better local/global coherence compared to the existing data-driven methods while providing even more ways to control the theme. GATA is comprised of two key ingredients. The first one is a novel embedding of themes into vectors of real numbers to achieve a single tool for multi-theme amplification. The theme component can leverage existing LIDAR data to generate similar terrain features. It can also generate new fictional themes by tuning the embedding vector or even encoding a new example terrain into an embedding. The second one is an adversarially trained model that, conditioned on an embedding and a low-resolution terrain, generates a high-resolution terrain adhering to the desired theme. The proposed integral approach reduces the need for unnecessary manual adjustments, can speed up the development, and brings the model quality to a new level. Our implementation of the proposed method has proved successful in large-scale terrain authoring for an open-world game.},
  author   = {Yiwei Zhao and Han Liu and Igor Borovikov and Ahmad Beirami and Maziar Sanjabi and Kazi Zaman},
  doi      = {10.1145/3355089.3356553},
  issn     = 15577368,
  issue    = 6,
  journal  = {ACM Transactions on Graphics},
  note     = {Se compare directement aux r\'{e}sultats produits par <br/><br/>Eric Gu\'{e}rin, Julie Digne, Eric Galin, Adrien Peytavie, ChristianWolf, Bedrich Benes, and Beno\^{\i}t Martinez. 2017. Interactive example-based terrain authoring with conditional generative adversarial networks. ACMTransactions on Graphics (TOG) 36, 6 (2017)<br/><br/>Produit de bien meilleurs r\'{e}sultats.},
  title    = {Multi-theme generative adversarial terrain amplification},
  volume   = 38,
  url      = {https://dl.acm.org/doi/pdf/10.1145/3355089.3356553},
  year     = 2019
}

@article{Zhou2007,
  abstract = {In this paper, we present an example-based system for terrain synthesis. In our approach, patches from a sample terrain (represented by a height field) are used to generate a new terrain. The synthesis is guided by a user-sketched feature map that specifies where terrain features occur in the resulting synthetic terrain. Our system emphasizes large-scale curvillnear features (ridges and valleys) because such features are the dominant visual elements in most terrains. Both the example height field and user's sketch map are analyzed using a technique from the field of geomorphology. The system finds patches from the example data that match the features found in the user's sketch. Patches are joined together using graph cuts and Poisson editing. The order in which patches are placed in the synthesized terrain is determined by breadth-first traversal of a feature tree and this generates improved results over standard raster-scan placement orders. Our technique supports user-controlled terrain synthesis in a wide variety of styles, based upon the visual richness of real-world terrain data. \textcopyright{} 2007 IEEE.},
  author   = {Howard Zhou and Jie Sun and Greg Turk and James M. Rehg},
  doi      = {10.1109/TVCG.2007.1027},
  issn     = 10772626,
  issue    = 4,
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {Digital elevation models,Terrain analysis,Terrain synthesis,Texture synthesis},
  pages    = {834--848},
  pmid     = 17495341,
  title    = {Terrain synthesis from digital elevation models},
  volume   = 13,
  year     = 2007
}

@article{Zhou2020,
  abstract  = {3D pose estimation is a challenging problem in computer vision. Most of the existing neural-network-based approaches address color or depth images through convolution networks (CNNs). In this paper, we study the task of 3D human pose estimation from depth images. Different from the existing CNN-based human pose estimation method, we propose a deep human pose network for 3D pose estimation by taking the point cloud data as input data to model the surface of complex human structures. We first cast the 3D human pose estimation from 2D depth images to 3D point clouds and directly predict the 3D joint position. Our experiments on two public datasets show that our approach achieves higher accuracy than previous state-of-art methods. The reported results on both ITOP and EVAL datasets demonstrate the effectiveness of our method on the targeted tasks.},
  author    = {Yufan Zhou and Haiwei Dong and Abdulmotaleb El Saddik},
  doi       = {10.1109/JSEN.2020.2999849},
  issn      = 15581748,
  issue     = 20,
  journal   = {IEEE Sensors Journal},
  keywords  = {Edge feature,depth image,pose regression network},
  month     = 10,
  pages     = {12334--12342},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Learning to Estimate 3D Human Pose from Point Cloud},
  volume    = 20,
  year      = 2020
}

@article{Zhu,
  abstract = {Recent progress in deep generative models has led to tremendous breakthroughs in image generation. However, while existing models can synthesize photorealistic images, they lack an understanding of our underlying 3D world. We present a new generative model, Visual Object Networks (VON), synthesizing natural images of objects with a disentangled 3D representation. Inspired by classic graphics rendering pipelines, we unravel our image formation process into three conditionally independent factors---shape, viewpoint, and texture---and present an end-to-end adversarial learning framework that jointly models 3D shapes and 2D images. Our model first learns to synthesize 3D shapes that are indistinguishable from real shapes. It then renders the object's 2.5D sketches (i.e., silhouette and depth map) from its shape under a sampled viewpoint. Finally, it learns to add realistic texture to these 2.5D sketches to generate natural images. The VON not only generates images that are more realistic than state-of-the-art 2D image synthesis methods, but also enables many 3D operations such as changing the viewpoint of a generated image, editing of shape and texture, linear interpolation in texture and shape space, and transferring appearance across different objects and viewpoints.},
  author   = {Jun-Yan Zhu and Zhoutong Zhang and Chengkai Zhang and Jiajun Wu and Antonio Torralba and Joshua B. Tenenbaum and William T. Freeman},
  month    = 12,
  title    = {Visual Object Networks: Image Generation with Disentangled 3D Representation},
  url      = {http://arxiv.org/abs/1812.02725},
  year     = 2018
}

@article{Zhu2006,
  abstract = {3D geological modeling, one of the most important applications in geosciences of 3D GIS, forms the basis and is a prerequisite for visualized representation and analysis of 3D geological data. Computer modeling of geological faults in 3D is currently a topical research area. Structural modeling techniques of complex geological entities containing reverse faults are discussed and a series of approaches are proposed. The geological concepts involved in computer modeling and visualization of geological fault in 3D are explained, the type of data of geological faults based on geological exploration is analyzed, and a normative database format for geological faults is designed. Two kinds of modeling approaches for faults are compared: A modeling technique of faults based on stratum recovery and a modeling technique of faults based on interpolation in subareas. A novel approach, called the Unified Modeling Technique for stratum and fault, is presented to solve the puzzling problems of reverse faults, syn-sedimentary faults and faults terminated within geological models. A case study of a fault model of bed rock in the Beijing Olympic Green District is presented in order to show the practical result of this method. The principle and the process of computer modeling of geological faults in 3D are discussed and a series of applied technical proposals established. It strengthens our profound comprehension of geological phenomena and the modeling approach, and establishes the basic techniques of 3D geological modeling for practical applications in the field of geosciences.},
  author   = {Liang Feng Zhu and Zheng He and Xin Pan and Xin Cai Wu},
  doi      = {10.1016/S1006-1266(07)60048-0},
  issn     = 10061266,
  issue    = 4,
  journal  = {Journal of China University of Mining and Technology},
  keywords = {Beijing Olympic Green District,Fault data,Geological fault,Stratum,Three dimensional geological modeling,Visualization},
  pages    = {461--465},
  title    = {Approach to computer modeling of geological faults in 3D and an application},
  volume   = 16,
  year     = 2006
}

@article{Zia2020,
  abstract = {Fluid driven fractures propagate in the upper earth crust either naturally or in response to engineered fluid injections. The quantitative prediction of their evolution is critical in order to better understand their dynamics as well as to optimize their creation. We present an open-source Python implementation of a hydraulic fracture growth simulator based on the implicit level set algorithm originally developed by Peirce \& Detournay (2008). This algorithm couples a finite discretization of the fracture with the use of the near tip asymptotic solutions of a steadily propagating semi-infinite hydraulic fracture. This allows to resolve the multi-scale processes governing hydraulic fracture propagation accurately, even on relatively coarse meshes. We present an overview of the mathematical formulation, the numerical scheme and the details of our implementation. A series of problems including a radial hydraulic fracture verification test, the propagation of a height contained hydraulic fracture, the lateral spreading of a magmatic dyke and an example of fracture closure are presented to demonstrate the capabilities, accuracy and robustness of the implemented algorithm. Program summary: Program title: PyFrac CPC Library link to program files: http://dx.doi.org/10.17632/gv7yy9mmwj.1 Licensing provisions: GPLv3 Programming language: Python Nature of problem: Simulation of the propagation and closure of a planar three-dimensional hydraulic fracture driven by the injection of a Newtonian fluid in a material having heterogeneous fracture toughness under a non-uniform in-situ stress field. Solution method: The fully coupled hydro-mechanical moving boundary problem is solved combining a finite volume scheme for lubrication flow with a boundary element method for elasticity. The algorithm couples a finite scale discretization of the fracture with the near-tip asymptotic solution of a steadily moving hydraulic fracture. The fracture front is tracked via a level set approach using a fast marching method.},
  author   = {Haseeb Zia and Brice Lecampion},
  doi      = {10.1016/j.cpc.2020.107368},
  issn     = {00104655},
  journal  = {Computer Physics Communications},
  keywords = {Fracture propagation,Hydraulic fracture,Level set,Non-linear moving boundary problem},
  title    = {PyFrac: A planar 3D hydraulic fracture simulator},
  volume   = 255,
  url      = {https://arxiv.org/pdf/1908.10788.pdf},
  year     = 2020
}

@article{Zimmerman2016,
  abstract = {<p>Empowerment research has generally been limited to the individual level of analysis. Efforts to study empowerment beyond the individual require conceptual frameworks suggesting attributes that define the construct and guide its measurement. This paper presents an initial attempt to describe the nomological network of empowerment at the organizational level of analysis--organizational empowerment (OE). Intraorganizational, interorganizational, and extraorganizational components of OE are described. Implications for empowerment theory and practice are discussed.</p>},
  author   = {N. Andrew Peterson and Marc A. Zimmerman},
  doi      = {10.1023/B:AJCP.0000040151.77047.58},
  issn     = {0091-0562},
  issue    = {1-2},
  journal  = {American Journal of Community Psychology},
  keywords = {and,and so-,cess through which individuals,communities gain greater control,efficacy,empowered organizations,empowerment is an active,empowerment theory,measurement,organizations,participatory pro-},
  month    = 9,
  pages    = {129--145},
  title    = {Beyond the Individual: Toward a Nomological Network of Organizational Empowerment},
  volume   = 34,
  url      = {https://onlinelibrary.wiley.com/doi/10.1023/B\%3AAJCP.0000040151.77047.58},
  year     = 2004
}

@article{Zmuda2013,
  abstract = {A goal of redirected walking (RDW) is to allow large virtual worlds to be explored within small tracking areas. Generalized steering algorithms, such as steer-to-center, simply move the user toward locations that are considered to be collision free in most cases. The algorithm developed here, FORCE, identifies collision-free paths by using a map of the tracking area's shape and obstacles, in addition to a multistep, probabilistic prediction of the user's virtual path through a known virtual environment. In the present implementation, the path predictions describe a user's possible movements through a virtual store with aisles. Based on both the user's physical and virtual location/orientation, a search-based optimization technique identifies the optimal steering instruction given the possible user paths. Path prediction uses the map of the virtual world; consequently, the search may propose steering instructions that put the user close to walls if the user's future actions eventually lead away from the wall. Results from both simulated and real users are presented. FORCE identifies collision-free paths in 55.0 percent of the starting conditions compared to 46.1 percent for generalized methods. When considering only the conditions that result in different outcomes, redirection based on FORCE produces collision-free path 94.5 percent of the time. \textcopyright{} 2013 IEEE.},
  author   = {Michael A. Zmuda and Joshua L. Wonser and Eric R. Bachmann and Eric Hodgson},
  doi      = {10.1109/TVCG.2013.88},
  issn     = 10772626,
  issue    = 11,
  journal  = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {Backtracking,motion compression,redirected walking,virtual reality},
  pages    = {1872--1884},
  pmid     = 24029907,
  title    = {Optimizing constrained-environment redirected walking instructions using search techniques},
  volume   = 19,
  year     = 2013
}

@misc{Pytel2015,
   abstract = {Figure 1. Procedurally modeled channel network: (a) protochannels; (b) channels with breakthrough from lower to higher level. Abstract Hydraulic erosion that takes place underground leads to the formation of complex channel networks whose morphology emerges from the dynamic behavior of each channel, based on the presence of other channels nearby. Our approach to the problem of modeling such channel networks for computer graphics application involves a self-organized model of channel development and a two-stage simulation for constructing the geometry of the channels. By emphasizing self-organization of flow and pressure, our simulation is able to reproduce several types of channel behavior known from hydrogeomorphology, such as tributary capture.},
   author = {Alex Pytel and Stephen Mann},
   issue = {2},
   journal = {Journal of Computer Graphics Techniques},
   title = {Procedural Modeling of Cave-like Channels},
   volume = {4},
   url = {http://jcgt.org},
   year = {2015},
}
