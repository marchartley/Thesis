% \chapter{State of the art}
% \label{chap:state-of-the-art}
% \minitoc

% - ...

\section{Terrain representations}
\label{sec:state-of-the-art_terrain-representations}

Terrain refers to the physical features and configuration of a specific area of land. It includes the elevation, slope, and the overall topography, such as mountains, valleys, and plains. Terrain is often used to describe the surface characteristics of the land, focusing on the natural contours and the geographical aspects that define a region's physical form.

While the term "terrain" describes the physical characteristics of land, it does not include the natural elements that shape an area's identity. Elements like vegetation, water bodies, and climatic conditions, such as snow cover, are essential to how we perceive and understand a landscape. Therefore, when discussing procedural generation in virtual environments, "landscape generation" is a more fitting term, as it integrates these natural elements along with the topographical features.

In addition to "terrain generation," other terms such as "landscape generation," "world generation," and "environment generation" can be used to describe the creation of virtual landscapes. These terms are interchangeable and can all refer to the process of generating physical terrain along with natural and artificial elements. However, by convention and for simplicity, the term "terrain generation" is most commonly used in the field. Despite its original focus on the physical features of the land, "terrain generation" has evolved to encompass a broader range of environmental elements, making it a convenient and widely accepted term for describing the comprehensive process of creating virtual environments.

% \subsection{Virtual terrain representations}
A terrain can be represented in various ways, each of them suited for a given application of which we give an brief overview, more details can be found in \cite{Galin2019}.

\subsection{Elevation models}

Elevation models are a fundamental approach in terrain representation, widely used in procedural generation due to their simplicity and efficiency. These models define the terrain as a function $h : \R^2 \to \R$, where each point in a 2D plane is mapped to an elevation value. This approach is particularly effective for representing terrains where the elevation is the only varying factor, such as hills, valleys, and plateaus, and it is best suited for terrains without complex 3D features like overhangs or caves. While we visualize elevation models in three dimensions, they are mathematically considered two-dimensional functions. In the domain of terrain generation, we will name them 2.5D models.

Elevation models are widely used in industries where large-scale terrain representation is crucial. In video games, they provide the foundation for creating vast open-world environments. In geographic information systems (GIS) and remote sensing, height fields are used to represent real-world terrain data, offering a practical means of visualizing and analyzing geographical features. The ability to manipulate and control terrain features procedurally makes elevation models a common choice for applications that require efficient terrain generation and rendering.

They offer a powerful method for representing terrains in procedural generation, combining simplicity with flexibility. While they have limitations in representing complex 3D structures, their efficiency and compatibility with existing algorithms make them indispensable in a variety of applications.

\subsubsection{Implicit height fields}
Implicit height fields represent the terrain as a mathematical function that provides a height value at any given point in the domain. These functions can be procedural or closed-form expressions, allowing for compact storage and infinite precision in theory. The elevation function allows for easy manipulation of terrain features, making it ideal for generating terrains that require smooth, continuous surfaces. However, the primary disadvantage is the computational complexity involved in evaluating the function, especially for large or highly detailed terrains. The challenge lies in constructing functions that can realistically represent large-scale terrains with complex landforms.

\subsubsection{Discrete height fields}
Discrete height fields, or explicit height fields, are one of the most prevalent methods for terrain representation. These models consist of a 2D grid where each cell contains a height value, representing the elevation at that point. Height fields are particularly advantageous because they are simple to implement and are directly compatible with many rendering techniques and hardware, but also due to their closeness with image processing, a domain studied for many decades now.

The main advantage of height fields is their ability to handle large datasets efficiently, providing a balance between memory usage and detail. However, they are limited by their inability to represent terrains with overhangs or caves, as each point on the grid can only hold a single elevation value. Additionally, height fields often require interpolation methods, such as bi-linear or bi-cubic interpolation, to reconstruct a continuous surface from the discrete grid points. 
% While this allows for smooth terrain surfaces, it can introduce artifacts at grid boundaries and requires careful handling to maintain realism.

\subsection{Volumetric models}
Volumetric models represent a more complex approach to terrain modeling, allowing for the depiction of 3D features that go beyond the simple surface-based representation provided by elevation models. These models capture not only the surface of the terrain but also its internal structure, making them ideal for representing terrains with overhangs, caves, and other subsurface features. 

Volumetric models, including layered materials, voxel grids, and implicit models, are essential in applications where terrain complexity and detail are primordial. In geological simulations, these models allow for accurate representation of subsurface structures and processes. Voxel models are widely used in games that require dynamic terrain deformation, providing a rich interactive environment for players. Implicit models are favored in situations where smooth, continuous surfaces are needed [FIND OTHER USE CASES].

\subsubsection{Implicit volumetric models}
Implicit volumetric models describe the terrain's shape and features using an implicit function. The terrain is represented by a mathematical function $f: \R^3 \to \R$ that determines the terrain surface by evaluating to an isovalue, often zero. This function provides a continuous representation of the terrain, with points inside the terrain returning positive values and while points in the air evaluate to negative values. It allows for the seamless representation of complex terrain features, including caves, overhangs, and varying geological structures, which are impossible to represent with  elevation models.

One of the key advantages of implicit models is their ability to produce smooth surfaces without the need for discrete polygonal meshes, which can result in realistic and natural-looking terrains. However, the computational complexity of evaluating the implicit function, especially for large terrains, can be a significant drawback. Additionally, converting an implicit surface into a mesh for rendering can be challenging and resource-intensive. 

\subsubsection{Layered models}
Layered models are a type of volumetric representation that encode different material layers within the terrain and are defined by a function $\mu : \R^3 \to M$, where $M$ denotes the material type at any given point in 3D space. This allows for a detailed representation of the terrain's internal composition, which can be crucial for applications requiring realistic geological simulations. Each layer is defined by its thickness or elevation, and multiple layers can be stacked to represent complex geological formations. These layers might include materials like bedrock, sand, soil, or water, each contributing to the overall structure of the terrain. Layered models are particularly useful in simulations that involve processes like erosion or sedimentation, where the interaction between different material layers affects the physical process.

The primary advantage of layered models is their ability to represent a stratified terrain with distinct material properties, which can be manipulated individually. This makes them well-suited for simulations that require detailed geological accuracy. However, they are more complex to implement than simple elevation models and require additional computational resources to manage the interactions between layers. 


\subsubsection{Voxel grid models}
Voxel grids are a common method for representing 3D terrains in procedural generation, offering the ability to capture complex internal structures and features that are difficult or impossible to represent with surface-based models. In a voxel grid, the 3D space is divided into a regular grid of small, cube-shaped elements called voxels (volumetric pixels). Each voxel holds information about the material or properties of the terrain at that specific point in space. This approach allows for detailed modeling of features such as caves, tunnels, overhangs, and intricate underground networks. The regular grid structure allows for the use of image processing-oriented algorithms.

There are three primary types of voxel grids used in terrain representation: binary voxel grids, material voxel grids and density voxel grids. Each has distinct characteristics, advantages, and limitations, making them suitable for different applications. 

\subsubsubsection{Binary voxel grids}
Binary voxel grids are the simplest form of voxel representation. In these grids, defined $f: \R^3 \to [0, 1]$, each voxel is either "filled" or "empty," representing the presence or absence of material. This binary state is typically represented by a 1 (filled) or 0 (empty). Binary voxel grids are straightforward to implement and require much less memory compared to more complex voxel representations, making them ideal for applications where the primary concern is whether a space is occupied or not.

The simplicity of binary voxel grids is one of their main advantages. They are easy to understand and visualize, with each voxel requiring only a single bit of information to represent its state. Additionally, because only a binary state is stored, these grids can be memory-efficient when combined with compression techniques like Sparse Voxel Octrees (SVOs) or voxel Directed Acyclic Graphs (DAG). The simplicity of the data structure also allows for quick processing, making binary voxel grids suitable for real-time applications where performance is required. However, the binary nature of these grids limits their ability to represent variations in material density or properties, or even smoothness, resulting in less detailed terrain models. This can lead to hard, blocky edges in the terrain, which may appear unnatural without additional smoothing or processing.

\subsubsubsection{Material voxel grids}
Material voxel grids, defined as $\mu: \R^3 \to M$, are commonly used in applications where simple occupancy information is sufficient. For example, voxel-based games like Minecraft utilize material grids to create terrains composed of solid blocks with clear boundaries. These grids are also employed in scientific simulations where the primary concern is the presence or absence of materials, rather than detailed material properties.

\subsubsubsection{Density voxel grids}
Finally, density voxel grids allow each voxel to store a range of values, representing varying degrees of material presence with $f: \R^3 \to \R$. Instead of a simple discrete state, a density voxel grid assigns a continuous value to each voxel, which can represent material density, opacity, or other properties. This added complexity enables density voxel grids to represent subtle variations in terrain, such as gradual changes in material density or smooth transitions between solid and empty spaces, allowing for more realistic and natural-looking terrain models.

% The use of density voxel grids results in soft transitions and smooth surfaces, reducing the blockiness typically associated with binary voxel grids. They are versatile and can represent not only solid terrain but also phenomena like fog, fluid densities, or temperature gradients. However, the increased detail and realism come at the cost of greater complexity. Density voxel grids require more memory and computational power, making them more challenging to implement and manage. The additional data and processing required can also lead to slower performance, particularly in real-time applications.

Density voxel grids are often used in high-fidelity simulations where detail and realism are essential. They are found in applications such as medical imaging, scientific visualizations, and advanced terrain modeling for films and visual effects. These grids are also employed in procedural terrain generation systems that require smooth and natural transitions between different terrain features, such as caves, cliffs, and eroded landscapes.

% \subsection{Terrain manipulation}
% - ... 

% - ...

% \subsection{2.5D terrains}
% - ...

% \subsubsection{Height maps}
% - ...

% \subsubsection{Height functions}
% - ...

% \subsection{3D terrains}
% - Need for 3D concepts \\
% ** Geological information \\
% ** Volumetric data \\
% - ...

% \subsubsection{Main issues}
% - Memory \\
% - Visualization \\
% - Modifications \\
% - Conversion between representations \\
% ** Information loss \\
% *** Error propagation on geometry (approximations on normals, Z resolution, surface, etc.) \\
% *** Loss of subsurface information \\
% - ...

% \subsubsection{Types, definitions, advantages, disadvantages}
% - Voxel grids \\
% - Material stacks \\
% - Meshes \\
% - Implicit surfaces \\
% - Implicit materials \\
% - ...

% \subsection{Other models}
% - Concept of semantics \\
% - ...


\section{Procedural terrain generation}
\label{sec:state-of-the-art_procedural-generation}
Procedural generation is a computational method used in computer science to create data algorithmically rather than manually, enabling the automatic generation of large amounts of content with minimal human input. This approach is crucial in fields such as game development, where it helps create large, varied worlds, and in simulations or data generation where diverse scenarios or datasets are needed. The process typically involves defining rules and algorithms that dictate how content is generated, ensuring it meets specific criteria and patterns, often incorporating randomness through noise functions to produce unique results each time. Incorporating adjustable parameters and customizable rules in the algorithms allows users to influence the characteristics and outcomes of the generated content. This method enhances efficiency, creativity, and scalability in digital content creation. However, one of the main challenges is ensuring that content generated by a single algorithm remains both diverse and coherent, but the main challenges are ensuring the generated content from a single algorithm is both diverse and coherent and achieving a balance between speed, realism and control to satisfy the desired design and quality.

\subsection{Definition}
Procedural generation is a powerful technique for creating data algorithmically, rather than manually. This method is massively used in areas such as computer graphics, simulations, and game development. Essentially, it involves using predefined rules or algorithms to generate complex structures or systems. For example, it can be employed to create landscapes, textures, or even entire worlds.

One of the main benefits of procedural generation is its data independence. Content is typically generated in real-time or on-the-fly, rather than being explicitly stored, which allows for the creation of large and dynamic environments without requiring significant storage space. However, procedural generation is also advantageous for producing diverse content quickly, enabling the creation of vast amounts of data that may require only minor adjustments or improvements.

In practical applications, procedural generation is commonly used in video games. It enables the creation of vast, varied, and detailed environments efficiently, without requiring large storage. For instance, games like \textit{Minecraft} use procedural generation to create expansive worlds with diverse biomes, while titles like \textit{No Man's Sky} generate entire galaxies filled with unique planets. This automated approach involves defining a set of rules or procedures that produce diverse outputs, making the content creation process both dynamic and flexible. The generated content can adapt and change in response to different inputs or conditions, which is particularly valuable for applications needing variability and adaptability. 

Beyond terrain generation, procedural generation is widely employed in various aspects of digital content creation across multiple industries. In video games, it is used for character animation, allowing for the automatic generation of diverse character movements and behaviors that respond dynamically to the environment. Level design benefits from procedural techniques by creating vast, intricate game levels that are unique with each playthrough, enhancing replayability. Texturing in games also utilizes procedural generation to produce varied surface details, such as the appearance of weathered stone or realistic skin textures, for example.

In the film industry, procedural generation plays a crucial role in generating realistic terrains for expansive outdoor scenes that would be time-consuming and costly to model by hand. It is also used in facial animation, where algorithms can create subtle, lifelike expressions that enhance the realism of CGI characters. Crowd simulations are another widely used application, where procedural techniques generate large numbers of unique characters with varied appearances and behaviors, populating scenes with realistic and dynamic crowds.

In simulations, procedural generation is integral to creating accurate representations of real-world environments. This includes generating complex ecosystems, urban layouts, and geological formations for scientific research, training simulations, and virtual reality applications. Additionally, procedural methods are used to isolate and control environmental variables, allowing researchers to test different scenarios and observe outcomes in a controlled, repeatable manner.

The integration of algorithms and data is a key aspect of procedural generation. It combines mathematical models, noise functions, and other algorithms to produce both realistic and abstract content. This might involve generating natural features like landscapes or textures, or even entire ecosystems. Incorporating elements of real-world phenomena, such as erosion patterns in terrain generation, can make the environments more believable and interactive.

Moreover, procedural generation allows for user-driven customization. Users can influence or guide the content generation process, leading to user-specific outcomes. This feature, combined with the scalability and efficiency of procedural methods, means that large amounts of data can be produced with relatively low computational and storage costs compared to manually crafted content.

Procedural generation can be categorized into two main types: deterministic and stochastic systems.

Deterministic systems produce outputs that are entirely predictable and repeatable given the same initial parameters and input conditions. This means that running the same algorithm with identical inputs multiple times generates the exact same output. This predictability is valuable in scenarios where consistency and reliability are essential, such as in engineering simulations or when reproducing specific results for debugging purposes in game development. For example, in a video game, a deterministic procedural system might be used to generate the same game world across different sessions, ensuring that all players experience the same environment under the same conditions. Or in content creation pipelines, where artists or designers might want to fine-tune specific aspects of the generated content. Since the output is repeatable, they can iteratively adjust parameters and see how these changes affect the final result, making it easier to achieve the desired outcome.

Stochastic systems, on the other hand, introduce elements of randomness into the generation process, resulting in varied outputs even when the same initial parameters are used. This randomness allows for the creation of diverse and unpredictable content, which is particularly important in applications where variation and uniqueness are desired. For instance, in procedural content generation for video games, stochastic systems might be employed to generate a wide variety of levels, landscapes, or in-game items, ensuring that each playthrough feels different.

In many cases, procedural generation systems may combine deterministic and stochastic elements to leverage the strengths of both approaches. For example, a game might use deterministic algorithms to generate the overall structure of a level, ensuring certain key elements are always present, while using stochastic processes to populate the level with varied details and features, less critical in the application. This hybrid approach can provide a balance between consistency and variability, making it possible to create dynamic content that remains coherent.

Rule-based systems are another aspect of procedural generation, using predefined rules to generate content. This approach allows for controlled and structured outputs. Typically, procedural generation involves iterative processes, where initial results are refined or adjusted based on additional rules or parameters.

The advantages of procedural generation include efficiency, as it reduces the need for significant manual efforts, and variability, as it can produce a wide range of unique outputs from the same set of rules. Additionally, it is adaptable, easily responding to changes in requirements or user input, and it minimizes storage needs by generating content on-the-fly.

However, there are challenges associated with procedural generation. The complexity of developing and fine-tuning algorithms can be significant, requiring careful balancing of parameters. Striking a balance between realistic content and computational performance can also be difficult. Furthermore, meeting user expectations for content quality and variety, especially in interactive applications, can be a challenge.

\subsection{History}
The history of procedural generation can be traced back to the mid-20th century, rooted in mathematical and algorithmic theories. During this period, foundational concepts such as randomness, fractal geometry, and noise functions were introduced, laying the groundwork for modern procedural techniques.

\subsubsection{Noises}
One of the earliest and most significant developments in procedural generation was the introduction of noise functions. Noise functions are mathematical constructs used to generate pseudo-random, yet smooth and coherent, patterns. These patterns are critical in creating natural-looking textures and landscapes in computer graphics.

Ken Perlin introduced Perlin noise in 1983, initially for the CGI movie \textit{Tron} (1982), a groundbreaking method for generating smooth, gradient-based noise. Perlin noise can be defined as a continuous function $P(\p)$ that takes a point $\p$ in n-dimensional space and returns a scalar value that represents the noise intensity at that point. The function is defined as a sum of several layers of noise, called "octaves," each with its own frequency and amplitude:

\begin{align}
P(\p) = \sum_{i=0}^{n-1} a_i \cdot \text{noise}(f_i \cdot \p)
\end{align}

where  $n$ is the number of octaves, $a_i$ is the amplitude of the $i$-th octave, $f_i$ is the frequency of the $i$-th octave.

The primary application of Perlin noise was in generating textures that mimic natural phenomena, such as clouds, fire, and marble. Perlin noise's key advantage was its ability to produce visually appealing, continuous gradients that avoided the harsh randomness seen in earlier noise functions. This made it an essential tool in computer graphics, particularly in texture mapping and terrain generation.

Building on his earlier work, Ken Perlin developed Simplex noise in 2001, which was designed to address some of the limitations of Perlin noise. Simplex noise is a more computationally efficient and visually isotropic alternative. It operates on a triangular (in 2D) or tetrahedral (in 3D) grid, reducing computational complexity, particularly in higher dimensions. The Simplex noise function, $S(\p)$, can be defined similarly to Perlin noise but uses a different gradient selection and interpolation process that results in fewer directional artifacts:

\begin{align}
S(\p) = \sum_{i=1}^{n} a_i \cdot \text{simplex\_noise}(f_i \cdot \p)
\end{align}

Simplex noise's reduced computational cost and smoother, isotropic results made it popular in real-time graphics applications, such as video games.

Wavelet noise uses wavelet transforms to control the frequency content of the noise across different scales, reducing artifacts like aliasing and improving texture fidelity. It is expressed as:

\begin{align}
\text{Wavelet\_Noise}(\p) = \sum_{i=0}^{n-1} \text{Wavelet\_Transform}(a_i \cdot \text{noise}(f_i \cdot \p)),
\end{align}

allowing for detailed and consistent textures at multiple resolutions.


Worley noise, introduced by Steven Worley, generates patterns based on the distances to randomly distributed points in space. This noise is particularly effective for creating cellular patterns, useful in simulating materials like stone or skin. The noise at a point $\p$ is computed as:

\begin{align}
W(\p) = \min_{i} \{ \text{distance}(\p, \q_i) \},
\end{align}

where $\q_i$ are the feature points.

Curl noise is particularly useful for simulating fluid-like motion, such as swirling patterns in water or smoke. It is generated by taking the curl of a vector field derived from a noise function, resulting in a divergence-free flow. The curl noise is mathematically described as:

\begin{align}
\mathbf{C}(\p) = \nabla \times \mathbf{F}(\p),
\end{align}

where $\mathbf{F}(\p)$ is a vector field generated by the noise function.


\subsubsection{Subdivision}
% Another significant mathematical concept that influenced procedural generation was fractal geometry, introduced by Benoît B. Mandelbrot in the 1970s. Fractals are complex structures that exhibit self-similarity across different scales, meaning that their patterns repeat at every level of magnification. 

In procedural generation, fractal geometry can be used to create natural-looking terrains and landscapes by generating structures that appear consistent across various scales. For example, the Diamond-Square algorithm, a fractal-based terrain generation technique, iteratively refines a coarse grid of points by introducing random variations. This process creates self-similar structures that resemble mountainous terrains:

\begin{align}
h(x, y) = \frac{h(x_1, y_1) + h(x_2, y_2) + h(x_3, y_3) + h(x_4, y_4)}{4} + \text{random\_offset}
\end{align}

where $h(x, y)$ is the height at a given point, and $(x_1, y_1), (x_2, y_2), (x_3, y_3), (x_4, y_4)$ are the surrounding points.

Fractal-based methods revolutionized terrain generation by providing a mathematical framework for creating realistic and complex natural landscapes.

\subsubsection{Entertaining industry}

As procedural generation techniques matured, they found early applications in video games and interactive media. One of the first notable examples was the game \textit{Rogue} (1980), which utilized procedural generation to create its dungeon levels. In Rogue, each dungeon was generated anew each time a player started a game, ensuring that no two playthroughs were alike. This approach not only enhanced replayability but also minimized the amount of storage needed, as the game did not store pre-made levels but rather generated them on-the-fly.

Another milestone in procedural generation was the game \textit{Elite} (1984), which utilized procedural algorithms to generate a massive universe containing 2048 unique planets, each with its own name, economy, and location in space. This vast universe was generated using only about 20KB of memory, thanks to the efficiency of the procedural techniques employed. The planets' attributes were generated using deterministic algorithms, ensuring that each planet's characteristics were consistent across different game sessions.

\textit{Dwarf Fortress} (2006) took procedural generation to new heights by generating not just terrain, but entire worlds, complete with histories, civilizations, and ecosystems. The game uses complex algorithms to simulate thousands of years of history, resulting in a deeply detailed and dynamic world. The procedural generation in Dwarf Fortress goes beyond mere randomization; it involves creating a coherent and interconnected world where every element, from geography to political structures, is generated algorithmically.

\textit{Spore} pushed the boundaries of procedural content generation by procedurally generating creatures, planets, and even entire galaxies. Unlike traditional games, Spore did not store textures, music, or animations. Instead, it generated these elements on-the-fly, allowing for an almost infinite level of variety and creativity.

\textit{Minecraft} (2011), revolutionized procedural generation in gaming by creating vast, open worlds composed of blocks, with different biomes, caves, and structures all generated procedurally. The game's world is generated using a combination of Perlin noise and other algorithms to create varied and dynamic landscapes that players can explore indefinitely. Minecraft's use of procedural generation allowed for an infinite world size, limited only by the computing power available.

Procedural generation's impact extends beyond gaming into simulations, scientific research, and computer graphics. In scientific simulations, procedural techniques are used to generate terrains for geological studies, allowing researchers to model and analyze various scenarios, such as erosion and sediment transport. Procedural generation is also used in fluid dynamics simulations to create realistic water flows, weather patterns, and other environmental phenomena.

In computer graphics and animation, procedural generation is essential for creating complex visual effects, such as realistic landscapes, textures, and particle systems in movies. Procedural methods enable the efficient generation of vast and detailed environments that would be impractical to model manually. For example, in movies like \textit{The Lord of the Rings} (2001) and \textit{Avatar} (2009), procedural techniques were used to generate large natural landscapes, facial animations, crowds simulations, etc.

\subsubsection{Parallelization and GPU utilisation}

The exponential increase in computing power over the past few decades allowed exponential advancements in procedural generation, particularly for real-time content creation and complex simulations. The evolution from single-core processors to multi-core CPUs (Central Processing Unit), and more significantly, the rise of powerful Graphics Processing Units (GPUs) capable of massive parallel processing, has transformed how procedural algorithms are implemented.

GPUs are perfect for procedural generation due to their architecture, which allows them to execute thousands of threads in parallel. Unlike CPUs, which are optimized for sequential processing and are typically limited to a few cores, GPUs contain thousands of smaller, simpler cores designed for handling multiple simple tasks simultaneously. This parallelization capability is essential for procedural generation, where large data grids need to be processed efficiently.

In procedural generation, many operations can be performed independently on different parts of the data, making them ideal candidates for parallel execution. For example, when generating a large terrain, each point on the terrain grid can be computed independently based on noise functions or subdivision algorithms. By distributing these computations across many parallel threads, GPUs can dramatically accelerate the generation process, allowing for real-time updates and interactions in complex environments.

GPGPU (General-purpose Processing on GPU) refers to the use of GPUs for performing computations that are traditionally handled by CPUs. Originally designed for rendering graphics, GPUs have evolved to support general-purpose computing tasks through frameworks like CUDA (Compute Unified Device Architecture) from NVIDIA and OpenCL (Open Computing Language). These frameworks allow developers to write programs that can harness the parallel processing power of GPUs for a wide range of computational tasks beyond just graphics rendering.

In procedural generation, GPGPU is employed to accelerate various algorithms that require intensive computation. For example, noise functions like Perlin or Simplex noise can be computed in parallel across the entire terrain grid or texture space, enabling the real-time generation of complex patterns and surfaces. Or techniques such as the Diamond-Square algorithm or midpoint displacement can be implemented on the GPU, where each refinement step of the grid can be processed simultaneously for different segments of the terrain. Finally, procedural simulations of fluid dynamics, particle systems, and other physical phenomena can be executed on the GPU, where the interactions of thousands or even millions of particles are computed in parallel, resulting in realistic, real-time simulations.

The integration of machine learning, particularly deep learning techniques, with procedural generation represents a the new step forwardin the domain. Machine learning models, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), have been leveraged to enhance the quality and diversity of procedurally generated content.

GANs are composed of two neural networks, a generator and a discriminator, that are trained together in a competitive manner. The generator creates new data samples, while the discriminator evaluates them against real data. Through this process, the generator learns to produce increasingly realistic outputs. In procedural generation, GANs can be trained on datasets of real-world terrains, textures, or architectural styles, and then used to generate new, highly detailed and realistic content that closely mimics the training data. For instance, GANs can create entire landscapes that are indistinguishable from real-world environments, adding a layer of realism that traditional procedural techniques.

VAEs are another type of deep learning model used in procedural generation. They work by encoding input data into a latent space, where similar inputs are mapped close to each other, and then decoding from this space to generate new data. VAEs are particularly useful for generating content that needs to maintain a certain level of coherence or adhere to specific stylistic constraints. For example, VAEs can generate new character models or textures that fit within a desired aesthetic, providing a high degree of control over the final output.

[TALK ABOUT TRANSFORMERS ALSO]





% Early developments in procedural generation can be traced back to the mid-20th century, grounded in mathematical and algorithmic theories. This period saw the introduction of key concepts like randomness and noise functions, which laid the foundation for procedural techniques. One notable advancement was the introduction of noise functions, such as Perlin noise in 1983. This method allowed for the generation of smooth, natural-looking randomness in computer graphics. [ORIGINAL USE CASE OF PERLIN NOISE + DESCRIPTION OF NOISE FUNCTION]

% Building on this, Ken Perlin developed Simplex noise in 1985. Simplex noise represented a significant improvement over Perlin noise by offering a more computationally efficient and visually pleasing alternative. During the same era, fractal geometry emerged, introducing the concept of generating self-similar structures. This had a substantial impact on terrain generation and procedural modeling, providing a new way to create intricate and repeating patterns. [DESCRIPTION OF NOISE FUNCTION]

% As procedural generation began to find applications in video games and interactive media, its impact became more pronounced. In 1980, the game "Rogue" showcased procedural generation in its level design, featuring randomly generated dungeons and item placements. This was followed by "Elite" in 1984, which utilized procedural generation to create unique characteristics for each planet of an entire world of 2048 planets, such as names, positions in space, economic models, and resource availability, for about 20Ko of memory storage. This approach contributed to a diverse and large game universe, enhancing replayability and exploration.

% The evolution continued with significant milestones in procedural content generation (PCG). "Dwarf Fortress," released in 2006, became renowned for its deep and complex world generation, which included detailed civilizations, histories, and ecosystems. "Spore," released in 2008, pushed the boundaries further by extensively using procedural generation, as the game did not store textures, music, or animations. "Minecraft," released in 2011, revolutionized procedural generation in gaming by creating vast, open worlds with a variety of biomes and features. [CITATIONS]

% In addition to video games, procedural generation found applications in simulations and computer graphics. For scientific simulations, it was used in terrain generation for geological studies and virtual landscapes, as well as in fluid dynamics to simulate realistic fluid behaviors. In the domain of computer graphics and animation, procedural techniques became essential for creating complex visual effects, landscapes, and textures in films, which would be labor-intensive to model manually. The emergence of real-time graphics and game engines like Unreal Engine and Unity further leveraged procedural generation to create dynamic content and diverse environments.

% Computer technology improvements have played a crucial role in the evolution of procedural generation. Improvements in noise functions, such as Worley noise and new variations of Perlin noise, enhanced both the quality and efficiency of procedural methods. Recent developments in machine learning and deep learning have been integrated with procedural generation to produce more complex and adaptive content. The increase in computing power has also been pivotal, allowing for the generation of more detailed and complex procedural content in real time. Additionally, the use of parallel processing and GPUs has accelerated these processes, enabling real-time applications and high-resolution simulations.

% % Looking to the future, current trends in procedural generation include hybrid approaches that combine procedural techniques with manual design to balance complexity and artistic control. User-driven content is becoming more prevalent, allowing players and users to influence procedural content generation. Moreover, procedural generation is increasingly being applied in advanced simulations for areas such as training, virtual reality, and scientific research, including climate modeling and urban planning.

\subsection{Terrain generation}
Procedural generation encompasses a diverse range of techniques used to create complex, natural-looking content, particularly in terrain generation. These techniques span from mathematical models to advanced simulations and can be broadly categorized into methods for large-scale terrain generation and procedural landform generation. 
% Each approach offers distinct advantages and is applied to generate expansive landscapes, intricate landforms, and other environmental features with minimal input data, making procedural generation an essential tool in modern terrain modeling and simulation.

Noise functions are foundational to procedural terrain generation, providing the basis for creating coherent, natural patterns across terrains. Perlin noise, developed by Ken Perlin in 1983, is a gradient-based noise function that produces smooth, continuous patterns, ideal for generating natural-looking textures and landscapes. Simplex noise, introduced by Perlin in 2001, improves upon Perlin noise by being more computationally efficient and reducing directional artifacts, especially in higher-dimensional spaces. Worley noise, another noise variant, generates patterns based on the distance between points, producing cellular structures useful for simulating natural textures like stone or marble, and for modeling phenomena like cloud formations. Fractional Brownian motion (fBm) builds on these noise functions by summing noise at different scales and amplitudes, creating terrains with varied features, from gentle hills to rugged mountains. Techniques like ridge noise focus on generating sharp features such as crests and ridges, while domain warping applies distortions to prevent grid artifacts and simulate erosion effects without the need for full physical simulations.

Cellular automata offer a rule-based approach to procedural generation, particularly useful for simulating complex systems and natural processes. Originating in the 1940s, these grid-based models evolve based on rules applied to neighboring cells. In terrain generation, cellular automata are commonly employed to simulate cave systems, forests, and other structured environments. Notable examples include Conway's Game of Life, which demonstrates how simple rules can lead to complex, self-organizing patterns, and Langton's Ant, which shows how basic rules can produce intricate behaviors. Cellular automata can be generalized to continuous time and space fields, making them versatile tools for modeling a wide range of natural phenomena, from fluid dynamics to vegetation patterns.

Large-scale terrain generation involves creating expansive terrains that exhibit natural-looking landscapes over large areas. Techniques like subdivision schemes—including the diamond-square algorithm—iteratively refine an initial coarse terrain by subdividing it and adding fractal detail. While effective in generating self-similar terrains, these methods may introduce artifacts such as directional inconsistencies, which require further refinement. Faulting is another technique, simulating tectonic activity by introducing random vertical faults into a flat terrain. This method creates realistic elevation changes by displacing points on either side of the fault line, with smooth step functions ensuring gradual transitions between displaced and non-displaced areas. Both methods are essential for generating the broad, natural features characteristic of large-scale terrains, although they may lack the precision needed for detailed landform creation.

Procedural landform generation focuses on creating specific terrain features, such as rivers, cliffs, and canyons, with greater precision and control. Controlled subdivision enhances traditional fractal methods by integrating user-defined features, such as river networks, directly into the terrain. This allows for the creation of landscapes that adhere to specific topological and hydrological requirements. Feature-based construction techniques further refine this approach by using interactive sketch-based interfaces, where users can define terrain features through control curves. These curves guide the multi-resolution deformation process, enabling the creation of detailed and complex landforms like layered terraces and isolated mesas. By blending different types of curves, such as elevation profiles and cross-sectional shapes, users can produce terrains that are both realistic and tailored to specific needs.

Neural networks represent a more recent advancement in procedural generation, particularly in terrain and texture generation. Generative models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) are used to create realistic terrains and photorealistic images. GANs operate by having two neural networks—a generator and a discriminator—compete to produce outputs that are increasingly realistic. VAEs, on the other hand, encode and decode data to and from a latent space, generating new, similar instances of terrains or textures. These models are powerful tools for adding detail and variety to procedurally generated environments, enhancing the realism and complexity of the final output.

Physical Simulations use models of real-world processes to generate and refine natural features in terrains. These include simulations of fluid dynamics, erosion, sediment transport, and other geological and environmental processes. While these simulations are often used to improve the realism of terrains rather than for initial creation, they are crucial for adding realistic details such as river erosion, weathering, and sediment deposition. Erosion models mimic natural processes like water flow and wind, shaping the terrain over time, while sediment transport models simulate the movement and deposition of sediment, contributing to the natural evolution of the landscape.

By combining these diverse techniques, procedural generation enables the creation of vast, detailed, and realistic terrains with minimal input data. This approach balances computational efficiency with the complexity required to simulate natural landscapes, making it a powerful tool in terrain modeling and simulation. Whether generating expansive landscapes or intricate landforms, procedural generation techniques provide the flexibility and precision needed to create dynamic and believable environments across various applications, from video games to scientific simulations.

% Procedural generation encompasses various models and techniques that create complex and natural-looking content. These models range from mathematical functions to advanced neural networks and physical simulations, each resulting on the generation of diverse and realistic environments.

% One foundational technique in procedural generation is noise. Perlin noise, developed by Ken Perlin in 1983, is a gradient noise function designed to produce smooth, coherent patterns that mimic natural phenomena. Its continuous and smooth randomness makes it particularly suitable for generating textures, terrains, and procedural landscapes that appear natural. Building on this, Simplex noise, introduced by Perlin in 2001, offers a more computationally efficient alternative with fewer directional artifacts. It is favored for its improved visual coherence and efficiency in higher-dimensional spaces, making it ideal for procedural texture generation and terrain creation. Another variant of noise, Worley noise creates patterns based on the distance between points in a space. This technique produces cellular structures with distinct boundaries, making it useful for generating textures like stone or marble, and for modeling natural patterns such as cloud formations and cellular structures.

% In addition to noise functions, cellular automata provide another approach to procedural generation. These are discrete, grid-based models where each cell evolves according to a set of rules applied to its neighbors. Originating in the 1940s with John von Neumann and Stanislaw Ulam, cellular automata have been used to model complex systems and processes using only few simple rules. They are particularly employed to generate cave systems in video games, but are also used to create various patterns and textures, including forests, vegetation, and city layouts. Notable examples include Conway's Game of Life, which demonstrates how simple rules can lead to complex, self-organizing patterns, and Langton's Ant, which showcases how basic rules can produce diverse and intricate behaviors. The mathematical formalism of cellular automata made it possible to represent real-world phenomena like avalanches, fluids, ...  in rules [CITATIONS]. Cellular automata got generalized to continuous time fields, and continuous space fields. [CITATIONS LENIA] 

% Neural networks represent a more recent advancement in procedural generation. Artificial Neural Networks (ANNs), inspired by the human brain, learn patterns and generate data. Generative models, including Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), are designed specifically for content generation. GANs use two neural networks—a generator and a discriminator—that compete with each other to produce realistic outputs. VAEs, on the other hand, encode and decode data to and from a latent space to generate new, similar instances. These models are applied to generate realistic textures, terrains, and photorealistic images, enhancing the detail and variety of content in video games and simulations.

% Finally, physical phenomena modeling uses simulations of real-world processes to generate natural features and behaviors. This includes models for fluid dynamics, erosion, sediment transport, and other geological and environmental processes. These models are most often used for improve the realistism of terrains than creating them. Terrain features such as mountains, valleys, and riverbeds, as well as environmental simulations that include weather patterns, climate, and natural disaster scenarios can be modeled through simulations. Erosion models, for instance, simulate the effects of weathering and erosion on terrain, using algorithms that mimic natural processes like water flow and wind. Sediment transport models simulate the movement and deposition of sediment, contributing to the realistic formation and evolution of terrain.

% % \subsection{Existing terrain generation techniques}
% [UP: PREVIOUS, BOTTOM: NEW]

% Procedural generation techniques in terrain generation involve creating terrains using algorithms that do not directly simulate physical processes but instead rely on mathematical models to produce realistic landscapes. These techniques are often phenomenological, focusing on reproducing the observable effects of natural phenomena like erosion, tectonic activity, and sediment deposition. The primary advantage of procedural generation is its ability to create detailed, vast terrains with relatively little data, often without relying on real-world exemplars. 

% Procedural terrain generation methods can be broadly classified into two categories: large-scale terrain generation and procedural landform generation. Large-scale terrain generation techniques focus on creating entire terrains over large areas, emphasizing fractal and self-similar properties to ensure that details appear consistent at various scales. These methods often offer limited direct control over the specific features of the terrain, as they are primarily concerned with creating natural-looking landscapes across large domains. Examples of such methods include subdivision schemes, faulting, and noise-based techniques, each of which brings a different approach to refining and detailing the terrain.

% [CITATIONS]

% Subdivision schemes iteratively refine an initial coarse terrain by subdividing it and adding detail, often guided by fractal principles. A well-known method is the diamond-square algorithm, which can produce terrains with fractal characteristics but may introduce unwanted artifacts such as local extrema. To mitigate these issues, alternative schemes like the square-square method, which uses a mix of triangle and square subdivisions, have been developed to maintain geometric consistency and reduce artifacts. However, these methods are still prone to producing directional artifacts, requiring further refinement through modified algorithms.

% Faulting is another procedural technique that begins with a flat terrain and adds random vertical faults, displacing points on either side of the fault line based on their distance from it. This method is effective in simulating the effects of tectonic activity on terrain formation. The terrain's elevation is determined by summing the contributions of multiple faults, with random coefficients controlling the magnitude of displacement. The use of smooth step functions ensures that the transition between displaced and non-displaced areas is gradual, creating realistic fault lines. However, this technique requires careful selection of faults to maintain terrain consistency and avoid excessive or unnatural elevation changes.

% Noise functions, particularly fractional Brownian motion (fBm), are foundational in procedural terrain generation, used to introduce turbulence and multi-scale effects that mimic the appearance of natural landscapes. By summing noise at different scales and amplitudes, these functions create terrains with a variety of features, from gentle rolling hills to rugged mountains. Specific noise functions, such as ridge noise, are designed to generate sharp features like crests and ridges, while multi-fractal noise allows for non-uniform fractal properties, enhancing the realism of the terrain. Warping techniques, such as domain warping, are applied to avoid grid artifacts and simulate erosion effects without resorting to full physical simulations, further refining the terrain's appearance.

% Procedural landform generation techniques, in contrast, focus on the creation of specific terrain features like rivers, cliffs, and canyons. These methods operate on a smaller scale and provide more direct control over the resulting shapes, allowing for targeted synthesis of particular landforms. Controlled subdivision [CITATION], for example, enhances traditional fractal methods by incorporating user-defined features like river networks into the terrain generation process. This approach can be extended to simulate planetary-scale watersheds, ensuring that the generated terrain adheres to the desired topological and hydrological characteristics.

% Feature-based construction techniques allow users to define terrain features through interactive sketch-based interfaces, where control curves determine the shape and extent of the landforms. These curves guide the multi-resolution deformation process, ensuring that the terrain conforms to the sketched profiles. By blending different types of curves, such as elevation and cross-sectional profiles, detailed and complex landforms can be created. Procedural generation is used to add fine details like layered terraces and isolated mesas, while shortest-path algorithms help define natural river trajectories.

% [TODO]
% % In volumetric procedural terrains, implicit modeling is employed to define terrains using a continuous field function. This allows for the creation of complex 3D features such as overhangs, caves, and cliffs, which are challenging to represent with surface-based models. The field function is warped to simulate overhangs and cliffs, while the terrain's surface is smoothed to achieve a realistic appearance. 
% % Layer stack models represent different material layers within the terrain, and smoothing techniques ensure that transitions between layers are natural and continuous.

% Procedural generation techniques offer a powerful and flexible approach to terrain generation, allowing for the creation of vast, detailed landscapes with minimal input data. However, these techniques also present challenges, particularly in balancing realism with computational efficiency. While large-scale methods excel at creating large terrains with fractal properties, they often lack the direct control needed to generate specific landforms. Conversely, landform generation techniques provide greater control but may require more computational resources to achieve the desired level of detail. The complexity and realism of a process is then defined by the mix of the different algorithms possible in order to create large terrains with realistic landforms.

% - Almost all rely on elevation models \\
% ** More precisely on discrete height fields \\
% *** Because of the closeness with image processing \\
% - Most algorithms are focused on alpine landscapes \\
% ** Because easier to observe, much more research on the topic, historically first geo features simulated

\subsection{Fluid simulations}
Fluid simulations are an essential component of procedural terrain generation, particularly for modeling the behavior of water and its interactions with the terrain. These simulations are crucial for creating realistic and dynamic environmental models that accurately reflect natural phenomena, such as river flow, coastal erosion, sediment transport, and overall hydrology.

At the core of fluid simulations are the Navier-Stokes equations, which describe the motion of fluid substances. These equations account for various forces acting on a fluid, such as pressure, viscosity, and external forces like gravity. 
\begin{align}
    \rho \left( \frac{\partial \mathbf{u}}{\partial t} + (\mathbf{u} \cdot \nabla) \mathbf{u} \right) = -\nabla p + \mu \nabla^2 \mathbf{u} + \mathbf{f}
\end{align}
Where $\mathbf{u} = (u, v, w)$ is the fluid velocity vector, with components $u$, $v$, and $w$ in the $x$-, $y$-, and $z$-directions, respectively, $t$ is time, $\rho$ is the fluid density, $p$ is the pressure field within the fluid, $\mu$ is the dynamic viscosity of the fluid, $\nabla p$ is the pressure gradient force, $\mu \nabla^2 \mathbf{u}$ is the viscous diffusion term, representing the effects of internal friction within the fluid and finally, $\mathbf{f}$ represents external body forces, such as gravity.

For an incompressible fluid like water, the Navier-Stokes equations can be simplified by assuming that the fluid density remains constant, leading to the incompressibility condition:

\begin{align}
    \nabla \cdot \mathbf{u} = 0
\end{align}

This condition ensures that the volume of fluid elements remains unchanged as they move through space, which is crucial for accurately simulating water flow.

The Navier-Stokes equations are highly non-linear, which means that even small changes in the input conditions can lead to significant and unpredictable changes in the fluid's behavior. The non-linearity makes solving these equations a expensive computational problem, as it requires iterative methods to find stable solutions. Each step of the simulation must balance the forces acting on the fluid, such as pressure and viscosity, while ensuring that the solution remains physically accurate and stable over time. This process becomes particularly demanding when aiming for realistic, high-resolution simulations where fine details like turbulence and surface tension must be accurately captured.In this case we require dense computational grids or a large number of particles, and these elements must be updated frequently to maintain the realism of the simulation, which exponentially increase the computations and the memory used.

The computation cost is further amplified when simulations are performed in 3D space. Unlike 2D simulations, where calculations are confined to a plane, 3D simulations must account for the full complexity of fluid movement in all directions. This increases the number of computations required, making real-time applications like as video games and interactive simulations almost incapable to use them.

Different fluid solvers have been developed to approximate the solutions to the Navier-Stokes equations, each with its strengths and weaknesses. These solvers vary in how they represent the fluid (the Lagrangian approach using particles or the Eulerian approach with discrete grids, or a combination of both) and how they handle the computational trade-offs between accuracy, stability, and performance. The choice of a fluid solver depends on the specific requirements of the simulation, such as the need for real-time performance, the level of detail required, or the types of fluid behavior being modeled.

\subsubsection{Marker-And-Cell (MAC) Method}

The Marker-And-Cell (MAC) method is one of the earliest and most fundamental grid-based techniques for simulating incompressible fluid flows. In the MAC method, the fluid's velocity components are stored at the faces of grid cells, while pressure values are stored at the cell centers. Marker particles are used to track the fluid's free surface, ensuring that fluid interfaces and boundaries are accurately captured. The MAC method excels at maintaining the incompressibility condition of fluids and accurately modeling pressure fields, which are important for realistic fluid dynamics. Because of its emphasis on accuracy and detailed pressure modeling, MAC is more oriented toward realism, especially in scenarios where the precise behavior of fluids is essential. However, its grid-based nature can lead to challenges in handling complex geometries and fine details at fluid boundaries, as the resolution is limited by the grid size. Moreover, the method can be computationally intensive, especially for high-resolution grids, making it less ideal for real-time applications.

\subsubsection{Stable Fluids}

Building on the grid-based approach of the MAC method, the Stable Fluids method addresses key stability issues that arise in fluid simulations. Stable Fluids uses a semi-Lagrangian advection scheme and implicit solvers to achieve stability even with large time steps, which is particularly advantageous in real-time applications like video games or interactive simulations. This method is designed with performance in mind, allowing for the simulation of fluid motion without the numerical dissipation that can degrade the accuracy of results over time, which was a common problem in other grid-based methods. While Stable Fluids prioritize performance and stability, particularly in real-time environments, the use of implicit solvers can introduce smoothing effects that reduce the sharpness of fine details in the fluid's motion. Additionally, the method's reliance on grid resolution still limits its ability to represent highly detailed surface interactions, making it a good compromise between realism and performance.

\subsubsection{Particle-In-Cell (PIC) Method}

The Particle-In-Cell (PIC) method represents a hybrid approach that combines the strengths of particle-based and grid-based methods. Fluid properties are stored on a grid, but the fluid's motion is tracked using particles, which carry velocity and position information only. The particles interact with the grid to update the fluid's velocity field, and the grid provides a stable mean for solving the fluid dynamics equations. PIC is particularly useful for capturing the large-scale motion of fluids, benefiting from the grid's stability while using particles to track detailed fluid behavior. However, the method leans more toward performance over accuracy due to its hybrid nature and ability to handle large-scale fluid movements efficiently. A major downside of PIC is its tendency toward numerical dissipation, where the fluid's kinetic energy is artificially reduced over time, leading to a loss of fine details, especially in turbulent flows. This dissipation occurs because the interpolation between particles and the grid tends to average out small-scale variations in velocity, making PIC less suitable for scenarios where high fidelity and detail are required.

\subsubsection{Fluid-Implicit Particle (FLIP) Method}

The Fluid-Implicit Particle (FLIP) method is an evolution of the PIC method designed to address its numerical dissipation problem. FLIP retains the grid-particle hybrid approach but modifies how particle velocities are updated. Instead of fully relying on the grid's velocity field, FLIP updates particle velocities by applying only the changes in the grid's velocity field, preserving the fluid's kinetic energy and maintaining the detail in small-scale motions. This approach significantly reduces numerical dissipation, making FLIP more oriented toward realism, particularly in simulations that require detailed fluid dynamics like splashing, swirling, and other turbulent effects. However, FLIP is more computationally expensive than PIC and can suffer from instability issues, particularly when dealing with highly turbulent flows. The increased computational cost and the need for careful tuning of simulation parameters to maintain stability make FLIP less ideal for performance-focused applications but suitable for scenarios where high fidelity and detailed fluid behavior are essential.

\subsubsection{Smoothed Particle Hydrodynamics (SPH)}

Smoothed Particle Hydrodynamics (SPH) is a purely particle-based method that models fluids using discrete particles, each representing a small volume of fluid. These particles interact with each other based on smoothing kernels, which define the influence of one particle on its neighbors over a certain distance. SPH is particularly well-suited for simulating free-surface flows, such as waves, splashes, and other fluid phenomena where the interaction between fluid particles is complex and highly dynamic. Due to its ability to handle complex boundaries and fluid interfaces naturally, SPH is much more focused on realism, especially in scenarios that require accurate computation of fluid dynamics and interactions. However, SPH is computationally intensive, especially for high-resolution simulations where a large number of particles is required. Additionally, SPH can suffer from stability issues, such as particle clumping or excessive smoothing, which can detract from the realism of the simulation if not carefully managed. These factors make SPH better suited for applications where realism is prioritized over performance, particularly in high-fidelity simulations used in film and scientific research, but not for real-time applications.









% \subsection{Fluid simulations}

% Fluid simulations are almost inevitable in representing natural phenomena in terrain generation, particularly in modeling water flow, erosion, and sediment transport. These simulations are used for creating realistic and dynamic environmental models that accurately reflect the interactions between fluids and terrain. The ability to simulate fluid behaviors such as river currents, coastal erosion, and sediment deposition is fundamental to producing realistic terrains.

% Fluid simulations can be categorized into various methods, each with its unique applications. Techniques like Particle-In-Cell (PIC), Fluid-Implicit Particle (FLIP), and Stable Fluids are commonly used to simulate fluid dynamics. PIC combines particles with a grid to offer a straightforward approach for basic fluid simulations and visualizations. FLIP builds on the PIC method by enhancing accuracy and efficiency through a hybrid approach that merges particle and grid techniques, making it suitable for complex fluid behaviors. Stable Fluids, a grid-based method, is designed for simulating stable, incompressible fluids with minimal computational complexity, often used in interactive applications where real-time rendering is required.

% More sophisticated methods include Smoothed Particle Hydrodynamics (SPH) and Marker-And-Cell (MAC). SPH is a particle-based method where fluid properties are represented by particles that interact based on smoothing kernels, useful for detailed simulations, including interactions between fluids and terrain. MAC and other grid-based approaches use a grid to simulate fluid behavior, providing detailed and accurate representations suitable for various scales of environments. Hybrid methods combine the strengths of grid and particle approaches, balancing the need for detail with performance requirements in complex simulations.

% Fluid simulations are integral to terrain generation, particularly in modeling erosion and sediment transport. These simulations allow for the realistic modeling of erosion processes, which affect terrain features like riverbeds and valleys over time. By simulating how fluids interact with the terrain, these models can show how sediment is moved and deposited, contributing to the natural evolution of the landscape. Water flow and hydrology are other applications of fluid simulations in terrain generation. Simulating surface water dynamics, such as the flow of rivers, lakes, and wetlands, helps create realistic environments where water interacts dynamically with the terrain. 
% % Additionally, subsurface flow simulations model groundwater movement and its interactions with surface features, adding another layer of realism to the terrain.

% % In interactive environments, such as video games and virtual simulations, real-time fluid simulations are crucial for creating dynamic water interactions. These simulations enable the depiction of responsive and changing environments, where water flow can be influenced by user actions or environmental conditions, enhancing the immersive experience.

% While significant for terrain generation, fluid simulations still present important challenges. The main issue is the computational resources required to run accurate and detailed simulations. Performance trade-offs are often necessary, especially in real-time applications where the simulation must balance accuracy with computational efficiency. Complex 2D (or 2.5D) fluid simulations already require powerful hardware, including advanced processors and substantial memory, to handle the intensive calculations involved. 3D simulations are even more computationally expensive, as the third dimension has to be taken into account.

% Another challenge lies in balancing accuracy with realism. While detailed fluid dynamics can produce highly realistic simulations, they often come at the cost of performance. Simulation artifacts, or inaccuracies, can also impact the perceived realism of the terrain, requiring careful attention to detail in the modeling process. Integrating fluid simulations with terrain models presents its own set of challenges. Ensuring that fluids interact seamlessly with the terrain, such as through fluid erosion or sediment deposition, requires sophisticated techniques to maintain consistency between the simulated fluid behaviors and the terrain features.

% Recent developments in fluid simulation technology have focused on enhancing both the accuracy and efficiency of these simulations. Advancements in algorithms have led to new techniques that improve the realism and computational performance of fluid models. There has also been significant progress in real-time fluid simulation, with innovations aimed at improving interactivity.

% The integration of Deep Learning and Machine Learning into fluid simulations represents a recent trend in this field. AI-enhanced simulations use machine learning to refine fluid simulation accuracy and adaptivity, enabling more realistic and responsive environments. Predictive models, powered by AI, can simulate complex fluid behaviors based on historical data, offering new possibilities for dynamic and evolving terrain representations.



% - Definition and purpose: \\
% ** Overview: explanation of fluid simulations and their role in representing natural phenomena in terrains, including water flow, erosion, and sediment transport. \\
% ** Importance: impact of accurate fluid simulations on creating realistic terrain and environmental models.\\
% \subsection{Types of fluid simulations}
% - 2D fluid simulations: \\
% ** Particle-In-Cell (PIC): \\
% *** Concept: combines particles with a grid to simulate fluid dynamics. \\
% *** Applications: used for simpler simulations and visualizations. \\
% ** Fluid-Implicit Particle (FLIP): \\
% *** Concept: a hybrid method that combines particle and grid approaches for better accuracy and efficiency. \\
% *** Applications: suitable for capturing complex fluid behaviors in 2D environments. \\
% ** Stable Fluids: \\
% *** Concept: a grid-based method for simulating stable, incompressible fluids with less computational complexity. \\
% *** Applications: often used in interactive applications where real-time performance is crucial.\\
% - 3D fluid simulations: \\
% ** Smoothed Particle Hydrodynamics (SPH): \\
% *** Concept: a particle-based method where fluid properties are represented by particles that interact based on smoothing kernels. \\
% *** Applications: useful for highly detailed simulations of fluids, including interactions with terrain. \\
% ** Grid-based methods: \\
% *** Concept: methods like Marker-And-Cell (MAC) and Navier-Stokes equations applied on a grid to simulate fluid behavior. \\
% *** Applications: used for detailed and accurate 3D simulations, including large-scale environments. \\
% ** Hybrid methods: \\
% *** Concept: combining grid and particle approaches to leverage the strengths of both methods.\\
% *** Applications: balancing detail and performance in complex simulations. 

% \subsection{Applications in terrain representation}
% - Erosion and sediment transport: \\
% ** Simulation of erosion: how fluid simulations model erosion processes affecting terrain features such as riverbeds and coastlines. \\
% ** Sediment movement: modeling the transport and deposition of sediment, contributing to realistic terrain evolution. \\
% - Water flow and hydrology: \\
% ** Surface water dynamics: representing the flow of water across terrain surfaces, including rivers, lakes, and wetlands. \\
% ** Subsurface flow: simulating groundwater movement and interactions with terrain features. \\
% - Interactive environments: \\
% ** Real-time simulations: implementing fluid simulations in interactive applications, such as video games and virtual environments, where dynamic water interactions are crucial. 

% \subsection{Challenges and considerations}
% - Computational resources: \\
% ** Performance trade-offs: balancing simulation accuracy with computational efficiency, especially for real-time applications. \\
% ** Hardware requirements: the need for powerful processors and memory to handle complex 3D fluid simulations. \\
% - Accuracy vs. realism: \\
% ** Detail vs. performance: finding the right balance between detailed fluid dynamics and the practical limitations of simulation resources. \\
% ** Simulation artifacts: addressing potential artifacts or inaccuracies in simulations that can impact realism. \\
% - Integration with terrain models: \\
% ** Interaction with terrain: ensuring fluid simulations integrate seamlessly with terrain models, including handling interactions such as fluid erosion or deposition. \\
% ** Data consistency: maintaining consistency between simulated fluid behaviors and terrain features for accurate representations. 

% \subsection{Recent developments and future trends}
% - Advancements in algorithms: \\
% ** New techniques: emerging algorithms and methods that enhance the accuracy and efficiency of fluid simulations. \\
% ** Real-time improvements: innovations aimed at improving real-time performance and interactivity in fluid simulations. \\
% - Integration with Deep Learning and Machine Learning: \\
% ** AI-enhanced simulations: using machine learning to improve fluid simulation accuracy and adaptivity. \\
% ** Predictive models: leveraging AI to predict and simulate complex fluid behaviors based on historical data. 

% - Very important in procedural terrain generation \\
% - Allows justifying the geophysics of a simulation/generation \\
% - Quite fast solutions in 2D (PIC, FLIP, Stable Fluids, SPH, etc.) \\
% - But becomes much heavier and memory-intensive in 3D \\
% - ...


\subsection{User interaction}
% \subsubsection{Realism-speed-control balance}
User interaction affects how users balance realism, speed, and control over generated content.

Realism refers to the extent to which generated content accurately represents real-world characteristics, such as visual details, physical processes, and natural patterns. This is especially important in simulations, visualizations, and training environments where plausibility [FIND BETTER TERM] is critical. Techniques to enhance realism include physical simulations, which model processes like erosion and sediment transport, and the integration of expert knowledge from fields such as geology and ecology. However, achieving realism can be challenging due to the complexity of detailed simulations and the need for specialized expertise, which can demand substantial computational resources and inputs.

Speed is about the efficiency of content generation within acceptable time constraints. While no official categorisation has been set, James Gain proposed to describe levels of speed based on response time:
\begin{itemize}
    \item Real-time: generation in less than 30 milliseconds, essential for interactive applications like VR environments. 
    \item Interactive: generation in under 3 seconds, suitable for user-driven customization in games and simulations. 
    \item Near-interactive: generation in less than 5 minutes, applicable for larger-scale simulations where some delay is acceptable. 
    \item Long-term: generation that takes longer, often used for precomputed content or offline rendering.
\end{itemize}

Optimizing speed involves using efficient algorithms and parallel processing. Almost all recent works achieve fast execution time thanks to high parallelisation on GPU. Other types of algorithm may rely on a refinement paradigm, generating a coarse result at first and then iteratively adding finer details, such that the global output shape is available long time before the real final result.

Control refers to how much users can influence or direct the procedural generation process to meet their specific needs or preferences. This includes parameters fine-tuning, allowing users to modify parameters like the noise functions parameters or the simulation parameters, and artistic control tools, made for artists and designers, to guide the generation process with the use of masks and brushes, allowing for combination and mixing of different algorithms.

Managing diverse and sometimes conflicting user expectations, such as balancing creative freedom with the demand for realistic outcomes, requires careful consideration. Additionally, it is essential to balance the complexity of procedural systems to ensure they remain user-friendly, avoiding overwhelming users or producing results that feel artificial or inconsistent.


% \subsubsection{Regeneration}
% The regeneration of procedurally generated models is an issue often overlooked. As the user is almost satisfied with its generation, he may decide to adjust slightly the parameters used. The challenges of the regeneration are multiple: How to let the user explore the \gloss{ParamSpace} of the model freely? How to ensure that a small change in a parameter induce a small change in the result? How to handle the edition from direct manipulations after regeneration? Those question arise directly from the realism-speed-control balance of our procedural models.

% Users can manually start the regeneration process to refresh or update a model. This allows the content to reflect new parameters or conditions as specified by the user. The generation speed has a strong influence on the possibility for the user to fine tune parameters as algorithms that can be executed in real-time or interactive-time keep the user active in his work. Longer execution times force him to find optimal parameters beforehand in order to create a satisfying model faster than if it was hand-made, which, when the model is not completely explicit, may feel impossible. 

% The fine-tuning speed can be improved by different strategies:
% \begin{itemize}
%     \item Modifications that have a local incidence on the resulting model requires only a local regeneration of the output. Limiting the spatial scope of an interaction is an efficient mean to keep at the same time a way to explore the \gloss{ParamSpace} of the algorithm while keeping the predictability of the outcome by avoiding global changes from a local edition.
%     \item Live preview of the outcome can be displayed in a coarse computation, allowing to have a rough idea of the result without the full computation. This strategy is easier to develop with algorithms using refinement paradigms.
% \end{itemize}

% [TODO]
% Interface controls: various tools and options in the user interface enable users to initiate regeneration. 
% This may include buttons or commands designed to reload or update the generated content based on user inputs.

% Customizable parameters: \\
% Adjustment of variables: before initiating regeneration, users can adjust parameters or settings to influence the outcome. 
% This might involve changing terrain features, texture types, or simulation conditions to achieve the desired results. \\
% Preview and validation: offering preview modes or validation checks helps users understand potential outcomes before finalizing the regeneration. 
% This feature ensures that users can visualize changes and make adjustments as needed.

% Issues with regeneration \\
% What to regenerate: \\
% Selective regeneration: deciding whether to regenerate the entire model or only specific parts is crucial. 
% For example, users may choose to regenerate just the terrain features while leaving other elements intact to preserve consistency. \\
% Scope and scale: determining how extensive the regeneration should be is essential. 
% This could involve minor updates or a complete overhaul of the generated content, depending on the changes required.

% How to regenerate: \\
% Algorithmic approaches: various methods can be used for regeneration, including reapplying existing algorithms or introducing new procedural rules. 
% These methods alter or update the existing content based on user inputs or new conditions. \\

% Incremental vs. complete regeneration: \\
% Incremental: gradual updates or changes applied to only parts of the generated content to minimize disruption and maintain consistency. \\
% Complete: full regeneration from scratch may be necessary for significant changes or when previous results are no longer valid, ensuring a fresh start if needed.

% \subsubsection{Interaction mechanisms}
% Interaction mechanisms are tools and methods used to facilitate user interaction with procedural generation: \\
% Parameter adjustment: user interfaces like sliders and controls enable adjustments to parameters such as terrain height or texture type. 
% Real-time feedback ensures users see the immediate impact of their adjustments. \\
% Guided creation: templates and presets offer predefined starting points that users can modify. 
% Assistive tools or wizards help guide users through the generation process, making it easier to understand and control the outcome. \\
% Direct manipulation: interactive tools allow users to directly manipulate generated content, such as sculpting terrain or painting textures. 
% Live updates reflect changes in real-time, facilitating immediate validation and adjustment.

% \subsubsection{Challenges and considerations}
% Challenges and considerations include balancing complexity and usability to ensure that sophisticated procedural systems remain user-friendly. \\
% Performance impact is another concern, especially in real-time applications where frequent updates are required. 
% Effective feedback and iteration mechanisms are crucial for helping users understand the impact of their interactions and refine their designs.

% Problems with user interactions \\
% Consistency: ensuring that regeneration maintains or enhances the consistency and quality of generated content is vital. 
% This involves avoiding artifacts or inconsistencies that could impact the user experience or the realism of the content. \\
% Feedback handling: effectively managing user feedback and requests for regeneration, which can vary in scope and detail, is important.
% Providing clear feedback mechanisms helps users understand how their inputs affect the generation process. \\
% Performance: addressing performance implications is crucial, particularly in real-time or interactive applications where frequent updates are necessary.
% Efficiently handling resource usage and computational demands during regeneration is key to maintaining a smooth experience.

% Action Storage
% Storage Formats:

% JSON: JavaScript Object Notation (JSON) files can be used to store regeneration actions and parameters. JSON is flexible and readable, making it a suitable format for saving and retrieving procedural settings.
% Other Formats: Alternatives such as XML, binary files, or custom formats may be used depending on specific needs or systems.
% Tracking Changes:

% Action History: Maintaining a history of user actions and regeneration events allows users to revert to previous states or track changes over time. This feature supports iterative development and refinement of generated content.
% Versioning: Implementing version control for procedural generation settings helps manage different versions of generated content, allowing users to compare and manage variations effectively.
% Restoration and Undo:

% Undo Mechanisms: Providing options for users to undo recent regeneration actions or revert to previous states enhances flexibility and control. This allows users to correct mistakes or adjust their approach as needed.
% Restoration of Defaults: Allowing users to restore default settings or regeneration conditions if custom changes lead to unsatisfactory results ensures that users can revert to a baseline if needed.
% Implementation Considerations
% Efficiency: Designing algorithms and systems to handle regeneration efficiently is crucial. This involves minimizing computational overhead and ensuring that updates are responsive and timely.

% User Experience: Creating intuitive interfaces and feedback mechanisms facilitates smooth user interactions with the regeneration process. Ensuring that users can easily understand and control the regeneration helps improve their overall experience.

% Error Handling: Implementing robust error handling and recovery mechanisms addresses potential issues that may arise during regeneration, such as unexpected results or system failures. Effective error management ensures that users can continue working without significant disruptions.


\section{Underwater landscapes}
- Use "seascape" instead of "landscape" and "aerial landscapes" for above water. \\
** Not official terms, but may be very useful for the rest of this thesis..! \\
- Describe main differences with landscape generation \\
- Describe coral islands ecosystems.

\subsection{Main differences with aerial terrains}
In the field of terrain generation, particularly when it comes to modeling underwater landscapes, the challenge is to accurately represent complex environments that include both geological and biological features. The underwater world is filled with diverse structures, ranging from vast coral reefs to intricate cave systems, each requiring specialized techniques to model their unique characteristics.

\subsubsection{3D Data for underwater landscapes}

One of the most challenging aspects of underwater landscape modeling is capturing the complexity of its structure. Taking the example of coral reefs,these environments feature highly intricate 3D structures, including branching corals, coral mounds, and encrusting forms. These formations are not just surface-level features; they extend into the terrain with voids and cavities, such as caves, grottos, and karst networks, which add layers of complexity to their representation. Accurate modeling of coral reefs demands that the porous and irregular nature of these formations is represented in high detail, which is a significant challenge due to the variability of their structures.

In addition to biological features, underwater landscapes are shaped by geological processes that must also be accurately represented. For example, sedimentary layers and underwater geological formations like seamounts and ridges are important components of the terrain. 
% Furthermore, volcanic activity, including underwater volcanoes and hydrothermal vents, significantly impacts the landscape and ecosystem, necessitating their inclusion in any comprehensive model of underwater environments.

To gather the data needed for such detailed modeling, advanced measurement techniques are employed. Sonar, including multi-beam echo sounders, and LIDAR (Light Detection and Ranging) are commonly used to capture detailed 3D data of underwater terrains. These technologies allow for the mapping of areas that are otherwise difficult to access, providing the foundational data necessary for accurate terrain generation. Remote sensing technologies also play a major role, enabling the collection of data over large and remote areas, further enhancing the model's accuracy, but represent a significant challenge as the approvision of humans and hardware in these areas is far from easy to achieve.

\subsubsection{Interdisciplinary data integration}

Accurately modeling underwater landscapes requires more than just geological data; it necessitates an interdisciplinary approach that integrates biological and ecological data. Geological validation is an important step in this process, involving collaboration with geologists and marine scientists to ensure that the models are not only scientifically accurate but also reflective of real-world conditions. This validation process ensures that the generated models accurately depict the geological and biological features present in underwater environments.

Biological data is also essential, particularly when modeling coral reefs and other marine ecosystems. Incorporating data on coral species, marine biodiversity, and ecosystem dynamics allows for the creation of realistic and biologically accurate representations. Additionally, the impact of biological processes, such as coral growth patterns and marine erosion, must be considered, as these factors significantly influence the terrain shape over time.

However, one of the major challenges in modeling underwater landscapes is the scarcity of high-resolution data, especially in remote, protected or less studied areas. This data scarcity makes it difficult to create detailed and accurate models. Another challenge lies in the integration of diverse data types, geological, biological, hydrological, etc, into a cohesive and comprehensive model. Effective integration requires complex techniques to ensure that all aspects of the underwater environment are accurately represented.

\subsubsection{Multi-scale modeling}

Underwater landscapes are characterized by features that vary greatly in scale, from vast underwater mountains and ridges to small-scale elements like individual coral polyps and marine vegetation. This diversity in scale necessitates multi-scale modeling techniques that can accommodate both large and small features within the same model.

A. Paris [CITATION THESIS] classified the different geological structures in four different spatial scales: the \textit{megascale} describes landforms spread on more than \si{100}{km} such as continents or mountain ranges, the \textit{macroscale} between \si{1}{km} and \si{100}{km} like river or cave networks, the \textit{mesoscale} ranging from \si{10}{m} to \si{1}{km} contains most complex structures (arches, ravines, cliffs, ...) and finally the \textit{microscale} for features between \si{10}{cm} and \si{10}{m}, like sand ripples, ventifacts, rocks, etc. Generally, we consider as \textit{large-scale} features that can be seen from far away and \textit{small-scale} elements for which somebody has to be to close to to observe it.

Large-scale features, such as underwater mountains and ridges, define the macrostructure of the landscape. These must be integrated seamlessly with small-scale features, such as detailed sedimentary textures and small coral formations, to ensure that the terrain is represented accurately across different scales.

[TODO]

% One of the key techniques used in multi-scale modeling is \gloss{LOD}, which involves adjusting the level of detail in the model based on factors like user interaction or viewing distance. Adaptive LOD techniques help balance the need for visual fidelity with the performance demands of rendering complex terrains. The goal is to preserve detail across scales, ensuring that both macro and micro features are represented without losing important details when the model is scaled or zoomed.

% Visualization techniques also play a crucial role in representing underwater landscapes accurately. Hydrographic mapping is one such technique, providing specialized methods to visualize underwater features clearly. Additionally, the use of textures and lighting that simulate underwater conditions, such as light absorption and scattering, enhances the realism of the model. These techniques help create visually accurate and scientifically meaningful representations of underwater environments.

The procedural generation of underwater landscapes involves the integration of advanced 3D data collection techniques, interdisciplinary collaboration, and multi-scale modeling approaches. Modeling underwater environments, from the complex structures of coral reefs to the accurate representation of geological and biological features, requires innovative solutions that combine geological plausibility with visual realism.


% - 3D data: \\
% ** Coral landscapes: addressing challenges in modeling coral reefs and underwater features. \\
% ** Cavities: representing underwater caves and karst formations. \\
% - Interdisciplinary data: \\
% ** Geological validation: integrating expert knowledge for accurate modeling. \\
% ** Challenges: fewer experts and more uncertainties in underwater environments. \\
% ** Data scarcity: limited data availability for detailed underwater landscapes. \\
% - Need for multi-scale: \\
% ** Integration of large and small elements. \\
% ** Level of Detail (LOD): Techniques for managing detail across different scales.

% \subsubsection{3D data}
% - Coral landscapes: \\
% ** Complex structures: coral reefs feature complex 3D structures with intricate patterns including branching corals, coral mounds, and encrusting forms. These structures often have a high degree of variability and detail. \\
% ** Void spaces: coral reefs contain many voids and cavities such as caves, grottos, and karst networks, adding to the complexity of modeling these environments. \\
% ** Challenges: modeling coral reefs requires accurately representing the porous and irregular nature of coral formations, which can be challenging due to the high level of detail and variability. \\
% - Geological features: \\
% ** Sedimentary layers: representing sedimentary layers and underwater geological formations such as seamounts and underwater ridges. \\
% ** Volcanic activity: incorporating features such as underwater volcanoes and hydrothermal vents, which affect the landscape and ecosystem. \\
% - Measurement and data collection: \\
% ** Sonar and LIDAR: using sonar (e.g., multi-beam echo sounders) and LIDAR (Light Detection and Ranging) to collect detailed 3D data of underwater terrain. \\
% ** Remote sensing: utilizing remote sensing technologies to map and model underwater landscapes, especially in areas that are difficult to access.

% \subsubsection{Interdisciplinary data}
% - Geological validation: \\
% ** Expert consultation: collaborating with geologists and marine scientists to validate and refine models based on real-world observations and data. \\
% ** Data accuracy: ensuring that the generated models accurately reflect real underwater geological and biological features. \\
% - Biological data: \\
% ** Coral and marine life: integrating data on coral species, marine biodiversity, and ecosystem dynamics to create realistic and biologically accurate representations. \\
% ** Ecological impact: considering the impact of various biological factors on the terrain, such as coral growth patterns and marine erosion. \\
% - Challenges: \\
% ** Data scarcity: limited availability of high-resolution data for some underwater environments, especially in less studied or remote areas. \\
% ** Integration: combining geological, biological, and hydrological data effectively to create comprehensive and accurate models. 

% \subsubsection{Multi-scale modeling}
% - Large vs. small scale elements: \\
% ** Macro features: incorporating large-scale features such as underwater mountains, ridges, and large coral formations. \\
% ** Micro features: modeling small-scale elements such as individual coral polyps, marine vegetation, and detailed sedimentary textures. \\
% - \Gloss{LOD} (LOD): \\
% ** Adaptive LOD: using techniques to adjust the level of detail based on user interaction or view distance to balance performance and visual fidelity. \\
% ** Detail preservation: ensuring that both macro and micro-scale features are accurately represented without losing important details during scaling or zooming. \\
% - Visualization techniques: \\
% ** Hydrographic mapping: employing specialized visualization techniques to represent underwater features clearly and accurately. \\
% ** Texture and lighting: using textures and lighting models that simulate underwater conditions, such as light absorption and scattering in water.

% - 3D Data \\
% ** Coral landscapes filled with voids \\
% ** Many cavities (caves, grottos, karst networks) \\
% - Interdisciplinary Data \\
% ** Rather common with terrain generation \\
% ** => Geological validation with experts \\
% ** For underwater, \\
% *** Fewer experts, \\
% *** More uncertainties \\
% *** Based more on observations \\
% *** Few data (coral landscapes < 0.1\% of oceans), for significant biological impact (25\% marine biodiversity) \\
% ** Mix of geology, biology, hydrology, and physics (especially fluid dynamics) \\
% - Need for multi-scale \\
% ** Not limited to underwater \\
% ** Integrate large elements (mountains) with small elements (vegetation) \\
% ** LOD \\
% - ...

\subsection{Coral reefs (biological aspects)}
\label{sec:state-of-the-art_biology}
[BLA BLA BLA TODO]

% Coral reefs are among the most vibrant and biologically diverse ecosystems on Earth. Understanding their formation, structure, and the critical roles they play in marine environments requires an interdisciplinary approach that spans historical, biological, and geological perspectives. This article delves into the biological aspects of coral reefs, exploring their historical discovery, structural formation, importance in biodiversity, the threats they face, and ongoing conservation efforts.

% \subsection{Historical discovery of coral reefs}

% The knowledge of coral reefs has evolved significantly over centuries, beginning with early observations by ancient civilizations such as the Greeks and Romans, who were among the first to document coral structures. During the Age of Exploration, figures like Captain James Cook and naturalist Alexander von Humboldt contributed to the early documentation of coral reefs, highlighting their biodiversity and unique structures. The scientific understanding of coral reefs took a major leap forward in the 19th century, particularly with the work of Charles Darwin, who developed influential theories on the formation of coral reefs, including the concept of atoll formation. The 20th century saw further advances in marine biology and oceanography, deepening our understanding of coral reef ecosystems and their role in the marine environment.

% \subsection{Coral reef structure and formation}

% Coral reefs are formed by the accumulation of calcium carbonate, primarily secreted by coral polyps, which are tiny, soft-bodied organisms. These polyps live in colonies and work together to build the massive structures we recognize as coral reefs. There are several types of coral reefs, each with distinct characteristics. Fringing reefs are directly attached to coastlines and extend outward into shallow waters, often featuring a narrow reef crest and slope. Barrier reefs run parallel to the coastline but are separated from it by a lagoon or deep channel, typically forming in deeper waters and with more pronounced lagoons. Atolls are circular or oval reefs that encircle a lagoon, often forming around a submerged volcanic island, creating a ring-like structure with no central landmass.

% The process of reef building is complex and involves both the deposition of calcium carbonate by living organisms and bioerosion, where marine creatures such as parrotfish and sea urchins erode the reef structure. This natural balance between construction and erosion is essential for the maintenance and growth of coral reefs over time.

% \subsection{Importance in biodiversity}

% Coral reefs are critical hotspots of marine biodiversity, supporting thousands of species, including fish, invertebrates, and algae. The structural complexity of coral reefs provides numerous niches and habitats, fostering high levels of species diversity and endemism—many species found in coral reefs exist nowhere else in the world. Beyond their ecological significance, coral reefs play crucial roles in ecosystem services. They provide essential habitats for a wide range of marine species, including those that are commercially important. Coral reefs also play a vital role in nutrient cycling, which is crucial for the productivity and health of the broader marine ecosystem.

% Economically, coral reefs are invaluable. They support fisheries that millions of people depend on for food and livelihood, and they are major attractions for tourism, generating significant revenue. Moreover, coral reefs hold cultural and spiritual significance for many coastal communities, forming an integral part of their traditions and practices.

% \subsection{Threats to coral reefs}

% Despite their importance, coral reefs are under severe threat from a variety of factors. Climate change is one of the most significant threats, with rising sea temperatures leading to coral bleaching, where corals expel the symbiotic algae that provide them with energy, often resulting in widespread coral mortality. Ocean acidification, driven by increased levels of carbon dioxide, further impacts coral growth by reducing calcification rates, weakening reef structures.

% Pollution also poses a grave danger to coral reefs. Nutrient runoff from agriculture and urban areas can lead to algal blooms that smother corals, while marine debris, particularly plastics, can cause physical damage and harm marine life. Overfishing exacerbates the problem by depleting fish stocks that are crucial for maintaining the ecological balance of reef ecosystems. Destructive fishing practices, such as blast fishing and cyanide fishing, cause direct physical damage to coral reefs, further threatening their survival.

% Coastal development contributes to the degradation of coral reefs through habitat destruction and increased sedimentation. Activities such as dredging, land reclamation, and construction can destroy or degrade coral habitats, while sediment runoff from deforestation and construction reduces light availability, which is essential for coral health and growth.

% \subsection{Conservation efforts}

% In response to these threats, numerous conservation efforts are underway to protect and restore coral reefs. Marine Protected Areas (MPAs) are designated zones where human activities are regulated or restricted to protect coral reefs and promote their recovery. There are several success stories where the implementation of MPAs has led to significant improvements in reef health and biodiversity.

% Restoration projects are also playing a vital role in coral reef conservation. Techniques such as coral gardening, where corals are grown in nurseries and then transplanted to damaged reefs, have shown promise in restoring reef structures. Artificial reefs, created by sinking ships, placing concrete structures, or using other materials, provide new habitats for marine life and can help jumpstart reef recovery.

% Community involvement is crucial for the success of these conservation efforts. Engaging local communities through education, stewardship, and sustainable practices helps ensure that conservation measures are culturally appropriate and effective. Citizen science initiatives, where members of the public participate in monitoring and research, have also been instrumental in gathering data and raising awareness about the importance of coral reefs.

% At the policy level, international agreements like the Convention on Biological Diversity and national regulations play a critical role in safeguarding coral reefs. These policies aim to address global issues such as climate change and marine pollution, which are central to the long-term survival of coral reefs.

% \subsection{Future research and monitoring}

% Looking ahead, ongoing research and monitoring are essential for understanding and mitigating the impacts of environmental changes on coral reefs. Innovative technologies, such as remote sensing using satellite imagery and drones, are increasingly being used to monitor reef health and track changes over time. Genomics is another promising area, offering insights into coral resilience and adaptation to environmental stressors, which could inform future conservation strategies.

% Adaptive management strategies are needed to respond dynamically to changing conditions and emerging threats. This requires collaboration among scientists, policymakers, and local communities to develop and implement effective conservation measures. Public education and awareness are also key components of this effort, as they help foster a broader understanding of the importance of coral reefs and the actions individuals can take to support their preservation.

% Coral reefs are vital ecosystems that require a multifaceted approach to conservation. By integrating historical knowledge, scientific research, and community engagement, we can work towards safeguarding these critical environments for future generations.

% - Historical discovery: evolution of knowledge about coral reefs. \\
% - Types of coral reefs: \\
% ** Islands, barriers, atolls: different forms and structures of coral reefs. \\
% - Atoll theories: historical and scientific theories explaining the formation of atolls. \\
% - Importance in biodiversity: coral reefs as critical ecosystems with high marine biodiversity. \\
% - Threats and protection: current threats to coral reefs and conservation efforts.

% \subsection{Historical discovery of coral reefs}
% - ... 
% \subsubsection{Early observations}
% - Ancient knowledge: initial observations by ancient civilizations (e.g., Greeks, Romans) and their interpretations of coral structures. \\
% - Exploration era: the role of early explorers and naturalists (e.g., Captain James Cook, Alexander von Humboldt) in documenting coral reefs and their biodiversity.
% \subsubsection{Scientific discovery}
% - 19th century advances: key contributions from scientists such as Charles Darwin, who developed theories on coral reef formation. \\
% - 20th century developments: advances in marine biology and oceanography that improved understanding of coral reef ecosystems.

% \subsection{Coral reef structure and formation}
% - ... 
% \subsubsection{Coral anatomy}
% - Coral polyps: basic building blocks of coral reefs, their structure, and function. Each polyp is a tiny, soft-bodied organism that secretes calcium carbonate to form the reef structure. \\
% - Coral colonies: how individual polyps form colonies and contribute to the growth of the reef structure. 
% \subsubsection{Types of coral reefs}
% - Fringing reefs: \\
% ** Definition: reefs that are directly attached to a coastline, extending out from the shore. \\
% ** Characteristics: shallow waters, often with a narrow reef crest and slope. \\
% - Barrier reefs: \\
% ** Definition: reefs that run parallel to the coastline but are separated by a lagoon or deep channel. \\
% ** Characteristics: typically found farther from the shore, with a more pronounced lagoon and deeper water. \\
% - Atolls: \\
% ** Definition: circular or oval reefs that encircle a lagoon, often formed around a submerged volcanic island. \\
% ** Characteristics: reefs form a ring around a central lagoon, with no land in the center. 
% \subsubsection{Reef building processes}
% - Calcium carbonate deposition: the process by which corals and other organisms secrete calcium carbonate to build the reef structure. \\
% - Bioerosion: the natural process by which reef structures are eroded by marine organisms such as parrotfish and sea urchins.

% \subsection{Importance in biodiversity}
% - ... 
% \subsubsection{Species diversity}
% - Marine life: coral reefs are among the most diverse ecosystems in the world, supporting thousands of marine species including fish, invertebrates, and algae. \\
% - Endemism: many species are found exclusively in coral reef environments, contributing to global biodiversity.
% \subsubsection{Ecosystem services}
% - Habitat provision: coral reefs provide essential habitats for a wide range of marine species, including commercially important fish and invertebrates. \\
% - Nutrient cycling: reefs play a critical role in nutrient cycling, supporting the productivity of marine ecosystems. 
% \subsubsection{Economic and cultural value}
% - Fishing and tourism: coral reefs support important fisheries and generate significant revenue through tourism and recreational activities. \\
% - Cultural significance: many coastal communities have cultural and spiritual connections to coral reefs, incorporating them into traditions and practices.

% \subsection{Threats to coral reefs}
% - ... 
% \subsubsection{Climate change}
% - Coral bleaching: caused by elevated sea temperatures, leading to the expulsion of symbiotic algae (zooxanthellae) and subsequent coral bleaching. \\
% - Ocean acidification: reduced calcification rates due to increased \ch{CO2} levels, impacting coral growth and reef structure.
% \subsubsection{Pollution}
% - Nutrient runoff: increased nutrient levels from agricultural and urban runoff can lead to algal blooms that smother corals and disrupt reef balance. \\
% - Marine debris: pollution from plastics and other debris that can damage coral reefs and harm marine life.
% \subsubsection{Overfishing}
% - Depletion of fish stocks: overfishing can lead to the loss of key reef species and disrupt ecological balance. \\
% - Destructive fishing practices: practices such as blast fishing and cyanide fishing cause direct physical damage to reefs and harm marine biodiversity. 
% \subsubsection{Coastal development}
% - Habitat destruction: development activities such as dredging, land reclamation, and construction can destroy or degrade coral reef habitats. \\
% - Sedimentation: increased sedimentation from coastal construction and deforestation can smother corals and reduce light availability.

% \subsection{Conservation efforts}
% - ... 
% \subsubsection{Marine Protected Areas (MPAs)}
% - Designated zones: areas where human activities are regulated or restricted to protect coral reefs and promote recovery. \\
% - Success stories: examples of successful MPA implementations and their positive impacts on reef health and biodiversity.
% \subsubsection{Restoration projects}
% - Coral gardening: techniques for growing and replanting corals to restore damaged reef areas. \\
% - Artificial reefs: creation of artificial structures to provide new habitats for marine life and promote reef recovery.
% \subsubsection{Community involvement}
% - Local engagement: involving local communities in reef conservation through education, stewardship, and sustainable practices. \\
% - Citizen science: encouraging public participation in monitoring and research efforts to support reef conservation. 
% \subsubsection{Policy and legislation}
% - International agreements: global and regional agreements aimed at protecting coral reefs and addressing climate change impacts (e.g., the Convention on Biological Diversity). \\
% - National policies: policies and regulations at the national level to safeguard coral reefs and manage marine resources sustainably. 

% \subsection{Future research and monitoring}
% - ... 
% \subsubsection{Innovative technologies}
% - Remote sensing: use of satellite imagery and drones to monitor reef health and track changes over time. \\
% - Genomics: applying genetic research to understand coral resilience and adaptation to environmental stressors. 
% \subsubsection{Adaptive management}
% - Dynamic strategies: developing flexible management approaches that can adapt to changing conditions and emerging threats. \\
% - Collaboration: promoting collaboration among scientists, policymakers, and local communities to address complex challenges facing coral reefs.
% \subsubsection{Education and awareness}
% - Public outreach: raising awareness about the importance of coral reefs and the actions individuals can take to support conservation efforts. \\
% - Training programs: providing training for scientists, managers, and local stakeholders to enhance reef management and restoration practices.



\section{Prototype creation}
\label{sec:introduction_prototype}
- C++23 and Qt5.12 \\
- OpenGL 4.6 and GLSL \\
- Marching Cubes on geometry shader \\
** Bad idea, but justify why \\
- Renderings: \\
** With the prototype: \\
*** Marching Cubes on geometry shader \\
*** Triplanar texture \\
*** Real-time results \\
*** Textures based on materials \\
** With Unreal Engine 5: \\
*** Static meshes \\
*** Added procedural vegetation with plugin [PLUGIN NAME] and ocean with [PLUGIN NAME] \\
** With Blender 4.1: \\
*** Static meshes \\
*** Easier script usage \\
- ...